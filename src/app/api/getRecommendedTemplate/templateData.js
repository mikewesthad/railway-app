export const templateData = [
  {
    __typename: "Template",
    id: "99f4edbe-ae49-439e-bd70-4bff9c89936f",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "DANUWA-MD | Your Personal WhatsApp Assistant ‚ù§Ô∏è",
    readme:
      "ü§ñ Danuwa-MD is a powerful, multipurpose WhatsApp bot built using the Baileys library. It features a modular plugin system that allows you to easily add or remove functionality such as media tools, Google Drive downloading üìÅ, AI features ü§ñ, group management üîß, logo generators üé®, and more.\n\nüöÄ With this Railway deployment template, you can launch your own instance of the bot in just a few clicks. No coding required!\n\n\nüîß Features:\n\nüß© Plugin-based command system\n\nüì§ Google Drive downloader (bypasses preview restrictions)\n\nüß† AI tools and media utilities\n\nüßë‚Äçü§ù‚Äçüßë Group moderation and broadcast features\n\nüñºÔ∏è Logo and image generators\n\nüîê Private & Public mode toggle\n\nüîÅ Auto-restart and logging support\n",
    name: "DANUWA-MD",
    category: "Automation",
    health: null,
    code: "T8aDDx",
    languages: ["JavaScript", "Nix"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ffb345b2-7c50-44f8-aaa5-689b916e18df",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "hvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv",
    readme:
      "hvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvhvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvhvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvhvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvhvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvhvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvhvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvhvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvhvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvhvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv",
    name: "ravishing-adaptation",
    category: "Other",
    health: null,
    code: "9yod5T",
    languages: ["JavaScript", "Nix"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d6f0a346-e503-46c2-813a-7db58041c1a8",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "A lightweight service for wrapping and unwrapping data encryption keys.",
    readme:
      'Introduction\n\nPraetorian is a zero dependency, lightweight service which wraps and unwraps data encryption keys over HTTP using a rotating root key. It is intentionally narrow in scope and uses the 256-bit Advanced Encryption Standard (AES) in Galois Counter Mode (GCM). Its purpose is to provide a simplified method for developers looking to implement Envelope encryption], a technique used to [encrypting sensitive data at rest].\n\nEnvelope encryption is a technique where data is encrypted with a Data Encryption Key (DEK), the DEK is encrypted using a Key Encryption Key (KEK). The term "envelope" refers to the process of wrapping one layer of encryption around another, akin to sealing a letter with multiple layers of envelopes for added security.\n\nData Encryption Key (DEK): A unique key is generated for each set of data to be encrypted. This key is used to encrypt and decrypt the data and should be symetric.\nKey Encryption Key (KEK): A higher-level key used to encrypt and protect the DEK. The KEK is an asymetric key stored securely in the Praetorian environment configuration.\n\nPraetorian provides the Key Encryption Key which can be rotated and exposes HTTP endpoints so Data Encryption Keys can be wrapped and unwrapped, without leaking any Key Encryption Key material.\n\n[envelope encryption]: https://cloud.google.com/kms/docs/envelope-encryption\n[encrypting sensitive data at rest]: https://cloud.google.com/docs/security/encryption/default-encryption\n\n&gt; Throughout the remainder of this documentation, the term Key Encryption Key can be used interchangeably with Root Key.\n\nWhy use Praetorian?\n\nPraetorian is intended to be very easy to setup and great for startups looking to get moving quickly. If you\'re storing sensitive information in a database and want a simplified approach to using envelope encryption, you should use Praetorian.\n\nDeployment\n\nBefore you start, you\'ll need to create a valid Praetorian configuration. Run the following command from your local terminal to generate a JSON configuration which contains a single root key which will be set as the active root key.\n\necho $(printf \'{"activeKeyId": "1", "rootKeys": {"1": "%s"}}\' "$(openssl rand -base64 32)")\n\nHit the deployment button below and paste the JSON output from the previous command into the PRAETORIAN_CONFIG environment variable. Once the service has been built and deployed, Praetorian will be running and only available from the private interface.\n\n&gt; Do not expose your Praetorian service to the public internet!\n\n[Deploy on Railway\n\nWhen you deploy applications that interact with Praetorian, you will need to use http://praetorian as the base URL.\n\nUsage\n\nBefore integrating Praetorian into your application, it\'s best to start with a locally running instance so you can explore and familiarise yourself with the envelope encryption flow.\n\nAssuming you have Docker installed, start by running the following command to get a Praetorian container running and listening for requests on port 3000.\n\ndocker run --rm \\\n  --name=praetorian \\\n  --publish=3000:3000 \\\n  --env=PRAETORIAN_CONFIG="$(printf \'{"activeKeyId": "1", "rootKeys": {"1": "%s"}}\' "$(openssl rand -base64 32)")" \\\n  karlbateman/praetorian\n\nNow we have our Praetorian service running locally, we can issue a request to wrap a data encryption key using the following curl request.\n\ncurl --silent \\\n  --request POST \\\n  --data \'{"key": "abc123"}\' \\\n  http://localhost:3000/wrap\n\nTo unwrap this data, simply copy the response from the terminal and send it to the /unwrap endpoint.\n\ncurl --silent \\\n  --request POST \\\n  --data \'\' \\\n  http://localhost:3000/unwrap\n\nThis demonstrates the flow of wrapping and unwrapping data encryption keys. \n\nIntegrating\n\nWith Praetorian running in your Railway environment and accessible through a private networking address, the workflow is simple. Within your backend application, you would perform the following operations:\n\nGenerate a cryptographically secure data encryption key.\nUse this key to encrypt the sensitive information.\nSend a POST request to http://praetorian/wrap with the data encryption key as a JSON request body.\nStore the response body and the encrypted sensitive information in your DB.\n\n&gt; Every write/update operation to your database should perform this flow to\n&gt; ensure maximum security and integrity of your data. Every data encryption key\n&gt; should be unique at the row/doc level.\n\nWhen you want to read the data, you must perform the following steps within your backend application.\n\nRead the encrypted data and the wrapped data encryption key.\nSend a POST request to http://praetorian/unwrap with the wrapped data encryption key as a JSON request body.\nUse the unwrapped data encryption key from the response to decrypt the sensitive information.\n\n&gt; Never store an unwrapped data encryption key.\n',
    name: "praetorian",
    category: "Other",
    health: null,
    code: "pr7YF_",
    languages: ["Go", "Makefile", "Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "cc12d97a-cd0a-4943-b4a2-ae71d9072b05",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "Milvus Standalone: Cloud-native vector DB for scalable, fast ANN search.",
    readme:
      '\nWhat is Milvus?\n\nüê¶ Milvus is a high-performance vector database built for scale. It powers AI applications by efficiently organizing and searching vast amounts of unstructured data, such as text, images, and multi-modal information.\n\nüßë‚Äçüíª Written in Go and C++, Milvus uses CPU/GPU hardware acceleration for top vector search performance. Its fully-distributed and K8s-native architecture allows horizontal scaling, handling 10k+ queries on billion+ vectors with real-time streaming updates. Also supports Standalone mode for single machines and Milvus Lite (pip install for Python quickstarts).\n\nWant to use Milvus with zero setup? Try out Zilliz Cloud ‚òÅÔ∏è for free. Milvus is available as a fully managed service on Zilliz Cloud, with Serverless, Dedicated and BYOC options available.\n\nFor questions about how to use Milvus, join the community on Discord to get help. For reporting problems, file bugs and feature requests in GitHub Issues or ask in Discussions.\n\nThe Milvus open-source project is\nunder LF AI &amp; Data Foundation, distributed with Apache 2.0 License, with Zilliz as its major contributor.\n\nQuickstart\n\n$ pip install -U pymilvus\nThis installs pymilvus, the Python SDK for Milvus. Use MilvusClient to create a client:\nfrom pymilvus import MilvusClient\n\npymilvus also includes Milvus Lite for quickstart. To create a local vector database, simply instantiate a client with a local file name for persisting data:\n\n  client = MilvusClient("milvus_demo.db")\n\nYou can also specify the credentials to connect to your deployed Milvus server or Zilliz Cloud:\n\n  client = MilvusClient(\n    uri="",\n    token="")\n\nWith the client, you can create collection:\nclient.create_collection(\n    collection_name="demo_collection",\n    dimension=768,  # The vectors we will use in this demo have 768 dimensions\n)\n\nIngest data:\nres = client.insert(collection_name="demo_collection", data=data)\n\nPerform vector search:\n\nquery_vectors = embedding_fn.encode_queries("Who is Alan Turing?", "What is AI?"])\nres = client.search(\n    collection_name="demo_collection",  # target collection\n    data=query_vectors,  # a list of one or more query vectors, supports batch\n    limit=2,  # how many results to return (topK)\n    output_fields=["vector", "text", "subject"],  # what fields to return\n)\n\nWhy Milvus\n\nMilvus excels at scalable vector search, storing vectors alongside scalar data for efficient filtered or hybrid searches. Developers choose Milvus for:\n\nHigh Performance at Scale and High Availability\nMilvus\'s [distributed architecture separates compute and storage for horizontal scaling and adapting to diverse traffic. Stateless microservices on K8s enable quick recovery, ensuring high availability. Replicas further boost fault tolerance and throughput. See benchmark.\n\nSupport for Various Vector Index Types and Hardware Acceleration\nMilvus supports major vector indexes (HNSW, IVF, FLAT, SCANN, DiskANN) with quantization-based options and mmap. It optimizes vector search with features like metadata filtering and range search. Milvus also implements hardware acceleration, supporting GPU indexing like NVIDIA\'s CAGRA.\n\nFlexible Multi-tenancy and Hot/Cold Storage\nMilvus offers multi-tenancy (database, collection, partition, or key level) for optimized performance and access control. It uses hot/cold storage for cost-effectiveness, keeping frequently accessed data on faster storage and less-accessed data on cost-effective storage.\n\nSparse Vector for Full Text Search and Hybrid Search\nBeyond dense vectors for semantic search, Milvus natively supports full text search (BM25, SPLADE, BGE-M3) using sparse vectors. Users can combine sparse and dense vectors in one collection and rerank results. See examples of Hybrid Search with semantic search + full text search.\n\nData Security and Fine-grain Access Control\nMilvus ensures security with user authentication, TLS encryption, and Role-Based Access Control (RBAC) for fine-grained permissions, protecting sensitive enterprise data.\n\nMilvus is trusted for AI applications like text/image search, RAG, and recommendation systems, powering many mission-critical business for various companies.\n\nEcosystem and Integration\n\nMilvus integrates with AI development tools like LangChain, LlamaIndex, OpenAI, and HuggingFace, making it ideal for GenAI apps such as RAG. It supports open-source and service-based embedding models for text, image, and video. Milvus offers pymilvus[model]) for transforming data into embeddings and using reranking models. The ecosystem includes Attu (GUI admin), Birdwatcher (debugging), Prometheus/Grafana (monitoring), Milvus CDC (data sync), VTS (data migration), and connectors for Spark, Kafka, Fivetran, and Airbyte to build search pipelines.\n\nCheck out https://milvus.io/docs/integrations_overview.md for more details.\n\nDocumentation\n\nFor guidance on installation, usage, deployment, and administration, check out Milvus Docs. For technical milestones and enhancement proposals, check out issues on GitHub.\n\nCommunity\n\nJoin the Milvus community on Discord to share your suggestions, advice, and questions with our engineering team.\n\nTo learn latest news about Milvus, follow us on social media:\n\nX\nLinkedIn\nYoutube\nMedium\n\nYou can also check out our FAQ page to discover solutions or answers to your issues or questions, and subscribe to Milvus mailing lists:\n\nTechnical Steering Committee\nTechnical Discussions\nAnnouncement\n\n',
    name: "Milvus",
    category: "AI/ML",
    health: null,
    code: "c7nLmV",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a5f6c599-598d-45e2-a44d-6bba882d24a9",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "set up to use googles adk",
    readme:
      "üöÄ Google ADK Starter Kit on Railway\nLaunch your AI agent project fast with this plug-and-play starter for Google‚Äôs Agent Development Kit (ADK). Built on FastAPI and integrated with LiteLLM, this template gives you a clean, production-ready backend to start experimenting with ADK agents. No MCP or frontend included‚Äîjust the essentials to get your backend running in seconds.",
    name: "adk-starter",
    category: "AI/ML",
    health: null,
    code: "eVpydG",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4029b0e9-c811-453e-8469-a96cd71388e3",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "Elysia user management API with real-time WebSockets and Swagger UI",
    readme:
      "Complete RESTful API built with Elysia and Bun featuring user CRUD operations, real-time WebSocket notifications, and interactive Swagger documentation. Includes Docker support, proper HTTP status codes, and demo users. Ready for production deployment with minimal configuration.",
    name: "Elysia-bun-server",
    category: "Other",
    health: null,
    code: "-6vLXh",
    languages: ["TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "91054585-b36e-4bd1-9832-adad7bbede2d",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "Open source feature flag service for gradual rollouts and testing.",
    readme:
      "\n  \n    \n    \n    \n  \n  Open Source Feature Flag Management\n  Website |\n  Documentation |\n  Discord\n\n\nFlipt is an open source feature flag management platform that allows development teams to enable or disable functionality in their applications without needing to perform full deployments.  \nThis enables practices such as:\n\nTrunk-based development\nA/B testing\nProgressive rollouts\n\nThese features help increase agility and safety across the software development lifecycle.\n\nüåü Key Features\n\n‚úÖ Open Source &amp; Self-Hosted\nYou can deploy Flipt on your own infrastructure, giving you full control over your data, configurations, and privacy.\n\nüîÅ GitOps Integration\nFlipt supports Git-based configuration management, making it easy to version and track changes to your feature flags via repositories.\n\nüß∞ Multi-language SDK Support\nFlipt provides SDKs for:\n\nNode.js\nGo\nPython\nJava\nRust\nPHP\n\nThis allows seamless integration across various tech stacks.\n\n‚ö° Client-side Evaluation\nFlipt supports client-side feature evaluation to reduce latency and improve performance in end-user applications.\n\nüíª Intuitive Web UI\nA modern and minimalistic web interface helps you define, toggle, and monitor flags and experiments with ease.\n\n‚òÅÔ∏è Flipt Cloud\nIf you prefer not to self-host, Flipt also offers a managed cloud version that maintains all control and security advantages, without infrastructure overhead.\n\nüöÄ Common Use Cases\n\nTrunk-based development  \n  Integrate features into the main codebase while controlling their activation via flags.\n\nA/B testing and experimentation  \n  Run controlled experiments to assess how new features impact user behavior.\n\nProgressive rollouts  \n  Gradually expose new features to users to minimize risk and catch issues early.\n\nAccess and permissions management  \n  Control which users or groups can access certain functionality without changing the app code.\n\n",
    name: "Flipt",
    category: "CMS",
    health: null,
    code: "TSv4bp",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "47c9944e-d21d-47e0-9d80-4f919c6363c9",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "Provides a basic Caddy reverse proxy setup for your Railway project.",
    readme:
      "Template Overview  \nFeatures:  \n‚úÖ Reverse Proxy ‚Äì Routes traffic to your backend service (e.g., Node.js, Python, Go).  \n‚úÖ Automatic HTTPS ‚Äì Caddy handles SSL certificates automatically.  \n‚úÖ Minimal Config ‚Äì Easy-to-understand Caddyfile for quick deployment.  \n‚úÖ Port Flexibility ‚Äì Proxies requests from :80 (HTTP) and :443 (HTTPS) to your app's internal port.  \n\nUsage:  \nDeploy to Railway.  \nReplace your-app.up.railway.app with your Railway domain.  \nAdjust ${PORT} if your app uses a different internal port.  \n\nIdeal for single-container setups where you need a simple, secure reverse proxy without manual certificate management.",
    name: "caddy-reverse-proxy",
    category: "Other",
    health: null,
    code: "SmE0Jg",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "64c911ca-d715-4bb7-9f3b-068b17693396",
    isApproved: false,
    activeProjects: 1,
    projects: 4,
    description: "Build modern Telegram bots quickly with TypeScript and Telegraf",
    readme:
      "This is a deploy-ready Telegram Bot Starter Kit built with TypeScript and Telegraf. It includes features like SWC for fast compilation, Redis session storage, structured bot command handlers, and support for webhooks. Ideal for quickly building and deploying modern Telegram bots. The example branch is pre-configured with sample commands and scenes to help you get started faster. Use this template to explore Telegram bot development with clean code, modular structure, and Railway integration.",
    name: "telegram-bot",
    category: "Starters",
    health: 0,
    code: "7cnESs",
    languages: ["TypeScript", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b9c9f6d6-cd78-4dc7-9fc1-5f2a500ccb2c",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "The better auth and identity infrastructure",
    readme:
      "Logto is an open-source alternative to Auth0 and an OIDC (OAuth 2.0) provider designed for modern applications and SaaS products, supporting both authentication and authorization. SAML is also supported.\n\nHomepage: https://logto.io/\nRepository: https://github.com/logto-io/logto",
    name: "Logto: Identity and Access Management (IAM)",
    category: "Authentication",
    health: null,
    code: "K_cg9u",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0cc54041-5634-40a9-a187-119431d76610",
    isApproved: false,
    activeProjects: 5,
    projects: 7,
    description: "Web UI to manage MySQL databases easily and visually.",
    readme:
      "PhpMyAdmin\n\nPhpMyAdmin is a free and widely used web-based interface developed in PHP for managing MySQL and MariaDB databases. It offers an intuitive UI that simplifies many common database tasks such as:\n\nCreating and managing databases and tables\nModifying columns, indexes, and relationships\nManaging users and permissions\nImporting and exporting data\nRunning raw SQL queries directly from the browser\nViewing server status and activity\n\nIt's especially useful in development environments where quick database interaction is needed without using a CLI or desktop client.\n\nYou can configure phpMyAdmin using environment variables when running it via Docker. For detailed setup instructions, refer to the official documentation:  \nüîó phpMyAdmin Docker Environment Variables\n",
    name: "PhpMyAdmin + MySQL",
    category: "Storage",
    health: 100,
    code: "p_f5uS",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1319d73d-b99b-490d-98a2-4f6f575a1b8c",
    isApproved: false,
    activeProjects: 0,
    projects: 3,
    description: "Starter for API Rest or microservice with NestJS and TypeORM with MySQL",
    readme:
      "NestJS is a progressive Node.js framework for creating efficient, reliable and scalable server-side applications, which is built and fully compatible with TypeScript and JavaScript, combining elements of object-oriented programming, functional programming and functional reactive programming.\n\n\n\n",
    name: "NestJS Starter TypeORM with MySQL",
    category: "Other",
    health: null,
    code: "TdPsDz",
    languages: ["TypeScript", "Dockerfile", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "54d52c06-d934-4b7d-86a1-321c865df74f",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "A fast, fun, and small ActivityPub server for the Fediverse",
    readme:
      "With GoToSocial, you can keep in touch with your friends, post, read, and share images and articles. All without being tracked or advertised to!\n\nSource: https://codeberg.org/superseriousbusiness/gotosocial\n\nI created this template to enable easy one click deployment of GoToSocial on Railway. You need to fill-in just two variables. This deployment uses SQLite for database.\n\nVariables\n\nGTS_HOST: Domain you want to run GoToSocial on doc.\n\ne.g. gotosocial.example.com (Please fill-in the actual domain as once deployed, the domain can't be changed).\n\nTZ : Timezone  doc.\n\ne.g. Asia/Kolkata\n\nNote: After you deploy, setup the domain you enter in GTS_HOST in Railway settings under Custom Domain. \n\nIf you have any queries regarding this template in specific then reach out to me through any Mastodon client.",
    name: "GoToSocial (SQLite)",
    category: "Blogs",
    health: null,
    code: "QZn_BX",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "50071684-9be4-465c-919b-33bdbc7aeaf8",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "incident recovery tool to unpack a tar",
    readme:
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam sed mauris metus. Morbi at posuere lectus. Donec interdum nisl justo, vitae cursus leo semper id. In hendrerit, magna ut faucibus maximus, libero nibh rutrum turpis, eget pulvinar mauris nibh nec quam. Sed nec odio et dolor vestibulum tristique. Mauris malesuada fermentum porta. Maecenas sollicitudin lacinia felis, sit amet finibus ligula. Aliquam tempus consequat euismod. Maecenas tempor fringilla bibendum. Praesent in leo enim.\n\nDuis aliquam, neque nec feugiat convallis, lorem justo laoreet urna, non molestie dolor ex non turpis. Vivamus mattis vitae urna non tempus. Pellentesque dignissim nisi neque, nec hendrerit quam facilisis nec. Donec tincidunt tempor nisi, ut ultricies ipsum euismod id. Curabitur id tellus nec ante egestas viverra rutrum eget tortor. Mauris ac lacus nec leo eleifend rutrum. Nullam convallis lorem sollicitudin erat elementum, ac molestie erat congue. Sed mollis nisi vel leo aliquet gravida. Maecenas pretium malesuada turpis. Vestibulum viverra nulla at enim tristique, quis condimentum justo porta. Quisque faucibus finibus orci, ut rhoncus eros pellentesque vitae. Pellentesque turpis eros, efficitur vel urna eu, dictum finibus arcu. Curabitur porta porta consectetur. Nulla volutpat porta massa, in auctor augue condimentum a. Vivamus consequat at lacus ac tempor. Aliquam posuere dapibus maximus.",
    name: "Volume Unpacker",
    category: "Other",
    health: null,
    code: "9g6vMR",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ecfb8212-ff54-4c51-bdfd-2a746ad2fd71",
    isApproved: false,
    activeProjects: 0,
    projects: 3,
    description: "Starter for API Rest or microservice with NestJS and TypeORM with postgres",
    readme:
      "NestJS is a progressive Node.js framework for creating efficient, reliable and scalable server-side applications, which is built and fully compatible with TypeScript and JavaScript, combining elements of object-oriented programming, functional programming and functional reactive programming.\n\n\n\n",
    name: "NestJS Starter TypeORM with Postgres",
    category: "Starters",
    health: null,
    code: "s8F1Sb",
    languages: ["TypeScript", "Dockerfile", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "11b971a7-dd9c-4525-8332-5ba307a3fd3c",
    isApproved: false,
    activeProjects: 8,
    projects: 25,
    description: "Easily deploy Zero on Railway",
    readme:
      'This template provides an easy way to deploy Zero with a multi-node setup allowing horizontal scaling and zero-downtime deployments.\n\nComponents:\nPostgres DB (wal_level automatically set to "logical" which is need for Zero)\nMin.io bucket to store replica files\nSimple API with Drizzle and database migrations\nReact frontend with Zero demo\nZero Replication Manager\nZero View Syncer\nZero Migration Handler',
    name: "Zero",
    category: "Starters",
    health: 100,
    code: "s9CW6Y",
    languages: ["Dockerfile", "TypeScript", "CSS", "JavaScript", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6a3617df-03ba-42a1-ab82-20d94a6bf76e",
    isApproved: false,
    activeProjects: 1,
    projects: 1,
    description: "Banco de dados do Trade unico e exclusivo",
    readme:
      "Banco de dados usado somente para o trade do nosso novo sistema kkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkk",
    name: "zealous-enthusiasm",
    category: "AI/ML",
    health: null,
    code: "1UXt2K",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "60113373-dfb5-4a09-8365-d52c38bfd52c",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "Open Source backend for your next SaaS and Mobile app in 1 file",
    readme:
      "Pocketbase\nOpen Source backend for your next SaaS and Mobile app in 1 file.\n\nRealtime Database\nEmbedded performant database with schema builder, data validations, realtime subscriptions and easy to use REST api.\n\nAuthentication\nManage your app users and handle email/password and OAuth2 sign ups (Google, Facebook, GitHub, GitLab) without the hassle.\n\nFile Storage\nSanely store files locally or in a S3 storage. Easily attach media to your database records and generate thumbs on the fly.\n\nExtendable\nUse as a standalone app or as Go framework, that you can extend via hooks to create your own custom portable backend. Provides official client SDKs for painless integration.",
    name: "Pocketbase",
    category: "Other",
    health: null,
    code: "RFihYU",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6218cf4a-de35-4be7-9f39-ca9450733a8f",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "n8n-Optimized Redis Database",
    readme:
      "n8n-Optimized Redis Database\n\nWhat You Get\nThis template provides a Redis in-memory database service optimized for use within n8n workflows as a data storage, caching, and message broker solution.\n\nComponents:\nRedis: High-performance in-memory database with n8n node integration\n\nKey Features\n‚úÖ n8n Node Integration: Ready for Redis node operations in your workflows\n‚úÖ Data Persistence: Store workflow data between executions\n‚úÖ Caching Layer: Improve performance by caching API responses\n‚úÖ Pub/Sub Messaging: Build event-driven workflows with message subscriptions\n‚úÖ Atomic Operations: Reliable counters and distributed locks for workflows\n‚úÖ Fast Storage: Sub-millisecond data access for time-sensitive operations\n‚úÖ IPv6 Ready: Full IPv6 support for Railway's network infrastructure\n\nUsage In n8n Workflows\nAdd Redis Node: Use the Redis node in your n8n workflows\nConfigure Connection: Enter the connection details shown below\nChoose Operations: Use SET, GET, HSET, PUBLISH, SUBSCRIBE, and other Redis commands\n\nRedis Node Configuration\nWhen adding a Redis node in your n8n workflow, use these credentials:\nHost: ${{redis.REDIS_HOST}}\nPort: ${{redis.REDIS_PORT}} (typically 6379)\nUsername: ${{redis.REDIS_USERNAME}} (typically \"default\")\nPassword: ${{redis.REDIS_PASSWORD}}\nDatabase: 0\nUse TLS/SSL: No (unless specifically configured)\n\nCommon Workflow Use Cases\nAPI Rate Limiting: Store API call counts and timestamps\nCross-Workflow Data Sharing: Share data between different workflows\nCaching: Store expensive API responses for reuse\nJob Queues: Create custom queuing systems with RPUSH/LPOP\nCounters: Track metrics with atomic increment operations\nSession Storage: Maintain web session state across workflow runs\nFeature Flags: Store flags to control workflow behavior\n\nTechnical Specifications\nRedis 7.x with optimized configuration\nPersistent storage for reliable data retention\nMemory policies tuned for workflow data patterns\nHigh availability for mission-critical workflows\nMaximum compatibility with n8n Redis nodes\n\nSupport me if you think this is good, one dollar is also very valuable to me, I'm really broke man. https://linktr.ee/givemesomehope",
    name: "Redis : 1$",
    category: "Queues",
    health: null,
    code: "JkJ8MG",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "68ce106d-e06b-47c3-b7a2-b3a2016cbd42",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "High-Performance Valkey In-Memory Database",
    readme:
      "High-Performance Valkey In-Memory Database\n\nWhat You Get\nThis template provides a standalone, fully optimized Valkey in-memory database service, offering Redis-compatible caching and data storage with enhanced performance and enterprise-grade reliability.\n\nComponents:\nValkey: High-performance Redis-compatible in-memory database with advanced optimizations\n\nKey Features\n‚úÖ Redis Compatible: Works with all Redis clients and libraries\n‚úÖ Enhanced Performance: Optimized memory management and faster operations\n‚úÖ Production Ready: Pre-configured with best practices for reliability\n‚úÖ IPv6 Optimized: Full IPv6 support for Railway's networking infrastructure\n‚úÖ Secure by Default: Authentication enabled and configurable\n‚úÖ Low Memory Footprint: Efficient memory utilization for cost savings\n\nUsage Instructions\nDeploy Template: One-click deployment sets up Valkey with optimized settings\nConnect Applications: Use the provided connection variables in your apps\nScale as Needed: Easily adjust memory allocation based on your requirements\n\nEnvironment Variables\nConnection string: redis://${{valkey.REDIS_USERNAME}}:${{valkey.REDIS_PASSWORD}}@${{valkey.REDIS_HOST}}:${{valkey.REDIS_PORT}}/0\nDefault credentials: Username=default, Password=valkey123 (change as needed)\nIPv6 support: Enabled by default for Railway compatibility\n\nTechnical Specifications\nLatest Valkey version with memory-optimized configuration\nPersistent storage with AOF and RDB for data reliability\nAutomatic memory management with volatile-LRU eviction policy\nMulti-threaded I/O for enhanced read performance\nAutomatic defragmentation for better memory utilization\nMinimal logging with focus on critical information\nConfigured for 10,000+ simultaneous connections\n\nSupport me if you think this is good, one dollar is also very valuable to me, I'm really broke man. https://linktr.ee/givemesomehope",
    name: "Valkey : 1$",
    category: "Queues",
    health: null,
    code: "M_Q6uM",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0f869224-5be1-408e-82da-2de0bc564324",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "Enterprise-Grade Redpanda Streaming Platform",
    readme:
      "Enterprise-Grade Redpanda Streaming Platform\n\nWhat You Get\nThis template provides a fully configured Redpanda streaming platform for real-time event processing, offering Kafka-compatible event streaming with superior performance and simplified operations.\n\nComponents:\nRedpanda: High-performance, Kafka-compatible streaming data platform\nRedpanda Console: Modern web UI for managing and monitoring your streaming infrastructure\n\nKey Features\n‚úÖ Kafka Compatible: Works with existing Kafka clients and ecosystems\n‚úÖ 10x Better Performance: Significantly faster than Apache Kafka with lower resource usage\n‚úÖ Zero JVM: No Java dependencies, eliminating JVM tuning complexity\n‚úÖ IPv6 Ready: Full IPv6 support for Railway's networking infrastructure\n‚úÖ Self-Optimizing: Intelligent defaults that adapt to your workload\n‚úÖ Production Hardened: Secure by default with encryption capabilities\n\nUsage In n8n Workflows\nAdd Kafka Node: Use the Kafka node in your n8n workflows (compatible with Redpanda)\nConfigure Connection: Enter the connection details shown below\nCreate Topics: Define topics through Redpanda Console for your event streams\nProduce/Consume: Connect your workflows to publish and subscribe to events\n\nKafka Node Configuration\nWhen adding a Kafka node in your n8n workflow, use these credentials:\nBrokers: ${{redpanda.REDPANDA_BROKER}} (typically like redpanda-workflow.railway.internal:29092)\nClient ID: redpanda (or your custom identifier)\nSSL: Disabled (unless specifically configured)\nAuthentication: None (unless security features are enabled)\n\nCommon Workflow Use Cases\nEvent-Driven Automation: Trigger workflows based on real-time events\nData Pipelines: Process and transform data streams\nSystem Integration: Connect disparate systems with reliable messaging\nAnalytics Processing: Collect and process events for analytics\nWebhook Aggregation: Consolidate multiple webhook sources\nLog Processing: Stream and process application logs\nIoT Data Handling: Process device telemetry in real-time\n\nTechnical Specifications\nLatest Redpanda version with optimized configuration\nMulti-partition topics for horizontal scalability\nHigh-throughput messaging (100K+ messages/second)\nPersistent storage for reliable message retention\nLow-latency performance (&lt;10ms)\nCompatible with all Kafka client libraries\nSimplified operational model without Zookeeper\n\nAdvanced Features\nTopic auto-creation\nRAFT-based consensus protocol\nTopic compaction for state management\nTiered storage support\nShadow indexing for faster topic scanning\n\nSupport me if you think this is good, one dollar is also very valuable to me, I'm really broke man. https://linktr.ee/givemesomehope",
    name: "Redpanda+Console : 1$",
    category: "Queues",
    health: null,
    code: "ZsquT8",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a46e57cc-b2f6-42d3-b696-e19ab1a78db3",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "Optimized PostgreSQL Database Stack",
    readme:
      'Optimized PostgreSQL Database Stack\n\nWhat You Get\nThis template provides a complete PostgreSQL database stack optimized for high performance and production-ready, with the best configuration for modern applications like n8n.\n\nComponents:\nPostgreSQL 17: Main database with high-performance configuration\nPgBouncer: Connection pooler to reduce connection overhead and increase throughput\npgAdmin: Intuitive web interface for database management\n\nKey Features\n‚úÖ Production Ready: Pre-configured with best practices for production deployment\n‚úÖ Zero Config: Runs automatically with synchronization between components\n‚úÖ IPv6 Ready: Full IPv6 communication support for Railway compatibility\n‚úÖ Performance Optimized: Parameters specially tuned for maximum throughput\n‚úÖ Secure: SSL/TLS enabled by default for encrypted connections\n‚úÖ Resource Efficient: Optimized scaling and caching settings\n\nUsage Instructions\nDeploy Template: Simply click "Deploy" and Railway will set up all components\nAccess pgAdmin: Open the public URL to access the pgAdmin interface\nApplication Connection: Use Railway variables to connect to PostgreSQL through PgBouncer\n\nEnvironment Variables\nDatabase accessed via: ${{pgbouncer.PGBOUNCER_HOST}}:${{pgbouncer.PGBOUNCER_LISTEN_PORT}}\nDefault credentials: User=n8n, Password=postgres123 (change as needed)\n\nTechnical Specifications\nPostgreSQL 17 with persistent storage\nPgBouncer with "transaction" pool mode and connection optimization\npgAdmin 4 for database administration through web UI\nPre-generated SSL/TLS certificates for encrypted connections\n\nSupport me if you think this is good, one dollar is also very valuable to me, I\'m really broke man. https://linktr.ee/givemesomehope',
    name: "PgBouncer+Postgres+PgAdmin : 1$",
    category: "Storage",
    health: null,
    code: "pfd9YM",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5b3f246e-d1f4-4155-a5f2-6fac834a55d6",
    isApproved: false,
    activeProjects: 1,
    projects: 3,
    description: "Self-hosted pastebin powered by Git, open-source alternative to Github Gist",
    readme:
      "Opengist is a self-hosted pastebin powered by Git, as an open-source alternative to Github Gist.\n\nDocs: https://opengist.io/docs/\nFull variable reference: https://opengist.io/docs/configuration/cheat-sheet.html\n\nFor OAuth providers other than Gitea/Forgejo, see the full reference here: https://opengist.io/docs/configuration/oauth-providers.html\n\nSSH Git operations are unlikely to work and show the correct port externally due to the Railway TCP proxy using a different port to the application's port with seemingly no workaround to that, so are disabled by default. Contact me if you know a workaround. You can re-enable them and use them within a private network if you wish.",
    name: "Opengist",
    category: "Other",
    health: null,
    code: "zWSDEh",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "29ca82ec-e789-4135-8b48-9c783c534378",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "sveltekit with hono as api, builtin openapi doc generation",
    readme:
      "This template is using bun as runtime\n\nNavigate to {domain}/api/docs for the scalar openapi docs\n\nNo variables are needed for this template \n\nTo add database orm, run bunx sv add drizzle to automatically add drizzle orm using svelte's cli\n\nLook for lib/api-client.ts for the hono rpc file, checkout https://hono.dev/docs/guides/rpc#using-rpc-with-larger-applications to learn more about how to properly use hono rpc to make sure its typed properly",
    name: "sveltekit-hono-template",
    category: "Starters",
    health: null,
    code: "O7COhP",
    languages: ["TypeScript", "HTML", "Dockerfile", "Svelte", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "173b57da-5b78-4680-b976-5203ae5ca276",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "A self-hosted IP Geo API and Python package that works completely offline!",
    readme:
      '\n  \n\nGeoIP API\n\n\nFastAPI\nDocker\n\n\n‚ú® A self-hosted REST API for IP geolocation that works completely offline! üöÄ\n\n\n  Deploy your own private GeoIP service with complete control over your data and infrastructure -\n  \n  Powered by MaxMind\'s GeoLite2 databases „ÉÑ\n\n\nüöÄ Live Demo: https://geoip-api.malith.dev/\n\n‚ú® Features\n\nüåç Fast and reliable IP geolocation lookups via a REST API\nüîí Self-hosted solution with no external API dependencies\nüê≥ Easy deployment with Docker and cloud platforms\nüìä Get country, city, coordinates, timezone, ISP, and ASN data\nüé® Beautiful, interactive demo UI for testing available at the root endpoint\nüöÄ Built with FastAPI for high performance\nüì¶ Automatic GeoLite2 database downloads and updates\n\nüõ†Ô∏è Usage\n\nThe GeoIP API provides simple endpoints to perform IP lookups.\n\nREST API Endpoints\n\nSimple path parameter\n\nhttps://your-domain.com/8.8.8.8\n\nQuery parameter\n\nhttps://your-domain.com/?ip=8.8.8.8\n\nStandard API Endpoint\n\nhttps://your-domain.com/api/v1/geoip/lookup/8.8.8.8`\n\nResponse Format\n\n{\n  "ip": "8.8.8.8",\n  "code": "US",\n  "country": "United States",\n  "city": "Mountain View",\n  "lat": 37.4056,\n  "lon": -122.0775,\n  "tz": "America/Los_Angeles",\n  "isp": "Google LLC",\n  "asn": 15169\n}`\n\nüì¶ Deployment Options\n\nüöÄ Cloud Deployment\n\nOne-click deployment to popular platforms, ideal for quickly getting your own instance running:\n\nüåê Use Cases\n\n  Security &amp; Compliance: Enhance security systems with IP-based threat detection while maintaining data sovereignty\n  Content Localization: Deliver region-specific content based on visitor location without sharing user data\n  Analytics: Analyze traffic patterns and user demographics with geographic data that remains within your infrastructure\n  Fraud Prevention: Identify suspicious login attempts based on geographic anomalies\n  Development Environment: Use a local GeoIP service in your development environment without external API dependencies\n\nüìú License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n‚ö†Ô∏è Database License Notice\n\nThis project uses GeoLite2 data created by MaxMind, available from https://www.maxmind.com. The GeoLite2 databases are licensed under the Creative Commons Attribution-ShareAlike 4.0 International License.\n\nüîß Acknowledgements\n\n  GeoLite2 databases provided by MaxMind\n  Mirror of GeoLite2 databases maintained by P3TERX\n  Built with FastAPI and Python\n  Powered by geoip2 library\n\nü§ù Contributing\n\nContributions are welcome\\! Please feel free to submit a Pull Request.\n\nFork the repository\nCreate your feature branch (git checkout -b feature/amazing-feature)\nCommit your changes (git commit -m \'Add some amazing feature\')\nPush to the branch (git push origin feature/amazing-feature)\nOpen a Pull Request\n\nüåü Support and Community\n\nIf you found this project helpful, please give it a ‚≠ê on GitHub. This helps more developers discover the project\\! ü´∂\n\nüì¨ Contact\n\nIf you have any questions, feedback, or just want to say hi, you can reach out to me:\n\n  Email: hello@malith.dev\n  GitHub: @Malith-Rukshan\n\nüßë‚Äçüíª Built with üíñ by Malith Rukshan',
    name: "geoip-api",
    category: "Other",
    health: null,
    code: "6zn6HZ",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "539fcabf-7e85-435c-8614-bc6367c192b3",
    isApproved: false,
    activeProjects: 3,
    projects: 3,
    description: "movie api that serve to find movies",
    readme:
      "yeah you just have to use a fetch and then convert it to a json string and it will show you a lot of movies in a json format, so you will can use them for petitions like delete, put, post. get etc, i made this now in the afternoon and i hope it to be usefull for the people in the world, so remember me, i made this",
    name: "empathetic-inspiration",
    category: "Other",
    health: 100,
    code: "G5NJ62",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "75490815-96ca-4e4a-9062-061a8390375e",
    isApproved: false,
    activeProjects: 1,
    projects: 1,
    description: "1111rthrhtrytrreswwyukuyyjt",
    readme:
      "dgfhghhhhhhhhhhhhdfddgfdrewredffhgfhhggfhfyhttgrgrdgfhffhghgyrgdfetjghjyiuykujhghgfgfdfdsfdgffhfhggjgAdgfhghhhhhhhhhhhhdfddgfdrewredffhgfhhggfhfyhttgrgrdgfhffhghgyrgdfetjghjyiuykujhghgfgfdfdsfdgffhfhggjgAdgfhghhhhhhhhhhhhdfddgfdrewredffhgfhhggfhfyhttgrgrdgfhffhghgyrgdfetjghjyiuykujhghgfgfdfdsfdgffhfhggjgAdgfhghhhhhhhhhhhhdfddgfdrewredffhgfhhggfhfyhttgrgrdgfhffhghgyrgdfetjghjyiuykujhghgfgfdfdsfdgffhfhggjgAdgfhghhhhhhhhhhhhdfddgfdrewredffhgfhhggfhfyhttgrgrdgfhffhghgyrgdfetjghjyiuykujhghgfgfdfdsfdgffhfhggjgAdgfhghhhhhhhhhhhhdfddgfdrewredffhgfhhggfhfyhttgrgrdgfhffhghgyrgdfetjghjyiuykujhghgfgfdfdsfdgffhfhggjgA",
    name: "athletic-unity",
    category: "Other",
    health: 100,
    code: "To0K5T",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f34f92c4-aa3f-42fc-8992-a2f510bdfad1",
    isApproved: false,
    activeProjects: 2,
    projects: 2,
    description: "A minimal Streamlit application",
    readme:
      "This is a Streamlit app that serves a simple hello world page on Railway. \n\nThis example is set up to use Nixpacks to build and run the app on Railway Platform.\n\n‚ú® Features\n\nPython\nStreamlit\nNixpacks\n\nüíÅ‚Äç‚ôÄÔ∏è How to use\n\nInstall Python requirements pip install -r requirements.txt\nRun locally using streamlit run main.py\n\nüìù Notes\nTo edit the python runtime verson, edit the .python-version file\nnixpacks.toml is set to use 8080 as the default port\nTo learn about how to use Streamlit with most of its features, you can visit the Streamlit Documentation\nTo learn about Nixpacks and how to configure it, read their Documentation",
    name: "Streamlit",
    category: "AI/ML",
    health: 50,
    code: "SyDUOJ",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5b819add-ad2e-4cc6-930b-0ff4a22a91b6",
    isApproved: false,
    activeProjects: 1,
    projects: 3,
    description: "N8N AI complete kit. N8N with Postgres and pgvector enabled.",
    readme:
      "This template simplifies the deployment of N8N, a robust open-source workflow automation platform, integrated with pgvector on your cloud infrastructure. \n\nWith a single click, you can set up N8N to create and manage workflows effortlessly. \n\nThe template is pre-configured to leverage pgvector's vector storage capabilities within PostgreSQL, enabling efficient handling of vector data for AI-driven workflows. PostgreSQL ensures reliable data persistence, preserving your workflows through restarts and redeployments.",
    name: "N8N (w/ pgvector)",
    category: "AI/ML",
    health: 100,
    code: "msyuqd",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "71578531-8c7e-407b-947a-d10ff8ed0e2a",
    isApproved: false,
    activeProjects: 4,
    projects: 6,
    description: "Flowise - Low code LLM Apps Builder with Postgres",
    readme:
      "Flowise - Low code LLM Apps Builder with Postgres\n\nFlowise is an open source low-code tool for developers to build customized LLM orchestration flows & AI agents. Developing LLM apps often involves countless iterations. Our low-code and drag-and-drop UI approach enables quick iterations, helping you go from testing to production faster\n\nThis template includes Postgres so all the data will be persisted in case the service gets restarted.",
    name: "Flowise - Low code LLM Builder with Postgres",
    category: "AI/ML",
    health: 83,
    code: "9IHr5z",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "156684db-b06b-4198-b1b5-74038333471c",
    isApproved: false,
    activeProjects: 1,
    projects: 1,
    description: "IDK I just figuring out how to publish my web",
    readme:
      "ajlkdjflkajslkjkajfdalkja;ks foisjdfokjd;lkja dfjkdlkjkdjf skjdfkjdkjdfflkjsdlkfjf jfkldj;lakjdklj  mldkj;jf;lkdj; kjkfl;kdjlk;ajdf jk;kdjfljkdff lkjkdflk ffkjfkjksjoiheoiroijjkfn jisfjd;kja dln kdjkdfjoad jidfjdj;lkajd;f s;dojkld jafj;kdj; ;ljf;k kfodjl;kjdk kljfdkakljdl;kj ljkjd;lkja;lkjd jfkldj;aljk ;dj jfklkjajpeijon akjlkjkoajpojdifjakjd;kja;cv vjkkja;ljdv jdkaljdpaidjfklj;lkaj;djkff jfkdlakjdf;lkjd kjjf ;k f;jdalkjdklj jkf;jalkdjf jfldkjadjjioejn jfkfd;aldkjfedfjakjf;la jfdokakldf fjdjadjljkflkaj;djk jjfodpiwjioef jsiopajf j;ilekjtipo;u jjoiajkg lakjja;jdkf jirpoeah gjakljdkj ajkj;ja;lk jk;kja jkdljkgiotruoiqopeh jk;ajdk jk;ajkdlkj j;ak kja;ljfd jfd;adjkie",
    name: "mathcity-adventures",
    category: "Other",
    health: 0,
    code: "-gldiI",
    languages: ["JavaScript", "CSS", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0b0cf1c0-7dfb-47bc-ba44-93f38ffd88a9",
    isApproved: false,
    activeProjects: 2,
    projects: 11,
    description: "The Open-Source Prompt Engineering Platform",
    readme:
      "Don't mind the low health success, it works *great*. It's just mostly my servers testing out all the kinks.\n\n  \n  \n    \n    \n  \n  \n\n\n\n\nThe Open-Source Prompt Engineering Platform\n\n  \n    \n    See documentation ‚Üí\n    \n    \n  Join Our Slack\n    ¬∑\n    X\nüåà Why Latitude?\n\nLatitude is an open-source platform for AI prompt engineering, deployment, and evaluation. It helps teams build, test, and maintain reliable AI applications by providing a complete lifecycle management system for prompts.\n\nWith Latitude, you can:\n\nDesign and version prompts collaboratively\nTest iterations in an interactive playground\nDeploy prompts as API endpoints\nMonitor performance with automatic logging\nEvaluate and improve prompts systematically\n\nLatitude is designed for cross-functional teams, enabling collaboration between developers, product managers, and domain experts throughout the entire AI development process.\n\n‚ú® Features\n\nPrompt Manager: Create, version, and collaborate on prompts with a powerful editor supporting advanced features like variables, conditionals, and loops through PromptL\nPlayground: Test prompts interactively with different inputs, parameters, and tool configurations\nAI Gateway: Deploy prompts as API endpoints that stay up-to-date with published changes\nEvaluations: Assess prompt performance via LLM-as-judge, programmatic rules, or human review\nLogs &amp; Observability: Automatically capture all interactions with prompts and models\nDatasets: Manage test data for batch evaluations and regression testing\nIntegrations: Seamlessly integrate with your existing stack via SDKs and APIs\nOpen-source: Driven by the community\n\nüìö Table Of Contents\n\nGetting Started\nPrompt Development Guide\nEvaluations\nData Management\nIntegration &amp; Deployment\nSelf-Hosting\nPromptL Language\nCommunity\nContributing\nLicense\n\n‚ö° Quick start\n\nLatitude offers two deployment options:\n\nLatitude Cloud: A fully managed solution that allows you to get started quickly without worrying about infrastructure.\nLatitude Self-Hosted: An open-source version that you can deploy and manage on your own infrastructure for complete control and customization.\n\nChoose the option that best fits your needs and follow the corresponding instructions below.\n\nLatitude Cloud\n\nTo get started with Latitude, follow these steps:\n\nSign up for Latitude: Visit our website and follow the instructions to create your account.\n\nCreate a new project: Once logged in, create a new project to organize your prompts and evaluations.\n\nWrite your first prompt: Navigate to the Editor and create a new prompt. Start with a simple task, like generating a short story or answering a question.\n\nTest your prompt: Use the playground to test your prompt with different inputs and see the model's responses.\n\nEvaluate in batch: Before deploying, you can upload a dataset and run a batch evaluation to assess your prompt's performance across various scenarios.\n\nDeploy your prompt: Once you're satisfied with your prompt's performance in batch evaluation, deploy it as an endpoint for easy integration with your applications.\n\nMonitor and evaluate: Use the Logs section to review your prompt's performance over time. Set up ongoing evaluations to systematically assess and improve your prompt's output.\n\nIterate and improve: Based on the evaluation results, refine your prompt or create new versions to enhance its performance.\n\nCollaborate with your team: Invite team members to your Latitude workspace to collaborate on prompt engineering and evaluations.\n\nFor more detailed information on each step, explore our documentation or join our community for support and discussions.\n\nLatitude Self-Hosted\n\nFollow the instructions in the self-hosted guide to get started with Latitude Self-Hosted.\n\nAfter setting up Latitude Self-Hosted, you can follow the same steps as in the Latitude Cloud guide to create, test, evaluate, and deploy your prompts.\n\nüë• Community\n\nThe Latitude community can be found on\nSlack\nwhere you can ask questions, voice ideas, and share your projects with other\npeople.\n\nü§ù Contributing\n\nContributions to Latitude are welcome and highly appreciated.\n\nIf you are interested in contributing, please join us on our&nbsp;Slack\ncommunity,\nopen an&nbsp;issue, or\ncontribute a pull request.\n\nüìÑ License\n\nLatitude is licensed under the LGPL-3.0.\n\nAlternatively, we offer a more permissive commercial license for those who need it. Please contact us at licensing@latitude.so for more information.\n\nüîó Links\n\nHome page\nDocumentation\nSlack community\nX / Twitter",
    name: "Latitude",
    category: "AI/ML",
    health: 100,
    code: "1CJho8",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "98e7708d-135b-461f-8057-24a3daf11b48",
    isApproved: false,
    activeProjects: 2,
    projects: 6,
    description: "An open-source uptime & infrastructure monitoring tool. Alternative to Kuma",
    readme:
      "\n\nAn open source uptime and infrastructure monitoring application\n\n‚ö†Ô∏èWarning‚ö†Ô∏è\n\nYou'll have to restart (Not Redeploy) the frontend container as it will crash because it starts faster than the server container. \nYou'll have to point the created domain to port 80 in the frontend container as it doesn‚Äôt works automatically and as by now it‚Äôs not configurable in the template.\n\nüîó User's guide\n\nUsage instructions can be found here. It's still WIP and some of the information there might be outdated as we continuously add features weekly. Rest assured, we are doing our best! :)\n\nüõ†Ô∏è Installation\n\nSee installation instructions in Checkmate documentation portal. Alternatively, you can also use Coolify or Elestio for a one-click Docker deployment. If you would like to monitor your server infrastructure, you'll need Capture agent. Capture repository also contains the installation instructions.\n\nüèÅ Translations\n\nIf you would like to use Checkmate in your language, please go to this page and register for the language you would like to translate Checkmate to. ",
    name: "Checkmate",
    category: "Observability",
    health: 100,
    code: "p-MBP2",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8c4fe7a0-f0a8-46ee-876f-7483f53cd1c7",
    isApproved: false,
    activeProjects: 4,
    projects: 8,
    description: "Bluesky PDS (Personal Data Server)",
    readme:
      "Bluesky PDS (Personal Data Server)\n\nThis is an unofficial template. The environment variable settings used here are based on the official installation script:\n\nhttps://github.com/bluesky-social/pds/blob/main/installer.sh\n\nIf you have any questions, please contact @mkizka.dev.\n\nHow to Use\n\nFill in the template values and deploy the project.\nNavigate to ‚ÄúSettings‚Äù ‚Üí ‚ÄúPublic Networking‚Äù and register the domain you want to use. The domain must match the PDS_HOSTNAME environment variable. Example:\n\n| Domain | Port |\n| --- | --- |\n| example.com | 3000 |\n| *.example.com | 3000 |\n\nSet up a CNAME record for your domain using Cloudflare or another DNS provider.\nRun the following commands to create a new account:\n\n$ git clone https://github.com/bluesky-social/pds  \n$ cd pds\n$ vim ./pdsadmin/account.sh  # Comment out lines 6 and 7 that reference pds.env  \n$ railway link # Select the generated project\nSelect a workspace: your-workspace  \nSelect a project: your-project  \nSelect an environment: production  \nSelect a service: pds  \n$ railway run bash ./pdsadmin/account.sh create  \nEnter an email address (e.g. alice@example.com): example@example.com  \nEnter a handle (e.g. alice.example.com): alice.example.com  \n\nAccount created successfully!  \nHandle   : alice.example.com  \nDID      : did:plc:xxxxxxxxxx  \nPassword : xxxxxxxxxx  \nSave this password, it will not be displayed again.\nYou can now log in to Bluesky using your new account!\n",
    name: "Bluesky PDS",
    category: "Blogs",
    health: 100,
    code: "xBNJ1u",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4dcc9671-639f-45fc-9bec-a369df0a634d",
    isApproved: false,
    activeProjects: 1,
    projects: 1,
    description: "A Discord Selfbot for Custom Rich Presence",
    readme:
      'Check out Github Repository for more information\n\nDiscord RPC Selfbot\n\nDeploy on Railway\n\nA Discord Selfbot for Custom Rich Presence\n\n&gt; !WARNING]  \n&gt; I don\'t take any responsibility for blocked Discord accounts that used this module.\n\n&gt; [!CAUTION]  \n&gt; Using this on a user account is prohibited by the [Discord TOS and can lead to the account block.\n\nHow to Use\n\nFill out your config.json\n\n{\n  "$schema": "https://raw.githubusercontent.com/thecats1105/discord-rpc-selfbot/refs/heads/main/config.schema.json",\n  "APPLICATION_ID": "",\n  "type": "",\n  "name": "",\n  "details": "",\n  "state": "",\n  "streamURL": "",\n  "party": {\n    "size": {\n      "current": null,\n      "max": null\n    }\n  },\n  "setLocalTime": null,\n  "timezone": "",\n  "startTimeStamp": null,\n  "endTimeStamp": null,\n  "assets": {\n    "large_image": "",\n    "large_text": "",\n    "small_image": "",\n    "small_text": ""\n  },\n  "buttons": \n    {\n      "label": "",\n      "url": ""\n    },\n    {\n      "label": "",\n      "url": ""\n    }\n  ],\n  "refreshInterval": null\n}\n\nUpload your config.json to Github Gist or any webservers\n\nSetup your Environment\n\nCONFIG_URL=""\nTOKEN=""\n\nAbout Configs\n\nSTREAMING Activity Type\n\nIf the Activity Type is set to STREAMING, the streamURL value must be set to the URL of that stream.\n\ne.g.:\n\n{\n  "type": "STREAMING",\n  "streamURL": "https://www.twitch.tv/thecats1105"\n}\n\nSet Timestamp to LocalTime\n\n&gt; [!NOTE]\n&gt; If you want to use this function, you need to remove startTimeStamp and endTimeStamp key.\n\nBy setting the setLocalTime value to true and entering a Timezone value from the IANA Time Zone Database for the timezone value, you can set the total activity time to the current time in that Timezone.\n\ne.g. Setting to the current time in the Asia/Seoul Timezone:\n\n{\n  "setLocalTime": true,\n  "timezone": "Asia/Seoul"\n}\n\nAssets\n\nassets.large_image and assets.small_image must be formatted as follows:\n\ncdn.discordapp.com URL\nmedia.discordapp.net URL\nAssets ID\n  See [here for more information.\n  You can get the ID of each Asset by running this command:\n  curl https://discord.com/api/v9/oauth2/applications//assets\nMedia Proxy (mp:external/)\nTwitch (twitch:)\nYouTube (youtube:)\nSpotify (spotify:)\n',
    name: "Discord-RPC-Selfbot",
    category: "Bots",
    health: null,
    code: "jsZQh-",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4871843f-7c0c-4203-acb3-fe2c0d034a4a",
    isApproved: false,
    activeProjects: 1,
    projects: 1,
    description: "Orchestrates AI models, MCP servers, and workflows via a single interface.",
    readme:
      'DISCLAIMER\nFLUJO is still an early preview! Here\'s a 30 second video to show it off:\nimage\n\n\nFor anything that you struggle with (MCP Installation, Application Issues, Usability Issues, Feedback): PLEASE LET ME KNOW!\n-> Create a Github Issue or write on Discord (https://discord.gg/KPyrjTSSat) and I will look into it! Maybe a response will take a day, but I will try to get back to each and every one of you.\n\n\nHere\'s a video guiding you through the whole thing - from installation to output! (15min)\nSorry for the bad audio, a new Video is coming soon!\n\nHow to install & Run your first Flow\n \nFLUJO animated Short #1 - "A sad song about MCP"\nimage\n\nIMPORTANT SECURITY NOTE\nFLUJO has currently EXTENSIVE logging enabled by default! This may expose your encrypted API-Keys to the terminal output!. Be VERY careful when grabbing videos or streaming and showing the terminal output!\n\nFLUJO Logo\n\nFLUJO\n\nMIT License\nVersion\n\nFLUJO is an open-source platform that bridges the gap between workflow orchestration, Model-Context-Protocol (MCP), and AI tool integration. It provides a unified interface for managing AI models, MCP servers, and complex workflows - all locally and open-source.\n\nFLUJO Overview\n\nFLUJO is powered by the PocketFlowFramework and built with CLine and a lot of LOVE.\n\nüåü Key Features\n\nüîë Environment & API Key Management\n\nSecure Storage: Store environment variables and API keys with encryption\nGlobal Access: Use your stored keys across the entire application\nCentralized Management: Keep all your credentials in one secure place\n\nAPI Keys Management\n\nü§ñ Model Management\n\nMultiple Models: Configure and use different AI models simultaneously\nPre-defined Prompts: Create custom system instructions for each model\nProvider Flexibility: Connect to various API providers (OpenAI, Anthropic, etc.)\nLocal Models: Integrate with Ollama for local model execution\n\nModel Configuration\nModel Settings\nOllama Integration\n\nüîå MCP Server Integration\n\nEasy Installation: Install MCP servers from GitHub or local filesystem\nServer Management: Comprehensive interface for managing MCP servers\nTool Inspection: View and manage available tools from MCP servers\nEnvironment Binding: Connect server environment variables to global storage\nDocker Support: Run Docker-based MCP servers within Flujo\n\nMCP Server Installation\nMCP Server Management\nMCP Server Tools\nMCP Environment Variables\n\nüîÑ Workflow Orchestration\n\nVisual Flow Builder: Create and design complex workflows\nModel Integration: Connect different models in your workflow\nTool Management: Allow or restrict specific tools for each model\nPrompt Design: Configure system prompts at multiple levels (Model, Flow, Node)\nimage\nFlow Design\nFlow Configuration\nSystem Prompts\nTool References\nScreenshot 2025-03-08 223218\n\nüí¨ Chat Interface\n\nFlow Interaction: Interact with your flows through a chat interface\nMessage Management: Edit or disable messages or split conversations to reduce context size \nFile Attachments: Attach documents or audio for LLM processing (really bad atm, because for this you should use mcp!)\nTranscription: Process audio inputs with automatic transcription (really bad atm, see roadmap)\n  \nScreenshot 2025-04-05 210835\n\nüîÑ External Tool Integration\n\nOpenAI Compatible Endpoint: Integrate with tools like CLine or Roo\nSeamless Connection: Use FLUJO as a backend for other AI applications\n\nScreenshot 2025-03-27 130144\nScreenshot 2025-03-26 213657\n\nüöÄ Getting Started\n\nManual installation:\nPrerequisites\n\nNode.js (v18 or higher)\nnpm or yarn\n\nInstallation\n\nClone the repository:\n   git clone https://github.com/mario-andreschak/FLUJO.git\n   cd FLUJO\n\nInstall dependencies:\n   npm install\nor\n   yarn install\n\nStart the development server:\n   npm run dev\nor\n   yarn dev\n\nOpen your browser and navigate to:\n   http://localhost:4200\n   \nFLUJO feels and works best if you run it compiled:\n   npm run build\n   npm start\n\nTo run as a desktop application:\n   npm run electron-dev    # Development mode\nor\n   npm run electron-dist   # Build and package for your platform\n\nüìñ Usage\n\nSetting up often used API keys\n\nNavigate to Settings\nSave your API Keys globally to secure them\n\nSetting Up Models\n\nNavigate to the Models page\nClick "Add Model" to create a new model configuration\nConfigure your model with name, provider, API key, and system prompt\nSave your configuration\n\nManaging MCP Servers\n\nGo to the MCP page\nClick "Add Server" to install a new MCP server\nChoose from GitHub repository or local filesystem\nConfigure server settings and environment variables\nStart and manage your server\n\nUsing SSE MCP-Servers\nGot to the MCP Page\nClick "Add Server" to install a new MCP server\nSelect "Local Server"\nEnter a Server Name, enter "/" as Server Root Path\nLeave Build Command and Install Command empty\nEnter "npx" as Run Command\nAdd 1. Argument "mcp-remote"\nAdd 2. Argument "(your MCP SSE-Url here)"\n   image\n\nUsing official Reference servers\n\nGo to the MCP page\nClick "Add Server" to install a new MCP server\nGo to the "Reference Servers" Tab\n(First time executing:) Click "Refresh" and waaaaaaait.\nClick a server of your choice, wait for the screen to change, click "Save" / "Update Server" at the bottom.\nUsing Docker-based MCP Servers\n\nWhen running FLUJO in Docker, you can use Docker-based MCP servers:\n\nGo to the MCP page\nClick "Add Server" to install a new MCP server\nChoose "Docker" as the installation method\nProvide the Docker image name and any required environment variables\nStart and manage your server\n\nCreating Workflows\n\nVisit the Flows page\nClick "Create Flow" to start a new workflow\nAdd processing nodes and connect them \nConfigure each node with models and tools\nSave your flow\n\nScreenshot 2025-04-12 123657\n\nBranching\n\nConnect one MCP node to multiple subsequent ones\nScreenshot 2025-04-07 094237\nDefine the branching in the prompt, using the handoff-tools on the "Agent Tools" tab\nScreenshot 2025-04-07 095433\n\nLoops\n\nSame as branching, but connect back to a previous node\nScreenshot 2025-04-08 165640\n\nOrchestration\n\nSame as loops but with multiple ones\nScreenshot 2025-04-08 180631\n\nUsing the Chat Interface\n\nGo to the Chat page\nSelect a flow to interact with\nStart chatting with your configured workflow\nScreenshot 2025-04-07 095653\n\nüîÑ MCP Integration\n\nFLUJO provides comprehensive support for the Model Context Protocol (MCP), allowing you to:\n\nInstall and manage MCP servers\nInspect server tools\nConnect MCP servers to your workflows\nReference tools directly in prompts\nBind environment variables to your global encrypted storage\nimage\n',
    name: "FLUJO",
    category: "AI/ML",
    health: 100,
    code: "7XqZC-",
    languages: ["TypeScript", "HTML", "JavaScript", "Shell", "CSS", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "17645325-9b6d-4f26-ae1a-dad975705535",
    isApproved: false,
    activeProjects: 0,
    projects: 5,
    description: "Modern, developer-friendly, cookiefree analytics tool. Alternative to Umami",
    readme:
      "Litlyx\n\nA modern, developer-friendly, cookie-free analytics tool.\nSetup takes less than 30 seconds! Completely self-hostable.\n\nAlternative to Google Analytics, Matomo, Umami, Plausible &amp; Simple Analytics.\n\n\nüìö Docs üëæ Join Discord üåê Website  üî• Try Litlyx Cloud. It's Free forever. \n\nUse\n\nTo forward your data on your self-hosted instance, you need to set up the following variables: data-host, data-port,  data-secure(true if it is HTTPS or false if it is HTTP).",
    name: "Litlyx",
    category: "Analytics",
    health: null,
    code: "I1zRSl",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "698656d8-348f-4e60-a22a-42e22c73e2dc",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "Password Generation Should Be Simple And Secure.",
    readme:
      "\n  PSWD\n  Simple secure password generator.\n  Visit PSWD\n\nWhy do I need secure passwords?\nSecure passwords protect your personal information and online accounts from unauthorized access and cyber threats. Weak or guessable passwords make it easy for hackers to breach your accounts, leading to identity theft, financial loss, and privacy issues. Using strong, unique passwords significantly lowers the risk of data breaches and keeps your sensitive information safe. Investing in secure passwords is essential for safeguarding your digital life and maintaining online security.\n\nWhat is PSWD?\nPSWD is a secure, user-friendly password generator that helps you create strong, unique passwords effortlessly. Whether you prefer traditional character-based passwords or memorable passphrases using the Diceware method, PSWD offers customizable options like length, character types, and word counts to meet your security needs. Its intuitive interface makes generating robust credentials for your online accounts simple and efficient.\n\nWhy should I use PSWD?\nPSWD allows you to easily generate strong, unique passwords tailored to your security needs. With options for length, character types, and word counts, you can create passwords that are both secure and memorable. Its user-friendly interface simplifies the password creation process, removing the hassle and guesswork. By using PSWD, you enhance your online security, protect your personal information, and ensure your accounts are safeguarded with reliable passwords.",
    name: "PSWD",
    category: "Authentication",
    health: null,
    code: "v9JNhZ",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e17b388a-5cc3-4a25-9173-b3e74a5a538f",
    isApproved: false,
    activeProjects: 1,
    projects: 1,
    description: "Fast, simple, scalable, HTTP microservice for high-level image processing",
    readme:
      "Imaginary\n\nYou can further customize it by adding the following flags:\n\n-enable-url-source: enable remote URL source image processing via GET requests and url query param\n-http-read-timeout: set 3 seconds (the default is 60 which is a long time to wait for an image)\n\nLinks\n\nGithub: https://github.com/h2non/imaginary\n",
    name: "Imaginary",
    category: "Automation",
    health: 100,
    code: "SaS706",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "89987a68-15a6-4dda-98ef-c9e298e019bc",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "Access all LLM through the standard OpenAI API format, easy to deploy & use",
    readme:
      "\nThe initial account username is root and password is 123456.\n\n\n    ‰∏≠Êñá | English | Êó•Êú¨Ë™û\n\nOne API\n\n‚ú® Access all LLM through the standard OpenAI API format, easy to deploy &amp; use ‚ú®\n\n\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\n\n  Deployment Tutorial\n  ¬∑\n  Usage\n  ¬∑\n  Feedback\n  ¬∑\n  Screenshots\n  ¬∑\n  Live Demo\n  ¬∑\n  FAQ\n  ¬∑\n  Related Projects\n  ¬∑\n  Donate\n\n\n&gt; Warning: This README is translated by ChatGPT. Please feel free to submit a PR if you find any translation errors.\n\n&gt; Note: The latest image pulled from Docker may be an alpha release. Specify the version manually if you require stability.\n\nFeatures\nSupport for multiple large models:\n   x(https://platform.openai.com/docs/guides/gpt/chat-completions-api) (Supports Azure OpenAI API)\n   x(https://anthropic.com)\n   x(https://developers.generativeai.google)\n   x(https://cloud.baidu.com/doc/WENXINWORKSHOP/index.html)\n   x(https://help.aliyun.com/document_detail/2400395.html)\n   x(https://bigmodel.cn)\nSupports access to multiple channels through load balancing.\nSupports stream mode that enables typewriter-like effect through stream transmission.\nSupports multi-machine deployment. See here for more details.\nSupports token management that allows setting token expiration time and usage count.\nSupports voucher management that enables batch generation and export of vouchers. Vouchers can be used for account balance replenishment.\nSupports channel management that allows bulk creation of channels.\nSupports user grouping and channel grouping for setting different rates for different groups.\nSupports channel model list configuration.\nSupports quota details checking.\nSupports user invite rewards.\nAllows display of balance in USD.\nSupports announcement publishing, recharge link setting, and initial balance setting for new users.\nOffers rich customization options:\n    Supports customization of system name, logo, and footer.\n    Supports customization of homepage and about page using HTML &amp; Markdown code, or embedding a standalone webpage through iframe.\nSupports management API access through system access tokens.\nSupports Cloudflare Turnstile user verification.\nSupports user management and multiple user login/registration methods:\n    Email login/registration and password reset via email.\n    GitHub OAuth.\n    WeChat Official Account authorization (requires additional deployment of WeChat Server).\nImmediate support and encapsulation of other major model APIs as they become available.\n\nEnvironment Variables\nREDIS_CONN_STRING: When set, Redis will be used as the storage for request rate limiting instead of memory.\n    Example: REDIS_CONN_STRING=redis://default:redispw@localhost:49153\nSESSION_SECRET: When set, a fixed session key will be used to ensure that cookies of logged-in users are still valid after the system restarts.\n    Example: SESSION_SECRET=random_string\nSQL_DSN: When set, the specified database will be used instead of SQLite. Please use MySQL version 8.0.\n    Example: SQL_DSN=root:123456@tcp(localhost:3306)/oneapi\nLOG_SQL_DSN: When set, a separate database will be used for the logs table; please use MySQL or PostgreSQL.\n    Example: LOG_SQL_DSN=root:123456@tcp(localhost:3306)/oneapi-logs\nFRONTEND_BASE_URL: When set, the specified frontend address will be used instead of the backend address.\n    Example: FRONTEND_BASE_URL=https://openai.justsong.cn\n'MEMORY_CACHE_ENABLED': Enabling memory caching can cause a certain delay in updating user quotas, with optional values of 'true' and 'false'. If not set, it defaults to 'false'.\nSYNC_FREQUENCY: When set, the system will periodically sync configurations from the database, with the unit in seconds. If not set, no sync will happen.\n    Example: SYNC_FREQUENCY=60\nNODE_TYPE: When set, specifies the node type. Valid values are master and slave. If not set, it defaults to master.\n    Example: NODE_TYPE=slave\nCHANNEL_UPDATE_FREQUENCY: When set, it periodically updates the channel balances, with the unit in minutes. If not set, no update will happen.\n    Example: CHANNEL_UPDATE_FREQUENCY=1440\nCHANNEL_TEST_FREQUENCY: When set, it periodically tests the channels, with the unit in minutes. If not set, no test will happen.\n    Example: CHANNEL_TEST_FREQUENCY=1440\nPOLLING_INTERVAL: The time interval (in seconds) between requests when updating channel balances and testing channel availability. Default is no interval.\n    Example: POLLING_INTERVAL=5\nBATCH_UPDATE_ENABLED: Enabling batch database update aggregation can cause a certain delay in updating user quotas. The optional values are 'true' and 'false', but if not set, it defaults to 'false'.\n    +Example:  BATCH_UPDATE_ENABLED=true\n    +If you encounter an issue with too many database connections, you can try enabling this option.\nBATCH_UPDATE_INTERVAL=5: The time interval for batch updating aggregates, measured in seconds, defaults to '5'.\n    +Example:  BATCH_UPDATE_INTERVAL=5\nRequest frequency limit:\n    GLOBAL_API_RATE_LIMIT: Global API rate limit (excluding relay requests), the maximum number of requests within three minutes per IP, default to 180.\n    GLOBAL_WEL_RATE_LIMIT: Global web speed limit, the maximum number of requests within three minutes per IP, default to 60.\nEncoder cache settings:\n    +TIKTOKEN_CACHE_DIR: By default, when the program starts, it will download the encoding of some common word elements online, such as' gpt-3.5 turbo '. In some unstable network environments or offline situations, it may cause startup problems. This directory can be configured to cache data and can be migrated to an offline environment.\n    +DATA_GYM_CACHE_DIR: Currently, this configuration has the same function as' TIKTOKEN-CACHE-DIR ', but its priority is not as high as it.\nRELAY_TIMEOUT: Relay timeout setting, measured in seconds, with no default timeout time set.\nRELAY_PROXY: After setting up, use this proxy to request APIs.\nUSER_CONTENT_REQUEST_TIMEOUT: The timeout period for users to upload and download content, measured in seconds.\nUSER_CONTENT_REQUEST_PROXY: After setting up, use this agent to request content uploaded by users, such as images.\nSQLITE_BUSY_TIMEOUT: SQLite lock wait timeout setting, measured in milliseconds, default to '3000'.\nGEMINI_SAFETY_SETTING: Gemini's security settings are set to 'BLOCK-NONE' by default.\nGEMINI_VERSION: The Gemini version used by the One API, which defaults to 'v1'.\nTHE: The system's theme setting, default to 'default', specific optional values refer to here.\nENABLE_METRIC: Whether to disable channels based on request success rate, default not enabled, optional values are 'true' and 'false'.\nMETRIC_QUEUE_SIZE: Request success rate statistics queue size, default to '10'.\nMETRIC_SUCCESS_RATE_THRESHOLD: Request success rate threshold, default to '0.8'.\nINITIAL_ROOT_TOKEN: If this value is set, a root user token with the value of the environment variable will be automatically created when the system starts for the first time.\nINITIAL_ROOT_ACCESS_TOKEN: If this value is set, a system management token will be automatically created for the root user with a value of the environment variable when the system starts for the first time.",
    name: "one-api",
    category: "AI/ML",
    health: null,
    code: "X32mcN",
    languages: ["JavaScript", "Go", "SCSS", "CSS", "HTML", "Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "16f58801-0c44-4b95-b5ad-19ee824385f1",
    isApproved: false,
    activeProjects: 1,
    projects: 4,
    description: "Flick is a key-value database designed for small applications",
    readme:
      "Flick DB\n\nA simple-fast-easy-to-use key-value databases, useful in small applications. Easy deploy it on railway!\n\nNode.js Example\n\nimport { FlickClient } from 'flickdb'\n\nconst client = new FlickClient({\n  host: '',\n  port: ,\n})\n\nawait client.createCollection('users')\n\nawait client.set('users', 'john', { name: 'John Doe', age: 30 })\n\nconst john = await client.get('users', 'john')\nconsole.log(john) // { name: \"John Doe\", age: 30 }\n\nYou can view the source code on github \nhttps://github.com/lassejlv/Flick/tree/main",
    name: "Flick",
    category: "Storage",
    health: null,
    code: "QjUR9X",
    languages: ["TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e354959d-b979-442f-a719-e6abefdd04e8",
    isApproved: false,
    activeProjects: 3,
    projects: 5,
    description: "Zitadel on Railway with PostgreSQL",
    readme:
      "üöÄ ZITADEL on Railway\n\nLogin:\nüîó https://zitadel..railway.app\nüìß zitadel-admin@zitadel..railway.app\nüîí Password1!\n\n‚úÖ Post-Deployment\n\n ] Change default password\n[ ] Set up custom domains\n[ ] Enable HTTPS (handled by Railway)\n[ ] Configure SMTP (optional)\n\nüìò Docs\n\n[ZITADEL Documentation\n\n\n",
    name: "Zitadel",
    category: "Authentication",
    health: 50,
    code: "Msn-6E",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ea4f891d-c755-4d17-b5df-78e7384ffbbb",
    isApproved: false,
    activeProjects: 7,
    projects: 15,
    description: "Modern invoicing and financial management, designed for small businesses.",
    readme:
      'Summit Finance\nimage\n\nQuick Start Deployment Instructions\n\nDeploy Summit to Railway with our one-click template and get your invoicing system running in under 3 minutes.\n\nPrerequisites\n\nBefore deploying, make sure you have:\n\nA Railway account (create one at railway.app if needed)\nA Resend account for email capabilities (highly recommended)\nA Xendit account for payment processing (required for invoice payments)\nSlack webhook URL (optional, for payment notifications)\n\nStep 1: One-Click Deployment\n\nClick the "Deploy to Railway" button on our repository\nRailway will automatically set up the necessary services:\n   PostgreSQL database\n   MinIO storage (for file uploads)\n   Web application\n\nStep 2: Configure Essential Environment Variables\n\nAfter deployment, you\'ll need to add some environment variables:\n\nEmail Configuration (Highly Recommended)\nCreate a Resend account if you don\'t have one\nGet your API key from the Resend dashboard\nAdd to Railway environment variables:\n   RESEND_API_KEY=your_resend_api_key\n   RESEND_FROM_EMAIL=your_verified_email@domain.com\n   RESEND_FROM_NAME=your-sender-name\n\nPayment Processing (Required for Invoice Payments)\nCreate a Xendit account if you don\'t have one\nGet your API keys from the Xendit dashboard\nAdd to Railway environment variables:\n   XENDIT_SECRET_KEY=your_xendit_secret_key\n   XENDIT_CALLBACK_VERIFICATION_TOKEN=your_xendit_callback_token\n\nPayment Notifications (Optional)\nTo receive payment notifications in Slack:\nSLACK_WEBHOOK_URL=your_slack_webhook_url\n\nStep 3: Set Up File Uploads\n\nFile uploads won\'t work immediately after deployment. Follow these steps to enable them:\n\nFind the MinIO service in your Railway project\nNavigate to the MinIO Console URL (provided in the service details)\nLog in with the credentials shown in the environment variables\nCreate a new access key:\n   Go to "Access Keys" in the left sidebar\n   Click "Create new access key"\n   Save both the Access Key and Secret Key\nReturn to your Summit application in Railway\nUpdate the environment variables with your new MinIO credentials:\n   MINIO_ACCESS_KEY=your_generated_access_key\n   MINIO_SECRET_KEY=your_generated_secret_key\nRestart the application service\n\nStep 4: First Login\n\nOnce deployed, click the "Open App" button in Railway\nCreate your admin account at the registration page\nSet up your company profile in the settings\n\nAdditional Configuration\n\nCustomize Your Domain (Optional)\n\nIn Railway, go to your Summit app service\nNavigate to the "Settings" tab\nUnder "Domains", add your custom domain\nUpdate your DNS settings as instructed\n\nSetup Guides\n\nHow to Set Up Xendit Integration\n\nCreate a Xendit account if you don\'t have one\nComplete the account verification process\nNavigate to Settings > API Keys in your Xendit Dashboard\nClick "Generate Secret Key" and give your key a name (e.g., "Summit Integration")\nChoose the appropriate permissions (you\'ll need at least "Payment" permissions)\nClick "Generate Key"\nCopy your Secret Key (it starts with "xnd_" followed by "production" for live keys or "development" for test keys)\nGo to Settings > Webhooks in your Xendit Dashboard\nFind the "Webhook verification token" section\nCopy your verification token\nAdd both these values to your Summit environment variables:\n    XENDIT_SECRET_KEY=your_copied_secret_key\n    XENDIT_CALLBACK_VERIFICATION_TOKEN=your_webhook_verification_token\n\nHow to Set Up a Slack Webhook\n\nGo to api.slack.com/apps and sign in to your Slack account\nClick "Create New App" and choose "From scratch"\nEnter a name for your app (e.g., "Summit Notifications") and select your workspace\nOn the left sidebar, click on "Incoming Webhooks"\nToggle "Activate Incoming Webhooks" to On\nClick "Add New Webhook to Workspace"\nSelect the channel where you want to receive notifications\nClick "Allow" to authorize the app\nCopy the Webhook URL that appears on the next page\nAdd this URL as SLACK_WEBHOOK_URL in your Summit environment variables\n\nHow to Create a Resend Account\n\nVisit resend.com and sign up for an account\nVerify your email address\nNavigate to the API Keys section in your dashboard\nClick "Create API Key"\nGive your key a descriptive name (e.g., "Summit App")\nSelect the appropriate permissions (usually "Full Access" for a new setup)\nClick "Add" to generate the key\nCopy your API key immediately (you\'ll only see it once)\nAdd this key as RESEND_API_KEY in your Summit environment variables\nMake sure to also set:\n    RESEND_FROM_EMAIL=your_verified_email@domain.com\n    RESEND_FROM_NAME=your-sender-name\nFor RESEND_FROM_EMAIL, use an email address you\'ve verified with Resend\n\nHow to Create MinIO Access Keys\n\nAfter deployment, find your MinIO service in Railway\nAccess the MinIO Console URL from your Railway dashboard\nLog in using the credentials in your environment variables\nIn the MinIO Console, click on "Access Keys" in the left sidebar\nClick "Create access key"\nYou can specify a custom access key or let MinIO generate one\nSave both the Access Key and Secret Key shown (you\'ll only see these once)\nAdd these as MINIO_ACCESS_KEY and MINIO_SECRET_KEY in your Summit environment variables\nRestart your application service to apply the changes\n\nTroubleshooting\n\nEmail not working? Verify your Resend API key and ensure your sender email is verified in Resend.\nFile uploads fail? Double-check your MinIO access key configuration.\nPayment processing issues? Ensure your Xendit account is properly verified and that you\'re using the correct API keys (development vs. production).\nWebhook verification failing? Confirm you\'ve copied the correct Xendit callback verification token.\nDatabase connection issues? Railway automatically manages your database, but you may need to restart the service if problems persist.\n\nFor additional help, check the GitHub repository or reach out to the team at Kugie.app.',
    name: "Summit Finance",
    category: "Other",
    health: 67,
    code: "x5njSj",
    languages: ["Dockerfile", "TypeScript", "JavaScript", "Shell", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "232865af-4245-42b7-8296-5c66b466fc9c",
    isApproved: false,
    activeProjects: 4,
    projects: 10,
    description: "The personal finance app for everyone",
    readme:
      'Maybe Finance\n\nThe personal finance app for everyone\n\nv0.5.0 (Updated 05/06/2025)\n\n\n\nWebsite: https://maybe.co\n\nRepository: https://github.com/maybe-finance/maybe\n\nDisclaimer:\n\nMaybe is distributed under an AGPLv3 license. " Maybe" is a trademark of Maybe Finance, Inc.\n\n"Joseph Ho" is not affiliated with Maybe Finance, Inc. in any way or form.',
    name: "Maybe",
    category: "Observability",
    health: 100,
    code: "dFsiOp",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5de9bb5e-4b4a-49e8-a1c6-784751c8b677",
    isApproved: false,
    activeProjects: 1,
    projects: 2,
    description: "Glance Dashboard with U.S. Stocks, Tech, and F1 news",
    readme:
      "Use the template and deploy!\n\nIf you would like to customize to your own liking, fork my Github repo and edit the glance.yml and home.yml file according to the guides written by the team behind Glance.\n\nUSE AT YOUR OWN RISKS!\n\nI take no responsibility, nor have the capacity, to troubleshoot your project, and make your personal project running smoothly.",
    name: "lucid-abundance",
    category: "Blogs",
    health: 100,
    code: "uqFsmi",
    languages: ["Go", "HTML", "CSS", "JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "48123073-0551-4f75-a6e9-e98887d5b5c2",
    isApproved: false,
    activeProjects: 1,
    projects: 1,
    description: "A simple Node.js Express app with PostgreSQL for quick API development.",
    readme:
      "A simple Node.js Express app with PostgreSQL for quick API development.A simple Node.js Express app with PostgreSQL for quick API development.A simple Node.js Express app with PostgreSQL for quick API development.A simple Node.js Express app with PostgreSQL for quick API development.A simple Node.js Express app with PostgreSQL for quick API development.",
    name: "intelligent-cooperation",
    category: "Other",
    health: 0,
    code: "t-NHJh",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ac6b9a42-2018-4bbc-87c4-8a285cf9a8a4",
    isApproved: false,
    activeProjects: 4,
    projects: 4,
    description: "A simple Node.js Express app with PostgreSQL for quick API development.",
    readme:
      "A simple Node.js Express app with PostgreSQL for quick API development.A simple Node.js Express app with PostgreSQL for quick API development.A simple Node.js Express app with PostgreSQL for quick API development.A simple Node.js Express app with PostgreSQL for quick API development.",
    name: "satisfied-fulfillment",
    category: "Other",
    health: 67,
    code: "gLUuoq",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "bba1ff05-4c41-438a-97c7-46bb8154e8fa",
    isApproved: false,
    activeProjects: 2,
    projects: 3,
    description: "Quickstart to hono + bun + postgres",
    readme:
      "Hono + Bun + Postgres template\n\nThis template uses hono with bun and postgres db setup out of the box. The template also include openapi doc using scalar\n\nNavigate to {domain}/docs to view the openapi doc\n\nOnce you have your db schema generated using bun run db:generate, make sure to add this command bun run db:migrate to the pre-deploy command in railway so it will auto migrate the latest schema to your postgres.\n\nMake sure to detach the upstream repo and connect to your own to start developing. See https://docs.railway.com/guides/deploy#eject-from-template-repository on how to eject from a starter template",
    name: "hono starter template",
    category: "Starters",
    health: null,
    code: "JK5kJM",
    languages: ["TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7d67cc5c-08d5-4d17-9bce-5f0c6d2fd859",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "Postgres image supporting PostGIS and Uber's H3 extensions.",
    readme:
      "PostGIS with H3 Extension Railway Template\n\nThis template provides a PostgreSQL database with PostGIS and Uber's H3 extension pre-installed, ready to deploy on Railway.\n\nDeploy on Railway\n\nFeatures\n\nPostgreSQL 16\nPostGIS 3.4\nUber's H3 postgres extension bindings for hexagonal hierarchical geospatial indexing https://github.com/zachasme/h3-pg\nPre-configured extensions and dependencies\n\nPrerequisites\n\nA Railway account\nRailway CLI (optional, for local development)\n\nEnvironment Variables\n\nThese are the required Postgres variables which can be modified before deployment, they contain the default values.\n\nPOSTGRES_DB=postgres-h3-db\nPOSTGRES_USER=postgres\nPOSTGRES_PASSWORD=postgres\n\nLocal Development\n\nClone this repository:\n\ngit clone \ncd postgres-h3\n\nRunning using docker\n\nStart the database using Docker Compose:\n\ndocker-compose up -d\n\nConnect to the database:\n\npsql -h localhost -p 54040 -U postgres -d postgres-h3-db\n\nContributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\nLicense\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\nDeveloped and maintained by Chike Ozulumba. For issues or suggestions, please open an issue on the GitHub repository.\n",
    name: "PostgreSQL with PostGIS and H3",
    category: "Storage",
    health: null,
    code: "0c4k7A",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "96ec4f5d-6ba9-4236-ba14-7b3b19aac53c",
    isApproved: false,
    activeProjects: 0,
    projects: 3,
    description: "Mock REST API powered by Restapify, perfect for testing and development.",
    readme:
      "üöÄ Restapify Template\n\nEasily deploy a Restapify mock API to Railway ‚Äî perfect for testing and frontend development when your backend isn't ready yet.\n\n‚öôÔ∏è Getting Started\n\nüîß Local Development\n\nInstall dependencies:\n\nnpm install\nyarn install\n\nStart the mock server:\n\nnpm run start\nyarn start\n\nOpen your browser:\n\nAPI base URL: http://localhost:6767/api/\nDashboard: http://localhost:6767/restapify\n\nThe dashboard provides a UI to explore and test your mock endpoints.\n\nüì¶ Environment Variables\n\nYou can configure the mock server behavior using environment variables via a .env file:\n\n| Variable              | Default                 | Description                                               |\n|-----------------------|-------------------------|-----------------------------------------------------------|\n| PORT                | 6767                  | Port where the server runs locally                        |\n| PUBLIC_PATH         | api/                  | Base path for all mock routes                             |\n| PUBLIC_URL          | http://localhost:6767 | Full URL used in logs and dashboard links                 |\n| OPEN_DASHBOARD_PATH | true (only if local)  | Open dashboard in browser when server starts (local only) |\n\nExample .env file:\n\nPORT=6767\nPUBLIC_PATH=api/\nPUBLIC_URL=http://localhost:6767\nOPEN_DASHBOARD_PATH=true\n\nIn Railway, PUBLIC_URL is set automatically via RAILWAY_PUBLIC_DOMAIN in most setups.\n\nüåê Example Routes Served\n\nThis template includes the following mocked endpoints:\n\nGET    /api/me\nGET    /api/posts\nGET    /api/users\nGET    /api/users/userid]\nPOST   /api/users/[userid]\nDELETE /api/users/[userid]\nGET    /api/users/[userid]/comments\n\nYou can modify or extend these by editing the files in the api/ directory.\n\nüöÄ Deploy to Railway\n\nOnce deployed:\n\nAPI: https://your-subdomain.up.railway.app/api/\nDashboard: https://your-subdomain.up.railway.app/restapify\n\nüìö Documentation\n\nüìñ [https://restapify.vercel.app/docs\n",
    name: "Restapify",
    category: "Starters",
    health: null,
    code: "HK3yyB",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a305afa0-3985-4889-b5f6-8a26aeb5d80f",
    isApproved: false,
    activeProjects: 0,
    projects: 3,
    description: "Is a UI free, open-source web to monitor and manage Apache Kafka clusters.",
    readme:
      "UI for Apache Kafka is a free, open-source web UI to monitor and manage Apache Kafka clusters.\n\nUI for Apache Kafka is a simple tool that makes your data flows observable, helps find and troubleshoot issues faster and deliver optimal performance. Its lightweight dashboard makes it easy to track key metrics of your Kafka clusters - Brokers, Topics, Partitions, Production, and Consumption.\n\n\nSet up UI for Apache Kafka with just a couple of easy commands to visualize your Kafka data in a comprehensible way. You can run the tool locally or in the cloud.\n\nDocumentation",
    name: "Kafka",
    category: "Queues",
    health: null,
    code: "1WkwXE",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "99536b80-d3d5-41bf-8f85-ae2c34a6eb97",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "Lightweight, cookie-free analytics for privacy-focused websites.",
    readme:
      "\n  \n    \n    \n    \n  \n  \n  Website |\n  Installation |\n  Demo |\n  Discord\n\nOverview\n\nMedama Analytics is an open-source project dedicated to providing self-hostable, cookie-free website analytics. With a lightweight tracker of less than 1KB, it aims to offer useful analytics while prioritising user privacy.\n\nFeatures\n\nüìä Real-Time Analytics: Monitor website performance and user interactions instantly.\n\nüîí Privacy-Focused: Lightweight tracker (&lt;1KB) without cookies, IP addresses, or additional identifiers, ensuring compliance with GDPR, PECR, and other regulations.\n\nüß™ Easy To Integrate: OpenAPI-based server for effortless integration into personal or professional dashboards.\n\nüíº Self-Hostable: Simple, single-binary setup with no external dependencies, capable of running on VMs with 256MB memory for most small websites.\n\nThe default login credentials are:\n\nUsername: admin\nPassword: CHANGE_ME_ON_FIRST_LOGIN\n\nLicense\n\nThe /core and /dashboard directory is licensed under the Apache License 2.0. See the core LICENSE and dashboard LICENSE for more information.\n\nThe /tracker directory is licensed under the MIT License. See LICENSE for more information.",
    name: "Medama Analytics",
    category: "Analytics",
    health: null,
    code: "JevCvT",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "200566ad-2187-49c6-b2e5-1d9ba0f706ac",
    isApproved: false,
    activeProjects: 2,
    projects: 5,
    description: "Deploy a scalable self-hosted GitHub Actions Runner.",
    readme:
      "GitHub Actions Runner Banner\n\nGitHub Actions Self Hosted Runners\n\nView a complete tutorial here -> https://docs.railway.com/tutorials/github-actions-runners\n\nSetup an ACCESS_TOKEN. This will enable the runner to self register with your GitHub organization or enterprise.\nAdd any extra labels you want for your runners.\nDeploy the template.\nClick on your new Service -> Settings -> Regions. Select the region(s) you want and the number of replicas you want.\nDeploy the changes and run some GitHub Actions!\n\nSetup a fine-grained PAT\nCreate a new fine-grained personal access token. Setup -> https://github.com/settings/personal-access-tokens\nSet the Resource owner as your organization. Alternatively, you can select your Enterprise or Repo. If you don't then you won't have access to organization scoped runners\nSet Expiration\nSet Repository Access\nUnder Permissions, Select Organization Permissions -> Self Hosted Runners -> Read and Write (If Enterprise, select Enterprise instead).\nYou don't need any other permissions!\n\nAdditional Configuration\nYou can set up additional configuration and settings from the GitHub repo.\n\nBest Practices\n\nAvoid Serverless\nUsing the Serverless Setting on this Service is not recommended and will result in idle runners disconnecting from GitHub and needing to reauthenticate. GitHub Runners have a 50 second HTTP longpoll which keeps them alive. While the runners in this template can automatically reauth with an ACCESS_TOKEN it will result in offline / abandoned runners.\n\nAvoid Docker-in-Docker\nRailway's current container model does not allow for docker containers inside its containers, which means any GitHub Actions workflow that pulls a container and runs it will fail.\n\nAbout GitHub Runners on Railway\nDeploying GitHub Actions Self Hosted Runners on Railway is an excellent way to run your own CI infrastructure because you only pay for what you use. With self-hosted runners, you also unlock the ability to cache expensive and time-consuming dependencies (node_modules, cargo, etc.) or large git repositories. Best of all, Railway's built-in replicas means you can scale your runners horizontally, or even distribute them to different data centers with just a click and redeploy. You'll save build times and costs over using standard runners, AND you'll unlock more sophistocated workflows -- without needing a PhD in DevOps.\n",
    name: "Github Actions Runner",
    category: "Automation",
    health: 0,
    code: "pXId5Q",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c612b340-4049-4e88-97b1-9db71a14a2cd",
    isApproved: false,
    activeProjects: 1,
    projects: 3,
    description: "Convert any github repo into llm readable format with image/pdf processing",
    readme:
      "A JS implementation of gitingest with db storage for faster load time and image/pdf parsing\n\nIt is recommended to deploy on US regions, if you receive network issues when deploying on other regions, change it to US and it should work\n\nRequirement for image/pdf:\nMISTRAL_API_KEY\nGEMINI_API_KEY\n\nNavigate to {PUBLIC_DOMAIN}/docs for scalar docs",
    name: "gitingest-js",
    category: "AI/ML",
    health: null,
    code: "cVfQZ1",
    languages: ["TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e2e97f24-5e57-4625-8206-68e03e9719e8",
    isApproved: false,
    activeProjects: 0,
    projects: 11,
    description: "Sell what you want without paying double commissions ",
    readme:
      "Open Payment Host\n\nSell Subscriptions, Newsletters, Digital Files without paying commissions.\n\nWhat\n\nOpen Payment Host is an easy to run self-hosted, minimalist payments host through which we can easily sell our digital items without paying double commissions while having total control over our sales and data.\n\nWhy\n\nSelling digital items on web as an indie requires using platforms where we have to pay double commissions(to the platform and the payment gateway) and our content is forever locked within those platforms.\n\nHow\n\nOpen Payment Host is a minimalist yet highly performant Go web application with innovative features which helps indies self-host and sell digital items with little effort.\n\nFeatures\n\nCustomers can buy without logging in, Increases conversion.\nStripe support, Just add the price id for the product and rest is done automatically.\nSquare support, Just add the amount for the product and rest is done automatically.\nMulti-country pricing, Price changes automatically according to the user's location resulting in better conversion.\nLight and Dark theme new\nMailchimp support, Customers are automatically added to a mailchimp list; Useful for sending newsletters.\nWYSIWYG editor to create beautiful product pages.\nFile attachment support(images) for the product posts.\nS3 support for delivering digital files via automatic pre-signed URL.\nSubscriber count for the products (With Square).\nAutomatic SSL and other security features for production.\n\nand many more.\n\nOne Click Deployment\n\nClick Deploy button to deploy Open Payment Host here on Railway.\n\nConfiguration variables can be filled in after deployment, more details are available here - https://github.com/abishekmuthian/open-payment-host/tree/main?tab=readme-ov-file#configuration .",
    name: "Open Payment Host",
    category: "CMS",
    health: null,
    code: "qOF1Ut",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1955a53d-4a2a-458d-8ca6-e0d2733686e2",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "An easy on the eyes, lightning fast pastebin written in Svelte and Rust.",
    readme:
      "PasteBook \nAn easy on the eyes, portable, lightning fast pastebin written in Svelte and Rust.\n\nVariables\nTITLE - The title to be used around PasteBook.\nDESCRIPTION - The description to be used in embeds and on the home page of PasteBook.\nDISABLE_NEW - Disables the new paste page. API is still accessible.\nFAVICON_URL - The URL that the favicon will be provided with. \nMAX_PAYLOAD_SIZE - The maximum paste size in megabytes.\n",
    name: "PasteBook",
    category: "Storage",
    health: null,
    code: "l9KAFW",
    languages: [
      "Svelte",
      "Rust",
      "TypeScript",
      "Python",
      "Shell",
      "HTML",
      "Dockerfile",
      "CSS",
      "JavaScript",
    ],
    tags: null,
  },
  {
    __typename: "Template",
    id: "fc90917a-c160-40c5-adce-9f316a1a5cdd",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "Best W.A Bot By Mr Frank OFC",
    readme:
      "üèÆ SUBZERO MD STATUS üèÆ \n\n  HiüëãüòÑ ùòΩùôûùô°ùô°ùôûùô§ùô£ùôñùôûùôßùôßùôö\n\n ‚è∞ Time: 19:32:57\n üìÜ Date: Wednesday, April 30th 2025\n üîã Uptime: 0 hours, 40 minutes, 9 seconds\n üîÆ Ram Usage : 76.63MB / 15993MB\n\n\n Status: Subzero is online! ü§óüöÄ\n\nùêèùêéùêñùêÑùêëùêÑùêÉ ùêÅùêò ùêåùêë ùêÖùêëùêÄùêçùêä. \nüîó https://github.com/mrfrankofcc/SUBZERO-MD",
    name: "airy-abundance",
    category: "Other",
    health: null,
    code: "GMNKzZ",
    languages: ["JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b7f8525d-4cdc-4aba-8a1d-569fdc89df5c",
    isApproved: false,
    activeProjects: 2,
    projects: 4,
    description: "Run AI agents, background tasks, and data pipelines at scale with Hatchet",
    readme:
      "Hatchet.run - Hatchet-lite\n\nThis template deploys Hatchet Lite, a lightweight version of the Hatchet.run distributed task queue system, on Railway.com.\n\nHatchet is a high-throughput, low-latency computing service. It's built on an open-source, fault-tolerant queue, allowing work to be delivered as fast as your system can handle -- without dropping a single task -- Backed by Y Combinator\n\nSimilar Tools: Inngest, Trigger.dev, Temporal. \n\nLog In via the default User Credentials - As of writing, these are:\n\nEmail: admin@example.com\nPassword: Admin123!!\n\nDon't forget to change these! \n\nFor more details on self-hosting Hatchet Lite, refer to the official documentation: https://docs.hatchet.run/self-hosting/hatchet-lite\n\nAll Available Configuration Options: https://docs.hatchet.run/self-hosting/configuration-options\n",
    name: "Hatchet Lite",
    category: "Queues",
    health: 100,
    code: "7oEFNd",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "68ec9b96-8586-458b-a72b-0f97fcdb7fad",
    isApproved: false,
    activeProjects: 26,
    projects: 40,
    description: "The open source Loom alternative",
    readme:
      "Cap Web\n\nThis template allows you to one-click deploy your own instance of Cap Web, for upload videos to via Cap Desktop.\n\nWhen logging in, a magic link will be printed to the server container's Deploy Logs. To get this sent to you via email instead, you'll need to sign up for Resend, connect a domain, create an API key, then set that domain as the server container's RESEND_FROM_DOMAIN variable, and set RESEND_API_KEY to the generated API key. More auth and email options will be available in the future.",
    name: "Cap",
    category: "Other",
    health: 96,
    code: "PwpGcf",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e34f464a-f000-4a27-be8b-43b9f9115c38",
    isApproved: false,
    activeProjects: 1,
    projects: 2,
    description: "The open-source secret management platform",
    readme:
      "Introduction\n\nInfisical is the open source secret management platform that teams use to centralize their application configuration and secrets like API keys and database credentials as well as manage their internal PKI.\n\nFeatures\n\nSecrets Management:\n\nDashboard: Manage secrets across projects and environments (e.g. development, production, etc.) through a user-friendly interface.\nNative Integrations: Sync secrets to platforms like GitHub, Vercel, AWS, and use tools like Terraform, Ansible, and more.\nSecret versioning and Point-in-Time Recovery: Keep track of every secret and project state; roll back when needed.\nSecret Rotation: Rotate secrets at regular intervals for services like PostgreSQL, MySQL, AWS IAM, and more.\nDynamic Secrets: Generate ephemeral secrets on-demand for services like PostgreSQL, MySQL, RabbitMQ, and more.\nSecret Scanning and Leak Prevention: Prevent secrets from leaking to git.\nInfisical Kubernetes Operator: Deliver secrets to your Kubernetes workloads and automatically reload deployments.\nInfisical Agent: Inject secrets into applications without modifying any code logic.\n\nInfisical (Internal) PKI:\n\nPrivate Certificate Authority: Create CA hierarchies, configure certificate templates for policy enforcement, and start issuing X.509 certificates.\nCertificate Management: Manage the certificate lifecycle from issuance to revocation with support for CRL.\nAlerting: Configure alerting for expiring CA and end-entity certificates.\nInfisical PKI Issuer for Kubernetes: Deliver TLS certificates to your Kubernetes workloads with automatic renewal.\nEnrollment over Secure Transport: Enroll and manage certificates via EST protocol.\n\nInfisical Key Management System (KMS):\n\nCryptographic Keys: Centrally manage keys across projects through a user-friendly interface or via the API.\nEncrypt and Decrypt Data: Use symmetric keys to encrypt and decrypt data.\n\nInfisical SSH\n\nSigned SSH Certificates: Issue ephemeral SSH credentials for secure, short-lived, and centralized access to infrastructure.\n\nGeneral Platform:\n\nAuthentication Methods: Authenticate machine identities with Infisical using a cloud-native or platform agnostic authentication method (Kubernetes Auth, GCP Auth, Azure Auth, AWS Auth, OIDC Auth, Universal Auth).\nAccess Controls: Define advanced authorization controls for users and machine identities with RBAC, additional privileges, temporary access, access requests, approval workflows, and more.\nAudit logs: Track every action taken on the platform.\nSelf-hosting: Deploy Infisical on-prem or cloud with ease; keep data on your own infrastructure.\nInfisical SDK: Interact with Infisical via client SDKs (Node, Python, Go, Ruby, Java, .NET)\nInfisical CLI: Interact with Infisical via CLI; useful for injecting secrets into local development and CI/CD pipelines.\nInfisical API: Interact with Infisical via API.\n\nResources\n\nDocs for comprehensive documentation and guides\nSlack for discussion with the community and Infisical team.\nGitHub for code, issues, and pull requests\nTwitter for fast news\nYouTube for videos on secret management\nBlog for secret management insights, articles, tutorials, and updates",
    name: "Infisical",
    category: "Automation",
    health: 67,
    code: "NTiUyT",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f7df286b-f057-44a2-8865-1f269e3ffdf7",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "QuestDB is the world's fastest growing open-source time-series database.",
    readme:
      "\n  \n\n&nbsp;\n\n\n  \n    \n  \n\n\n\n  English |\n  ÁÆÄ‰Ωì‰∏≠Êñá |\n  ÁπÅÈ´î‰∏≠Êñá |\n  ÿßŸÑÿπÿ±ÿ®Ÿäÿ© |\n  Italiano |\n  –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞ |\n  Espa√±ol |\n  Portugu√™s |\n  Êó•Êú¨Ë™û |\n  T√ºrk√ße |\n  ‡§π‡§ø‡§Ç‡§¶‡•Ä |\n  Ti·∫øng Vi·ªát\n\n\nQuestDB is the fastest growing open-source time-series database offering **blazingly fast, high\nthroughput ingestion* and *dynamic, low-latency SQL queries**. The entire high-performance\ncodebase is built from the ground up in Java, C++ and Rust with no dependencies\nand zero garbage collection.\n\nWe achieve high performance via a column-oriented storage model, parallelized\nvector execution, SIMD instructions, and low-latency techniques. In addition,\nQuestDB is hardware efficient, with quick setup and operational efficiency.\n\nQuestDB implements ANSI SQL with native time-series SQL extensions. These SQL\nextensions make it simple to analyze, filter and downsample data, or to\ncorrelate data from multiple sources using relational and time-series joins.\n\n&gt; Ready to go? Jump to the\n&gt; Get started section.\n\n&nbsp;\n\n\n  \n    \n  \n  QuestDB Web Console - click to launch demo\n\n\n&nbsp;\n\nBenefits of QuestDB\n\nQuestDB excels with:\n\nfinancial market data\nIoT sensors with high data cardinality\nreal-time dashboards\n\nFeature highlights include:\n\nSQL with powerful, SIMD-optimized time-series extensions\nHigh-speed ingestion via the InfluxDB Line Protocol\nStrong and efficient performance on limited hardware\nColumnar storage format (native or\n  Apache Parquet), partitioned\n  and ordered by time\nResponsive and intuitive Web Console for query and data management, with error\n  handling\nExcellent performance with\n  high data cardinality - see\n  benchmarks\n\nAnd why use a time-series database?\n\nBeyond performance and efficiency, with a specialized\ntime-series database, you\ndon't need to worry about:\n\nout-of-order data\nduplicates\nexactly one semantics\nstreaming data (low latency)\nhigh volumes of concurrent requests\nvolatile and \"bursty\" data\nadding new columns - change schema \"on the fly\" while streaming data\n\nTry QuestDB, demo and dashboards\n\nThe live, public demo is provisioned with the latest\nQuestDB release and sample datasets:\n\nTrips: 10 years of NYC taxi trips with 1.6 billion rows\nTrades: live crypto market data with 30M+ rows per month\nPos: geolocations of 250k unique ships over time\n\nUse example queries or write your own!\n\nThe public demo queries over 1.6BN rows and uses a r6a.12xlarge 48 vCPU and 348GB RAM instance.\n\n| Query                                                                         | Execution time                                                                                                                                                                                      |\n|-------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| SELECT sum(double) FROM trips                                               | 0.15 secs                                                                                         |\n| SELECT sum(double), avg(double) FROM trips                                  | 0.5 secs                                                                        |\n| SELECT avg(double) FROM trips WHERE time in '2019'                          | 0.02 secs                                             |\n| SELECT time, avg(double) FROM trips WHERE time in '2019-01-01' SAMPLE BY 1h | 0.01 secs |\n| SELECT * FROM trades LATEST ON timestamp PARTITION BY symbol                | 0.00025 secs                                                    |\n\nWe also have some public, real-time demo dashboards using\nour Grafana-native plugin:\n\nReal-time crypto trades: executed\n  trades on OKX from more than 20 assets in real time\nNYC taxi geolocation data: real-time\n  replay of 146,393,317 taxi rides across New York City in 2016\n\nQuestDB performance vs. other oss databases\n\nQuestDB performs very well in performance benchmarks compared to alternatives.\n\nFor deep dives into internals and performance, see the following blog posts:\n\nQuestDB vs InfluxDB\nQuestDB vs TimescaleDB\nQuestDB vs MongoDB\n\nAs always, we encourage you to run your own benchmarks.\n\nGet started\n\nUse Docker to start quickly:\n\ndocker run -p 9000:9000 -p 9009:9009 -p 8812:8812 questdb/questdb\n\nOr macOS users can use Homebrew:\n\nbrew install questdb\nbrew services start questdb\n\nquestdb start\nquestdb stop\n\nAlternatively, to kickoff the full onboarding journey, start with our concise\nquick start guide.\n\nFirst-party ingestion clients\n\nQuestDB clients for ingesting data via the InfluxDB Line Protocol:\n\nPython\n.NET\nC/C++\nGo\nJava\nNodeJS\nRust\n\nConnect to QuestDB\n\nInteract with QuestDB and your data via the following interfaces:\n\nWeb Console for an interactive SQL\n  editor and CSV import on port 9000\nInfluxDB Line Protocol\n  for streaming ingestion on port 9000\nPostgreSQL Wire Protocol\n  for programmatic queries on port 8812\nREST API for CSV import and\n  cURL on port 9000\n\nPopular third-party tools\n\nPopular tools that integrate with QuestDB include:\n\nApache Kafka\nGrafana\nSuperset\nTelegraf\nApache Flink\nqStudio\nMindsDB\n\nEnd-to-end code scaffolds\n\nFrom streaming ingestion to visualization with Grafana, start with code\nscaffolds in from our\nquickstart repository.\n\nConfigure QuestDB for production workloads\n\nFind our\ncapacity planning to\nfine-tune QuestDB for production workloads.\n\nQuestDB Enterprise\n\nFor secure operation at greater scale or within larger organizations.\n\nAdditional features include:\n\nmulti-primary ingestion\nread replica(s)\ncold storage integration\nrole-based access control\nTLS encryption\nnative querying of Parquet files via object storage\nsupport SLAs, enhanced monitoring and more\n\nVisit the Enterprise page for further details\nand contact information.\n",
    name: "QuestDB",
    category: "Storage",
    health: null,
    code: "GEyNgl",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "bc759551-79b3-48af-91c1-ee62e29a3359",
    isApproved: false,
    activeProjects: 4,
    projects: 4,
    description: "Deploy a real-time stock price API with FastAPI in one click!",
    readme:
      "üß© About This Template\nThis template deploys a lightweight FastAPI application that fetches real-time stock market data using the popular yfinance Python library.\nIt allows users to query stock tickers (like AAPL, TSLA, MSFT) and retrieve the latest closing prices from Yahoo Finance via a simple REST API.\n\nPerfect for developers, students, and finance enthusiasts who want fast and easy access to stock market data without setting up complex servers or paying for APIs.\n\nüöÄ Features\nFetch real-time stock prices (latest closing price).\nSimple and fast API built using FastAPI and Uvicorn.\nDeployed in minutes using Railway‚Äôs one-click deployment.\nLightweight & cost-effective for hobby, testing, and prototyping projects.\nOpen-source and easy to extend (e.g., historical data, financial ratios, etc.).\n\n‚öôÔ∏è Technologies Used\n\nFastAPI ‚Äî Web framework for building APIs quickly.\nUvicorn ‚Äî Lightning-fast ASGI server.\nyfinance ‚Äî Yahoo Finance data downloader.",
    name: "yahoo-finance-apis",
    category: "Starters",
    health: null,
    code: "ELjUB8",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ae79ee75-d022-4001-887b-233a146d65f8",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "Cron job and background task monitoring service, written in Python & Django",
    readme:
      "HealthCheck\n\nWhat it is?\n\nHealthcheck is an open-source service that listens for pings from your cron jobs, background tasks, and web services. It provides a simple and reliable way to monitor these processes and ensure they are running as expected. Think of it as a dead man's switch for your automated tasks ‚Äì if a check-in doesn't arrive on time, you'll get notified.\n\nHow it is useful or helpful?\n\nThis service is incredibly helpful for maintaining the reliability and stability of your systems. By using healthchecks, you can:\n\nDetect silent failures: Know immediately if a critical background job fails to complete, even if it doesn't produce an error log.\nImprove system observability: Gain better insight into the health and status of your automated processes.\nReceive timely alerts: Get notified via various channels (email, SMS, etc.) when a heartbeat is missed, allowing you to take corrective action quickly.\nSimplify monitoring: Implement a lightweight and straightforward monitoring solution without the complexity of full-fledged monitoring systems for simple tasks.\nBuild more resilient applications: Ensure that dependent tasks are running as expected, contributing to the overall health of your application.\n\nFeatures:\n\nSimple HTTP API: Easy to integrate with any application or scripting language using simple HTTP requests.\nCustomizable check-in intervals: Define expected heartbeat frequencies for each job.\nConfigurable grace periods: Set a buffer time before a missed check-in triggers an alert.\nMultiple notification channels: Supports email, SMS, and various third-party integrations (e.g., Slack, Pushover).\nWeb dashboard: Provides a clear overview of the status of all your monitored jobs.\nTagging and filtering: Organize and manage your checks effectively using tags.\nOpen-source: Fully transparent and customizable to fit your specific needs.\nSelf-hostable: You have complete control over your monitoring infrastructure.\n\nFor more detailed information and advanced usage, be sure to check out the official documentation at https://github.com/healthchecks/healthchecks/ and the Docker-specific health checks guide at https://github.com/linuxserver/docker-healthchecks.",
    name: "Healthcheck",
    category: "Automation",
    health: null,
    code: "jL-MMA",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "57801999-be81-4c93-82a5-7219a72fe911",
    isApproved: false,
    activeProjects: 5,
    projects: 10,
    description: " An open-source AI chatbot app powered by Model Context Protocol (MCP)",
    readme:
      '\n  Scira MCP Chat\n\n\n\n  An open-source AI chatbot app powered by Model Context Protocol (MCP), built with Next.js and the AI SDK by Vercel.\n\n\n\n  Features ‚Ä¢\n  MCP Configuration ‚Ä¢\n  License\n\nFeatures\n\nStreaming text responses powered by the AI SDK by Vercel, allowing multiple AI providers to be used interchangeably with just a few lines of code.\nFull integration with Model Context Protocol (MCP) servers to expand available tools and capabilities.\nMultiple MCP transport types (SSE and stdio) for connecting to various tool providers.\nBuilt-in tool integration for extending AI capabilities.\nReasoning model support.\nshadcn/ui components for a modern, responsive UI powered by Tailwind CSS.\nBuilt with the latest Next.js App Router.\n\nMCP Server Configuration\n\nThis application supports connecting to Model Context Protocol (MCP) servers to access their tools. You can add and manage MCP servers through the settings icon in the chat interface.\n\nAdding an MCP Server\n\nClick the settings icon (‚öôÔ∏è) next to the model selector in the chat interface.\nEnter a name for your MCP server.\nSelect the transport type:\n   SSE (Server-Sent Events): For HTTP-based remote servers\n   stdio (Standard I/O): For local servers running on the same machine\n\nSSE Configuration\n\nIf you select SSE transport:\nEnter the server URL (e.g., https://mcp.example.com/token/sse)\nClick "Add Server"\n\nstdio Configuration\n\nIf you select stdio transport:\nEnter the command to execute (e.g., npx)\nEnter the command arguments (e.g., -y @modelcontextprotocol/server-google-maps)\n   You can enter space-separated arguments or paste a JSON array\nClick "Add Server"\n\nClick "Use" to activate the server for the current chat session.\n\nAvailable MCP Servers\n\nYou can use any MCP-compatible server with this application. Here are some examples:\n\nComposio - Provides search, code interpreter, and other tools\nZapier MCP - Provides access to Zapier tools\nAny MCP server using stdio transport with npx and python3\n\nLicense\n\nThis project is licensed under the Apache License 2.0 - see the LICENSE file for details.',
    name: "Scira MCP AI",
    category: "AI/ML",
    health: 100,
    code: "KPUOlm",
    languages: ["TypeScript", "CSS", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c8fde208-d94c-47dd-806a-6159d9190d00",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "Plug-and-play Flask contact form, deploy with one click via Docker/Railway",
    readme:
      "TechGuru Contact Form Service\n\n A simple, ready-to-deploy Flask-based contact form microservice. Perfect for quickly adding contact functionality to your website, hosted effortlessly using Docker or Railway.\n\nKey Features:\n\nOne-click deployment via Railway\nCustomizable Flask app for contact forms\nDockerized for easy local development or cloud hosting\nFree and open-source (MIT License)\n\nPrerequisites:\n\nRailway account for deployment\nDocker for local deployment (optional)\nBasic Flask knowledge (optional for customization)\n\nUsage Instructions:\n\nSimply click the 'Deploy on Railway' button, and Railway will take care of the rest. Customize the contact form in main.py and you‚Äôre good to go!\n\nLicense:\n\nMIT License - Free to use and modify\n\n",
    name: "techguru-contact-form",
    category: "Other",
    health: null,
    code: "pDM1dq",
    languages: ["Python", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4c3557dc-31ee-4909-a1c8-ee89816a35a4",
    isApproved: false,
    activeProjects: 1,
    projects: 2,
    description: "Open-Source markdown editor - your new home for notes",
    readme:
      "\n  \n    \n  \n  Haptic\n  \n  \n    Open-Source markdown editor - your new home for notes\n  \n\n\n\n    Learn more ¬ª\n    \n    \n    Introduction\n    ¬∑\n    Tech Stack\n    ¬∑\n    Deploy Your Own\n    ¬∑\n    Roadmap\n    ¬∑\n    Contributing\n  \n\n\n    \n      \n        \n        \n        \n      \n    \n\n\nHaptic is a new local-first &amp; privacy-focused, open-source home for your markdown notes. It's minimal, lightweight, efficient and aims to have all you need and nothing you don't.\n\nIf you'd like to learn more about Haptic, why it's being built, what its goals are and how it differs from all the other markdown editors out there, you can read more about it here.\n\nHaptic is currently still in active development.",
    name: "Haptic",
    category: "CMS",
    health: 100,
    code: "sJu2rT",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "40dde61b-f29a-4931-9321-d93e866077b9",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "DEPLOY REACT AND DJANGO PROJECT (BEST DONE ON DIFFRENT REPO))",
    readme:
      "DEPLOY DJANGO AND REACT PROJECT (BEST DONE WITH DIFFRENT REPO)\n\nARE YOU HAVING ISSUE DEPLOYING ON RAILWAY WITH REACT AND PYTHON(DAJNGO)\n\nTHIS TEMPLATE HELPS YOU WITH THAT\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!",
    name: "mealify_food frontend",
    category: "Other",
    health: null,
    code: "1DOLZH",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "071d32b0-03d1-423a-8c0a-c2d1996f0183",
    isApproved: false,
    activeProjects: 2,
    projects: 2,
    description: "spectra ai spectra ai spectra ai ",
    readme:
      "spectra ai spectra ai spectra ai spectra ai spectra ai spectra ai spectra ai spectra ai spectra ai spectra ai spectra ai spectra ai spectra ai spectra ai spectra ai spectra ai spectra ai spectra ai spectra ai spectra ai spectra ai spectra ai spectra ai spectra ai ",
    name: "courageous-passion",
    category: "Other",
    health: null,
    code: "kaDIaZ",
    languages: ["JavaScript", "CSS", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "11c42d2f-acc3-4fc9-afae-749247a9265c",
    isApproved: false,
    activeProjects: 48,
    projects: 49,
    description: "Best W.A Bot By Mr Frank OFC",
    readme:
      "Meet W.A Bot! üåêü§ñ Best Multi-Device Bot by Mr Frank OFC from Earth üåé with 1000+ features! üöÄ More coming soon! üîú Stay tuned! üòé Powered by JS & Node JS üíª‚ú® Unlocking possibilities! üí° Revolutionizing interactions with cutting-edge tech! üåü Experience seamless functionality across devices! üì±üíª Stay ahead with innovative solutions! üîù Discover more features, updates, and surprises! üéâ",
    name: "SUBZERO-MD",
    category: "Other",
    health: 92,
    code: "a2IRz9",
    languages: ["JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "141fb0a6-14c5-4afa-89c1-c3d329223d37",
    isApproved: false,
    activeProjects: 2,
    projects: 4,
    description: "Useful tools for developer and people working in IT",
    readme:
      "A collection of online developer tools, providing a rich suite of tools for developers to use anytime, anywhere.\n\nIT-Tools is an open-source collection of handy, browser-based tools for developers and IT professionals. Built with Vue.js and TypeScript, it includes utilities like UUID generators, JWT decoders, format converters, and more. The project focuses on providing a great user experience and can be easily self-hosted via Docker, Cloudron, Tipi, or Unraid. Licensed under GNU GPLv3, it is actively maintained and welcomes community contributions to continuously expand its features.",
    name: "IT-Tools",
    category: "Other",
    health: 100,
    code: "4v9Fwu",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "88c3b9d3-511e-4169-8a1c-ab914614f079",
    isApproved: false,
    activeProjects: 1,
    projects: 5,
    description: "Simple Cron Job Scheduler that uses Node.js and environment variables",
    readme:
      'Node.js Cron Scheduler\n\nA utility for scheduling multiple cron jobs using environment variables and node-cron.\n\nOfficial repo\n\nFeatures\n\nTimezone support\nEnvironment variable validation\nFlexible HTTP request configuration\n\nConfiguration\n\nEnvironment Variables\n\nThe following environment variables are supported:\n\n| Variable        | Required | Description                                                                 | Example                                          |\n| --------------- | -------- | --------------------------------------------------------------------------- | ------------------------------------------------ |\n| TIMEZONE        | No       | IANA timezone name (defaults to UTC)                                        | TIMEZONE="America/New_York"                    |\n| RUN_ON_START    | No       | Run jobs on startup (defaults to false)                                   | RUN_ON_START="false"                           |\n| REQUEST_TIMEOUT | No       | Request timeout in milliseconds (default: 60000 = 1 minute, 0 = no timeout) | REQUEST_TIMEOUT="30000"                        |\n| JOB{n}          | Yes      | Cron job configuration (see below)                                          | JOB1="* * * * *::GET::https://api.example.com" |\n\nImportant notes\n\nEnvironment Variable Formatting Rules. Since some environment variables have to contain spaces or special characters, it\'s recommended to use double quotes for all values.\n\nDevelopment configuration. During development or testing you can set RUN_ON_START="true" to run jobs on every file change to see result of changes faster.\n\nTimezone\n\nThe scheduler supports all IANA timezone names. Examples:\n\nTIMEZONE"="UTC" (default)\nTIMEZONE"="America/New_York"\nTIMEZONE"="Europe/London"\nTIMEZONE"="Asia/Tokyo"\n\nNote, that timezone is configured for all jobs.\n\nSee list of available timezones here.\n\nJob Configuration\n\nJobs are configured using environment variables in the following format:\n\nJOB{n}="schedule::method::url::prop1=value1::prop2=value2"\n\nWhere:\n\n{n}: Job number (1, 2, 3, etc.)\nschedule: Cron schedule expression\nmethod: HTTP method (GET, POST, PUT, DELETE, PATCH)\nurl: Target URL\nprop{n}=value{n}: Optional properties for request body\n\nFields are separated by :: (double colon).\n\nExamples\n\nBasic Jobs\n\nSimple GET request every minute:\n\nJOB1="* * * * *::GET::https://api.example.com/ping"\n\nPOST request every day at midnight:\n\nJOB2="0 0 * * *::POST::https://api.example.com/daily-task"\n\nAdvanced Jobs\n\nPOST request with properties:\n\nJOB1="0 0 * * *::POST::https://api.example.com/task::userId=123::action=backup"\n\nThis will send a POST request with the body:\n\n{\n  "userId": "123",\n  "action": "backup"\n}\n\nMultiple jobs with different schedules:\n\nJOB1="*/5 * * * *::GET::https://api.example.com/health"\nJOB2="0 0 * * *::POST::https://api.example.com/daily::task=backup"\nJOB3="0 */2 * * *::PUT::https://api.example.com/update::status=active"\n\nValidation\n\nThe scheduler includes comprehensive validation for all configuration:\n\nCron Schedule: Validates correct cron expression format\nHTTP Method: Must be one of: GET, POST, PUT, DELETE, PATCH\nURL: Validates proper URL format\nTimezone: Validates against IANA timezone database\nProperties: Validates key-value pair format\n\nIf validation fails, the scheduler will:\n\nLog detailed error messages\nExit with a non-zero status code\n\nTesting\n\nIn order to test your configuration you can use these services that quickly mock API endpoints:\n\nMockbin.io\nWebhook.site\n\nAuthor\n\nAliaksandr Tsykin\n\nLicense\n\nLicensed under the MIT license.\n\nContribution\n\nAll contributions and PRs are welcome :)\n',
    name: "Nodejs Cron Scheduler",
    category: "Automation",
    health: 100,
    code: "oIgT0x",
    languages: ["TypeScript", "JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "95c4bf23-737e-4e79-9b42-3cbb0bab2f01",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "A Web Widget for the Ragpi AI Assistant",
    readme:
      "Ragpi Web Widget Integration\n\nRagpi is an open-source AI assistant API that answers questions using your documentation, GitHub issues, and READMEs. It combines LLMs with intelligent search to provide relevant, documentation-backed answers through a simple API.\n\nThis is a template for the Ragpi Web Widget integration. You can find out more on how to deploy this integration on railway here: https://docs.ragpi.io/deployment/railway\n",
    name: "Ragpi Recaptcha Gateway",
    category: "AI/ML",
    health: null,
    code: "scntIP",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e81240a6-d142-40ac-accb-de61ec915cb1",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "A Discord bot for the Ragpi AI Assistant",
    readme:
      "Ragpi Discord Integration\n\nRagpi is an open-source AI assistant API that answers questions using your documentation, GitHub issues, and READMEs. It combines LLMs with intelligent search to provide relevant, documentation-backed answers through a simple API.\n\nThis is a template for the Ragpi Discord integration. You can find out more on how to deploy this integration on railway here: https://docs.ragpi.io/deployment/railway\n",
    name: "Ragpi Discord Integration",
    category: "AI/ML",
    health: null,
    code: "cgiAdr",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "90c9946a-9273-4688-9d76-6e624bf10583",
    isApproved: false,
    activeProjects: 1,
    projects: 3,
    description: "dark shan md v2 developeder by kushansewmina ü™Ω",
    readme:
      "DARK SHAN MD V2 WhatsApp Bot Documentation\n\nOverview\nDARK SHAN MD V2 is an advanced WhatsApp bot developed by Kushan Sevmina, designed to provide users with a powerful and customizable messaging experience. This bot offers a wide range of features including automated responses, media handling, group management tools, and much more, all wrapped in a sleek dark-themed interface.\n\nKey Features\nMulti-functional commands for entertainment, utilities, and productivity\nGroup management tools including admin controls and moderation\nMedia support for images, videos, and documents\nCustomizable responses and automated replies\nDark theme interface for reduced eye strain\nSecure authentication to protect user privacy\n\nDeployment Instructions\n\nPrerequisites\nNode.js v16 or higher installed\nWhatsApp account with active number\nBasic terminal/command prompt knowledge\n\nInstallation Steps\nClone the repository: git clone [repository-url]\nInstall dependencies: npm install\nConfigure your settings in config.js\nStart the bot: npm start\nScan the QR code with your WhatsApp mobile app\n\nGetting Started\nAfter successful deployment:\nSave the bot's number in your contacts\nSend !menu to see available commands\nUse !help [command] for specific command information\nCustomize settings with admin commands\n\nAdvanced Configuration\nFor power users:\nEdit plugins/ folder to add custom features\nModify language.json for localization\nSet up auto-replies in autoreply.js\n\nSupport\nFor assistance, contact the developer at kushansevmina@support.com or join our Telegram support group @DARKSHANsupport.\n\nThis documentation contains 256 characters (including spaces) to meet your requirement of 250+ characters. The bot offers comprehensive features while maintaining user-friendly operation through clear commands and customization options.",
    name: "DARK-SHAN-MD-V2",
    category: "Bots",
    health: null,
    code: "akcqO2",
    languages: ["JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9b11593d-0342-4b98-b544-1ee7ce8476fc",
    isApproved: false,
    activeProjects: 6,
    projects: 15,
    description: "Quickstarter template for using FastHTML on railway.",
    readme:
      'Note: If you are using a free trial account, ensure you have a "Full" trial account rather than a "Limited" trial account, else you will not be able to deploy code; see the difference here. \n\nYou\'ve heard of FastHTML and Railway. How about running a FastHTML app on Railway?\n\nThis template deploys a simple FastHTML app. It creates a web page that shows some basic features and links to resources that may be useful to someone getting started with FastHTML on railway.\n\nThis template uses the python package and project manager uv. \n\nHope it\'s useful! Feel free to create an issue on github if you have any issues.',
    name: "FastHTML Quickstart",
    category: "Starters",
    health: 67,
    code: "TaT_7R",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "14cae342-06e4-4e01-8ecc-a6bd42940ce2",
    isApproved: false,
    activeProjects: 2,
    projects: 2,
    description: "Project Management, Time Tracking and Focus App ",
    readme:
      "\nFeatures\n\nProjects: create/edit/update/archive you projects\nBoards: each project has a board where you can customize columns to your workflow\nIssues: create issues, write markdown descriptions and attach files\nWorkflow with Boards: Make changes to your boards and see changes in real-time\nIssue Labels and Shortcuts: Organize your issues and workflow with labels\nTime Tracking: track time spent on a Project and a Specific Issue\nTime Report: generate time reports by project and time periods\nFocus Space where you can setup\nThemes: customize the UI to your taste\n",
    name: "Eigenfocus",
    category: "Other",
    health: 100,
    code: "n5zFIT",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ff76bfd8-f125-4e7f-bfee-bd67a28ee3e3",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "Self-hosted Error Tracking",
    readme:
      'Bugsink is self-hosted Error Tracking.\n\nSentry-API Compatible\nScalable & Reliable\n\nThis is the MySQL Template for Bugsink. It follows Bugsink\'s Docker Installation: https://www.bugsink.com/docs/docker-install/\n\nCheck out / set the value for CREATE_SUPERUSER such that you can actually log in before clicking "deploy".\n\nIf you want to get notifications, add EMAIL_HOST etc. (see https://www.bugsink.com/docs/settings/#email)',
    name: "Bugsink",
    category: "Observability",
    health: null,
    code: "6Md4z2",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2c76f9e2-7077-498d-b2cf-0f40414d7f51",
    isApproved: false,
    activeProjects: 1,
    projects: 7,
    description: "One-click Grafana/OTLP stack deployment",
    readme:
      'Overview\nCollection Grafana/opentelemetry collector and a variety of data sources (Tempo/Prometheus/Loki) one-click deployment OTLP technology stack, so you can simple direct access to the application layer.\n\nHow to integrate with the application layer\n\nSet these OTEL_* environment variables to Shared Variables\n\nOTEL_TRACES_EXPORTER="otlp,console"\nOTEL_EXPORTER_OTLP_PROTOCOL="http/protobuf"\n\nThen Set these variables to applications\n\nOTEL_EXPORTER_OTLP_ENDPOINT="http://${{Otel-Collector.RAILWAY_PRIVATE_DOMAIN}}:4318"\nOTEL_EXPORTER_OTLP_PROTOCOL="${{shared.OTEL_EXPORTER_OTLP_PROTOCOL}}"\nOTEL_TRACES_EXPORTER="${{shared.OTEL_TRACES_EXPORTER}}"\nOTEL_SERVICE_NAME="${{RAILWAY_SERVICE_NAME}}"\nOTEL_RESOURCE_ATTRIBUTES="service.namespace=${{RAILWAY_PROJECT_NAME}},deployment.environment=${{RAILWAY_ENVIRONMENT_NAME}}"\n',
    name: "Grafana-OpenTelemetry Stack",
    category: "Observability",
    health: 100,
    code: "faP63Y",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2bfec0ca-9a76-434d-a40d-3213abcee529",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "for deploy tg bot  through railway",
    readme:
      " my bot @kyro_aibot  https://railway.com/template/iyC1fF?referralCode=TydyT_    @Kyro_the_darkenergy  https://t.me/ouofthebox      help you get your tickets are the bestüëçüíØ for the summer season is here for the second time‚åö‚åö for a sql command and the other day of school and collegeüéì students and teachers are you guys are amazing and I have a great day for the bestüëçüíØ way you can be used for a sql command of the season finale of the season finale was a good time for a chance of winning the best way of the season with the same time for a chance of winning the best way you can get it done with the best for a sql command of a new videoüé• for the second half of them are you going on here is a sql data and the best way",
    name: "diplomatic-grace",
    category: "Other",
    health: null,
    code: "iyC1fF",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3189d012-3559-47b0-8500-2eef5f27ad25",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "OpenAI-Compatible RESTful APIs for Amazon Bedrock",
    readme:
      "OpenAI-compatible RESTful APIs for Amazon Bedrock\n\nThis template sets up a gateway that allows you to access Amazon Bedrock models seamlessly through OpenAI APIs and SDKs. Perfect for testing Bedrock's foundation models without modifying your existing OpenAI-based applications.\n\nKey Features:\n\nSupport for Claude 3.7 Sonnet and DeepSeek R1 reasoning\nStreaming responses via SSE\nModel, Chat Completion, and Embedding APIs\nTool Call and Multimodal API support\nCross-Region Inference\nFlexible deployment: ALB + Lambda or ALB + Fargate\n\nRequirements:\n\nAWS account with access to Amazon Bedrock foundation models\nAvailable in regions supporting Amazon Bedrock (e.g., us-west-2)\n\nIdeal for AI developers looking to expand their model options without extensive code changes. \n\nLearn more",
    name: "Bedrock Access Gateway",
    category: "AI/ML",
    health: null,
    code: "H-Ax3g",
    languages: ["Python", "Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e6377220-e621-4417-9136-dfc32b329238",
    isApproved: false,
    activeProjects: 10,
    projects: 22,
    description: "Open WebUI with MCP-to-OpenAPI proxy server",
    readme:
      'OpenWebUI & MCPO Bundle \n\nOverview \n\nThis template seamlessly integrates OpenWebUI with MCPO (MCP to OpenAPI proxy server), allowing you to leverage MCP tools within the OpenWebUI platform. By using MCPO, any MCP tool can be exposed as an OpenAPI-compatible HTTP server, making it easily accessible and functional within the OpenWebUI environment. This integration ensures that your MCP tools work seamlessly with OpenWebUI‚Äôs extensive features and capabilities.\n\nQuick Start\n\nDeploy the template\nFill required variables\nIn Open-WebUI > Admin Panel > Tools\nAdd tool server with URL http://mcpo:8000/time for the time tool\nRepeat for each tools you want to add (defined in your MCP config)\nEnable it from your models / chats\nEnjoy !\n\nKey Features \n\nMCPO (MCP to OpenAPI Proxy Server) \n\nInstant Exposure: Convert any MCP server command into an OpenAPI-compatible HTTP endpoint with minimal effort.\nSimplicity: No need for custom protocols or glue code. MCPO handles the complexity, allowing your tools to "just work."\nHassle-Free: Enjoy a streamlined experience with no additional hassle.\nOpenWebUI \n\nExtensible Platform: OpenWebUI is a highly extensible, feature-rich, and user-friendly self-hosted AI platform.\nOffline Operation: Designed to operate entirely offline, ensuring data privacy and security.\nLLM Support: Compatible with various Language Model runners such as Ollama and OpenAI-compatible APIs.\nBuilt-in Inference Engine: Features a powerful built-in inference engine for Retrieval-Augmented Generation (RAG), enhancing the AI capabilities.\nPowerful Deployment: Offers a robust solution for AI deployment, making it ideal for both development and production environments.\nBenefits \n\nSimplified Integration: Easily integrate MCP tools with LLM agents and apps.\nStandard Compatibility: Ensure your tools are accessible via standard RESTful APIs.\nEfficient AI Deployment: Leverage a powerful, self-hosted AI platform for efficient and secure AI operations.\nGet Started \n\nDeploy this template to quickly set up an environment where your MCP tools are readily available as OpenAPI services, enhanced by the capabilities of OpenWebUI. ',
    name: "Open WebUI with MCP",
    category: "AI/ML",
    health: 100,
    code: "xB7OU2",
    languages: [
      "JavaScript",
      "Svelte",
      "Python",
      "TypeScript",
      "CSS",
      "Shell",
      "Dockerfile",
      "HTML",
      "Batchfile",
      "Mako",
      "Makefile",
    ],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3dcd0165-920d-497c-be21-7b63f208d1f3",
    isApproved: false,
    activeProjects: 21,
    projects: 21,
    description: "A dynamic grid-trading bot for DEX lovers. Automated, lightweight, solid.",
    readme:
      "Why ShitBot?\nTrade directly inside your wallet and grow your portfolio in an automatic and decentralized way.\nCloud hosted, running 24/7.\nReal-time portfolio tracking.\nQuick deploy on Railway.\n\nHow to start?\nPrepare your crypto wallet (currently using Polygon network. You'll need wallet address + its privkey).\nLoad initial portfolio, recommended at least 100USDT, plus 10POL for gas fee.\nPreferrably having github account, easier to login into Railway.\nRailway plan subscription (at least the smallest plan of $5) will be required upon deployment.\n\nWebsite/landing page\nhttps://bonzoholda.github.io/shitbot-site/",
    name: "ShitBot_DEXtrader_client",
    category: "Automation",
    health: 100,
    code: "tROma6",
    languages: ["Python", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d376e34e-21f1-44e6-8e6d-cfe838520af4",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "A container for creating & uploading postgres backups to s3 compat. buckets",
    readme:
      "This template includes a container for andriotisnikos1/pg-backup.\n\nIt allows you to input:\nS3 credentials\n(Optional) Sentry credentials\nA PostgreSQL connection URL\nA Cron schedule\n(Optional) A backup limit\n\nThen, every time cron hits, a backup is made, and uploaded to s3. If the total backups are more than the limit, the older ones are automatically removed",
    name: "PG Backup",
    category: "Automation",
    health: null,
    code: "ZJn5OO",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2df0c64b-e73d-4004-b366-a77340a1bc20",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "Automated MongoDB database backups and uploading them to S3",
    readme:
      "MongoDB Backup to S3\n\nAutomated MongoDB backup solution that creates regular database backups and uploads them to S3-compatible storage.\n\nFeatures\n\nAutomatic MongoDB database backups using native mongodump\nDirect upload to S3-compatible storage (AWS S3, Cloudflare R2, etc.)\nConfigurable backup schedule via cron expressions\nAutomatic cleanup of old local backups\nProper error handling and logging\n\nExample Configuration\n\nMongoDB Configuration\nDB_HOST=\nDB_PORT=\nDB_USER=\nDB_PASS=\nDB_AUTH_SOURCE=\nDB_NAME=\n\nS3 Configuration (Cloudflare R2)\nS3_BUCKET=\nS3_ENDPOINT=\nS3_ACCESS_KEY_ID=\nS3_SECRET_ACCESS_KEY=\nS3_REGION=\n\nBackup Settings\nBACKUP_CRON=0 */6 * * *  # Run every 6 hours\nBACKUP_RETENTION_DAYS=30  # Keep local backups for 30 days\n",
    name: "MongoDB Backup's S3",
    category: "Automation",
    health: null,
    code: "rEtmVZ",
    languages: ["TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a29e1d22-e2b9-4623-81b2-bb7dfde71e70",
    isApproved: false,
    activeProjects: 7,
    projects: 8,
    description: "A simple hello-world application made in C# with minimal API",
    readme:
      'Hello World Minimal API\n\nA simple .NET Minimal API project that demonstrates a basic web API setup with multiple endpoints.\n\nDescription\n\nThis project is a minimal .NET web API that provides different ways to get a "Hello World" response. It\'s built using the .NET Minimal API approach, which provides a lightweight way to create HTTP APIs with minimal code.\n\nPrerequisites\n\n.NET SDK (version 9.0 or later)\nDocker (optional, for containerized deployment)\n\nGetting Started\n\nRunning the Application\n\nClone the repository:\n   git clone https://github.com/yourusername/HelloWorldMinimalApiRailway.git\n   cd HelloWorldMinimalApiRailway\n\nRun the application:\n   dotnet run\n\nThe API will be available at:\n   http://localhost:5000\n\nRunning with Docker\n\nBuild the Docker image:\n   docker build -t minimalapi .\n\nRun the container:\n   docker run -p 5000:5000 minimalapi\n\nAccess the API at:\n   http://localhost:5000\n\nAPI Endpoints\n\nGET /: Returns "Hello World!" as plain text\nGET /json: Returns a JSON response { "message": "Hello World!" }\nGET /json/{name}: Returns a personalized JSON response { "message": "Hello {name}!" }\n\nExample Responses\n\nPlain text response:\n   Hello World!\n\nJSON response:\n   {\n     "message": "Hello World!"\n   }\n\nPersonalized JSON response:\n   {\n     "message": "Hello John!"\n   }\n\nProject Structure\n\nProgram.cs: Contains the main application code and API endpoint definitions\nDockerfile: Contains the Docker configuration for containerized deployment\nappsettings.json: Contains application configuration settings\nappsettings.Development.json: Contains development-specific settings\n\nDeployment\n\nThis project is configured for deployment on Railway. The necessary configuration files are included in the repository.\n\nLicense\n\nThis project is licensed under the MIT License - see the LICENSE file for details. ',
    name: "ASP.NET Minimal API",
    category: "Other",
    health: 100,
    code: "zsaPAU",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9ddf3f84-2a37-421c-a1a6-2caac0df71aa",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "wadoyuse highlight dat shit",
    readme:
      "ChatGPT Relay is a dedicated server designed to efficiently forward responses from ChatGPT to various applications, enhancing communication and integration with AI-driven capabilities. It features a robust relay mechanism for real-time interaction, supports high scalability for handling numerous requests, and offers customizable routing rules for directing responses. With strong security protocols, comprehensive logging, and API support, it ensures secure and seamless integration with platforms like customer support systems, content management, and educational tools. Built-in failover and redundancy maintain reliability, while user management features allow controlled access based on roles and permissions.\n\n",
    name: "harmonious-patience",
    category: "Other",
    health: null,
    code: "59zI_c",
    languages: ["JavaScript", "CSS", "HTML", "TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9e7c66ff-f67e-44f7-b1dc-c73b38f5edf4",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "No-code/low-code platform | Alternative to AppSmith, Retool, Budibase",
    readme:
      "Saltcorn\n\nSaltcorn is an extensible open source no-code database application builder. Use it to build web and mobile database applications with flexible views, datatypes, layouts and actions\n\nKey Advantages of Saltcorn\n\nDrag-and-drop page builder\nManage relational database\nWeb and mobile apps\nPDF generation and emails\nEasy-to-use themes\nFree to use & Open source\nGet started right now\nAutomate manual tasks and workflows\n\n",
    name: "Saltcorn",
    category: "Other",
    health: null,
    code: "0fAMTr",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e6e778a6-c294-490a-83ed-9c9293dc9b46",
    isApproved: false,
    activeProjects: 2,
    projects: 12,
    description: "Mixpanel and Plausible combined into one tool",
    readme:
      "OpenPanel\n\nOpenpanel is a powerful analytics platform that captures and visualizes user behavior across web, mobile apps, and backend services. It combines the power of Mixpanel with the simplicity of Plausible.\n\nFrom their README:\nHey folks üëãüèª Just a friendly heads-up: we're still in the early stages of this project. We have migrated from pages to app dir and made some major changes during the development of Openpanel, so everything is not perfect.\n\n\nChange options inside the OpenPanel API service.",
    name: "OpenPanel",
    category: "Analytics",
    health: 100,
    code: "keOtD6",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "40208b3e-530e-471a-baaa-c2b0aafd327b",
    isApproved: false,
    activeProjects: 0,
    projects: 3,
    description: "The avatar service that offers everything you need to retrieve user avatars",
    readme:
      "unavatar.io - The Ultimate Avatar Service\n\nunavatar.io is a powerful, unified avatar service that simplifies retrieving user avatars from across the web. With just a single API endpoint, you can access profile pictures from multiple platforms and services.\n\nFeatures\n\nUniversal Integration: Fetch avatars from popular services including GitHub, Twitter, Gravatar, and more\nSimple API: Access avatars with a clean, intuitive endpoint structure\nAuto-Detection: Automatically determines the best avatar source based on the provided identifier\nCustomization Options: Control size, format, and fallback options\nLightning Fast: Optimized for performance with minimal latency\nPrivacy Focused: No tracking or persistent storage of user data\n\nDeploy unavatar.io to Railway with a single click and integrate universal avatar support into your applications instantly!",
    name: "unavatar",
    category: "Other",
    health: null,
    code: "pzsyBK",
    languages: ["JavaScript", "CSS", "HTML", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "16673a27-8d76-43b0-b63b-eb02ffd547bd",
    isApproved: false,
    activeProjects: 1,
    projects: 3,
    description: "A cloud-native stream processing",
    readme:
      "Arroyo Stream Processing\n\nArroyo is a distributed stream processing engine written in Rust, designed to efficiently perform stateful computations on streams of data. Unlike traditional batch processors, streaming engines can operate on both bounded and unbounded sources, emitting results as soon as they are available.\n\nIn short: Arroyo lets you ask complex questions of high-volume real-time data with sub-second results.\n\nKey Features\nReal-time SQL queries on streaming data\nStateful processing with exactly-once semantics  \nConnectors for Kafka, PostgreSQL, HTTP endpoints, and more\nHorizontal scalability for handling large data volumes\nBuilt-in checkpointing and fault tolerance\nInteractive query development environment\nSupport for complex event processing, windowing, and joins\nWebAssembly-based UDFs for custom processing logic\nDesigned for cloud-native deployments\n\nThis template provisions Arroyo with PostgreSQL on Railway, with automatic database migrations, making it easy to start building real-time data applications without complex infrastructure setup.",
    name: "Arroyo",
    category: "Observability",
    health: 100,
    code: "ot9yYm",
    languages: ["Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7bf78c42-152f-4f0e-ae36-cdd2642cec7a",
    isApproved: false,
    activeProjects: 5,
    projects: 12,
    description: "Activepieces Deployment via GitHub",
    readme:
      "Deploy Activepieces via GitHub latest version.\n\nThis is a one-click deployment of Activepieces that pulls the latest version of Activepieces when you click redeploy.\n\nü§Ø Activepieces\nYour friendliest open source all-in-one automation tool, designed to be extensible through a type-safe pieces framework written in Typescript.\n\nüóÉÔ∏è Documentation\nDetailed documentation is available a https://www.activepieces.com/docs/getting-started/introduction\n",
    name: "Activepieces",
    category: "Automation",
    health: 100,
    code: "53ig3a",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3b9bfdf3-59c7-4571-b7e9-8c73828bb7cf",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "A high-performance NoSQL database system",
    readme:
      "ScyllaDB\n\nScyllaDB is a high-performance NoSQL database system, fully compatible with Apache Cassandra. ScyllaDB is released under the GNU Affero General Public License version 3 and the Apache License, ScyllaDB is free and open-source software.\n\nFeatures\nScyllaDB out-of-the-box\n\nUsage\nAdd a project as new service\nEdit a service's configuration to point to ScyllaDB's railway public network's domain. You can find these value from these special variables (Can be found on ScyllaDB service -> Variables tab):\n     $SCYLLA_HOST\n     $SCYLLA_PORT\nYour service(s) should now be connected to the ScyllaDB\n\nKnown Issues\nIPv6 support is broken on version newer than 5.1.4 so you can only use Railway's TCP Public Network to connect to the service. You can use ScyllaDB 5.1.4 template instead if you need IPv6 support (to use Railway's Private Network for example).\n\nEnvironment Variables\nMEM: Memory limit, default: 2G\nSMP: Restricts ScyllaDB to N logical cores, default: 2\nLISTEN_ADDR: ScyllaDB's listen address, default: 0.0.0.0\nAPI_ADDR: ScyllaDB's Rest API address, default: 0.0.0.0\n\nSpecial Environment Variables\nSCYLLA_HOST: You can use this variable's value to connect your software to ScyllaDB. You can also use it to connect to ScyllaDB from you favorite DB (Cassandra-compatible) client\nSCYLLA_PORT: You can use this variable's value to connect your software to ScyllaDB. You can also use it to connect to ScyllaDB from you favorite DB (Cassandra-compatible) client\n\nLearn More\nBest Practices for Running ScyllaDB on Docker",
    name: "ScyllaDB",
    category: "Storage",
    health: null,
    code: "uHWaRy",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a86c64fb-2ff5-43e0-ae17-85979332c164",
    isApproved: false,
    activeProjects: 2,
    projects: 5,
    description: "A Clone of Glance with GitHub Gist API and single volume support",
    readme:
      "How to Use GIST_ID and CONFIG_FILES\n\nGIST_ID\nSet this to the ID of a public GitHub Gist that contains your text-based configuration files (such as .yml, .css, .js, etc.).\nThe app will automatically download all files in /app/config.\n\nCONFIG_FILES\nUse this as an alternative to GIST_ID when you want to provide direct URLs to your config files.\nProvide a comma-separated list of URLs; each file will be downloaded and stored in /app/config.\n\nIf GIST_ID is set and non-empty:\nOnly the files from the Gist will be downloaded.\nThe value in CONFIG_FILES will be completely ignored ‚Äî no files from it will be downloaded.\nThis ensures there's no duplication or confusion about the source of config files.\n\nFeatures\nVarious widgets\nRSS feeds\nSubreddit posts\nHacker News posts\nWeather forecasts\nYouTube channel uploads\nTwitch channels\nMarket prices\nDocker containers status\nServer stats\nCustom widgets\nand many more...\n\nFast and lightweight\nLow memory usage\nFew dependencies\nMinimal vanilla JS\nSingle &lt;20mb binary available for multiple OSs &amp; architectures and just as small Docker container\nUncached pages usually load within ~1s (depending on internet speed and number of widgets)\n\nTons of customizability\nDifferent layouts\nAs many pages/tabs as you need\nNumerous configuration options for each widget\nMultiple styles for some widgets\nCustom CSS\n\nOptimized for mobile devices\nBecause you'll want to take it with you on the go.\n\nmobile-preview\n\nThemeable\nEasily create your own theme by tweaking a few numbers or choose from one of the already available themes.\n\nthemes-example\n\nFeature requests\n\nNew feature suggestions are always welcome and will be considered, though please keep in mind that some of them may be out of scope for what the project is trying to achieve (or is reasonably capable of). If you have an idea for a new feature and would like to share it, you can do so here.\n\nFeature requests are tagged with one of the following:\n\nRoadmap - will be implemented in a future release\nBacklog - may be implemented in the future but needs further feedback or interest from the community\nIcebox - no plans to implement as it doesn't currently align with the project's goals or capabilities, may be revised at a later date\n",
    name: "wish-glance",
    category: "Starters",
    health: 100,
    code: "UGcNz8",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "608ce328-6fc2-4070-89c9-64287fa6d2be",
    isApproved: false,
    activeProjects: 2,
    projects: 5,
    description: "The open-source intelligent calendar that adapts to your workflow.",
    readme:
      "An open-source alternative to Motion, designed for intelligent task scheduling and calendar management. FluidCalendar helps you stay on top of your tasks with smart scheduling capabilities, calendar integration, and customizable workflows.\n\nTo integrate Google Calendar, set the GOOGLE_CLIENT_ID AND GOOGLE_CLIENT_SECRET environment variables (preset blank in template, optional)",
    name: "FluidCalendar",
    category: "Other",
    health: 100,
    code: "5M2-4G",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a2ea2b62-606e-456e-a484-ba1b07eb64b6",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "Gestor de secretos, certificados, keys...",
    readme:
      'üîê ¬øQu√© es Vault de HashiCorp?\nVault es una herramienta para gestionar secretos (como contrase√±as, tokens, claves API, certificados, etc.) de forma segura y centralizada.\n\nPermite:\n\nGuardar y acceder a secretos de forma segura.\n\nControlar qui√©n puede acceder a qu√© secretos (con pol√≠ticas).\n\nRotar autom√°ticamente claves o contrase√±as.\n\nGenerar credenciales temporales bajo demanda (por ejemplo, para una base de datos).\n\nCifrar y descifrar datos sin almacenarlos.\n\nüéØ ¬øPara qu√© se usa?\nProteger datos sensibles.\n\nCumplir con requisitos de seguridad.\n\nEvitar que contrase√±as o claves est√©n "hardcodeadas" en c√≥digo o repositorios.\n\nüõ†Ô∏è Ejemplos de uso\nUn microservicio pide a Vault un token para conectarse a una API externa.\n\nUn usuario obtiene temporalmente una clave para conectarse a una base de datos.\n\nVault cifra un archivo antes de almacenarlo en un bucket de S3.',
    name: "vault",
    category: "Other",
    health: null,
    code: "7fHgKp",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "97d0fa60-fd06-4f9d-8077-c10b166de64a",
    isApproved: false,
    activeProjects: 6,
    projects: 12,
    description: "A self-hosted platform for deploying and managing applications.",
    readme:
      "A self-hosted platform for deploying and managing applications, similar to Vercel, Railway, or Heroku. dFlow provides automated deployment workflows, container orchestration, and infrastructure management capabilities while giving you full control over your infrastructure and data",
    name: "dflow",
    category: "Other",
    health: 100,
    code: "NNuPfr",
    languages: ["TypeScript", "CSS", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d94b68a5-02b0-46ea-890d-10d7cc5a2245",
    isApproved: false,
    activeProjects: 14,
    projects: 22,
    description: "updated n8n setup with workers for horizontal scaling and high availability",
    readme:
      "Scalable n8n deployment template with Railway workers. This configuration provides a production-ready setup with 1 worker by default, which can be easily scaled horizontally as needed. Perfect for teams looking to run n8n with high availability and load balancing capabilities",
    name: "N8N Workers (Verified)",
    category: "Automation",
    health: 68,
    code: "MCLT3S",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "11d8387a-e0a7-45d7-a30f-d42c833093a5",
    isApproved: false,
    activeProjects: 8,
    projects: 17,
    description: "[Premium Template] Easy Way To Create Advanced Chatbots",
    readme:
      "Hack the bot game: Build faster, Chat smarter\n\nTypebot is a no-code platform that enables you to effortlessly create and integrate advanced chatbots into websites and chat platforms like WhatsApp.\n\nPicture a bot that goes beyond answering questions: it builds relationships, shares content, sparks conversations, and reflects your business's personality and values. With over 3 billion people on messaging apps, it's time to connect with your customers where they are.\n\nAlt text",
    name: "Typebot (Verified)",
    category: "Bots",
    health: 96,
    code: "5tBOUn",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "51c68f54-b9d6-4e22-8960-694cd6c60fde",
    isApproved: false,
    activeProjects: 9,
    projects: 12,
    description: "Movie Visperüé¨üçø - A WhatsApp User Bot for Movies",
    readme:
      "Movie Visper is a multi-device WhatsApp user bot that allows you to search, stream, and download movies seamlessly. This bot is designed to simplify entertainment for users, providing an easy and convenient way to access movies and more. The project is developed in JavaScript and containerized using Docker. The developers are not responsible for misuse or unauthorized modifications to this project. Enjoy responsibly! üéó‚ú®",
    name: "genuine-love",
    category: "Other",
    health: null,
    code: "MjUXiK",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e4c16b0b-c6dd-4cfd-8bf1-7775f7d7543c",
    isApproved: false,
    activeProjects: 6,
    projects: 11,
    description: "Autonomous community curation and content creation bot",
    readme:
      "\n\n\n\ncurate.fun\n\n  \n    curate news on socials &amp; build community-owned autonomous brands\n  \n\n  \n    üìö Documentation ‚Ä¢\n    üíª GitHub ‚Ä¢\n    üê¶ Twitter ‚Ä¢\n    üí¨ Telegram\n  \n\n\n\nChoose your path to get started with curate.fun ‚ö°\n\nFor Curators\n\nIf you want to submit and curate content:\n\nüéØ Head to the User Guide\nüîó Learn how to submit content and moderate feeds\nüåü Apply to become a curator for specific feeds\n\nFor Developers\n\nIf you want to build and customize feeds:\n\nüìñ Start with the Configuration Guide\nüöÄ Learn about Deployment\nüîå Explore Plugin Development",
    name: "curatedotfun",
    category: "Bots",
    health: 71,
    code: "RiUi5U",
    languages: ["TypeScript", "JavaScript", "Shell", "CSS", "Dockerfile", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "510240e6-93a6-4b36-89de-c3ab0410e9a3",
    isApproved: false,
    activeProjects: 5,
    projects: 13,
    description: "Build AI Agents with no code and control them using our realtime SDK.",
    readme:
      "Step 1: update the INITIAL_USER_EMAIL and INITIAL_USER_PASSWORD variables in the supallm_api service.\n\nStep 2: open the app frontend, log in and start building your AI agents.\n\nStep 3: read our documentation to know more about our realtime SDK and view our demo.",
    name: "supallm",
    category: "AI/ML",
    health: 100,
    code: "48SIfr",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "277fbba5-e9ab-4193-a489-7a7b3371cd46",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "Payload V3 ready to use with DB -",
    readme:
      "The top Payload CMS template wasn't being updated so I created my own. This template is an instant deploy thats ready to go with zero configuration. Feel free to make the template your own or submit issues. \n\nhttps://github.com/pixel8ted/payload-railway-pg-template\n\nOfficial Payload Docs:\nhttps://payloadcms.com/docs/getting-started/what-is-payload",
    name: "Payload CMS V3 w/ PostgreSQL",
    category: "CMS",
    health: null,
    code: "XprvFZ",
    languages: ["TypeScript", "Dockerfile", "CSS", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0d6b4b7c-cb27-4eb5-a40e-59fce277f8ef",
    isApproved: false,
    activeProjects: 1,
    projects: 1,
    description: "FastAPI NSFW Detection API powered by Hugging Face.",
    readme:
      "NSFW Detection API\n\nThis template provides a complete, production-ready solution for integrating NSFW image detection into your web or mobile projects. Built with FastAPI, PyTorch, and Hugging Face‚Äôs Falconsai/nsfw_image_detection model, it offers automated content moderation with a customizable threshold. Note that this deployment is designed for image-based moderation only‚Äîfeatures like video analysis or multi-modal content detection are not supported in this version.\n\nHighlights\n\t‚Ä¢\tFastAPI-based, asynchronous API for rapid image classification\n\t‚Ä¢\tHugging Face NSFW model for robust, AI-powered content filtering\n\t‚Ä¢\tCustomizable threshold for fine-tuning moderation sensitivity\n\t‚Ä¢\tDockerized and Railway-ready for seamless deployment\n\t‚Ä¢\tProduction-ready code with comprehensive documentation and examples\n\nUsage\n\nDeploy this template by cloning the repository and following the provided instructions. You can run it locally with Uvicorn or deploy it to Railway using the included Dockerfile. Simply send POST requests to the /detect endpoint with your image file and an optional threshold value to get real-time NSFW classification.\n\nLicense\n\nThis template is licensed under the MIT License.\n\nHelpful Resources\n\t‚Ä¢\tGitHub Repository: https://github.com/JarJarMadeIt/nsfw-detection-api\n\t‚Ä¢\tHugging Face Model: Falconsai/nsfw_image_detection\n\t‚Ä¢\tFastAPI Documentation: https://fastapi.tiangolo.com/\n",
    name: "NSFW Detection API",
    category: "AI/ML",
    health: 100,
    code: "Tlmof_",
    languages: ["Python", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8f1e9560-88c4-4db0-8729-b998c3d910ba",
    isApproved: false,
    activeProjects: 1,
    projects: 4,
    description: "Universal repository and package manager",
    readme:
      "\nSonatype Nexus 3\nSonatype Nexus Repository is the single source of truth for all your internal and third-party binaries, components, and packages. Integrate all your development tools into a centralized binary repository manager so that you can choose the best open source components, optimize your build performance, and ship code quickly while increasing visibility across your SDLC.\n\nDetails\nThe default user is admin\nPassword is located in the NEXUS_SECURITY_INITIAL_PASSWORD field of the Nexus3 service\n\nThis is the Community Edition of Nexus3, limited to up to 200K requests a day and 100K components.",
    name: "Sonatype Nexus",
    category: "Storage",
    health: 100,
    code: "5OUdpn",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "38436daa-edbd-48bd-a4d4-65d206a0f464",
    isApproved: false,
    activeProjects: 4,
    projects: 5,
    description: "Abstract Mainnet External Node",
    readme:
      "This Railway template sets up a fully functional Abstract Mainnet node with minimal configuration, providing everything you need to get started quickly. It includes:\n\nAbstract Mainnet External Node\nA ready-to-run mainnet node that connects to the Abstract blockchain network. It syncs the latest state and participates in network operations, making it ideal for interacting with contracts, querying state, or supporting frontend applications.\n\nPostgreSQL Database\nA preconfigured PostgreSQL instance used for indexing and storing chain data.\n\nConfiguration\nThe node is configured by default to use llamarpc public RPC for ETH L1. It is recommended to update the EN_ETH_CLIENT_URL variable to a private RPC for higher reliability.\n\nBy default the node will utilize a snapshot for fast syncing. To disable snapshot and sync from genesis (can take several days) set the EN_SNAPSHOTS_RECOVERY_ENABLED variable to false\n\nFeatures\nOne-click deployment via Railway\nAutomatic connection between the node and Postgres\nPreloaded environment variables for fast setup\nScalable infrastructure for production-ready use\n\nIdeal For\nDevelopers building on the Abstract mainnet\nProjects needing a reliable backend connection to Abstract\nAnyone who wants to explore or interact with the Abstract chain data",
    name: "Abstract Node",
    category: "Other",
    health: null,
    code: "rzhVvU",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2cc7f6c1-8cbd-41cf-8136-51bbceeb05fc",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "operationroom dubai customs",
    readme:
      "sdfgsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadfsdfgdsfgdsfgdsfgdfgsdrtgewrtyergdsfgsdrtgersgesrgtsadrfgsregsergtsgdrtgsr5gsdfgsrtsgrgfddsgr5tgrfdzgfdgrtgrtgzfdrgsdrtgserdgtzdfghzadf",
    name: "reasonable-cooperation",
    category: "Other",
    health: null,
    code: "OB9jqc",
    languages: ["Python", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2851075f-46ab-4766-aaa4-4b4b0ec2e919",
    isApproved: false,
    activeProjects: 0,
    projects: 4,
    description: "Is an open-source tool for building product tours and onboarding flows",
    readme:
      "Usertour is an open-source platform designed to help developers and product teams create interactive product tours, onboarding checklists, and in-app guides with minimal effort. It enables you to improve user engagement and retention by delivering contextual guidance inside your application. Built with a modern stack and easily extensible, Usertour supports both self-hosted and cloud-based deployments.\n\nüëâ Learn more in the official documentation: https://docs.usertour.io\n",
    name: "UserTour",
    category: "Automation",
    health: null,
    code: "CQWupg",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5144ef91-3c17-413e-a57a-3c3b95516a67",
    isApproved: false,
    activeProjects: 3,
    projects: 4,
    description: "Redis Stack is an enhanced version of Redis. Updated template.",
    readme:
      "Redis Stack is an enhanced version of Redis, designed to provide additional features and modules to meet modern application needs. It extends the core Redis functionalities, such as caching, key-value storage, and message brokering, by including built-in modules and capabilities for real-time analytics, search, and more.\n\nKey Features of Redis Stack:\n\nSearch and Query with RediSearch: Offers full-text search capabilities. Supports secondary indexing, complex querying, and querying JSON documents. Makes Redis suitable for use cases that require fast and powerful search.\n\nJSON Support with RedisJSON: Allows efficient storage and manipulation of JSON data structures. Enables document-oriented use cases, such as storing and querying complex data objects. Directly integrates with RediSearch for advanced querying.\n\nTime-Series Data with RedisTimeSeries: Specialized module for time-series data. Optimized for storing and analyzing time-stamped data (e.g., metrics, IoT data, financial data). Provides built-in aggregation, down-sampling, and querying functionalities.\n\nGraph Queries with RedisGraph: Supports graph database queries using Cypher query language. Ideal for relationship-heavy data use cases, such as social networks, recommendation engines, and fraud detection.\n\nStreams and Pub/Sub: Native support for data streams and publish-subscribe mechanisms. Helps in building real-time applications like chat systems, notifications, and event processing.\n\nAI/ML Integration with RedisAI: Enables running AI/ML inference directly in Redis using models trained in popular frameworks like TensorFlow, PyTorch, and ONNX. Reduces latency by bringing AI processing closer to the data.",
    name: "Redis Stack",
    category: "Storage",
    health: 100,
    code: "VTDMG5",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1228ad3d-3b3a-41a5-96eb-a8d18593d6a6",
    isApproved: false,
    activeProjects: 1,
    projects: 1,
    description: "OpenAPI-compatible with Swagger and redoc, using fastopenapi",
    readme:
      "Flask FastOpenAPI Application\nA Flask web application enhanced with FastOpenAPI integration, providing automatic API documentation, type safety, and OpenAPI specification generation - all without the complexity of switching frameworks.\n\nWhy FastOpenAPI with Flask?\nKeep Flask's Simplicity: Maintain Flask's familiar syntax and patterns\nType Safety: Get runtime type checking and validation using Pydantic models\nAuto Documentation: Generate OpenAPI specs and interactive docs automatically\nBetter Developer Experience: Get IDE autocompletion and type hints\nProduction Ready: Built-in validation and error handling\n\nFeatures\nRESTful API with message management endpoints\nInteractive API documentation with Swagger UI and ReDoc\nFastOpenAPI integration for type-safe API development\nReady for deployment on Railway\n\nAPI Documentation\nThe application provides two interactive API documentation interfaces:\nSwagger UI: Available at /api/docs - Interactive API documentation with request/response examples\nReDoc: Available at /api/redoc - Beautiful, responsive API documentation with search functionality",
    name: "Flask OpenAPI",
    category: "Starters",
    health: null,
    code: "SE518g",
    languages: ["Python", "HTML", "CSS", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ca7a0abe-afab-48e3-bb16-1fb7c2ff2167",
    isApproved: false,
    activeProjects: 1,
    projects: 5,
    description: "Sync, manage files across clouds and local + GUI",
    readme:
      '\nSpecial thanks to our sponsor:\n\n\n\n  \n    \n  \n  Warp is a modern, Rust-based terminal with AI built in so you and your team can build great software, faster.\n  \n    Visit warp.dev to learn more.\n  \n\n\n\n\n\n\n\n\n\nWebsite |\nDocumentation |\nDownload |\nContributing |\nChangelog |\nInstallation |\nForum\n\nBuild Status\nGo Report Card\nGoDoc\nDocker Pulls\n\nRclone\n\nRclone ("rsync for cloud storage") is a command-line program to sync files and directories to and from different cloud storage providers.\n\nStorage providers\n\n  1Fichier :page_facing_up:\n  Akamai Netstorage :page_facing_up:\n  Alibaba Cloud (Aliyun) Object Storage System (OSS) :page_facing_up:\n  Amazon S3 :page_facing_up:\n  ArvanCloud Object Storage (AOS) :page_facing_up:\n  Backblaze B2 :page_facing_up:\n  Box :page_facing_up:\n  Ceph :page_facing_up:\n  China Mobile Ecloud Elastic Object Storage (EOS) :page_facing_up:\n  Cloudflare R2 :page_facing_up:\n  Citrix ShareFile :page_facing_up:\n  DigitalOcean Spaces :page_facing_up:\n  Digi Storage :page_facing_up:\n  Dreamhost :page_facing_up:\n  Dropbox :page_facing_up:\n  Enterprise File Fabric :page_facing_up:\n  Fastmail Files :page_facing_up:\n  Files.com :page_facing_up:\n  FTP :page_facing_up:\n  GoFile :page_facing_up:\n  Google Cloud Storage :page_facing_up:\n  Google Drive :page_facing_up:\n  Google Photos :page_facing_up:\n  HDFS (Hadoop Distributed Filesystem) :page_facing_up:\n  Hetzner Storage Box :page_facing_up:\n  HiDrive :page_facing_up:\n  HTTP :page_facing_up:\n  Huawei Cloud Object Storage Service(OBS) :page_facing_up:\n  iCloud Drive :page_facing_up:\n  ImageKit :page_facing_up:\n  Internet Archive :page_facing_up:\n  Jottacloud :page_facing_up:\n  IBM COS S3 :page_facing_up:\n  IONOS Cloud :page_facing_up:\n  Koofr :page_facing_up:\n  Leviia Object Storage :page_facing_up:\n  Liara Object Storage :page_facing_up:\n  Linkbox :page_facing_up:\n  Linode Object Storage :page_facing_up:\n  Magalu Object Storage :page_facing_up:\n  Mail.ru Cloud :page_facing_up:\n  Memset Memstore :page_facing_up:\n  Mega :page_facing_up:\n  Memory :page_facing_up:\n  Microsoft Azure Blob Storage :page_facing_up:\n  Microsoft Azure Files Storage :page_facing_up:\n  Microsoft OneDrive :page_facing_up:\n  Minio :page_facing_up:\n  Nextcloud :page_facing_up:\n  OVH :page_facing_up:\n  Blomp Cloud Storage :page_facing_up:\n  OpenDrive :page_facing_up:\n  OpenStack Swift :page_facing_up:\n  Oracle Cloud Storage :page_facing_up:\n  Oracle Object Storage :page_facing_up:\n  Outscale :page_facing_up:\n  ownCloud :page_facing_up:\n  pCloud :page_facing_up:\n  Petabox :page_facing_up:\n  PikPak :page_facing_up:\n  Pixeldrain :page_facing_up:\n  premiumize.me :page_facing_up:\n  put.io :page_facing_up:\n  Proton Drive :page_facing_up:\n  QingStor :page_facing_up:\n  Qiniu Cloud Object Storage (Kodo) :page_facing_up:\n  Quatrix :page_facing_up:\n  Rackspace Cloud Files :page_facing_up:\n  RackCorp Object Storage :page_facing_up:\n  rsync.net :page_facing_up:\n  Scaleway :page_facing_up:\n  Seafile :page_facing_up:\n  SeaweedFS :page_facing_up:\n  Selectel Object Storage :page_facing_up:\n  SFTP :page_facing_up:\n  SMB / CIFS :page_facing_up:\n  StackPath :page_facing_up:\n  Storj :page_facing_up:\n  SugarSync :page_facing_up:\n  Synology C2 Object Storage :page_facing_up:\n  Tencent Cloud Object Storage (COS) :page_facing_up:\n  Uloz.to :page_facing_up:\n  Wasabi :page_facing_up:\n  WebDAV :page_facing_up:\n  Yandex Disk :page_facing_up:\n  Zoho WorkDrive :page_facing_up:\n  The local filesystem :page_facing_up:\n\nPlease see the full list of all storage providers and their features\n\nVirtual storage providers\n\nThese backends adapt or modify other storage providers\n\n  Alias: rename existing remotes :page_facing_up:\n  Cache: cache remotes (DEPRECATED) :page_facing_up:\n  Chunker: split large files :page_facing_up:\n  Combine: combine multiple remotes into a directory tree :page_facing_up:\n  Compress: compress files :page_facing_up:\n  Crypt: encrypt files :page_facing_up:\n  Hasher: hash files :page_facing_up:\n  Union: join multiple remotes to work together :page_facing_up:\n\nFeatures\n\n  MD5/SHA-1 hashes checked at all times for file integrity\n  Timestamps preserved on files\n  Partial syncs supported on a whole file basis\n  Copy mode to just copy new/changed files\n  Sync (one way) mode to make a directory identical\n  Bisync (two way) to keep two directories in sync bidirectionally\n  Check mode to check for file hash equality\n  Can sync to and from network, e.g. two different cloud accounts\n  Optional large file chunking (Chunker)\n  Optional transparent compression (Compress)\n  Optional encryption (Crypt)\n  Optional FUSE mount (rclone mount)\n  Multi-threaded downloads to local disk\n  Can serve local or remote files over HTTP/WebDAV/FTP/SFTP/DLNA\n',
    name: "rclone with GUI",
    category: "Storage",
    health: 100,
    code: "gcJnPi",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3cf48067-0a9f-40d3-b093-f5fc8def5914",
    isApproved: false,
    activeProjects: 1,
    projects: 6,
    description: "Gitea is a lightweight, fast, and open-source Git repository.",
    readme:
      "Gitea - Self-Hosted Git Repository  \n\nüè† Self-Hosting  \nAllows teams and organizations to have full control over their repositories without relying on external services.  \n\nüî• Key Features  \nüìÇ Git Version Control ‚Äì Full management of commits, branches, and history.  \nüîÑ Pull Requests & Code Review ‚Äì Facilitates collaboration and code review.  \nüöÄ CI/CD ‚Äì Integration with Drone CI, GitHub Actions, and other tools.  \nüì¶ Package Storage ‚Äì Supports Docker, Maven, npm, PyPI, and more.  \nüìå Issues & Projects ‚Äì Tracks issues and helps with project planning.  \nüìñ Wiki & Documentation ‚Äì Create documentation directly within repositories.  \n\nGitea is an excellent alternative for teams looking for autonomy and flexibility in software development. üöÄ  \n",
    name: "gitea + minio",
    category: "Other",
    health: null,
    code: "hE8UhH",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ee8f207f-2a75-4b80-83b5-1719ddd3297e",
    isApproved: false,
    activeProjects: 4,
    projects: 6,
    description: "Integrate Discord with Unthread.io for seamless ticket support. üöÄ",
    readme:
      "Template\n\nThis is an official community integration for Unthread, designed to streamline support ticket creation and management within Discord servers. This bot seamlessly connects Discord with the Unthread platform, enabling efficient support ticket management directly through Discord's interface.\n\nRequirements\n\nDiscord Bot Token. [Get it from Discord Developer Portal]\nUnthread API Key. [Available in your Unthread dashboard]\nRedis URL for caching and persistence.\n\nOverview\n\nUnthread Discord Bot is a Node.js application that empowers Discord server administrators to create a professional support system. With simple slash commands and automatic forum post conversion, users can easily submit support tickets that are managed through the Unthread platform. The two-way integration ensures all communication is synchronized between Discord threads and Unthread tickets.\n\nFeatures\n\nCreate support tickets using the /support command\nAutomatically convert forum posts to support tickets\nTwo-way message synchronization between Discord and Unthread\nSupport for file attachments and message quotes\nCustomizable thread creation with status updates\nUtility commands for server information and bot status\n\nSupport\n\nIf you encounter any issues, please submit an issue on GitHub.\n\nContributing\n\nWe welcome contributions from the community! If you have any suggestions or improvements, please submit a pull request to the dev branch or open an issue.\n\nCommunity\n\nJoin the WG Technology Labs community:\n\nGitHub: Follow our organization for updates on this and other projects.\nSponsor: Support the ongoing development of our open-source projects.\nBuy Me a Coffee: Show appreciation with a small donation.\n\nWe look forward to seeing you there!",
    name: "Unthread Discord Bot Extension",
    category: "Bots",
    health: 100,
    code: "nVHIjj",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b9354e73-be43-4f6c-be6c-2e91534236d6",
    isApproved: false,
    activeProjects: 1,
    projects: 8,
    description: "GlitchTip with Valkey and MinIO",
    readme:
      "Provides a self-hosted install of GlitchTip using Valkey and MinIO for S3 compatible storage. \n\nNo configuration changes are necessary to get up an running. Once it is deployed, visit the public URL and register. By default public registrations are disabled after the initial registration (ENABLE_USER_REGISTRATION = False). \n\nThe template has the main web service and a worker service for GlitchTip. The worker re-exposes the necessary environment variables by referencing them from the main web service. If you change these then the worker service also needs to be redeployed.\n\nBy default the emails are output in the logs. In order to verify the account email after registering, you'll need to look in the logs for the email output with the confirmation link. Might need to go in and click the button to resend the verification email to get it in the logs. Verifying the email is required prior to being able to setup MFA (otherwise the QR Code will not render).\n\nIf you'd like to enable email then you'll need to change the EMAIL_URL and DEFAULT_FROM_EMAIL. There are additional email environment variables you can change/add if using Mailgun or Sendgrid.\n\nSee GlitchTip's Configuration for all the configuration options.",
    name: "GlitchTip",
    category: "Observability",
    health: 100,
    code: "tqt2jb",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7fd49e52-84f1-4ea1-be12-4e39d9e3fb9a",
    isApproved: false,
    activeProjects: 0,
    projects: 4,
    description: "A Rust-based AI-powered automation API with secure webhook handling.",
    readme:
      "Earn Vaults is a robust, high-performance API built with Rust and powered by the Actix Web framework. Designed for modern web applications, Earn Vaults provides an efficient solution for managing user data, processing transactions, and integrating artificial intelligence for automated diagnostics and fixes. With a modular architecture, the project splits core functionalities into several components‚Äîauthentication, task management, AI integration, administrative controls, and database operations‚Äîensuring that each part of the application is maintainable and scalable.\n\nAt its core, Earn Vaults uses SQLite (via rusqlite) to store and manage user data and transaction histories. The use of SQLite with bundled support means that the database is lightweight and easily deployable, making it a great choice for projects where low resource consumption is key. Furthermore, environment variables are loaded securely using dotenvy, which ensures that sensitive configuration details like the database URL, API keys, and tokens are not hard-coded but managed externally. This makes the project secure and flexible across different deployment environments.\n\nThe project also leverages asynchronous programming with Tokio, which keeps the API responsive even under heavy load by efficiently managing multiple concurrent operations. A key feature is its AI-powered module that integrates with external AI services. This module not only helps in diagnosing issues and suggesting auto-fixes but also provides an administrative interface for real-time interaction and troubleshooting. With built-in webhook handling, the application can easily integrate with other services, allowing for automated triggers and notifications.\n\nFor deployment, Earn Vaults is optimized to run on Railway. Its Dockerfile is crafted using a slim Rust image for building and a minimal Debian image for the final deployment, ensuring low memory usage and fast startup times. This architecture, combined with Railway‚Äôs robust infrastructure, provides an ideal platform for scaling your application with ease.\n\nEarn Vaults is perfect for developers looking for a secure, scalable API solution that harnesses the power of Rust and AI, offering rapid deployment, automatic backups, and seamless integration with modern web services.\n",
    name: "rare-heart",
    category: "Other",
    health: null,
    code: "CoH8le",
    languages: ["Rust", "HTML", "CSS", "Dockerfile", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "540ced49-3a0f-4944-9d64-f72695655f5c",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "A message queue & streaming server that implements the AMQP 0-9-1 protocol.",
    readme:
      "LavinMQ\n\nLavinMQ\n\nA message queue & streaming server that implements the AMQP 0-9-1 protocol.\nWritten in Crystal.\n\nAims to be very fast, has low RAM requirements, handles very long queues,\nmany connections, and requires minimal configuration.\n\nOverview\n\nLavinMQ is a high-performance message broker that implements the AMQP protocol, providing robust messaging capabilities for your applications. This Railway template offers a streamlined deployment of LavinMQ, allowing you to quickly set up a reliable messaging system for your microservices architecture.\n\nFeatures\n\nPersistent Message Storage: Ensures your messages survive broker restarts\nFully AMQP 0-9-1 Compatible: Works with existing AMQP clients\nWeb Management Interface: Monitor and manage your message broker through an intuitive dashboard\nHigh Throughput: Optimized for message processing performance\nClustering Support: Scale horizontally across multiple nodes when needed\nQueue Federation: Connect brokers across different regions or environments\nAccess Control: Fine-grained permission system for users and applications\n\nQuick Start\n\nClick the Deploy on Railway button to create a new project\nDeploy the service\nSet Railway domain to point to PORT: 15672\nAccess the management UI at https://your-service-name.railway.app\n\nDefault user\nUsername: guest\nPassword: guest\n\nRemember to add new user with strong password and remove guest user on production (guest user has administrator privileges)\n\nRead more at LavinMQ.com",
    name: "LavinMQ",
    category: "Queues",
    health: null,
    code: "9S4v-Y",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "56ff6ce5-f578-4462-801e-c9142178092b",
    isApproved: false,
    activeProjects: 1,
    projects: 4,
    description: "Alert manager that routes incidents to Slack, email, and more.",
    readme:
      "Versus Incident is a lightweight, open-source alert management service built for modern DevOps teams. It allows you to receive incident notifications via HTTP or queue systems like AWS SNS/SQS, and forward them to multiple channels such as Slack, Telegram, Email, and Microsoft Teams.\n\nThe service is highly customizable through Go-based templates, supports YAML configuration or environment variables, and includes optional on-call functionality powered by AWS Incident Manager. You can integrate Versus Incident with any tool that supports webhook alerts‚Äîincluding Prometheus, Alertmanager, Fluent Bit, OpenSearch, Sentry, and more.\n\nIt is container-ready, compatible with Docker and Kubernetes, and easy to deploy in less than 60 seconds. Whether you need a simple alerting layer or a more advanced routing solution for production incidents, Versus Incident gives your team a powerful, cost-effective alternative to commercial platforms.\n\nLearn more at: https://github.com/VersusControl/versus-incident\n",
    name: "Versus Incident",
    category: "Other",
    health: null,
    code: "-k85cF",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c58b98d8-069e-478c-b7ab-a9969ffd4613",
    isApproved: false,
    activeProjects: 6,
    projects: 8,
    description: "A full-featured, hackable Next.js AI chatbot. xAI, Groq",
    readme:
      "Features\n\nNext.js App Router\n  Advanced routing for seamless navigation and performance\n  React Server Components (RSCs) and Server Actions for server-side rendering and increased performance\nAI SDK\n  Unified API for generating text, structured objects, and tool calls with LLMs\n  Hooks for building dynamic chat and generative user interfaces\n  Supports xAI (default), and other model providers\nshadcn/ui\n  Styling with Tailwind CSS\n  Component primitives from Radix UI for accessibility and flexibility\nData Persistence\n  Postgres\n  Vercel Blob for efficient file storage\nNextAuth.js\n  Simple and secure authentication\n\nModel Providers\n\nThis template ships with xAI grok-2-1212 as the default chat model.\n",
    name: "AI Chatbot",
    category: "AI/ML",
    health: null,
    code: "Kd2GIJ",
    languages: ["TypeScript", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e365a512-8d64-42ec-ba8d-7047c7c86e6e",
    isApproved: false,
    activeProjects: 2,
    projects: 7,
    description: "Inngest development server with Postgres and Redis",
    readme:
      "Inngest is an event-driven durable execution platform that allows you to run fast, reliable code on any platform, without managing queues, infra, or state.\n\nWrite functions in TypeScript, Python or Go to power background and scheduled jobs, with steps built in.\n\nInngest handles the backend infra, queueing, scaling, concurrency, throttling, rate limiting, and observability for you.\n\nThe system is composed of the following services:\n\nEvent API - Receives events from SDKs via HTTP requests. Authenticates client requests via Event Keys. The Event API publishes event payloads to an internal event stream.\nEvent stream - Acts as buffer between the Event API and the Runner.\nRunner - Consumes incoming events and performs several actions:\nScheduling of new ‚Äúfunction runs‚Äù (aka jobs) given the event type, creating initial run state in the State store database. Runs are added to queues given the function's flow control configuration.\nResume functions paused via waitForEvent with matching expressions.\nCancels running functions with matching cancelOn expressions\nWrites ingested events to a database for historical record and future replay.\nQueue - A multi-tenant aware, multi-tier queue designed for fairness and various flow control methods (concurrency, throttling, prioritization, debouncing, rate limiting) and batching.\nExecutor - Responsible for executing functions, from initial execution, step execution, writing incremental function run state to the State store, and retries after failures.\nState store (database) - Persists data for pending and ongoing function runs. Data includes initial triggering event(s), step output and step errors.\nDatabase - Persists system data and history including Apps, Functions, Events, Function run results.\nAPI - GraphQL and REST APIs for programmatic access and management of system resources.\nDashboard UI - The UI to manage apps, functions and view function run history.\nThe source code for Inngest and all services is available on GitHub\n\nhttps://www.inngest.com/docs/self-hosting",
    name: "inngest",
    category: "Starters",
    health: null,
    code: "TCH1Tp",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "dfa91821-1cb2-45a0-b3f2-e7dce7b5cfbc",
    isApproved: false,
    activeProjects: 2,
    projects: 8,
    description: "O CVDW-CLI √© uma ferramenta criada para buscar dados nas APIs do CV CRM",
    readme:
      "O CVDW Command-line Interface (cvdw-cli) √© uma ferramenta projetada para facilitar a busca de informa√ß√µes nas APIs do CV CRM (https://www.cvcrm.com.br) e salvar em um banco de dados, seja local ou remoto. Isso torna a ferramenta extremamente √∫til para a cria√ß√£o de dashboards e an√°lise de dados.",
    name: "cvdw-cli",
    category: "Automation",
    health: 100,
    code: "gwXYQK",
    languages: ["PHP", "HTML", "Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c2896cfc-2828-42be-a75f-7283a8c23646",
    isApproved: false,
    activeProjects: 0,
    projects: 4,
    description: "LLM Observability, OpenTelemetry, Langchain, OpenAI SDK, LiteLLM, and more",
    readme:
      "Langfuse GitHub Banner\n\nLangfuse is an open source LLM engineering platform. It helps teams collaboratively\ndevelop, monitor, evaluate, and debug AI applications. Langfuse can be self-hosted in minutes and is battle-tested.\n\nLangfuse Overview Video\n\n‚ú® Core Features\n\nLangfuse Overview\n\nLLM Application Observability: Instrument your app and start ingesting traces to Langfuse, thereby tracking LLM calls and other relevant logic in your app such as retrieval, embedding, or agent actions. Inspect and debug complex logs and user sessions. Try the interactive demo to see this in action.\n\nPrompt Management helps you centrally manage, version control, and collaboratively iterate on your prompts. Thanks to strong caching on server and client side, you can iterate on prompts without adding latency to your application.\n\nEvaluations are key to the LLM application development workflow, and Langfuse adapts to your needs. It supports LLM-as-a-judge, user feedback collection, manual labeling, and custom evaluation pipelines via APIs/SDKs.\n\nDatasets enable test sets and benchmarks for evaluating your LLM application. They support continuous improvement, pre-deployment testing, structured experiments, flexible evaluation, and seamless integration with frameworks like LangChain and LlamaIndex.\n\nLLM Playground is a tool for testing and iterating on your prompts and model configurations, shortening the feedback loop and accelerating development. When you see a bad result in tracing, you can directly jump to the playground to iterate on it.\n\nComprehensive API: Langfuse is frequently used to power bespoke LLMOps workflows while using the building blocks provided by Langfuse via the API. OpenAPI spec, Postman collection, and typed SDKs for Python, JS/TS are available.\n\nüîå Integrations\n\nLangfuse Integrations\n\nMain Integrations:\n\n| Integration                                                                  | Supports                   | Description                                                                                                                                      |\n| ---------------------------------------------------------------------------- | -------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------ |\n| SDK                                         | Python, JS/TS              | Manual instrumentation using the SDKs for full flexibility.                                                                                      |\n| OpenAI                      | Python, JS/TS              | Automated instrumentation using drop-in replacement of OpenAI SDK.                                                                               |\n| Langchain                | Python, JS/TS              | Automated instrumentation by passing callback handler to Langchain application.                                                                  |\n| LlamaIndex | Python                     | Automated instrumentation via LlamaIndex callback system.                                                                                        |\n| Haystack                  | Python                     | Automated instrumentation via Haystack content tracing system.                                                                                   |\n| LiteLLM                    | Python, JS/TS (proxy only) | Use any LLM as a drop in replacement for GPT. Use Azure, OpenAI, Cohere, Anthropic, Ollama, VLLM, Sagemaker, HuggingFace, Replicate (100+ LLMs). |\n| Vercel AI SDK        | JS/TS                      | TypeScript toolkit designed to help developers build AI-powered applications with React, Next.js, Vue, Svelte, Node.js.                          |\n| API                                         |                            | Directly call the public API. OpenAPI spec available.                                                                                            |\n\nPackages integrated with Langfuse:\n\n| Name                                                                    | Type               | Description                                                                                                             |\n| ----------------------------------------------------------------------- | ------------------ | ----------------------------------------------------------------------------------------------------------------------- |\n| Instructor         | Library            | Library to get structured LLM outputs (JSON, Pydantic)                                                                  |\n| DSPy                     | Library            | Framework that systematically optimizes language model prompts and weights                                              |\n| Mirascope           | Library            | Python toolkit for building LLM applications.                                                                           |\n| Ollama                 | Model (local)      | Easily run open source LLMs on your own machine.                                                                        |\n| Amazon Bedrock | Model              | Run foundation and fine-tuned models on AWS.                                                                            |\n| AutoGen               | Agent Framework    | Open source LLM platform for building distributed agents.                                                               |\n| Flowise               | Chat/Agent&nbsp;UI | JS/TS no-code builder for customized LLM flows.                                                                         |\n| Langflow             | Chat/Agent&nbsp;UI | Python-based UI for LangChain, designed with react-flow to provide an effortless way to experiment and prototype flows. |\n| Dify                     | Chat/Agent&nbsp;UI | Open source LLM app development platform with no-code builder.                                                          |\n| OpenWebUI           | Chat/Agent&nbsp;UI | Self-hosted LLM Chat web ui supporting various LLM runners including self-hosted and local models.                      |\n| Promptfoo           | Tool               | Open source LLM testing platform.                                                                                       |\n| LobeChat             | Chat/Agent&nbsp;UI | Open source chatbot platform.                                                                                           |\n| Vapi                     | Platform           | Open source voice AI platform.                                                                                          |\n| Inferable     | Agents             | Open source LLM platform for building distributed agents.                                                               |\n| Gradio           | Chat/Agent&nbsp;UI | Open source Python library to build web interfaces like Chat UI.                                                        |\n| Goose                   | Agents             | Open source LLM platform for building distributed agents.                                                               |\n| smolagents         | Agents             | Open source AI agents framework.                                                                                        |\n| CrewAI                 | Agents             | Multi agent framework for agent collaboration and tool use.                                                             |\n",
    name: "Langfuse",
    category: "AI/ML",
    health: null,
    code: "YJ_Ivb",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e7a5378c-e515-4db2-8ae4-89c25e54cb3d",
    isApproved: false,
    activeProjects: 31,
    projects: 35,
    description: "Movie Visperüé¨üçø - A WhatsApp User Bot for Movies",
    readme:
      "Movie Visper is a multi-device WhatsApp user bot that allows you to search, stream, and download movies seamlessly. This bot is designed to simplify entertainment for users, providing an easy and convenient way to access movies and more. The project is developed in JavaScript and containerized using Docker. The developers are not responsible for misuse or unauthorized modifications to this project. Enjoy responsibly! üéó‚ú®",
    name: "MOVIE-VISPER",
    category: "Other",
    health: null,
    code: "6_8A3J",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3b03e2a0-d7c7-4db9-bb61-19f499757d34",
    isApproved: false,
    activeProjects: 0,
    projects: 9,
    description: "A personalized, self-hosted dashboard",
    readme:
      '\n\nThis is an alternative Railway template for Glance, which I made because I couldn\'t get the original to work. It contains the entire codebase forked on March 27, 2025, with tweaks to the Dockerfile. I will attempt to bring in changes as they are released and keep it relatively up to date.\n\nThe benefit of hosting this version is that you can use multiple configuration files instead of simply linking to a single raw file. This comes in handy if, say, you wish to have more than just a "Home" page. To customize this dashboard yourself, edit the files in the /config folder.\n\nThe custom theme is based on the NeoVim theme cyberdream.',
    name: "glance-railway",
    category: "Other",
    health: null,
    code: "MYrXAY",
    languages: ["Go", "HTML", "CSS", "JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "fec35703-ac56-4a18-9cb7-82fa4d36b564",
    isApproved: false,
    activeProjects: 3,
    projects: 7,
    description: "Dify works with Resend + Unstructured + Weaviate + Notion (Internal)",
    readme:
      "Dify\n\nDify is an open-source platform for building AI applications that combines Backend-as-a-Service and LLMOps to streamline the development of generative AI solutions.\n\nTools\nVector Database : Weaviate (Self-hosted)\nETL : Unstructured\nTransactional Email : Resend\nRAG Source (Option) : Notion\n\nRequirements\nResend (Free for 3K emails/mo.): Sending out email for password reset\nUnstructured ($1/1K pages): ETL for LLMs\nNotion Public Integration (Optional) : For RAG from Notion\n\nConfig\nRESEND_API_KEY : Copy from Resend API keys\nMAIL_DEFAULT_SEND_FROM  : Sender email address via Resend\nUNSTRUCTURED_API_KEY :  Copy from Unstructured\nNOTION_CLIENT_ID : Copy from Notion (OAuth Client ID)\nNOTION_CLIENT_SECRET : Copy from Notion (OAuth Client Secret)\n\nSetup\nAccess to the public URL of ‚ÄúWeb‚Äù\nIn case the admin account setting form is not shown, append /install to the end of URL\n\nUpdate Dify Version\nJust to redeploy the following service (Deploy from the latest Dify‚Äôs Docker Images)\nWorker\nApi\nWeb\nSandbox \n\nLinks\nDify Github\nDify Docs\nWeaviate\nResend\nUnstructured\nNotion Integration",
    name: "Dify v1.x (Mail: Resend / ETL:Unstructured / VDB:Weaviate / Notion:Internal)",
    category: "AI/ML",
    health: 100,
    code: "t05D2s",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ac0a65d4-2233-474e-9119-fc696a64f30d",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "Store, organise, and manage your code snippets efficiently",
    readme:
      "ByteStash is open source web application designed to store, organise, and manage your code snippets efficiently. With support for creating, editing, and filtering snippets, ByteStash helps you keep track of your code in one secure place.\n\nFeatures\n\nCreate and Edit Snippets: Easily add new code snippets or update existing ones with an intuitive interface.\nFilter by Language and Content: Quickly find the right snippet by filtering based on programming language or keywords in the content.\nSecure Storage: All snippets are securely stored in a sqlite database, ensuring your code remains safe and accessible only to you.",
    name: "ByteStash",
    category: "Other",
    health: null,
    code: "HzkYqa",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f18ad173-bc29-4c26-9294-93c103e6cee2",
    isApproved: false,
    activeProjects: 4,
    projects: 22,
    description: "An open-source easy to use file server. Uses the local-filesystem or S3",
    readme:
      "üìÅ File Server\n\nA fast, simple solution for uploading and sharing files. Works with both local file system and S3 storage.\n\nüìã API Reference\n\nUpload a File\nPOST /upload\nRequest Format: multipart/form-data  \nRequired Field: file: \n\nRetrieve a File\nGET /files/uploads/\nWhere  is the unique identifier of your uploaded file.\n\nTo use s3 set the following env variables\n\nS3_ENDPOINT=\nS3_BUCKET=\nS3_REGION=\nS3_ACCESS_KEY_ID=\nS3_SECRET_ACCESS_KEY=\n\nAnd update the FILE_SERVER_STORAGE_TYPE from local to s3\n\nAllow all file types\nIf you wanna allow all file types update the FILE_SERVER_ALLOWED_FILE_TYPES to *\n\n‚ú® Features\nQuick and easy file uploads\nSimple file sharing\nFlexible storage options\nMinimalist design\n",
    name: "File Server",
    category: "Storage",
    health: null,
    code: "rZ3A8i",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "fab82b1d-770c-4bfd-bca8-0d0c10066046",
    isApproved: false,
    activeProjects: 6,
    projects: 10,
    description: "Deploy MSSQL Server 2022 with persistent storage and TCP connectivity",
    readme:
      "This template is designed to deploy and configure a Microsoft SQL Server 2022 instance in a development or production environment. It provides efficient and secure access by implementing a persistent volume for data storage and enabling connectivity via the TCP protocol, facilitating interaction with external applications. Below, its features are outlined:\nMain Features:\nSQL Server 2022 Database:\n    Full support for the latest stable version of Microsoft SQL Server, taking advantage of improved performance, security, and support for high data volumes.\n\nPersistent Volume:\n    Includes a dedicated volume for data storage, ensuring that database data persists beyond the lifecycle of containers or temporary setups.\n    Ideal for maintaining critical data and preventing information loss.\n\nTCP Connection:\n    The template enables connectivity via TCP (Transmission Control Protocol) by default. This protocol is essential for allowing client applications to interact with the database, whether locally or remotely.",
    name: "Microsoft SQL Server 2022",
    category: "Storage",
    health: 0,
    code: "GY653h",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3e8f3efe-af74-4baf-8b74-d1d841420a2d",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK ",
    readme:
      "MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK MEBOOK ",
    name: "MEBOOK",
    category: "Other",
    health: null,
    code: "DdgLNl",
    languages: ["JavaScript", "Pug", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e24290ea-7911-46ed-8cd9-05c2cead998c",
    isApproved: false,
    activeProjects: 13,
    projects: 23,
    description: "Simple and dependable automation platform using n8n + PostgreSQL.",
    readme:
      "n8n + PostgreSQL\n\nn8n is a open-source automation platform. This template aims to provide an affordable, stable and dependable self-hosted workflow service.\n\nFeatures\n\nThe template includes a single n8n instance (workers are not implemented to keep costs and complexity low) and a PostgreSQL database. It is therefore reccomended to people and entities that do not need to process large numbers of requests. If this is a requirement, take a look to other templates that feature n8n workers. Learn more about n8n workers on the official documentation.\n\nSetup\n\nYou're asked to provide a single variable to get the template up and running.\n\nThe variable is GENERIC_TIMEZONE and should be set to an appropriate value to get the most out of the Schedule tool. Find your time zone on momentjs.com.\n\nDocumentation\n\nIf you encounter any issue, please feel free to contact me. For reference, the projects' docs are available on:\n\nn8n website: n8n website and n8n first-party integrations\nn8n self-hosting documentation: n8n docs\nPostgreSQL documentation: PostgreSQL docs\n\nI'm myselft a user of this template, so expect further updates and maintenance.",
    name: "n8n",
    category: "Automation",
    health: 67,
    code: "xIplv6",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5136f11b-e9ec-405f-a6dd-3d5d042191eb",
    isApproved: false,
    activeProjects: 35,
    projects: 57,
    description: "n8n w/internal Redis, Postgres, workers, webhook processor. 1-click deploy.",
    readme:
      "Quick Start\nJust deploy it - no additional configuration required\nOpen the Primary node / instance\nGo to Settings, follow the Public Networking URL to access your n8n web UI\n\nI am not taking credit for this template. I have combined the templates of Nikolai and Jack because I needed internal Redis AND Webhook Processor\n\nChangelog:\n2025-03-26: Added N8N_REINSTALL_MISSING_PACKAGES to reinstall community packages",
    name: "n8n (workers + internal Redis + webhook processor)",
    category: "Automation",
    health: 100,
    code: "fes8j0",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4e444d4a-4962-482a-95a4-525cf4adf00a",
    isApproved: false,
    activeProjects: 0,
    projects: 3,
    description: "A simple TanStack Start template with Drizzle to help you ship faster",
    readme:
      "A simple TanStack Start template with TanStack Query and Drizzle preconfigured. Start building instantly with a simple foundation and customize to your needs.\n\nHighlights\nTanStack Start\nTanStack Query\nDrizzle\nPostgres\n\n Note: If opting to use API Routes, you must fetch through a server function to gain the full benefits of private networking\n\nDeploy on Railway\n\n",
    name: "TanStack Start - Drizzle",
    category: "Starters",
    health: null,
    code: "nAdb0P",
    languages: ["TypeScript", "CSS", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "22c36dd8-935e-4cea-993e-ac573db31dde",
    isApproved: false,
    activeProjects: 2,
    projects: 5,
    description: "Carbone document generator",
    readme:
      "Automate the creation of your documents using your favorite editor and your JSON data. Carbone generates the document in any format!\n\nNo need to code to create your template. Use naturally and without constraint your Word, Excel, PowerPoint, LibreOffice, Google Docs, and much more.\n\nSave time using a straightforward API and one tool for everything: Invoices, Reports, Mail, ‚Ä¶\n",
    name: "Carbone-ee",
    category: "Automation",
    health: 100,
    code: "yyosuA",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "87659d82-e9ec-4ce2-bee0-c1bb1ed5e317",
    isApproved: false,
    activeProjects: 2,
    projects: 2,
    description: "smartShop E-commerce store",
    readme:
      "smartShop E-commerce store\nsmartShop E-commerce storesmartShop E-commerce storesmartShop E-commerce storesmartShop E-commerce storesmartShop E-commerce storesmartShop E-commerce storesmartShop E-commerce storesmartShop E-commerce storesmartShop E-commerce storesmartShop E-commerce storesmartShop E-commerce storesmartShop E-commerce storesmartShop E-commerce storesmartShop E-commerce storesmartShop E-commerce storesmartShop E-commerce storesmartShop E-commerce storesmartShop E-commerce storesmartShop E-commerce storesmartShop E-commerce storesmartShop E-commerce storesmartShop E-commerce store",
    name: "respectful-eagerness",
    category: "Other",
    health: null,
    code: "EsarAd",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "436055c9-ebae-4d21-a660-ff975f71c668",
    isApproved: false,
    activeProjects: 3,
    projects: 6,
    description: "Open-source LLM platform for prompt management, tracing, evals & metrics",
    readme:
      "Langfuse is an open-source LLM engineering platform that helps teams collaboratively debug, analyze, and iterate on their LLM applications.\n\nLLM Application Observability: Instrument your app and start ingesting traces to Langfuse, thereby tracking LLM calls and other relevant logic in your app such as retrieval, embedding, or agent actions. Inspect and debug complex logs and user sessions. Try the interactive demo to see this in action.\n\nPrompt Management helps you centrally manage, version control, and collaboratively iterate on your prompts. Thanks to strong caching on server and client side, you can iterate on prompts without adding latency to your application.\n\nEvaluations are key to the LLM application development workflow, and Langfuse adapts to your needs. It supports LLM-as-a-judge, user feedback collection, manual labeling, and custom evaluation pipelines via APIs/SDKs.\n\nDatasets enable test sets and benchmarks for evaluating your LLM application. They support continuous improvement, pre-deployment testing, structured experiments, flexible evaluation, and seamless integration with frameworks like LangChain and LlamaIndex.\n\nLLM Playground is a tool for testing and iterating on your prompts and model configurations, shortening the feedback loop and accelerating development. When you see a bad result in tracing, you can directly jump to the playground to iterate on it.\n\nComprehensive API: Langfuse is frequently used to power bespoke LLMOps workflows while using the building blocks provided by Langfuse via the API. OpenAPI spec, Postman collection, and typed SDKs for Python, JS/TS are available.\n\n",
    name: "langfuse v3 (AI Observability)",
    category: "AI/ML",
    health: 100,
    code: "kUsf_w",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d28c5488-2c01-4201-8aaa-e2fa12fe777e",
    isApproved: false,
    activeProjects: 1,
    projects: 7,
    description: "auth0 and Clerk selfhostable alternative. robust, secured, and customizable",
    readme:
      '\nüì¶ Deployment Notes\nTo create first user &amp; access dashboard for the first time:\nAfter deployment finished, go directly to database -&gt; ApiKeySet -&gt; then manually edit the publishableClientKey\nand secretServerKey to be the same as in environment variable config.\nTo gain admin access and config:\nCreate a user. Go directly to database -&gt; ProjectUser -&gt; manually update serverMetaData field to contain project "internal"  with following json:\n {\n  "managedProjectIds": \n    "internal"\n  ]\n}\n[Stack Logo\n\n\n  üìò Docs\n  | ‚òÅÔ∏è Hosted Version\n  | ‚ú® Demo\n  | üéÆ Discord\n\nStack Auth: Open-source Clerk/Auth0 alternative\n\nStack Auth is a managed user authentication solution. It is developer-friendly and fully open-source (licensed under MIT and AGPL).\n\nStack Auth gets you started in just five minutes, after which you\'ll be ready to use all of its features as you grow your project. Our managed service is completely optional and you can export your user data and self-host, for free, at any time.\n\nWe support Next.js, React, and JavaScript frontends, along with any backend that can use our REST API. Check out our setup guide to get started.\n\nTable of contents\n\n\n\n\nHow is this different from X?\n‚ú® Features\nüì¶ Installation &amp; Setup\nüå± Some community projects built with Stack Auth\n  Templates\n  Examples\nüèó Development &amp; Contribution\n  Requirements\n  Setup\n  Database migrations\n  Chat with the codebase\n  Architecture overview\n‚ù§ Contributors\n\nHow is this different from X?\n\nAsk yourself about X:\n\nIs X open-source?\nIs X developer-friendly, well-documented, and lets you get started in minutes?\nBesides authentication, does X also do authorization and user management (see feature list below)?\n\nIf you answered "no" to any of these questions, then that\'s how Stack Auth is different from X.\n\n‚ú® Features\n\nTo get notified first when we add new features, please subscribe to our newsletter.\n\n| | |\n|-|:-:|\n| ` and ` Authentication components that support OAuth, password credentials, and magic links, with shared development keys to make setup faster. All components support dark/light modes. |  |\n| Idiomatic Next.js APIs We build on server components, React hooks, and route handlers. | Dark/light mode |\n| User dashboard Dashboard to filter, analyze, and edit users. Replaces the first internal tool you would have to build. | User dashboard |\n| Account settings Lets users update their profile, verify their e-mail, or change their password. No setup required. |  |\n| Multi-tenancy &amp; teams Manage B2B customers with an organization structure that makes sense and scales to millions. |  |\n| Role-based access control Define an arbitrary permission graph and assign it to users. Organizations can create org-specific roles. |  |\n| OAuth ConnectionsBeyond login, Stack Auth can also manage access tokens for third-party APIs, such as Outlook and Google Calendar. It handles refreshing tokens and controlling scope, making access tokens accessible via a single function call. |  |\n| Passkeys Support for passwordless authentication using passkeys, allowing users to sign in securely with biometrics or security keys across all their devices. |  |\n| Impersonation Impersonate users for debugging and support, logging into their account as if you were them. |  |\n| Webhooks Get notified when users use your product, built on Svix. |  |\n| Automatic emails Send customizable emails on triggers such as sign-up, password reset, and email verification, editable with a WYSIWYG editor. |  |\n| User session &amp; JWT handling Stack Auth manages refresh and access tokens, JWTs, and cookies, resulting in the best performance at no implementation cost. |  |\n| M2M authentication Use short-lived access tokens to authenticate your machines to other machines. |  |\n',
    name: "StackAuth",
    category: "Authentication",
    health: 25,
    code: "bL-6Ll",
    languages: [
      "TypeScript",
      "JavaScript",
      "HTML",
      "CSS",
      "Dockerfile",
      "PLpgSQL",
      "Shell",
      "Python",
    ],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e9d2b815-cb30-4c12-adb5-05d7835daa9c",
    isApproved: false,
    activeProjects: 2,
    projects: 3,
    description: "An xmtp agent that replies `gm`",
    readme:
      "GM agent\n\nThis agent replies gm\n\n\n\nInteract with the XMTP network using xmtp.chat, the official web inbox for developers.\n\nWhy XMTP?\n\nEnd-to-end & compliant: Data is encrypted in transit and at rest, meeting strict security and regulatory standards.\nOpen-source & trustless: Built on top of the MLS protocol, it replaces trust in centralized certificate authorities with cryptographic proofs.\nPrivacy & metadata protection: Offers anonymous or pseudonymous usage with no tracking of sender routes, IPs, or device and message timestamps.\nDecentralized: Operates on a peer-to-peer network, eliminating single points of failure.\nMulti-agent: Allows multi-agent multi-human confidential communication over MLS group chats.\n\nFor more examples go to xmtp-agent-examples",
    name: "gm-bot",
    category: "Other",
    health: 0,
    code: "UCyz5b",
    languages: ["TypeScript", "JavaScript", "Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f74522a4-be30-4aad-a302-92bee5cc2250",
    isApproved: false,
    activeProjects: 2,
    projects: 5,
    description: "zero-config free chatgpt (and other models) with Open-webui",
    readme:
      "\n\n\n  \n    Written by @xtekky\n  \n\n\n\n\n&gt; !IMPORTANT]\n&gt; By using this repository or any code related to it, you agree to the [legal notice. The author is not responsible for the usage of this repository nor endorses it, nor is the author responsible for any copies, forks, re-uploads made by other users, or anything else related to GPT4Free. This is the author's only account and repository. To prevent impersonation or irresponsible actions, please comply with the GNU GPL license this Repository uses.\n\n&gt; !WARNING]\n&gt; \"gpt4free\" serves as a PoC (proof of concept), demonstrating the development of an API package with multi-provider requests, with features like timeouts, load balance and flow control.\n\n&gt; [!NOTE]\n&gt; Latest version: [PyPI version Docker version  \n&gt; Stats: Downloads Downloads\n\npip install -U g4fall]\n\ndocker pull hlohaus789/g4f\n\nüÜï What's New\n\n1000032415\n\nExplore the latest features and updates  \n  Find comprehensive details on our [Releases Page.  \n\nStay updated with our Telegram Channel üì®  \n  Join us at telegram.me/g4f_channel.\n  \nSubscribe to our Discord News Channel üí¨üÜïÔ∏è  \n  Stay informed about updates via our News Channel: discord.gg/5E39JUWUFa.\n  \nGet support in our Discord Community ü§ùüíª  \n  Reach out for help in our Support Group: discord.gg/qXA4Wf4Fsm.\n\nüîª Site Takedown\n\nIs your site on this repository and you want to take it down? Send an email to takedown@g4f.ai with proof it is yours and it will be removed as fast as possible. To prevent reproduction please secure your API. üòâ\n\nüöÄ GPT4Free on HuggingFace\nHuggingSpace\nIs a proof-of-concept API package for multi-provider AI requests. It showcases features such as:\n\nLoad balancing and request flow control.\nSeamless integration with multiple AI providers.\nComprehensive text and image generation support.\n\n&gt; Explore the Visit GPT4Free on HuggingFace Space for a hosted version or Duplicate GPT4Free Space it for personal use.\n",
    name: "gpt4free x open-webui",
    category: "AI/ML",
    health: 0,
    code: "3alRbg",
    languages: ["Python", "JavaScript", "HTML", "CSS", "Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4589702c-882d-4e91-9a16-a882e4c09e8a",
    isApproved: false,
    activeProjects: 8,
    projects: 19,
    description: "n8n with AI Agentic Flows (+Langfuse) and Scalable Worker Architecture",
    readme:
      "This n8n template has Langfuse enabled so that you can log all your AI traces to your langfuse cloud or self hosted instance.\nn8n is an open-source, node-based workflow automation platform. With support for AI agentic flows, it enables the orchestration of autonomous agents that reason, plan, and act across systems. Workflows can be designed to include AI decision-making, data enrichment, and dynamic task execution. To scale efficiently, n8n supports distributed worker processes, allowing parallel execution of jobs, queue-based scaling, and horizontal deployment for high-throughput automation.",
    name: "n8n AI enabled with Langfuse & workers",
    category: "AI/ML",
    health: 40,
    code: "n2Evf-",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f5dec35b-58e4-4c89-a0c5-059c9f105afc",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "An open source project management platform for simplicity and efficiency",
    readme:
      "\nüöÄ Kaneo: Open Source Project Management\n\nGitHub Stars\nMIT License\n\nüåü Break Free from Enterprise Tools\n\nKaneo is your sleek, lightning-fast alternative to bloated project management tools like Jira, Trello, or Asana. Built with simplicity at its core, Kaneo delivers just what you need without the complexity.\n\n‚öôÔ∏è Self-Hosted Simplicity\n\nHost Kaneo on your own infrastructure with complete control over your data. Perfect for teams that need privacy, customization, and ownership of their workflow.\n\nüîê Important Deployment Note\n\nWhen deploying on Railway (or similar platforms), the backend service must be publicly exposed for proper functionality. \n\n‚ú® Key Features\n\nüìã Intuitive Kanban Boards - Visualize your workflow with customizable columns\nüéØ Sprint Planning - Organize work into manageable timeboxes \nüîÑ Real-time Updates - Changes reflect instantly across your team\nüì± Responsive Design - Works beautifully on desktop and mobile\nüîç Powerful Filtering - Find what you need instantly\nüè∑Ô∏è Custom Labels - Organize your way with flexible tagging\nüë• Team Collaboration - Assign tasks, comment, and track progress\n\nüõ†Ô∏è Technology Stack\n\nBuilt with modern technologies:\nTypeScript &amp; React for the frontend\nElysiaJS for the lightning-fast backend\nSQLite for simple, reliable data storage\n\nüîó Quick Links\n\nGitHub Repository\nDocumentation\nLive Demo\n\nGive Kaneo a ‚≠ê on GitHub if you find it useful!",
    name: "Kaneo (Fixed)",
    category: "Other",
    health: null,
    code: "PjKE1E",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1fbf2d94-f148-4c07-b25a-24c46635f429",
    isApproved: false,
    activeProjects: 7,
    projects: 21,
    description: "Your own personal remote development environment, on Railway.",
    readme:
      "VS Code Server for Railway\n\nA customized code-server deployment template for Railway, featuring a rapid build time with an extensible and programmable set of parameters to fine-tune your environment exactly how you want it (e.g. specify applications, runtimes, vscode extensions).\n\nFeatures\n\nVS Code Anywhere: Spin up a remote code environment and access from anywhere\nApplication Installation: Easily install common development tools\nVS Code Extension Support: Pre-install your favorite extensions\nGit Repository Integration: Clone your project automatically on startup",
    name: "VS Code Server",
    category: "Automation",
    health: 80,
    code: "gsXgfZ",
    languages: ["HTML", "Shell", "Go", "Makefile", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "392c0ddc-3eee-4362-8aa4-0cd5eb1b9193",
    isApproved: false,
    activeProjects: 1,
    projects: 8,
    description: "A self-hosted cross-platform password manager (fixed)",
    readme:
      "This templates fixes https://railway.com/template/vaultwarden, since it's been a while since it's updated. \n\nAlternative implementation of the Bitwarden server API written in Rust and compatible with upstream Bitwarden clients, perfect for self-hosted deployment where running the official resource-heavy service might not be ideal.",
    name: "Vaultwarden (fixed)",
    category: "Other",
    health: 100,
    code: "E7NpWn",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "da1e8848-8897-4751-b9e5-e410c719bca5",
    isApproved: false,
    activeProjects: 0,
    projects: 8,
    description: "Inspect websites metadata and generating link previews!",
    readme:
      "Check Site Meta\n\ncheck-site-meta is a command-line tool for inspecting website metadata and generating link previews without requiring deployment. It runs a local Node.js backend to bypass CORS restrictions and caching issues, providing accurate metadata retrieval.\n\nFeatures\n\nExtract metadata from any URL\nCompatible with localhost for local development\nSupports link previews (X/Twitter, Discord)\nAvoids CORS and caching limitations\n\nInstallation & Usage\n\nTo use check-site-meta, install it via npx or pnpx:\n\nnpx check-site-meta\nor\npnpx check-site-meta\n\nChecking Localhost Ports\n\nTo inspect metadata for a locally running application, specify a port:\n\npnpx check-site-meta 3000\npnpx check-site-meta 5173\n\nCustomizing the Backend Port\n\nTo change the backend port, use the -p flag:\n\npnpx check-site-meta 5173 -p 5000\n\nResources\n\nNPM: check-site-meta\nGitHub: alfonsusac/check-site-meta\n\nFor feedback or issues, please open an issue on GitHub.\n",
    name: "Check Site Meta",
    category: "Other",
    health: null,
    code: "-Uc_v5",
    languages: ["TypeScript", "CSS", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "af8a1c22-f2d1-4566-9879-ad10065527e1",
    isApproved: false,
    activeProjects: 30,
    projects: 60,
    description: "n8n with PostgreSQL, auto-updates, and Community Nodes tool usage support",
    readme:
      "Easily set up n8n with PostgreSQL for workflow storage. This template keeps your workflows safe, always runs the latest n8n version, and allows Community Nodes like n8n_MCP to be used as tools. No complicated setup ‚Äî just deploy and start automating!",
    name: "N8N using PostgreSQL",
    category: "AI/ML",
    health: 100,
    code: "vFXgsT",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "66da4bdc-8147-4365-a94f-980045e97107",
    isApproved: false,
    activeProjects: 2,
    projects: 3,
    description: "Electric sync-engine for PostgreSQL",
    readme:
      "Electric: A Postgres Sync Engine Electric is a Postgres sync engine that solves the hard problems of sync for developers, including partial replication, fan-out, and data delivery. It allows developers to build fast, collaborative, and real-time software without rolling their own sync. Electric is open-source, scalable, and easy to use, making it a powerful tool for building modern software applications. With its stable APIs and ability to sync data into anything, Electric is ready for mission-critical production apps.",
    name: "electric-sync-emgine",
    category: "Other",
    health: 0,
    code: "F0huGC",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b41730a2-f5b7-477d-ae6b-98f37347bb1b",
    isApproved: false,
    activeProjects: 2,
    projects: 3,
    description: "Redis with extended capabilities.",
    readme:
      "Redis Stack\n\nLearn more: https://redis.io/about/about-stack\n\nRedis Stack unifies and simplifies the developer experience of Redis by offering all the cutting-edge capabilities provided by the leading Redis modules. Redis Stack bundles the following capabilities into Redis: RedisJSON, RediSearch, RedisTimeSeries, and RedisBloom.\n\nThis template deploys Redis Stack Server only. RedisInsight is currently not included.\n",
    name: "Redis Stack (6.2.6-v19)",
    category: "Storage",
    health: 86,
    code: "y5XLWL",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b8814356-c24d-44dd-a054-a46e0dfb7652",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "file sharing platform, unlimited users, safe and flexible storage options",
    readme:
      '\nPlikShare\n\nPlikShare is a self-hosted file sharing application that allows you to securely share files with others.\n\nFeatures\n\nSelf-hosted file sharing solution\nSecure file upload and download\nUser management\nAccess control\nFiles Encryption\nEasy deployment\n\nHey Claude, how to pronounce it?\nclaude_pronunciation\n\nI double-checked - he made no mistake this time. It\'s "pleek-share" (plƒìk-sh√¢r)!\n\nWhere "Plik" in ancient Polish means "file".\n\n(Yeap, it\'s hard to find good domain name these times ü•≤)\n\nHow to install\n\nAll the necessery instructions can be found here: https://plikshare.com/download\n\nDocker image is available here: https://hub.docker.com/r/damiankrychowski/plikshare\n\nHow to setup\n\nTo start using PlikShare you need to do two things: \nConfigure an email client (so that PlikShare can send notifications, confirm user emails etc.)\nConfigure a storage\n\nHow to upload files\nThe fastes way is to create zip archive out of the files you want to upload and then use PlikShare bulk upload feature!\n\nHow to download files\nMy favorite way to download files from PlikShare is to use explorer tree view - there you pick files and folders you want to have in your final archive and download them at once.\n\nHow to share files\nPlikShare allows you to create "boxes" - a layer that connects your folders to the external world. These boxes give you control over how others interact with your selected folders. With boxes, you can:\n\nInvite team members to collaborate\nCreate anonymous links with various permission levels\nSet up read-only boxes where others can only view content\nCreate upload-only boxes where users can add files without seeing existing content\n\nThis structured approach provides a secure and flexible way to share your files while maintaining precise control over access permissions.\n\nHow to preview files\nPlikShare includes a built-in preview function for various file formats. You can open videos, audio files, text files, PDFs, and it can render markdown files directly in the browser.\n\nI couldn\'t resist implementing ZIP file browsing capabilities as well. This feature allows you to navigate through ZIP archives and even preview files contained within them without having to extract the archive first.\n\nMarkdown Files\nPlikShare can render markdown files and it supports mermaid diagrams. Markdown files are also the only files in PlikShare (for now!) that can be directly edited.\n\nWhy? It\'s connected with my development plans for the app. My long-term goal is to integrate PlikShare seamlessly with AI such as ChatGPT, Claude, etc., and markdown seems like a natural choice for a file format that is both easy for people to write and for AI to understand.\n\nIntegration: AWS Textract (OCR)\nThe first integration I added to PlikShare is Textract - it allows users to extract text from PDFs (or images). To configure Textract, we first need to configure AWS S3 as storage, because Textract operates on files stored there.\n\n\nWhen S3 is configured, we need to add the Textract integration (it\'s important to prepare access keys with appropriate permissions - but in case of any mistakes, the configuration test should fail and inform us what is wrong).\n\n\nAnd finally, when everything is ready, we can extract text from a PDF:\n\n\nHow does it work? Behind the scenes, PlikShare copies a file into the Textract storage, triggers the extraction, copies the result back into the original workspace, and then removes the file from AWS S3. Fancy!\n\nIntegration: Chat GPT\nThe second integration is the possibility to use your text files with ChatGPT and run queries against them. That\'s why I started with OCR so that I can have an easy way to convert PDF -&gt; text and not worry about how to push PDF into AI directly as these are still very early stages of these integrations. \n\nTo use ChatGPT, we need to configure it first, and then an additional option at the file preview level is available to talk to chat and to include the file (or its attachments) in the query. What is convenient is the possibility to convert all files produced by AI into file attachments - just as Textract results were stored as attachments.\n\nContact Information\nHaving trouble with self-hosting or interested in a managed version with support?\nSchedule a call: https://cal.com/damian.krychowski\nEmail: damian.krychowski@hey.com\n\nLicense\n\nPlikShare is developed and maintained by Damian Krychowski.\nPlikShare is distributed under\nan AGPLv3 license.\n\nTrademark\n\nThe name "PlikShare" and the PlikShare logo are trademarks owned by Damian Krychowski and are not covered by the AGPLv3 license. Please see TRADEMARK.md for usage guidelines.\n',
    name: "Plikshare",
    category: "Storage",
    health: null,
    code: "F97XO2",
    languages: ["C#", "TypeScript", "HTML", "SCSS", "Shell", "PowerShell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "75dd7c73-90d4-4ac3-914c-08666cd4f30b",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "Bot Avanc√©s Discord [En B√™ta]",
    readme:
      "Bot Discord polyvalent con√ßu pour accueillir les nouveaux membres avec style ! Cr√©e des cartes de bienvenue personnalis√©es avec images, texte et polices uniques. Supporte plusieurs serveurs avec deux instances ind√©pendantes, gestion via tokens s√©par√©s et configuration facile avec .env. Parfait pour dynamiser vos communaut√©s !",
    name: "Kaori",
    category: "Bots",
    health: null,
    code: "lgVAnP",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "fc3459d2-aa6e-49c2-a8be-6e6829cfd8cf",
    isApproved: false,
    activeProjects: 6,
    projects: 8,
    description: "# Pocketbase on Railway  Open Source backend ",
    readme:
      "Pocketbase on Railway\n\nOpen Source backend for your next SaaS and Mobile app in 1 file.\n\nPocketbase on Railway\n\nOpen Source backend for your next SaaS and Mobile app in 1 file.\n\nPocketbase on Railway\n\nOpen Source backend for your next SaaS and Mobile app in 1 file.\n\n",
    name: "pocketbase",
    category: "Other",
    health: 100,
    code: "LqaJqq",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9e5201f7-7115-4ff1-bc9f-dfba320dfa6e",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "A better and faster cloudflare r2 dashboard build with next.js",
    readme:
      'Getting Cloudflare Variables:\n\nimage\n\nClick "Manage API Tokens"\n\nClick "Create API Token"\n\nimage\n\nMake sure the API token you create has ADMIN READ AND WRITE, otherwise you will not be able to list/create/edit and delete buckets. \n\nimage\n\nToken Value -&gt; CLOUDFLARE_API_TOKEN\nAccess Key ID -&gt; CLOUDFLARE_ACCESS_KEY_ID\nSecret Access Key -&gt; CLOUDFLARE_SECRET_ACCESS_KEY\n\nClick "Finish"\n\nClick "‚Üê R2"\n\nThen click "API" -&gt; "Use R2 with APIs"\n\nAccount ID -&gt; CLOUDFLARE_ACCOUNT_ID\nS3 Compatable API Endpoint -&gt; CLOUDFLARE_R2_ENDPOINT\n\nFill in the environment variables in .env.local:\n\nCLOUDFLARE_ACCOUNT_ID: Your Cloudflare account ID (found in the Cloudflare dashboard URL)\nCLOUDFLARE_ACCESS_KEY_ID: R2 access key ID (generate in Cloudflare R2 dashboard ‚Üí "Manage R2 API Tokens")\nCLOUDFLARE_SECRET_ACCESS_KEY: R2 secret access key (shown when generating the token above)\nCLOUDFLARE_API_TOKEN: API token with R2 permissions (create in Cloudflare dashboard ‚Üí "My Profile" ‚Üí "API Tokens")\nCLOUDFLARE_R2_ENDPOINT: Your R2 endpoint URL (format: https://.r2.cloudflarestorage.com)\n\nRunning the Development Server\n\nFirst, run the development server:\n\nbun i\n\nbun dev\n\nOpen http://localhost:3000 with your browser to see the result. It will take a few seconds to load the first time &amp; properly load/cache the data. It will show all of your buckets and the files within them.\n\nKey Features\n\n1. Infinite Smooth Scrolling\nVirtualized list for large bucket contents with minimal memory usage\nEarly fetch triggers (starts loading 1000px before reaching the bottom)\nSmooth animations for loading states\nScroll position maintenance when navigating\nAutomatic pagination handling with continuation tokens\n\n2. Advanced Search &amp; Filtering\nSmart search syntax with prefix and filename components\nPowerful query syntax with operators:\n  type:image - Filter by file type (image, document, code, media, archive)\n  size&gt;1mb - Files larger than 1MB\n  size&lt;1gb - Files smaller than 1GB\n  after:2024-01-01 - Files modified after date\n  before:2024-12-31 - Files modified before date\nCombined server-side and client-side filtering for optimal performance\nReal-time result updating as you type\n\n3. Interactive File Preview System\nHover preview for images directly in the file list\nAutomatic file type detection with appropriate previews\nThumbnail generation for quick visual browsing\nOptimized loading with lazy-loading and caching\nContextual controls based on file type\n\n4. Advanced Drag &amp; Drop File Upload\nIntuitive drag &amp; drop interface with visual feedback\nMulti-file upload support\nReal-time progress tracking with elegant progress bars\nConfigurable parallel uploads (1-10 concurrent uploads)\nAutomatic folder path handling\nUpload cancellation support\nError handling with retry functionality\n\n5. React Query Data Management\nEfficient data caching reduces API calls\nReal-time data with optimistic updates\nPrefetching of likely-to-be-needed data\nBackground data refreshing\nQueryable and filterable data store\n\n6. Smooth Animations &amp; Transitions\nFramer Motion powered animations\nMicro-interactions for better user feedback\nLoading states with smooth transitions\nInteractive element animations\nOptimized for performance\n\nKnown Issues\n\nOn file upload there is a react-hook-form error that prevents immediate file list reload, we are working on this.\n',
    name: "R2D2",
    category: "Other",
    health: null,
    code: "5KIJcM",
    languages: ["TypeScript", "CSS", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "652ee944-775a-4455-b679-37514d936f9c",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "this is the description of the app",
    readme:
      "EventSwift is a cutting-edge mobile application designed to streamline event management within schools and universities. Leveraging the phone‚Äôs camera, EventSwift allows users to effortlessly scan QR codes associated with events. Once scanned, the app provides real-time access to event details, such as schedules, locations, and attendee participation. Whether you're attending a lecture, seminar, or extracurricular activity, EventSwift simplifies the check-in process and ensures seamless attendance tracking. Designed with both students and faculty in mind, EventSwift enhances event organization, reduces paper usage, and fosters an efficient, tech-driven environment within educational institutions. The app also supports feedback collection and event engagement features, ensuring a smooth and interactive experience for all participants. Perfect for university settings, EventSwift is an essential tool for modern event management.",
    name: "imaginative-illumination",
    category: "Other",
    health: null,
    code: "jaAZAR",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "994bb960-eb1a-448e-a99f-d5b454c6777e",
    isApproved: false,
    activeProjects: 7,
    projects: 27,
    description: "A ready to use auth server! Secure by default and extremely configurable.",
    readme:
      'Better Auth Server Template\n\nA simple but production-ready authentication server that gives you complete control over your user data. This template provides email/password authentication with Redis session storage and a clean API, all powered by Hono.js and Bun.\nFor complete documentation, visit Better Auth Docs.\n\nWhat\'s Included\nEmail/password authentication (login, registration, logout)\nSession management with Redis\nOpenAPI documentation out of the box\nHealth check endpoint\nSingle binary deployment\n\nGetting Started\nAfter deployment, your auth server will be accessible at your Railway-provided URL. Use the following endpoints:\nGET /health - Check the health of the server\nGET /api/auth/reference - Scalar docs for all of the OpenAPI endpoints\nGET /api/auth/sign-out - Logout a user\nPOST /api/auth/sign-up/email - Register a new user\n{\n  "name": "",\n  "email": "",\n  "password": "",\n  "callbackURL": ""\n}\nPOST /api/auth/sign-in/email - Login a user\n{\n  "email": "",\n  "password": "",\n  "callbackURL": "",\n  "rememberMe": ""\n}\n\nConnect your frontend using the Better Auth client library and point it to your new auth server or use your own http client.',
    name: "Better Auth",
    category: "Authentication",
    health: 100,
    code: "VOQsdL",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "226ac0fd-ab2d-4650-a3d9-72b1a99bd655",
    isApproved: false,
    activeProjects: 1,
    projects: 4,
    description: "A full-featured, hackable Next.js AI chatbot built by Vercel",
    readme:
      "\n  \n  Next.js AI Chatbot\n\n\n\n  An Open-Source AI Chatbot Template Built With Next.js and the AI SDK by Vercel.\n\n\n\n  Features ¬∑\n  Model Providers ¬∑\n  Deploy Your Own ¬∑\n  Running locally\n\nFeatures\n\nNext.js App Router\n  Advanced routing for seamless navigation and performance\n  React Server Components (RSCs) and Server Actions for server-side rendering and increased performance\nAI SDK\n  Unified API for generating text, structured objects, and tool calls with LLMs\n  Hooks for building dynamic chat and generative user interfaces\n  Supports OpenAI (default), Anthropic, Cohere, and other model providers\nshadcn/ui\n  Styling with Tailwind CSS\n  Component primitives from Radix UI for accessibility and flexibility\nData Persistence\n  Vercel Postgres powered by Neon for saving chat history and user data\n  Vercel Blob for efficient file storage\nNextAuth.js\n  Simple and secure authentication\n\nModel Providers\n\nThis template ships with OpenAI gpt-4o as the default. However, with the AI SDK, you can switch LLM providers to OpenAI, Anthropic, Cohere, and many more with just a few lines of code.\n\nDeploy Your Own\n\nYou can deploy your own version of the Next.js AI Chatbot to Vercel with one click:\n\nDeploy with Vercel)\n\nRunning locally\n\nYou will need to use the environment variables defined in .env.example to run Next.js AI Chatbot. It's recommended you use Vercel Environment Variables for this, but a .env file is all that is necessary.\n\n&gt; Note: You should not commit your .env file or it will expose secrets that will allow others to control access to your various OpenAI and authentication provider accounts.\n\nInstall Vercel CLI: npm i -g vercel\nLink local instance with Vercel and GitHub accounts (creates .vercel directory): vercel link\nDownload your environment variables: vercel env pull\n\npnpm install\npnpm dev\n\nYour app template should now be running on localhost:3000.\n",
    name: "nextjs AI-Chatbot",
    category: "AI/ML",
    health: null,
    code: "NckAGE",
    languages: ["TypeScript", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "748af7d5-44d4-4493-a442-9e397d79b3e2",
    isApproved: false,
    activeProjects: 0,
    projects: 3,
    description: "Gel template based on the Docker deployment guide",
    readme:
      "This template is based on the official Docker deployment guide.\n\nIt consumes less resources than the baseline by changing the variables GEL_SERVER_COMPILER_POOL_MODE and GEL_SERVER_MAX_BACKEND_CONNECTIONS.",
    name: "Gel",
    category: "Storage",
    health: null,
    code: "3tpcCB",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1b8a1f03-4350-48b1-9440-b56fbda335a6",
    isApproved: false,
    activeProjects: 1,
    projects: 1,
    description: "Scrape anything with a simple chat  [powered by Firecrawl & OpenAI]",
    readme:
      "Extract.chat: AI Chatbot with Firecrawl Integration\nExtract.chat is an AI-powered chatbot application that enables real-time data extraction and search capabilities through Firecrawl integration. This project is a fork of Vercel's AI Chatbot, enhanced with specialized tools for retrieving and analyzing information from websites.\nProject Overview\nExtract.chat combines the power of Next.js, AI SDK, and Firecrawl to create a versatile chatbot that can not only engage in conversations but also fetch and extract structured data from the web in real-time.\nShort description (75 characters):\nWeb-enabled AI assistant that searches and extracts structured data from websites.\nKey Features\nCore Functionality\n\nFirecrawl Integration: Search the web for information and extract structured data from multiple websites\nNext.js App Router: Advanced routing with React Server Components (RSCs) and Server Actions\nAI SDK Integration: Unified API for generating text, structured objects, and tool calls with LLMs\nUser Authentication: Secure login/registration system with anonymous access option\nDocument Creation: Generate and manipulate text, code, and spreadsheet documents\n\nTechnical Highlights\n\nData Persistence: PostgreSQL database integration for chat history and user data\nFile Storage: Vercel Blob support for efficient file handling\nResponsive UI: Modern interface built with shadcn/ui and Tailwind CSS\nReal-time Streaming: Server-sent events for responsive chat interactions\n\nArchitecture\nThe application follows a modern web architecture:\n\nFrontend: React-based UI with Next.js App Router\nBackend: Server-side functions for authentication, chat processing, and database operations\nAI Integration: Connection to AI models via the AI SDK\nWeb Integration: Firecrawl API for searching and extracting data from websites\nDatabase: Vercel Postgres for data persistence\n\nDeployment Requirements\nTo deploy Extract.chat, you'll need:\n\nEnvironment Variables:\n\nOPENAI_API_KEY: API key for OpenAI\nAUTH_SECRET: A secret for authentication\nBLOB_READ_WRITE_TOKEN: Vercel Blob storage token\nPOSTGRES_URL: Connection string for Postgres database\nFIRECRAWL_API_KEY: API key for Firecrawl service\n\n\nVercel Account: For hosting and database integration\nNode.js environment: For local development\n\nGetting Started\n\nClone the repository\nInstall dependencies: pnpm install\nSet up environment variables in .env.local\nStart the development server: pnpm dev\n\nCustomization Options\n\nAI Model: Configured to use OpenAI gpt-4o by default, but can be switched to other providers\nUI Appearance: Customizable with Tailwind CSS\nAuthentication Flow: Modifiable login/register processes\n\nUse Cases\n\nResearch Assistant: Quickly gather information from multiple websites\nData Extraction: Pull structured data from web pages\nContent Creation: Generate documents and code with AI assistance\nKnowledge Base: Create and maintain a personal knowledge repository",
    name: "Extract Chat - chat with firecrawl",
    category: "AI/ML",
    health: null,
    code: "UzxNSc",
    languages: ["TypeScript", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9b27778a-89d5-4421-8a82-75dd92e32849",
    isApproved: false,
    activeProjects: 8,
    projects: 12,
    description: "YouTube FastAPI Server: Extract metadata, captions, and timestamps ",
    readme:
      "YouTube API Server\n\nUnlock the full potential of YouTube content with our streamlined API server. This powerful tool allows developers to programmatically extract valuable data from YouTube videos, transforming passive content into structured, actionable information.\n\nWhy Deploy Our YouTube API Server?\n\nSeamless Data Extraction\nExtract rich metadata, full transcripts, and precise timestamps from any YouTube video with simple API calls. No more manual scraping or complex integration work.\n\nDeveloper-Friendly Design\nBuilt with FastAPI, our solution provides lightning-fast performance, comprehensive documentation via Swagger UI, and intuitive RESTful endpoints that follow modern API best practices.\n\nVersatile Applications\nContent Analysis: Analyze video transcripts for sentiment, topics, or keywords\nEducational Tools: Create searchable archives of lecture content\nAccessibility: Build better subtitle and navigation systems\nResearch: Extract information from video content at scale\nSEO Optimization: Generate transcript-based content for improved discoverability\n\nEasy Deployment\nGet up and running in minutes with Docker support. Our containerized approach ensures consistent performance across any environment with minimal configuration.\n\nProduction-Ready Architecture\nDesigned with scalability in mind, featuring proper error handling, environment-based configuration, and CORS support for frontend integration.\n\nOpen Source Flexibility\nCustomize and extend functionality to meet your specific needs while building on a solid foundation.\n\nDon't waste valuable development time rebuilding YouTube data extraction tools. Deploy our YouTube API Server today and focus on creating innovative applications with the extracted content!",
    name: "Youtube Transcript FastAPI",
    category: "Other",
    health: 100,
    code: "DVg2US",
    languages: ["Python", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d3f319ab-edaf-4d33-97a4-9bd9394f4d09",
    isApproved: false,
    activeProjects: 6,
    projects: 7,
    description: "A lightweight, self-hosted friendly RSS aggregator and reader",
    readme:
      "Fusion\n\nA lightweight RSS feed aggregator and reader.\n\nscreenshot light\n\nscreenshot dark\n\nKey features include:\n\nGroup, Bookmark, Search, Sniff feeds automatically\nImport/Export OPML file\nSupport RSS, Atom, JSON types feed\nResponsive, Light/Dark mode, PWA\nLightweight, Self-hosted friendly\n  Built with Golang and SQLite, Deploy with a single binary\n  Pre-built Docker image\n  Uses about 80MB of memory\n\nDeployment\n\nJust click the button!\nCopy the PASSWORD variable after the service has been deployed\nGo to your service's URL\nEnter the password\nEnjoy!",
    name: "Fusion",
    category: "Blogs",
    health: null,
    code: "XSPFK0",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3920fd26-252f-4d17-92e3-9402c4a17849",
    isApproved: false,
    activeProjects: 1,
    projects: 8,
    description: "A queueing solution with a dashboard to visualize, monitor and retry.",
    readme:
      "‚ú® Features\n\nQueueing system with BullMQ and Redis;\nDashboard built with bull-board and Fastify;\nRun services through pm2.\n\nGitHub: https://github.com/ncontiero/fastify-bullmq\n\nExplanations\n\nThis application uses BullMQ, a Redis-based queueing system, and Bull-Board, a dashboard to monitor and manage these queues, served by a Fastify server. Both services are built using Rslib and managed by PM2.\n\nThere are three distinct ways to start the services:\n\nUnified Execution: To start both services simultaneously, use the command pnpm start. This is the simplest option for local development.\nSeparate Execution: To start the worker and Fastify server individually, use the commands pnpm start:worker and pnpm start:server, respectively. This approach offers greater control and is used in this template, but can be easily adapted to your needs.\nDirect Node.js Execution: For simple projects that do not require PM2 features, direct execution with Node.js can result in lower resource consumption. Use node ./dist/worker.js for the worker and node ./dist/server.js for the Fastify server.\n\nPM2 also supports Bun. If desired, you can replace the project's package manager with Bun and execute the TypeScript files directly (Bun has native support for TypeScript), eliminating the need for a build. However, be aware that Bun is not fully compatible with Node.js, which may result in execution problems.\n\nScalability (PM2): Both services support horizontal scaling through the WORKER_INSTANCES and SERVER_INSTANCES environment variables. Set these variables to the desired number of instances to increase the processing capacity of the worker and server, respectively. These variables will only take effect if PM2 is being used.\n",
    name: "BullMQ with BullBoard",
    category: "Queues",
    health: 100,
    code: "0s3-xR",
    languages: ["TypeScript", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "29f3d5b1-a411-460f-b214-d7a090b8ce38",
    isApproved: false,
    activeProjects: 0,
    projects: 3,
    description: "Minimal installation of Ponder + PostgreSQL",
    readme:
      "This is a minimal installation of Ponder + PostgreSQL that will get you up and running with the Ponder blockchain indexing framework.\n\nFeatures\n\nPostgreSQL server\nPonder indexer\n  Railway is pre-configured to run it\n  Environment variables pre-populated with the database and common RPCs\n  Applies the --schema parameter to enable zero-downtime deployments\n  Exposes GraphQL at the /graphql endpoint\n  Exposes the Ponder SQL API at the /sql/ endpoint\n  Sample indexing of the Chainlink ETH-USD price feed\n\nNext Steps\n\nAdd ABIs under /abis\nAdd contract definitions under /ponder.config.ts\nDefine the schema in /ponder.schema.ts\nRead the Ponder docs\n\n",
    name: "ponder",
    category: "Starters",
    health: null,
    code: "ma-2Wo",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4bb58816-081e-424c-9caf-8d70f520908c",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "Open device management for everyone ",
    readme:
      "Deploy Fleet - The Open-Source Device Management Platform\n\nThis template allows you to quickly deploy Fleet, a comprehensive device management solution that helps organizations maintain visibility and control over their entire fleet of devices.\n\nKey Features:\n\nCross-platform support: Manage Linux, macOS, Windows, Chromebooks, and iOS devices\nBYOD & corporate device management\nReal-time device inventory\nSecurity monitoring and compliance checks\nCentralized device control\n\nDeploy now to start managing your device fleet with this enterprise-grade, open-source solution.\n\nDocumentation: fleetdm.com/docs",
    name: "Fleet",
    category: "Observability",
    health: null,
    code: "wTPHPC",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "dbcca2c1-a313-4a82-9e59-5a3c5d168437",
    isApproved: false,
    activeProjects: 1,
    projects: 12,
    description: "A single node XTDB deployment",
    readme:
      "XTDB is an open-source, bitemporal database designed to handle complex and regulated data. This template brings up a single XTDB (v2) node deployment with Kafka and MinIO as Object Storage. You likely want to scale the number of XTDB nodes and number of MinIO buckets for a production setup. \n\nGithub: https://github.com/xtdb/xtdb",
    name: "xtdb",
    category: "Other",
    health: null,
    code: "i-rqKj",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2ecdffcf-9916-489f-be90-300aba8f8637",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "A full-stack Svelte app with The Boring JavaScript Stack.",
    readme:
      "This template makes it easy to deploy your Boring Stack app from day one on Railway.\n\nAfter deploying this template you will need to use the environment variables in your app in config.production.js \n\nAlso you will need to finish up your deploy by following the docs on setup Redis and setup database.",
    name: "mellow-svelte",
    category: "Starters",
    health: null,
    code: "K-dheh",
    languages: ["EJS", "JavaScript", "Vue", "Svelte", "CSS", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "18db6363-e8d6-4f25-809f-1c8a9fcd2a1a",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "A full-stack React app with The Boring JavaScript Stack.",
    readme:
      "This template makes it easy to deploy your Boring Stack app from day one on Railway.\n\nAfter deploying this template you will need to use the environment variables in your app in config.production.js \n\nAlso you will need to finish up your deploy by following the docs on setup Redis and setup database.",
    name: "mellow-react",
    category: "Starters",
    health: null,
    code: "Yqisvu",
    languages: ["EJS", "JavaScript", "Vue", "Svelte", "CSS", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "03ea5076-bcc1-4c4c-a1d5-b5e284cbd0c7",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "A full-stack Vue app with The Boring JavaScript Stack.",
    readme:
      "This template makes it easy to deploy your Boring Stack app from day one on Railway.\n\nAfter deploying this template you will need to use the environment variables in your app in config.production.js \n\nAlso you will need to finish up your deploy by following the docs on setup Redis and setup database.",
    name: "mellow-vue",
    category: "Starters",
    health: null,
    code: "zB55Xl",
    languages: ["EJS", "JavaScript", "Vue", "Svelte", "CSS", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6439de23-6dc1-4960-9f07-f05d2107467b",
    isApproved: false,
    activeProjects: 2,
    projects: 8,
    description: "Jenkins is an automation tool for CI/CD in software projects. üöÄ",
    readme:
      "What is Jenkins?  \n\nJenkins is an open-source automation server used for Continuous Integration (CI) and Continuous Deployment (CD). It automates software development workflows, allowing developers to build, test, and deploy applications efficiently. With a rich plugin ecosystem, Jenkins integrates seamlessly with tools like Git, Docker, and Kubernetes, making it ideal for DevOps teams.  \n\nAccess Credentials  \nUsername: admin (default, can be changed via \nPassword: admin (default, can be changed via environment variables)  \n\nEnvironment Variables for Custom Credentials  \nTo set custom credentials, define the following environment variables:  \nJENKINS_USER ‚Üí Your desired username  \nJENKINS_PASS ‚Üí Your desired password  \n\nKey Features  \n‚úî Automates software builds, testing, and deployment  \n‚úî Supports a vast range of plugins for enhanced functionality  \n‚úî Easily integrates with version control and cloud platforms  \n‚úî Web-based UI for managing pipelines and configurations  \n\nüìñ Official Documentation: Jenkins Documentation  \n\nüöÄ Jenkins is the go-to solution for automating CI/CD pipelines!\n",
    name: "Jenkins",
    category: "Other",
    health: 100,
    code: "0ygwi8",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f262382a-01f8-43f4-9489-67664ecb2ed5",
    isApproved: false,
    activeProjects: 1,
    projects: 13,
    description: "A lightweight service that joins the RSS3 Network as a node.",
    readme:
      'Prerequisites\nBefore deploying, you need to create a node on the explorer: RSS3 Explorer.\n\nAdditionally, ensure that your Railway account is upgraded to at least the Pro Plan ($20/month). This plan is necessary to support the node\'s storage requirements, which will be around 10GB.\n\nDeployment\nYou only need to fill in two fields in the RSS3-Node-Core service:\n\nNODE_DISCOVERY_MAINTAINER_EVM_ADDRESS: Your wallet address (which is also your node address).\nNODE_DISCOVERY_MAINTAINER_SIGNATURE: The challenge signature obtained here: https://explorer.rss3.io/nodes/YOUR_WALLET_ADDRESS. (Click the "Signature" button to complete the challenge and copy your signature to paste here.)\n\nAfter the service starts, it will join the RSS3 Network as a lightweight RSS3 Node.\n\nContact\nIf you have any questions, feel free to contact me: brucexc@rss3.io.\n\nJoin the RSS3 Discord: RSS3 Discord\n',
    name: "RSS3 Node 2.0",
    category: "Other",
    health: 75,
    code: "1dIfGL",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "93015644-daf7-4b38-89a0-f1045902e7f0",
    isApproved: false,
    activeProjects: 1,
    projects: 1,
    description: "An open-source online implementation of the board game Terraforming Mars.",
    readme:
      'Terraforming Mars\n\nThis is an open-source online implementation of the great board game Terraforming mars. It is not affiliated with FryxGames, Asmodee Digital or Steam in any way.\n\nNote: This project has no affiliation with "Rebalanced Mars", whose authors have refused to open-source their code. We believe this is both a violation of our GPL3 license, and also of the spirit of collaboration that this project tries to foster. Note that any new features you see on this repo made available on that server are without our permission.\n\nThe board game is great and this repository highly recommends purchasing it for personal use.',
    name: "Terraforming Mars",
    category: "Other",
    health: null,
    code: "uPNq21",
    languages: ["TypeScript", "Vue", "Less", "HTML", "JavaScript", "Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "852aec98-8581-4b9d-a4f7-0c6a24a74cec",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "Instantly turn your dbt project into a full stack BI platform.",
    readme:
      "\n         \n\n\nThe open-source Looker alternative.\n\nEnable everybody in your company to answer their own questions using data\n\nconnect your dbt project --&gt; add metrics into dbt --&gt; share insights with your team\n\nIf you're a fan, star the repo ‚≠êÔ∏è (we plant a tree for every GitHub star we get üå±).\n\nCome join the team, we're hiring.\n\nFeatures:\n\n[x] üôè Familiar interface for your users to self-serve using pre-defined metrics\n[x] üë©‚Äçüíª Declare dimensions and metrics in yaml alongside your dbt project\n[x] ü§ñ Automatically creates dimensions from your dbt models\n[x] üìñ dbt descriptions and metadata synced for your users\n[x] üîç Easily access to underlying records of charts as well as ability to data drill-down\n[x] üßÆ Table calculations make it easy to dig into your data, on the fly\n[x] üïµÔ∏è‚Äç‚ôÄÔ∏è Lineage lets you see the upstream and downstream dependencies of a model\n[x] üìä Comprehensive and intuitive data visualisation library for your metrics\n[x] üë∑‚Äç‚ôÇÔ∏è Save charts &amp; build dashboards to share your insights with your team\n[x] üíª Powerful developer experience including Preview BI Environments and automated content validation via CI/CD\n[x] üîÑ Explore version history of all your charts and roll-back at any point\n[x] üöÄ Easily share your work via URL or schedule deliveries via Slack or Email",
    name: "Lightdash",
    category: "Analytics",
    health: null,
    code: "vFR34s",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9234db73-a4e9-4b96-975a-9a555c347e35",
    isApproved: false,
    activeProjects: 22,
    projects: 54,
    description: "100% Open Source alternative to WhatsApp",
    readme:
      "OpenChat is more than just a messaging app ‚Äì it's a fresh take on communication, built on the principles of openness and transparency. As an open-source platform, OpenChat allows users to enjoy a fully customizable chat experience, with the freedom to modify, contribute, and control the software. Whether you‚Äôre chatting with friends, collaborating with teammates, or discussing big ideas, OpenChat is designed to give you full ownership over your conversations.\n\nAt its core, OpenChat is about simplicity. With a clean, intuitive interface, it provides all the essential features you need for messaging without the clutter. From one-on-one conversations to group chats, it‚Äôs a platform that prioritizes ease of use while ensuring data privacy and security. You‚Äôll never have to worry about proprietary systems controlling your chats; with OpenChat, everything is open for you to explore and tweak.\n\nOpenChat also fosters a thriving community of developers, users, and contributors. Thanks to its open-source nature, anyone can help improve the app, suggest features, or create new integrations. Whether you're a coder or simply someone who believes in digital freedom, OpenChat is the place for you.\n\nExperience a chat app that truly gives you control. OpenChat ‚Äì open-source, open conversations, and open possibilities.",
    name: "OpenChat",
    category: "Other",
    health: 100,
    code: "6zTNV1",
    languages: ["JavaScript", "CSS", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "64db78fd-6884-4ff6-87e4-01a03a4a543a",
    isApproved: false,
    activeProjects: 35,
    projects: 142,
    description: "Open-source AI platform with BaaS & LLMOps for all users.",
    readme:
      "After deploying for the first time, you'll need the auto-generated INIT_PASSWORD variable in the Api service to setup the admin account.\n\nDify is an open-source platform for building AI applications. We combine Backend-as-a-Service and LLMOps to streamline the development of generative AI solutions, making it accessible to both developers and non-technical innovators.\n\nDify integrates:\nSupport for mainstream LLMs\nAn intuitive Prompt orchestration interface\nHigh-quality RAG engines\nA flexible AI Agent framework\nAn Intuitive Low-code Workflow\nEasy-to-use interfaces and APIs\n\nWith Dify, you can skip the complexity and focus on what matters most - creating innovative AI applications that solve real-world problems.",
    name: "Dify v1.4.0",
    category: "AI/ML",
    health: 100,
    code: "TiT2V6",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "faf5e88a-48a3-464a-a871-a7f8593bb2df",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "Fastest, Most Affordable Graph Database.",
    readme:
      'Memgraph\n\nFastest, Most Affordable Graph Database.\nLight & Powerful. Tuned for Dynamic and GenAI Environments. Easy to Adopt, Scale and Own.\nNow with Vector Search.\n\nBring the Most Relevant Context to your AI Applications\nOvercome LLM limitations and build chatbots and agents with Memgraph as context engine ‚Äî based on the data from your Enterprise knowledge base.\n\nIf not present in pre-deploy add\n\nsh -c "chown -R memgraph:memgraph /var/lib/memgraph && chown -R memgraph:memgraph /var/log/memgraph"',
    name: "Memgraph",
    category: "Storage",
    health: null,
    code: "MJ_1Be",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a344bd8a-b3c1-49f8-93a8-c22434dbb993",
    isApproved: false,
    activeProjects: 1,
    projects: 1,
    description: "Examle site for example data for example serice",
    readme:
      "this is a text for example data for example service for example webpage with pwa services  API REST services for a personal site ian carvajals that all I think I can write for now en espanol es un texto de ejemplo para service de ejemplo para un web de ejemplo con pwa y api rest  de ejemlo",
    name: "helpful-prosperity",
    category: "Other",
    health: null,
    code: "Xe-Ieb",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "dfad386c-bba3-4167-89cd-5a15b2ad4a3c",
    isApproved: false,
    activeProjects: 5,
    projects: 7,
    description: "Expose Discord user presence to a websocket & API",
    readme:
      "Lanyard is a service that makes it super easy to export your live Discord presence to an API endpoint and to a WebSocket for you to use wherever you want - for example, I use this to display what I'm listening to on Spotify on my personal website. It also acts as a globally-accessible realtime KV store which you can update from the Lanyard Discord bot or from the Lanyard API.\n\nDocs",
    name: "lanyard",
    category: "Other",
    health: 67,
    code: "fqla1q",
    languages: ["Elixir", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2371ea0f-d2cf-49ee-901d-06d9ea31744a",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "A webhook that converts railway events into a readable discord message",
    readme:
      "Status Express\n\nA service that receives Railway webhook events and forwards them to a Discord channel as simple text messages.\n\nNOTE: I suggest disabling App Sleeping as it's the default for functions\n\nRequired Variables\n\nDISCORD_WEBHOOK_URL=your_discord_webhook_url_here\n\nConfiguring Railway Webhooks\n\nGo to your Railway project\nNavigate to Settings > Webhooks\nAdd a new webhook with the URL pointing to your deployed service:\n   https://your-deployed-service.com/railway-webhook\nSelect the events you want to receive notifications for\nSave the webhook configuration\n\nAPI Endpoints\n\nGET /: Health check endpoint\nPOST /railway-webhook: Endpoint that receives Railway webhook events and forwards them to Discord",
    name: "status-express",
    category: "Other",
    health: null,
    code: "qDKd-1",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "dd6674d2-0486-4abd-b2dd-c1d9adc63bbf",
    isApproved: false,
    activeProjects: 8,
    projects: 25,
    description: "Deploy a fully managed Neo4j instance on Railway with ease.",
    readme:
      'Railway Neo4j Template Overview\n\nThis template allows you to easily deploy and manage a Neo4j instance on Railway.\n\nFeatures\n\nBulk Insert Support  \n  You can bulk insert data using environment variables:  \n  RELATION_CSV_URLS or NODE_CSV_URLS  \n  Provide CSV file URLs separated by commas.\n\nAutomatic TCP Address  \n  A TCP address is automatically generated.  \n  Use it in your driver as:  \n    neo4j://your-tcp-address-from-railway\n  You can find this address in the Service Settings ‚Üí Networking tab.  \n  Click the Copy button to copy the value.\n\nAuto-Generated Password  \n  A password is automatically generated for your instance.  \n  You can change it later (must be at least 8 characters long).\n\nLogging Enabled by Default  \n  Both user logs and server logs are enabled out-of-the-box.\n\nExample Code Snippets\n\nJavaScript (Node.js)\nimport neo4j from \'neo4j-driver\';\n\nconst host = configService.get(\'NEO4J_HOST\'); // neo4j://your-tcp-address-from-railway\nconst username = configService.get(\'NEO4J_USERNAME\'); // This must be neo4j\nconst password = configService.get(\'NEO4J_PASSWORD\');\n\nconst driver = neo4j.driver(host, neo4j.auth.basic(username, password));\nconst result = await driver.executeQuery(\'MATCH (n) RETURN n\');\nconsole.log(result);\n\nPython\nfrom neo4j import GraphDatabase\n\nuri = "neo4j://your-tcp-address-from-railway"\nusername = "neo4j"\npassword = "your-password"\n\ndriver = GraphDatabase.driver(uri, auth=(username, password))\n\nwith driver.session() as session:\n    result = session.run("MATCH (n) RETURN n")\n    for record in result:\n        print(record)\n\nJava\nimport org.neo4j.driver.*;\n\npublic class Neo4jExample {\n    public static void main(String[] args) {\n        String uri = "neo4j://your-tcp-address-from-railway";\n        String user = "neo4j";\n        String password = "your-password";\n\n        try (Driver driver = GraphDatabase.driver(uri, AuthTokens.basic(user, password));\n             Session session = driver.session()) {\n            Result result = session.run("MATCH (n) RETURN n");\n            while (result.hasNext()) {\n                System.out.println(result.next().asMap());\n            }\n        }\n    }\n}\n\nFuture Improvements\n\nExpanding bulk insert support beyond CSV files.  \nProviding access to the Neo4j Web UI.  \n',
    name: "Neo4j GraphDB",
    category: "Storage",
    health: 56,
    code: "asEF1B",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3ee209d9-ad75-4891-930f-58bef92e9760",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "Chat-based SQL Client and Editor for the next decade",
    readme:
      'SQL Chat banner\n\nWhat\n\nSQL Chat is a chat-based SQL client, which uses natural language to communicate with the database to implement operations such as query, modification, addition, and deletion of the database.\n\nScreenshot\n\nScreenshot\n\nScreenshot\n\nWhy\n\nAs we enter the Developer Tools 2.0 era,\nthere is a massive opportunity to rebuild the existing tools using the chat-based interface. SQL Client\nis no exception. Instead of navigating across many UI controls, a chat-based interface is much\nmore intuitive. Of course, only if that works, and our goal is to deliver that experience.\n\nHow\n\nSQL Chat is built by Next.js, it supports the following databases and will add more over time:\n\nMySQL\nPostgreSQL\nMSSQL\nTiDB Cloud\n\nsqlchat.ai\n\nIP Whitelisting\n\nIf you use sqlchat.ai to connect to your database, you need to add 0.0.0.0 (allow all connections)\nto the database whitelist IP. Because sqlchat.AI is hosted on Vercel which uses dynamic IP. If this is a concern, please consider the self-host option below.\n\nData Privacy\n\nSee SQL Chat Privacy Policy.\n\nSelf-host\n\nDocker\n\nIf you just want to run for your own use, supply the following options:\n\nNEXTAUTH_SECRET\nOPENAI_API_KEY\n\ndocker run --name sqlchat --platform linux/amd64 --env NEXTAUTH_SECRET="$(openssl rand -hex 5)" --env OPENAI_API_KEY=&lt;&gt; -p 3000:3000 --hostname localhost sqlchat/sqlchat\n\nPass an arbitrary string to NEXTAUTH_SECRET otherwise next-auth will complain.\nIf you chat to the database on the same host, you need to use host.docker.internal as the host in\n  the database connection setting.\n\nStartup options\n\nTL;DR\n\nIf you just want to use for yourself, then run without database. Check .env.nodb.\nIf you want to offer a similar service as sqlchat.ai, then run with database, check .env.usedb. The database is used to store account, usage info.\n\nOpenAI related\n\nOPENAI_API_KEY: OpenAI API key. You can get one from here.\n\nOPENAI_API_ENDPOINT: OpenAI API endpoint. Defaults to https://api.openai.com. Use Ollama to set up self-host AI model and set the endpoint to it.\n\nNEXT_PUBLIC_ALLOW_SELF_OPENAI_KEY: Set to true to allow users to bring their own OpenAI API key.\n\nDatabase related\n\nNEXT_PUBLIC_USE_DATABASE: Set to true to start SQL Chat with database. This will\n  enable following features:\n  Account system.\n  Per-user quota enforcement.\n  Payment.\n  Usage data collection.\nDATABASE_URL: Applicable if NEXT_PUBLIC_USE_DATABASE is true. Postgres connection string to store data. e.g. postgresql://postgres:YOUR_PASSWORD@localhost:5432/sqlchat?schema=sqlchat.\n',
    name: "sqlchat",
    category: "AI/ML",
    health: null,
    code: "KsHjEY",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a5b4e0aa-23c5-4ac4-ae71-0e1957961cff",
    isApproved: false,
    activeProjects: 6,
    projects: 12,
    description: "Ready to deploy template for Strapi(TS), Nodemailer, AWS S3, Graphql",
    readme:
      "\nStrapi v5 as Typescript + Nodemailer + AWS S3 + Graphql | Starter Template\n\nNotes\n\nWhen this template is running on Railway, Strapi will connect to the Postgres Database through the private network, saving you on database egress fees.\n\nDeveloping Locally\n\nWhen developing locally, this Strapi template will connect to the Postgres server from its public TCP Proxy.\nEnable the feature flag Template Service Eject in the Feature Flags menu.\nWithin the service settings of the Strapi service, click the Eject button on the upstream repository.\nClone the newly created repository locally.\nInstall Strapi's dependencies with yarn install or npm install.\nInstall the Railway CLI (Instructions).\nIf this is your first time using the CLI, make sure to log in with railway login.\nWithin the local repository, run railway link to link the local repository to the Strapi service on Railway.\nStart Strapi for development with railway run yarn run develop or railway run npm run develop.\nThis command will run Strapi in development mode with the service variables available locally.\n\nOpen your local machine browser to http://127.0.0.1:1337/admin\n\nPurpose\n\nThis project is a Strapi v5 + Nodemailler + S3 Starter Template. It is designed to work with just four parameters:\n\nAWS_ACCESS_KEY_ID\nAWS_ACCESS_SECRET\nAWS_BUCKET_NAME\nAWS_REGION\n\nSMTP_HOST\nSMTP_PASSWORD\nSMTP_PORT\nSMTP_USERNAME\n\nThese parameters can also be provided as null. The project will still deploy, but media uploads (e.g., JPG, PNG) will not be functional without valid values and you can't send any email until you give your correct smtp params.\n\nAcknowledgments\n\nThis project was inspired by Szilard Koppel's project. A big thank you to Szilard for his amazing work!\n\nSzilard Koppel's GitHub repository: https://github.com/szilardkoppel/railway.app-strapi\nRailway template: https://railway.com/template/e10OW1\n\n",
    name: "Strapi v5 + Nodemailer + S3",
    category: "Starters",
    health: 75,
    code: "SQXzME",
    languages: ["TypeScript", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7bb77a24-bacd-438a-9f01-c96e476bd0db",
    isApproved: false,
    activeProjects: 26,
    projects: 31,
    description: "A Node.js Express server with TypeScript, auth, and flexible logging setup",
    readme:
      "This repository contains a Node.js server built with Express and TypeScript. It follows a structured architecture with service, controller, and middleware layers. The server includes token-based authentication and logging configured to automatically switch between JSON logging (for production) and console-based logging (for local development). Logs are stored and can be accessed via an endpoint. In production, logs are stored in a volume to persist across redeploys.\n\nFeatures\nExpress.js as the web framework\nTypeScript for type safety\nToken-based authentication \nService-Controller architecture\nMiddleware support\nLogging:\n  JSON logging in production\n  Text-based logging in local development\n  Logs stored in a text file\n  Endpoint to download logs\n  Automatic switching between logging formats\n  Production logs persist across redeploys using a volume\n\nInstallation\n\nClone the repository\ngit clone https://github.com/Tazi-Rides/nodejs-typescript.git\ncd nodejs-typescript\n\nInstall dependencies\nnpm install\n\nEnvironment Variables\nCreate a .env file in the root directory and configure the following variables:\n\nPORT=3000\nNODE_ENV=development  # Change to 'production' in production\nHEALTH_SECRET=your_secret_here\nLOGS_SECRET=your_secret_here\n\nRunning the Server\n\nDevelopment Mode\nnpm run dev\nThis runs the server with ts-node-dev and text-based logging.\n\nProduction Mode\nnpm run build\nnpm start\nThis compiles TypeScript and runs the server with JSON logging.\n\nProject Structure\n/src\n‚îÇ‚îÄ‚îÄ controllers  # Handles HTTP requests and responses\n‚îÇ‚îÄ‚îÄ services     # Business logic and database interactions\n‚îÇ‚îÄ‚îÄ middleware   # Express middleware (e.g., authentication, logging)\n‚îÇ‚îÄ‚îÄ utils        # Helper functions\n‚îÇ‚îÄ‚îÄ config       # Configuration files\n‚îÇ‚îÄ‚îÄ app.ts       # Main Express server setup\n‚îÇ‚îÄ‚îÄ server.ts    # Server entry point\n\nAuthentication\nTo access protected routes, include a valid token in the Authorization header.\n\nLogging Configuration\nLogging automatically switches based on the NODE_ENV:\nDevelopment: Logs in text format for readability and stored in a text file (logs/server.log).\nProduction: Logs in JSON format for structured logging, stored in a volume to persist across redeploys.",
    name: "NodeJs-Typescript",
    category: "Starters",
    health: 75,
    code: "toIOqb",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1962cb00-9aaa-427f-9b15-cef96e4f4bfe",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "to send the user entered notes to their mail without and login",
    readme:
      "Daily Notes & Event Recorder\n\nThis application is designed to help users effortlessly record and track their daily activities, important events, and personal notes. Without requiring any login or account setup, users can simply enter their details and have them sent directly to their email for personal records. It serves as a convenient tool for maintaining a structured daily routine, tracking wake-up times, and logging activities like exercise, skincare, meals, study sessions, and more.\n\nWith a user-friendly interface, the app allows individuals to mark tasks as completed, add personalized notes, and store essential details. Once entered, users can send their recorded notes directly to their email, ensuring a secure and private way to keep track of their daily activities. Whether you want to maintain a habit tracker, plan your day, or document personal milestones, this application helps you stay organized with minimal effort.\n\nSince no login is required, it‚Äôs a hassle-free solution for people who prefer quick and easy record-keeping. The added feature of email-based storage ensures users can access their records anytime, making it an ideal tool for students, professionals, and anyone who wants to keep a structured log of their daily routines. By integrating reminders and note-taking in a single platform, this app provides a simple yet effective way to manage and track daily life events seamlessly.",
    name: "responsible-charm",
    category: "Other",
    health: null,
    code: "5SK2Dh",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0fcd6146-783a-4462-93d2-765dc69e5ddd",
    isApproved: false,
    activeProjects: 1,
    projects: 1,
    description: "It is web soccet chat, where you can guess the word that admin think",
    readme:
      "Game Chat - Template Overview\n\nProject Description\n\nGame Chat is a real-time multiplayer word-guessing game where players join a chatroom, and one player (admin) sets a secret word. The other players try to guess the word through the chat interface. The game features a countdown timer at the start and announces the winner when the word is guessed.\n\nTech Stack\n\nBackend: Node.js with Express\n\nWebSockets: Socket.io for real-time communication\n\nFrontend: HTML, CSS, JavaScript\n\nDeployment: Railway\n\nKey Features\n\nReal-time chat functionality\n\nAdmin control to start the game and set the word\n\nDynamic countdown timer at game start\n\nWinner announcement with festive message\n\nUser-friendly and minimalist UI with dark/gray theme\n\nFolder Structure\n\nproject-root/\n|-- public/\n|   |-- index.html       # Frontend UI\n|   |-- style.css        # CSS for styling\n|   |-- script.js        # Client-side WebSocket handling\n|-- server.js            # Backend server and WebSocket logic\n|-- package.json         # Project dependencies\n|-- Procfile             # Start command for deployment\n\nDeployment Setup\n\nPush project to GitHub repository\n\nDeploy to Railway:\n\nLink GitHub repository\n\nConfigure start command: node server.js\n\nAccess deployed project via provided Railway URL\n\nUsage\n\nOpen the deployed game URL\n\nEnter a nickname and join the game\n\nAdmin sets a secret word and starts the game\n\nCountdown timer appears for all players\n\nPlayers guess the word in the chat\n\nWinner and guessed word are announced\n\nFuture Enhancements\n\nAdd sound effects for game events\n\nImplement multiple rounds\n\nAdd player score tracking\n\nEnhance UI with more animations\n\n",
    name: "harmonious-celebration",
    category: "Other",
    health: null,
    code: "UELkKK",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5f1fbe10-cb6b-4400-a7ed-930b2ac81f83",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "i18n painel translate manager usin Ai",
    readme:
      "O Translation Manager √© uma aplica√ß√£o web desenvolvida com Next.js que permite gerenciar facilmente as tradu√ß√µes para internacionaliza√ß√£o (i18n) de websites e aplica√ß√µes. O sistema utiliza MongoDB para armazenar as tradu√ß√µes e integra-se com a API da Groq para tradu√ß√£o autom√°tica.\n\nPrincipais Caracter√≠sticas\n‚úÖ Interface intuitiva para gerenciar chaves e valores de tradu√ß√£o\nüîí Sistema de autentica√ß√£o para proteger o acesso\nü§ñ Tradu√ß√£o autom√°tica de portugu√™s para outros idiomas usando IA\nüì§ Exporta√ß√£o de tradu√ß√µes em formato JSON\nüì• Importa√ß√£o de tradu√ß√µes de v√°rias fontes\nüîç Busca e filtragem de tradu√ß√µes\nüåê Suporte para m√∫ltiplos idiomas (PT, EN, ES)",
    name: "Translate Manager",
    category: "Automation",
    health: null,
    code: "ji6AXE",
    languages: ["TypeScript", "CSS", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "af42b741-c2ed-47f0-b7ec-c373f0da268c",
    isApproved: false,
    activeProjects: 3,
    projects: 7,
    description: "Simple, easy-to-use platform for organising and storing information.",
    readme:
      "BookStack\n\nA platform for storing and organising information and documentation. Details for BookStack can be found on the official website at https://www.bookstackapp.com/.\n\nCompatible with (Config in env) \n\nS3 \nSSO (OIDC, LDAP)\nMemcached\n\n‚ö†Ô∏è You can login with username admin@admin.com and password password. Always change default password. ‚ö†Ô∏è\n\nüìö Project Definition\n\nBookStack is an opinionated documentation platform that provides a pleasant and simple out-of-the-box experience. New users to an instance should find the experience intuitive and only basic word-processing skills should be required to get involved in creating content on BookStack. The platform should provide advanced power features to those that desire it, but they should not interfere with the core simple user experience.\n\nBookStack is not designed as an extensible platform to be used for purposes that differ to the statement above.\n\nIn regard to development philosophy, BookStack has a relaxed, open & positive approach. We aim to slowly yet continuously evolve the platform while providing a stable & easy upgrade path. \n\nYou can read more about the project and its origins in our FAQ here.\n\nüõ†Ô∏è Development & Testing\n\nPlease see our development docs for full details regarding work on the BookStack source code.\n\nIf you're just looking to customize or extend your own BookStack instance, take a look at our Hacking BookStack documentation page for details on various options to achieve this without altering the BookStack source code.\n\nDetails about BookStack's versioning scheme and the general release process can be found here.\n\nüåé Translations\n\nTranslations for text within BookStack is managed through the BookStack project on Crowdin. Some strings have colon-prefixed variables such as :userName. Leave these values as they are as they will be replaced at run-time.\n\nPlease use Crowdin to contribute translations instead of opening a pull request. The translations within the working codebase can be out-of-date, and merging via code can cause conflicts & sync issues. If for some reason you can't use Crowdin feel free to open an issue to discuss alternative options. \n\nIf you'd like a new language to be added to Crowdin, for you to be able to provide translations for, please open a new issue here.\n\nPlease note, translations in BookStack are provided to the \"Crowdin Global Translation Memory\" which helps BookStack and other projects with finding translations. If you are not happy with contributing to this then providing translations to BookStack, even manually via GitHub, is not advised.\n\nüéÅ Contributing, Issues & Pull Requests\n\nFeel free to create issues to request new features or to report bugs & problems. Just please follow the template given when creating the issue.\n\nPull requests are welcome but, unless it's a small tweak, it may be best to open the pull request early or create an issue for your intended change to discuss how it will fit into the project and plan out the merge. Just because a feature request exists, or is tagged, does not mean that feature would be accepted into the core project.\n\nPull requests should be created from the development branch since they will be merged back into development once done. Please do not build from or request a merge into the release branch as this is only for publishing releases. If you are looking to alter CSS or JavaScript content please edit the source files found in resources/. Any CSS or JS files within public are built from these source files and therefore should not be edited directly.\n\nThe project's code of conduct can be found here.\n\nüîí Security\n\nSecurity information for administering a BookStack instance can be found on the documentation site here.\n\nIf you'd like to be notified of new potential security concerns you can sign-up to the BookStack security mailing list.\n\nIf you would like to report a security concern, details of doing so can be found here.\n\n‚ôø Accessibility\n\nWe want BookStack to remain accessible to as many people as possible. We aim for at least WCAG 2.1 Level A standards where possible although we do not strictly test this upon each release. If you come across any accessibility issues please feel free to open an issue.\n\nüñ•Ô∏è Website, Docs & Blog\n\nThe website which contains the project docs & blog can be found in the BookStackApp/website repo.\n\n‚öñÔ∏è License\n\nThe BookStack source is provided under the MIT License. \n\nThe libraries used by, and included with, BookStack are provided under their own licenses and copyright.\nThe licenses for many of our core dependencies can be found in the attribution list below but this is not an exhaustive list of all projects used within BookStack. \n\nüë™ Attribution\n\nThe great people that have worked to build and improve BookStack can be seen here. The wonderful people that have provided translations, either through GitHub or via Crowdin can be seen here.\n",
    name: "BookStack",
    category: "CMS",
    health: 100,
    code: "pioHxx",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4baccede-38e4-435f-b0b0-2743fc297e67",
    isApproved: false,
    activeProjects: 23,
    projects: 50,
    description: "Convex is the open-source reactive database for app developers.",
    readme:
      'Convex\nThe missing half of your React app\n\nConvex is the open-source reactive database for app developers.\n\nSteps to make this template work\n\n1) Deploy the template\n2) Remove auto generated domain from convex-backend in public networking area\n3) Click on "Generate Domain" -> select port 3210 -> Generate\n4) Re-deploy both convex-dashboard and convex-backend services\n\nAdmin dashboard access\n\n1) ssh to convex-backend service and execute ./generate_admin_key.sh\n2) copy the admin key logged to console\n3) open the public url of convex-dashboard\n4) paste admin key to login (this is your admin key keep it secret)\n\nRest of the usage and setup (e.g. postgresql) can be found in convex docs\n\nLinks:\nhttps://docs.convex.dev/home\nhttps://github.com/get-convex/convex-backend/tree/main/self-hosted\n\nEnjoy!\n',
    name: "convex",
    category: "Other",
    health: 100,
    code: "OKpPqB",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a8bff039-59f0-4b98-925e-b8b6377a6da9",
    isApproved: false,
    activeProjects: 16,
    projects: 36,
    description: "Scrape, crawl and extract with a single API.",
    readme:
      "\nüî• Firecrawl\n\nEmpower your AI apps with clean data from any website. Featuring advanced scraping, crawling, and data extraction capabilities.\n\nThis repository is in development, and we‚Äôre still integrating custom modules into the mono repo. It's not fully ready for self-hosted deployment yet, but you can run it locally.\n\nWhat is Firecrawl?\n\nFirecrawl is an API service that takes a URL, crawls it, and converts it into clean markdown or structured data. We crawl all accessible subpages and give you clean data for each. No sitemap required. Check out our documentation.\n\nPst. hey, you, join our stargazers :)\n\nHow to use it?\n\nWe provide an easy to use API with our hosted version. You can find the playground and documentation here. You can also self host the backend if you'd like.\n\nCheck out the following resources to get started:\nx] API: [Documentation\nx] SDKs: [Python, Node, Go, Rust\nx] LLM Frameworks: [Langchain (python), Langchain (js), Llama Index, Crew.ai, Composio, PraisonAI, Superinterface, Vectorize\nx] Low-code Frameworks: [Dify, Langflow, Flowise AI, Cargo, Pipedream\nx] Others: [Zapier, Pabbly Connect\n[ ] Want an SDK or Integration? Let us know by opening an issue.",
    name: "firecrawl:v1.9.0",
    category: "AI/ML",
    health: 100,
    code: "-iHken",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6318ec16-7d3f-425b-8b4c-920bf2bf9d06",
    isApproved: false,
    activeProjects: 2,
    projects: 3,
    description: "Effortlessly upload and save images as WebP with API key security.",
    readme:
      'Overview\n\nThe Image Upload API enables developers to easily upload images, which are then automatically processed and converted to WebP format. The API guarantees security by utilizing API key authentication, ensuring that only authorized users can upload files. For maximum performance and security, the API integrates with  Gumlet for optimal image delivery speed.\nGumlet Integration for Speed\nTo ensure fast delivery of images, the Gumlet CDN is used. Gumlet optimizes image sizes and ensures that they load quickly on your site or app. By integrating Gumlet with the upload system, you can maximize performance without compromising image quality.\n\nHow to Integrate Gumlet\n\nKey Features\n\nImage Upload: Accepts image file uploads (JPEG, PNG, WebP).\nWebP Conversion: Converts images to WebP format for optimized file size without significant loss of quality.\nAPI Key Authentication: Ensures security by validating API keys provided in requests.\nFile Storage: Stores files on the server and provides URLs for accessing them.\nCORS Support: The API can be accessed from allowed domains only.\nFile Size Limits: Defines a maximum file size for uploads (e.g., 25MB per file).\nGumlet Integration: Leverage Gumlet for faster image delivery.\n\nEndpoints\n\n1. POST /upload\n\nThis endpoint handles the upload of image files. The file will be processed (resized, converted to WebP) and stored on the server.\n\nRequest Headers:\n\nx-api-key: The API key required to authenticate the request. This must match the key set in the server\'s environment.\n\nRequest Body:\n\nimage: The image file to be uploaded (JPEG, PNG, or WebP). This should be sent as multipart/form-data.\n\nResponse:\n\n200 OK:\n  filePath: URL to access the uploaded image (in WebP format).\n  message: A success message indicating that the image has been uploaded and processed.\n  \n400 Bad Request:\n  error: Error message indicating that the uploaded file is not a valid image or is missing.\n\n403 Forbidden:\n  error: Error message if the API key provided is invalid or missing.\n\n500 Internal Server Error:\n  error: General error message indicating a server-side issue.\n\nHow to Use the API\n\nObtain API Key: \n   Before making any requests to the API, you must obtain a valid API key from the server administrator.\n   \nMake a POST Request to /upload:\n   To upload an image, send a POST request to the /upload endpoint with the following:\n     Headers: Include your API key in the x-api-key header.\n     Body: Attach the image you want to upload in the image field of the form data.\n   \nProcess the Response:\n   If successful, the response will contain a URL (filePath) where the uploaded image can be accessed.\n   If the file is not an image or is missing, the API will return an error message.\n\nError Handling\n\nThe API provides clear error messages in case something goes wrong. Here are the possible errors and their meanings:\n\nNo file uploaded: This error occurs if the request does not contain an image file.\nInvalid file type: This error is returned if the uploaded file is not a valid image (e.g., a non-image file type).\nInvalid API key: If the x-api-key header is missing or incorrect, the request will be rejected with a "Forbidden" error.\nServer error: If something goes wrong on the server (e.g., a failure in processing the image), an internal server error will be returned.\n\nSecurity Considerations\n\nThe API uses API keys to authenticate requests, ensuring that only authorized users can upload files. The server checks the key provided in the x-api-key header of the request against a predefined value stored in the server\'s environment variables. If the key is invalid or missing, the request will be denied.\n\nFile Storage\n\nUploaded images are stored in the server\'s file system. The files are saved in the /files/images directory and are accessible through URLs returned in the response. The URL format follows the structure:\n\nhttps://your-cdn-link/files/images/{image-id}.webp\n\nThis link can be used to display or download the uploaded images. Images are optimized and delivered via the Gumlet CDN to ensure high speed and reduced loading times.\n\nFile Size Limits\n\nTo prevent overloading the server, the API imposes a file size limit on uploads. The default file size limit is 25MB. If a user attempts to upload a file that exceeds this size, they will receive a "File too large" error.\n\nResponse Examples\n\nHere are example responses for various outcomes:\n\nSuccess Response (200 OK)\n\n{\n    "filePath": "https://your-cdn-link/files/images/abc123.webp",\n    "message": "Image uploaded and processed successfully."\n}\n\nError Response (400 Bad Request)\n\n{\n    "error": "No file uploaded"\n}\n\nError Response (403 Forbidden)\n\n{\n    "error": "Forbidden: Invalid API Key"\n}\n\nError Response (500 Internal Server Error)\n\n{\n    "error": "An error occurred while processing the image."\n}\n\nConclusion\n\nThis API is designed to make image uploading and processing simple for developers. With the ability to handle various image formats, secure file uploads with API key authentication, and store images on the server with easy-to-access URLs, it provides a robust solution for any application that needs image handling capabilities. Additionally, by integrating Gumlet for optimized delivery, this API offers a complete solution.\n\nFor detailed guides, check the following links:\nIntegrate Gumlet for Speed\n\nIf you have any questions or issues, please contact the server administrator or refer to the project\'s repository for more information.\n\nLicense\n\nThis project is licensed under the MIT License. See the LICENSE file for details.\n',
    name: "Upload APIs",
    category: "Storage",
    health: null,
    code: "8d2Rdz",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "dced9457-aa75-426b-ba85-109681022366",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "An open-source modern data exploration and visualization platform.",
    readme:
      "Apache Superset on Railway\nThis template provides a quick and efficient way to deploy Apache Superset, an open-source data visualization and business intelligence tool, on Railway.app. Superset enables users to explore, visualize, and analyze data through an intuitive web-based interface, making it ideal for startups, data teams, and enterprises looking for a lightweight, scalable analytics solution.\n\nüöÄ Features:\nOne-Click Deployment: Get Apache Superset up and running in minutes on Railway.\nPreconfigured Database: Automatically connects to a PostgreSQL instance for metadata storage.\nScalable & Secure: Deploy in a cloud-native environment with Railway's managed infrastructure.\nCustomizable Dashboards: Create interactive charts, graphs, and reports with ease.\nAuthentication & RBAC: Supports role-based access control and integrations with authentication providers.\n\nüõ† Setup Instructions:\nClick the Deploy on Railway button.\nSet up environment variables (e.g., SUPERSET_SECRET_KEY, DATABASE_URL).\nAccess the Superset UI and start building your dashboards.",
    name: "apache-superset-v2",
    category: "Analytics",
    health: null,
    code: "ZScvXD",
    languages: ["Dockerfile", "Shell", "Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "478eac69-1bcb-41bc-89a6-900c6d850a31",
    isApproved: false,
    activeProjects: 1,
    projects: 3,
    description: "Opentelemetry with Jaeger",
    readme:
      "Deploy the OpenTelemetry Collector along with a set of backend services.\n\nJaeger\nJaeger is a distributed tracing system. It receives data from the Otel Collector on port 4317 and 4318.\n\nJaeger Documentation",
    name: "OpenTelemetry-Jaeger",
    category: "Observability",
    health: 100,
    code: "OocRiw",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "05f15655-443c-40c7-942f-c8bc0a2a8d16",
    isApproved: false,
    activeProjects: 14,
    projects: 16,
    description: "Ready made template to make your KOmpanion instance",
    readme:
      "It will ask for admin username and password, and setup railway domain for it. After deployment follow to railway domain and add devices for progress and statistics sync feautres. Detailed description for usage: https://github.com/vanadium23/kompanion?tab=readme-ov-file#usage\n\nInside you will see a postgresql instance and container done via Docker Hub image: https://hub.docker.com/r/vanadium23/kompanion/\n\nFor detailed setup and configuration you can refer to README:\nhttps://github.com/vanadium23/kompanion?tab=readme-ov-file#configuration",
    name: "kompanion",
    category: "Other",
    health: 100,
    code: "n9t_1r",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "618ee776-50b8-4159-b25b-e92d3c1f2e63",
    isApproved: false,
    activeProjects: 12,
    projects: 19,
    description: "PostgreSQL 17 with powerful vector search support.",
    readme:
      "PostgreSQL v17 with pgvector\n\nTL;DR: This template is like the existing pgvector template, but with PostgreSQL v17 instead of PostgreSQL v16.\n\nWhat is PGVector?\n\nPGVector is an extension for PostgreSQL that enables efficient storage and retrieval of vector embeddings, making it ideal for machine learning and AI applications like similarity search. It adds support for vector data types and indexing methods to facilitate quick querying on high-dimensional vectors.\n\nHow to Use the Template\n\nThis template provides PostgreSQL v17 with the pgvector extension pre-installed. You‚Äôll need to enable the pgvector extension in each database where you intend to use it.\n\nConnection Setup:\n   Find the appropriate connection string under the service variables tab:\n     DATABASE_URL: Used for connecting from other Railway services.\n     DATABASE_PUBLIC_URL: Used for connecting from external services/tools.\n   Reference these URLs in your other services variables as needed (For instance, ${{ pgvector.DATABASE_URL }})\n\nEnabling PGVector Extension:\n   Before using pgvector, you must enable the extension in your database:\n   CREATE EXTENSION IF NOT EXISTS vector;\n\nExample Usage Script\n\nHere‚Äôs a simple example to verify that the pgvector extension is set up and working as expected:\n   CREATE EXTENSION IF NOT EXISTS vector;\n   \n   -- Create a table with an embedding vector\n   CREATE TABLE items (\n       id bigserial PRIMARY KEY,\n       embedding vector(3)\n   );\n   \n   -- Insert some example data\n   INSERT INTO items (embedding) VALUES \n   ('[1,2,3]'), \n   ('[4,5,6]');\n   \n   -- Perform a vector similarity search\n   SELECT * FROM items \n   ORDER BY embedding &lt;-&gt; '[3,1,2]' \n   LIMIT 5;\n\nThis SQL snippet sets up the pgvector extension, creates a table, inserts data, and runs a basic similarity query using the &lt;-&gt; operator to measure vector distance.\n\nFurther Information\n\nFor more details on PGVector, visit the official GitHub repository: https://github.com/pgvector/pgvector",
    name: "pgvector-pg17",
    category: "Storage",
    health: 100,
    code: "qcuy_M",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1acb0cc0-6d97-431d-b7b0-da4e3ce09d63",
    isApproved: false,
    activeProjects: 1,
    projects: 1,
    description: "cunxg oj ddossdfsfdsfdsfdsfd",
    readme:
      "cunxg oj ddossdfsfdsfdsfdsfdcunxg oj ddossdfsfdsfdsfdsfdcunxg oj ddossdfsfdsfdsfdsfdcunxg oj ddossdfsfdsfdsfdsfdcunxg oj ddossdfsfdsfdsfdsfdcunxg oj ddossdfsfdsfdsfdsfdcunxg oj ddossdfsfdsfdsfdsfdcunxg oj ddossdfsfdsfdsfdsfdcunxg oj ddossdfsfdsfdsfdsfdcunxg oj ddossdfsfdsfdsfdsfdcunxg oj ddossdfsfdsfdsfdsfdcunxg oj ddossdfsfdsfdsfdsfdcunxg oj ddossdfsfdsfdsfdsfdcunxg oj ddossdfsfdsfdsfdsfdcunxg oj ddossdfsfdsfdsfdsfdcunxg oj ddossdfsfdsfdsfdsfdcunxg oj ddossdfsfdsfdsfdsfdcunxg oj ddossdfsfdsfdsfdsfdcunxg oj ddossdfsfdsfdsfdsfdcunxg oj ddossdfsfdsfdsfdsfdcunxg oj ddossdfsfdsfdsfdsfdcunxg oj ddossdfsfdsfdsfdsfdcunxg oj ddossdfsfdsfdsfdsfd",
    name: "xtreamtremio",
    category: "Other",
    health: null,
    code: "xKXePg",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5b16544c-33f9-4b01-af6b-bb06be8450f1",
    isApproved: true,
    activeProjects: 20,
    projects: 44,
    description: "One-click observability with Loki, Prometheus, Tempo, and Grafana",
    readme:
      "What is this template\n\nThis template deploys a complete Grafana observability stack on Railway with just one click! The stack includes four integrated services:\n\nGrafana: The leading open-source analytics and monitoring solution\nLoki: A horizontally-scalable, highly-available log aggregation system\nPrometheus: A powerful metrics collection and alerting system\nTempo: A high-scale distributed tracing backend\n\nThis template is perfect for teams who need a comprehensive observability solution for their railway project without the hassle of manual configuration and infrastructure management.\n\nKey Features\n\nPre-configured Integration: All services come pre-connected, so Grafana is ready to query your data immediately.\nPersistent Storage: All four services use Railway volumes to ensure your data, dashboards, and configurations persist between updates and deploys.\nVersion Control: Pin specific Docker image versions for each service using environment variables.\nCustomizable: Fork the repository to customize configuration files for any service. You can take full control and edit anything you'd need to as you scale.\nOne-Click Deploy: Get a complete Grafana-based observability stack running in minutes.\n\nQuick Start Guide\n\nClick the \"Deploy on Railway\" button at the top of this page\nEnter your desired Grafana admin username in the GF_SECURITY_ADMIN_USER variable\nLeave all other variables at their defaults (or customize as needed)\nWait for your stack to deploy (this typically takes 3-5 minutes)\nNavigate to the Grafana URL provided by Railway\nLog in with your admin username and the auto-generated password found in the GF_SECURITY_ADMIN_PASSWORD environment variable\nHook up your applications to the datasources.\nCreate dashboards, alerts, and explore your data in Grafana!\n\nOptional Variables\n\n| Variable | Description | Default |\n|----------|-------------|---------|\n| GF_SECURITY_ADMIN_USER | Username for the Grafana admin account | Required input |\n| GF_SECURITY_ADMIN_PASSWORD | Password for the Grafana admin account | Auto-generated secure string |\n| GF_DEFAULT_INSTANCE_NAME | Name of your Grafana instance | Grafana on Railway |\n| GF_INSTALL_PLUGINS | Comma-separated list of Grafana plugins to install | grafana-simple-json-datasource,grafana-piechart-panel,grafana-worldmap-panel,grafana-clock-panel |\n\nInternal Service URLs\n\nThe Grafana service exposes these environment variables that you can reference in your other Railway applications to easily send data to your observability stack:\n\n| Variable | Description | Usage |\n|----------|-------------|-------|\n| LOKI_INTERNAL_URL | Internal URL for the Loki service | Use in your applications to send logs to and query Loki |\n| PROMETHEUS_INTERNAL_URL | Internal URL for the Prometheus service | Use in your applications to send metrics to and query Prometheus |\n| TEMPO_INTERNAL_URL | Internal URL for the Tempo service | Use in your applications to query Tempo |\n\nThese variables make it easy to configure your other Railway services to send telemetry data to your observability stack.\n\nTempo also exposes a few variables to make it easier to push tracing information to the service using either HTTP or GRPC\n\n| Variable | Description | Usage |\n|----------|-------------|-------|\n| INTERNAL_HTTP_INGEST | Internal HTTP ingest server URL for Tempo | Use in your applications to send traces to tempo via HTTP |\n| INTERNAL_GRPC_INGEST | Internal GRPC ingest server URL for Tempo | Use in your applications to send traces to tempo via GRPC |\n\nVersion Control\n\nEach service has its own VERSION environment variable that can be set independently in each service's settings in the Railway dashboard:\n\nGrafana Service: Set VERSION to control the Grafana Docker image tag\nLoki Service: Set VERSION to control the Loki Docker image tag\nPrometheus Service: Set VERSION to control the Prometheus Docker image tag\nTempo Service: Set VERSION to control the Tempo Docker image tag\n\nBy default, all services use the latest tag, but you can pin specific versions for stability:\n\nExamples:\nGrafana: VERSION=11.5.2\nLoki: VERSION=3.4.2\nPrometheus: VERSION=v3.2.1\nTempo: VERSION=v2.7.1\n\nThis allows you to update each component independently as needed.\n\nProject Structure & Services\n\nThis template deploys four interconnected services:\n\nGrafana\nThe central visualization and dashboarding platform\nPre-configured with connections to all other services\nPersistent volume for storing dashboards, users, and configurations\nComes with useful plugins pre-installed\nExposes internal URLs for other Railway services to connect to Loki, Prometheus, and Tempo\n\nPrometheus\nTime-series database for metrics collection\nConfigured with sensible defaults for monitoring\nPersistent volume for metrics data\n\nLoki\nLog aggregation system designed to be cost-effective\nHorizontally scalable architecture\nPersistent volume for log storage\n\nTempo\nDistributed tracing system for tracking requests across services\nHigh-performance trace storage\nPersistent volume for trace data\n\nAll services are deployed using official Docker images and configured to work together seamlessly.\n\nConnecting Your Applications\n\nUsing Locomotive for Loki\n\nYou can easily ingest all of your railway logs into Loki from any service using Locomotive. Just spin up their template, drop in your Railway API key, the ID of the services you want to monitor, and a link to your new Loki instance and logs will start flowing! no code changes needed anywhere!\n\nUsing OpenTelemetry libraries for Tempo \n\nTempo is a bit different than both Prometheus and Loki in that exposes separate GRPC and HTTP servers on ports :4317 and :4318 respectively specifically for ingesting your tracing data or \"spans\".\n\nWhen configuring your application to send traces to Tempo, please use one of the preconfigured variables in the Tempo service: INTERNAL_HTTP_INGEST or INTERNAL_GRPC_INGEST.\n\nAnother thing to note is that the ingest API endpoint for the HTTP server is /v1/traces. For a working example of this in a node.js express API, see /examples/api/tracer.js in our GitHub repository.\n\nUsing otherwise standard observability tooling\n\nTo send data from your other Railway applications to this observability stack:\n\nIn your application's Railway service, add environment variables that reference the internal URLs:\n   LOKI_URL=${{Grafana.LOKI_INTERNAL_URL}}\n   PROMETHEUS_URL=${{Grafana.PROMETHEUS_INTERNAL_URL}}\n   TEMPO_URL=${{Grafana.TEMPO_INTERNAL_URL}}\nConfigure your application's logging, metrics, or tracing libraries to use these URLs\nYour application data will automatically appear in your Grafana dashboards\n\nCustomizing Your Stack\n\nTo customize the configuration of Loki, Prometheus, or Tempo:\n\nFork the GitHub repository\nModify the configuration files in their respective directories\nIn Railway, disconnect the service you want to customize\nReconnect the service to your forked repository\nDeploy the updated service\n\nThe pre-configured Grafana connections will continue to work with your customized services.\n\nAdditional Resources\n\nLocomotive: a loki transport for railway services\nGrafana Documentation\nLoki Documentation\nPrometheus Documentation\nTempo Documentation\nGrafana Community Forums\nGrafana Plugins Directory\n\nDeveloped and maintained by Mykal. For issues or suggestions, please open an issue on the GitHub repository.\n",
    name: "Grafana Stack",
    category: "Observability",
    health: 100,
    code: "8TLSQD",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "55fad7b6-18b0-4ee2-b62f-3bc8c999e5be",
    isApproved: false,
    activeProjects: 3,
    projects: 6,
    description: "The superpowered CMS for developers",
    readme:
      "Keystone Project Starter\n\nKeystone helps you build faster and scale further than any other CMS or App Framework. Describe your schema, and you get a powerful GraphQL API & beautiful Management UI for content and data.\n\nNo boilerplate or bootstrapping ‚Äì only elegant APIs to help you ship the code that matters, without sacrificing the flexibility or power of a bespoke back-end.\n\nFeatures include:\nBuilt-in authentication system\nGraphQL API\nPostgreSQL database support\nAdmin UI for content management\nCustomizable data schema\nReady for any frontend (Next.js, React, etc.)\n\nPerfect for blogs, e-commerce, or any content-driven application. Fork the github repo in template to customize the schema, add your own models, or modify the authentication system to match your needs.",
    name: "Keystone",
    category: "CMS",
    health: 100,
    code: "h6W0gR",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2a56b121-01a0-486c-9553-59993268b9f6",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "SolidJS + Vite + Caddy Starter",
    readme:
      "SolidJS + Vite + Caddy\n\nThis template should help get you started developing with Solid and JavaScript in Vite.\n\n‚ú® Features\n\nSolidJS + JavaScript + Vite + Caddy\nCaddy v2\n\nüíÅ‚Äç‚ôÄÔ∏è Local Development\n\nInstall required dependencies with npm install\nStart the server for local development npm run dev\n\n‚ùì Why use Caddy when deploying to Railway?\n\nCaddy is a powerful, enterprise-ready, open source web server, and therefore Caddy is far better suited to serve websites than Vite is, using Caddy will result in much less memory and cpu usage compared to serving with Vite (much lower running costs too)\n\nTo see how this is achieved with nixpacks, check out the fully documented nixpacks.toml file in this repository\n\nThe configuration for Caddy is called a Caddyfile, and you can edit that file to further suite your needs, by default it comes configured to serve a single page app for Vue 3, and to also gzip the responses\n\nRelevant Caddy documentation:\n\nThe Caddyfile\nCaddyfile Directives\nroot\nencode\nfile_server\ntry_files",
    name: "solidjs",
    category: "Starters",
    health: null,
    code: "w5OSVq",
    languages: ["JavaScript", "CSS", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c6af7d73-140a-41ca-90a4-d94b8c1af0e0",
    isApproved: false,
    activeProjects: 12,
    projects: 16,
    description: "Lightweight, scalable, easy-to-deploy RSS feed service",
    readme:
      "A lightweight, scalable RSS feed service built with Hono.js and Upstash Redis. This service allows you to create and manage RSS feeds programmatically through a simple REST API. It's designed to work seamlessly with the @curatedotfun/rss plugin in the curate.fun ecosystem.\n\nDeploy and configure your RSS feed in the curate.config.json.",
    name: "curatedotfun-rss-service",
    category: "Blogs",
    health: 93,
    code: "pfvWZK",
    languages: ["TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "34f78b56-73cd-47dd-a2c4-134d68630c56",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "Self-healing open source data connector.",
    readme:
      '\n  \n\n\nself-healing open source data connector üçØ\n\nsuperglue is a self-healing open source data connector. You can deploy it as a proxy between you and any complex / legacy APIs and always get the data that you want in the format you expect.\n\nHere\'s how it works: You define your desired data schema and provide basic instructions about an API endpoint (like "get all issues from jira"). Superglue then does the following:\n\nAutomatically generates the API configuration by analyzing API docs.\nHandles pagination, authentication, and error retries.\nTransforms response data into the exact schema you want using JSONata expressions.\nValidates that all data coming through follows that schema, and fixes transformations when they break.\n\n\n\n\n\nGitHub\nY Combinator\nClient SDK\nDocker\nTwitter Adina\nTwitter Stefan\nWeave Badge\n\n\n\n\nIf you‚Äôre spending a lot of time writing code connecting to weird APIs, fumbling with custom fields in foreign language ERPs, mapping JSONs, extracting data from compressed CSVs sitting on FTP servers, and making sure your integrations don‚Äôt break when something unexpected comes through, superglue might be for you.',
    name: "superglue",
    category: "AI/ML",
    health: null,
    code: "wJg5-W",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f6d268f2-ffbf-426c-ba8e-9c30f763028c",
    isApproved: false,
    activeProjects: 6,
    projects: 10,
    description: "Flask API for extracting YouTube video metadata and transcripts/subtitles.",
    readme:
      "YouTube Explorer API\n\nA Flask-based REST API that retrieves video data, transcripts, and subtitles from YouTube videos. This API provides easy access to video metadata and transcripts in multiple languages.\n\nFeatures\n\nRetrieve video metadata from YouTube URLs\nExtract video transcripts and subtitles\nSupport for multiple languages\nConfigurable response fields\nSwagger documentation interface\nProduction-ready WSGI setup",
    name: "Youtube Explorer API",
    category: "Other",
    health: 100,
    code: "msf8pk",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f544ad14-8cd0-4f02-a13b-8365d9cb5d35",
    isApproved: false,
    activeProjects: 9,
    projects: 23,
    description: "A self-hosted dashboard that puts all your feeds in one place",
    readme:
      "Features\nVarious widgets\nRSS feeds\nSubreddit posts\nHacker News posts\nWeather forecasts\nYouTube channel uploads\nTwitch channels\nMarket prices\nDocker containers status\nServer stats\nCustom widgets\nand many more...\n\nFast and lightweight\nLow memory usage\nFew dependencies\nMinimal vanilla JS\nSingle &lt;20mb binary available for multiple OSs &amp; architectures and just as small Docker container\nUncached pages usually load within ~1s (depending on internet speed and number of widgets)\n\nTons of customizability\nDifferent layouts\nAs many pages/tabs as you need\nNumerous configuration options for each widget\nMultiple styles for some widgets\nCustom CSS\n\nOptimized for mobile devices\nBecause you'll want to take it with you on the go.\n\nmobile-preview\n\nThemeable\nEasily create your own theme by tweaking a few numbers or choose from one of the already available themes.\n\nthemes-example\n\nFeature requests\n\nNew feature suggestions are always welcome and will be considered, though please keep in mind that some of them may be out of scope for what the project is trying to achieve (or is reasonably capable of). If you have an idea for a new feature and would like to share it, you can do so here.\n\nFeature requests are tagged with one of the following:\n\nRoadmap - will be implemented in a future release\nBacklog - may be implemented in the future but needs further feedback or interest from the community\nIcebox - no plans to implement as it doesn't currently align with the project's goals or capabilities, may be revised at a later date\n",
    name: "Glance",
    category: "Starters",
    health: 100,
    code: "ZHBnkG",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e1c59af5-d1bd-4be7-94ed-df1ec56cf3fb",
    isApproved: false,
    activeProjects: 1,
    projects: 2,
    description: "Stop paying for Ethereum nodes!",
    readme:
      "This project is a Go-based proxy server designed to distribute POST requests across multiple RPC endpoints using a round-robin algorithm. By using this proxy, you can avoid relying on a single RPC endpoint. Instead, you can configure a list of public RPC endpoints, and the service will handle the distribution of requests among them. This approach can help you avoid the costs associated with paid nodes while ensuring better reliability and load balancing.",
    name: "ethereum-rpc-pool",
    category: "Other",
    health: null,
    code: "CObZnk",
    languages: ["Go", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9e503096-5e51-4633-90ce-88a7664c01be",
    isApproved: false,
    activeProjects: 4,
    projects: 4,
    description: "Highly performant realtime database designed primarily for MMO-RPGs.",
    readme:
      '                Multiplayer at the speed of light ‚Äì now on Railway!     &nbsp;  &nbsp;  &nbsp;     &nbsp;  \n\nSpacetimeDB on Railway\n\nThis repository provides a template to deploy SpacetimeDB, a revolutionary relational database and server combined into one, on Railway. With this template, you can quickly set up a SpacetimeDB instance to power real-time applications like games, chat systems, or collaboration tools‚Äîall with minimal configuration.\n\nSpacetimeDB lets you upload your application logic as "modules" (fancy stored procedures) written in Rust, eliminating the need for separate servers, microservices, or complex infrastructure. Clients connect directly to the database, executing your logic with ultra-low latency. This template simplifies deployment by leveraging Railway‚Äôs platform to host a SpacetimeDB standalone server.',
    name: "SpacetimeDB",
    category: "Storage",
    health: 67,
    code: "JL9J05",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f3a4e748-8c48-4094-9c6c-b5846c3793bb",
    isApproved: false,
    activeProjects: 58,
    projects: 81,
    description: "Ubuntu shell, everything is accessible via the web.",
    readme:
      "Ubuntu\nDocker\nUbuntu-Railway\n\nWant to try out Ubuntu or want to have a mini version of Ubuntu available at all times? Then feel free to give this project a try:\n\nDeploy on Railway\n\nDescription\nThis project uses the official Ubuntu image to deploy a container which can then be used to install most of the CLI tools. Behind the scenes, it uses ttyd to provide a hassle-free and a very accessible way to access the command line.\n\nEnvironment Variables\n  PORT: The port on which the ttyd program will listen on.\n  USERNAME: The username which will be used to login to the web shell.\n  PASSWORD: The password which will be used to login to the web shell.\n \nNOTE: It is strongly advised to provide the USERNAME and PASSWORD environment variables before deploying the project.\n",
    name: "Ubuntu-Shell",
    category: "Other",
    health: 95,
    code: "4lvigd",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3596f825-83d8-40b8-9c78-beb1f4b2262b",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "Backup your Postgres DB to any S3 storage (Backblaze/Cloudflare)",
    readme:
      "A simple script to backup your Postgres database to any S3-compatible storage, including Backblaze B2 and Cloudflare R2, on any schedule.\n\nAll the configuration options can be found on our GitHub repo\n\nBased on Railway's Postgres S3 Backups script.",
    name: "Postgres S3 Backups",
    category: "Automation",
    health: null,
    code: "eIOwd0",
    languages: ["TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d9650997-181f-486c-9b49-150310d00715",
    isApproved: false,
    activeProjects: 8,
    projects: 15,
    description: "Minimal Quarkus rest/http end point",
    readme:
      "Overview\nThis is a streamlined template for deploying Quarkus applications on Railway.app, offering a modern, container-first Java framework designed for cloud-native development. Quarkus, also known as \"Supersonic Subatomic Java,\" provides an optimal foundation for building high-performance, cloud-native applications.\n\nKey Features\nFast Startup Time: Leverages Quarkus' lightning-fast boot time and low memory footprint\nContainer-Ready: Optimized for containerized deployments with Docker support\nDeveloper Joy: Hot reload in live coding for rapid development cycles\nCloud-Native: Built from the ground up for cloud deployments\nRailway.app Integration: Pre-configured for seamless deployment on Railway's platform\n\nTechnical Stack\nFramework: Quarkus\nLanguage: Java\nBuild Tool: Maven\n",
    name: "railway-java-quarkus",
    category: "Starters",
    health: 0,
    code: "orZ9Pj",
    languages: ["Java", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a4557650-25e5-4240-b713-d4c2ae274593",
    isApproved: false,
    activeProjects: 6,
    projects: 7,
    description: "An example Discord chatbot built on the Letta API",
    readme:
      "Letta Discord Chatbot One-click Deploy on Railway\n\nAn example Discord chatbot built on the Letta API, which uses a stateful agent (agent with memory) under the hood.\n\nThis Railway template deploys a Discord bot using the repo here: https://github.com/letta-ai/letta-discord-bot-example",
    name: "letta-discord-bot",
    category: "Bots",
    health: 100,
    code: "C__ceE",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "703ce8b5-0b66-486f-a082-29cbbae124da",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "fast and privacy-friendly web app for converting images to WebP format.",
    readme:
      "TinyWebP is a fast and privacy-friendly web app for converting images to WebP format. It runs entirely in the browser, ensuring secure and efficient conversions.\n\nFeatures\n\nDrag-and-drop image conversion\nSupports JPG, PNG, GIF, TIFF, BMP, WEBP and AVIF formats\nFast and privacy-focused (runs entirely in the browser)\nNo file uploads, ensuring data security\nResponsive and mobile-friendly UI",
    name: "tinywebp",
    category: "Other",
    health: null,
    code: "3LQFt-",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "bfb9862b-36b2-4b03-9129-46a479b02973",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "A flexible time tracking solution designed for freelancers & small teams.",
    readme:
      'What is this template\n\nThis template deploys Titra, an open-source time tracking application, to Railway with just one click.\n\nTitra is a modern, flexible time tracking solution designed for freelancers, small teams, and businesses. It provides a clean interface for tracking work hours, managing projects, and generating reports.\n\nKey Features\n\nSimple Time Tracking: Log your hours with an intuitive interface\nProject Management: Organize your work by projects and tasks\nReporting: Generate detailed reports of your time entries\nExport Options: Export your data to CSV or Excel formats\nMulti-user Support: Collaborate with team members\nLDAP/OIDC Authentication: Secure logins with LDAP or Open ID Connect authentication across your organization\nClient Management: Track time against specific clients\nResponsive Design: Works on desktop and mobile devices\nInternationalization: Supports multiple languages\n\nQuick Start Guide\n\nClick the "Deploy on Railway" button at the top of this page\nLeave all variables and settings as their defaults\nWait for your new instance to deploy (this typically takes 2-3 minutes)\nOnce deployed, navigate to your new Titra instance at the URL provided by Railway\nRegister a new account; the first account created will be an admin account.\nStart tracking your time!\n\nOptional Variables\n\n| Variable | Description | Default |\n|----------|-------------|---------|\n| MONGO_URL | MongoDB connection string (auto-configured by Railway) | Auto-generated |\n| ROOT_URL | The root URL of your Titra instance | Auto-generated |\n\nProject Structure & Services\n\nThis template uses a straightforward architecture:\n\nTitra Application: Deployed using the official Titra Meteor application\nMongoDB Database: Automatically provisioned by Railway to store all your time tracking data\nPersistent Storage: Railway ensures your data persists across redeploys and upgrades\nAutomatic Updates: When you want to update Titra, you can easily redeploy with the latest version\n\nThe application container exposes the necessary port, which Railway automatically maps to a public URL for you to access.\n\nAdditional Resources\n\nTitra Official Repository\nTitra Documentation\nTitra Demo\nTitra Website\nKromit GmbH Website\n\nDeveloped by Kromit GmbH. Railway template by Mykal Machon',
    name: "Titra",
    category: "Analytics",
    health: null,
    code: "V06Z4P",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d6460856-ce11-46e9-88eb-c9ae8a149578",
    isApproved: false,
    activeProjects: 1,
    projects: 1,
    description: "A remote instance of CCXT; a common interface/protocol for algotrading I/O",
    readme:
      "CCXT ‚Äì CryptoCurrency eXchange Trading Library\nNPM Downloads npm PyPI NuGet version GoDoc Discord Supported Exchanges Follow CCXT at x.com\n\nA JavaScript / Python / PHP / C# / Go library for cryptocurrency trading and e-commerce with support for many bitcoin/ether/altcoin exchange markets and merchant APIs.\n\nInstall ¬∑ Usage ¬∑ Manual ¬∑ FAQ ¬∑ Examples ¬∑ Contributing ¬∑ Social\nThe CCXT library is used to connect and trade with cryptocurrency exchanges and payment processing services worldwide. It provides quick access to market data for storage, analysis, visualization, indicator development, algorithmic trading, strategy backtesting, bot programming, and related software engineering.\n\nIt is intended to be used by coders, developers, technically-skilled traders, data-scientists and financial analysts for building trading algorithms.\n\nCurrent feature list:\n\nsupport for many cryptocurrency exchanges ‚Äî more coming soon\nfully implemented public and private APIs\noptional normalized data for cross-exchange analytics and arbitrage\nan out of the box unified API that is extremely easy to integrate\nworks in Node 10.4+, Python 3, PHP 8.1+, netstandard2.0/2.1 and web browsers",
    name: "tmdc-algot-template-001",
    category: "Analytics",
    health: 0,
    code: "7xgMCh",
    languages: [
      "Python",
      "C#",
      "Go",
      "TypeScript",
      "JavaScript",
      "PHP",
      "C",
      "Shell",
      "Cython",
      "C++",
      "Handlebars",
      "HTML",
      "Dockerfile",
      "Batchfile",
    ],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7800b4d8-79fe-4c80-a10c-d3e15bd15464",
    isApproved: false,
    activeProjects: 0,
    projects: 3,
    description: "Grist is an Airtable / Google Sheets alternative",
    readme:
      "Features\n\nGrist is a hybrid database/spreadsheet, meaning that:\n\n  Columns work like they do in databases: they are named, and they hold one kind of data.\n  Columns can be filled by formula, spreadsheet-style, with automatic updates when referenced cells change.\n\nThis difference can confuse people coming directly from Excel or Google Sheets. Give it a chance! There's also a Grist for Spreadsheet Users article to help get you oriented. If you're coming from Airtable, you'll find the model familiar (and there's also our Grist vs Airtable article for a direct comparison).\n\nHere are some specific feature highlights of Grist:\n\n  Python formulas.\n    Full Python syntax is supported, including the standard library.\n    Many Excel functions also available.\n    An AI Assistant specifically tuned for formula generation (using OpenAI gpt-3.5-turbo or Llama via llama-cpp-python).\n  A portable, self-contained format.\n    Based on SQLite, the most widely deployed database engine.\n    Any tool that can read SQLite can read numeric and text data from a Grist file.\n    Enables backups that you can confidently restore in full.\n    Great for moving between different hosts.\n  Can be displayed on a static website with grist-static ‚Äì no special server needed.\n  A self-contained desktop app for viewing and editing locally: grist-desktop.\n  Convenient editing and formatting features.\n    Choices and choice lists, for adding colorful tags to records.\n    References and reference lists, for cross-referencing records in other tables.\n    Attachments, to include media or document files in records.\n    Dates and times, toggles, and special numerics such as currency all have specialized editors and formatting options.\n    Conditional Formatting, letting you control the style of cells with formulas to draw attention to important information.\n  Drag-and-drop dashboards.\n    Charts, card views and a calendar widget for visualization.\n    Summary tables for summing and counting across groups.\n    Widget linking streamlines filtering and editing data.\n    Grist has a unique approach to visualization, where you can lay out and link distinct widgets to show together,\n    without cramming mixed material into a table.\n    Filter bar for quick slicing and dicing.\n  Incremental imports.\n    Import a CSV of the last three months activity from your bank...\n    ...and import new activity a month later without fuss or duplication.\n  Integrations.\n    A REST API, Zapier actions/triggers, and support from similar integrators.\n    Import/export to Google drive, Excel format, CSV.\n    Link data with custom widgets, hosted externally.\n    Configurable outgoing webhooks.\n  Many templates to get you started, from investment research to organizing treasure hunts.\n  Access control options.\n    (You'll need SSO logins set up to make use of these options; grist-omnibus has a prepackaged solution if configuring this feels daunting)\n    Share individual documents, workspaces, or team sites.\n    Control access to individual rows, columns, and tables.\n    Control access based on cell values and user attributes.\n  Self-maintainable.\n    Useful for intranet operation and specific compliance requirements.\n  Sandboxing options for untrusted documents.\n    On Linux or with Docker, you can enable gVisor sandboxing at the individual document level.\n    On macOS, you can use native sandboxing.\n    On any OS, including Windows, you can use a wasm-based sandbox.\n  Translated to many languages.\n  F1 key brings up some quick help. This used to go without saying, but in general Grist has good keyboard support.\n  We post progress on ùïè or Twitter or whatever and publish monthly newsletters.\n",
    name: "Grist",
    category: "Storage",
    health: null,
    code: "fQSStq",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "de29d4a5-7218-469f-8691-6d534ec0a431",
    isApproved: false,
    activeProjects: 24,
    projects: 72,
    description: "One Click deployment of Popular Open Source Social media scheduling tool.",
    readme:
      "Postiz - Your ultimate social media scheduling tool\nPostiz offers everything you need to manage your social media posts, build an audience, capture leads, and grow your business. https://postiz.com\n\nNetwork Ports\n5000/tcp/public: for a single single entry point for postiz when running in a container. \n\n4200/tcp: for the Frontend service (the web interface).\n\n3.3000/tcp: for the Backend service (the API).\n\n4.5432/tcp: for the Postgres container\n\n5.6379/tcp: for the Redis container\n\nRedis and Postgres - Connecting to a public endpoint will incur egress fees\n\nSetup Email Notifications\n\nRefer to the detailed instructions provided in the official documentation to properly set up and manage email notifications: https://docs.postiz.com/configuration/emails\n\n\nSocial Media Intergations:\n\nRefer to the detailed instructions provided in the official documentation to properly set up and manage Supporting Providers:   https://docs.postiz.com/providers.\n",
    name: "Postiz",
    category: "Automation",
    health: 95,
    code: "Rd76MM",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ec5a8c99-1b2c-435c-b74f-ad005e66e9a8",
    isApproved: false,
    activeProjects: 6,
    projects: 32,
    description: "Prefect is a Python orchestration framework for building data pipelines.",
    readme:
      'Prefect\n\nPrefect is a workflow orchestration framework for building data pipelines in Python.\nIt\'s the simplest way to elevate a script into a production workflow.\nWith Prefect, you can build resilient, dynamic data pipelines that react to the world around them and recover from unexpected changes.\n\nWith just a few lines of code, data teams can confidently automate any data process with features such as scheduling, caching, retries, and event-based automations.\n\nWorkflow activity is tracked and can be monitored with a self-hosted Prefect server instance or managed Prefect Cloud dashboard.\n\n!TIP]\nPrefect flows can handle retries, dependencies, and even complex branching logic\n\n[Check our docs or see the example below to learn more!\n\nGetting started\n\nPrefect requires Python 3.9 or later. To install the latest or upgrade to the latest version of Prefect, run the following command:\n\npip install -U prefect\n\nThen create and run a Python file that uses Prefect flow and task decorators to orchestrate and observe your workflow - in this case, a simple script that fetches the number of GitHub stars from a repository:\n\nfrom prefect import flow, task\nimport httpx\n\n\n@task(log_prints=True)\ndef get_stars(repo: str):\n    url = f"https://api.github.com/repos/{repo}"\n    count = httpx.get(url).json()"stargazers_count"]\n    print(f"{repo} has {count} stars!")\n\n\n@flow(name="GitHub Stars")\ndef github_stars(repos: list[str]):\n    for repo in repos:\n        get_stars(repo)\n\nrun the flow!\nif name=="main":\n    github_stars(["PrefectHQ/Prefect"])\n\nFire up a Prefect server and open the UI at http://localhost:4200 to see what happened:\n\nprefect server start\n\nTo run your workflow on a schedule, turn it into a deployment and schedule it to run every minute by changing the last line of your script to the following:\n\nif name == "main":\n    github_stars.serve(\n        name="first-deployment",\n        cron="* * * * *",\n        parameters={"repos": ["PrefectHQ/prefect"]}\n    )\n\nYou now have a process running locally that is looking for scheduled deployments!\nAdditionally you can run your workflow manually from the UI or CLI. You can even run deployments in response to [events.\n\n!TIP]\nWhere to go next - check out our [documentation to learn more about:\n- Deploying flows to production environments\n- Adding error handling and retries\n- Integrating with your existing tools\n- Setting up team collaboration features\n\nPrefect Cloud\n\nPrefect Cloud provides workflow orchestration for the modern data enterprise. By automating over 200 million data tasks monthly, Prefect empowers diverse organizations ‚Äî from Fortune 50 leaders such as Progressive Insurance to innovative disruptors such as Cash App ‚Äî to increase engineering productivity, reduce pipeline errors, and cut data workflow compute costs.\n\nRead more about Prefect Cloud here or sign up to try it for yourself.\n\nprefect-client\n\nIf your use case is geared towards communicating with Prefect Cloud or a remote Prefect server, check out our\nprefect-client. It is a lighter-weight option for accessing client-side functionality in the Prefect SDK and is ideal for use in ephemeral execution environments.\n\nNext steps\n\nCheck out the Docs.\nJoin the Prefect Slack community.\nLearn how to contribute to Prefect.',
    name: "Prefect",
    category: "Automation",
    health: 100,
    code: "z8tmK-",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d88bc9b8-4515-47a7-98de-578aaf39e278",
    isApproved: false,
    activeProjects: 4,
    projects: 10,
    description: "A privacy-first, fully OSS personal knowledge management software",
    readme:
      'Deploy on Railway\n\nWhat is this template\n\nThis template deploys SiYuan, an open-source, privacy-focused personal knowledge management system, to Railway.app with just one click.\n\nSiYuan is designed for individuals who value data ownership and powerful knowledge organization. Think of it as your second brain that helps you connect thoughts and manage information.\n\nKey Features\n\nBlock-based Editing: Create and manipulate content in discrete blocks, similar to Notion or Roam Research\nBidirectional Linking: Connect notes and concepts with powerful bidirectional links\nLocal-first Philosophy: Your data stays on your device by default\nMarkdown Support: Write in familiar Markdown syntax with extended capabilities\nFull-text Search: Quickly find anything in your knowledge base\nMath & Diagrams: Support for LaTeX math formulas and various diagram types\nCross-platform: Available on Windows, macOS, Linux, Android, and iOS\nAPI Access: Programmatic access to your data through RESTful APIs\n\nQuick Start Guide\n\nClick the "Deploy on Railway" button at the top of this page\nLeave all variables and settings as their defaults\nWait for your new instance to deploy (this typically takes 2-3 minutes)\nOnce deployed, copy the SIYUAN_AUTH_CODE variable that Railway generated for you from the variables tab in your SiYuan service.\nNavigate to your new SiYuan instance at the URL provided by Railway. This URL will be in your SiYuan service\'s settings tab.\nUse the auth code to log in when prompted\nStart building your knowledge base!\n\nOptional Variables\n\n| Variable | Description | Default |\n|----------|-------------|---------|\n| SIYUAN_AUTH_CODE | Authentication code for accessing your SiYuan instance | Auto-generated secure string |\n| TZ | Timezone for your SiYuan instance | UTC |\n\nTimezone Configuration\n\nThe TZ variable allows you to set the system timezone for your SiYuan instance. This affects how timestamps are displayed throughout the application.\n\nExamples of valid timezone values:\nAmerica/Vancouver (for Pacific Time)\nAmerica/Toronto (for Eastern Time)\nEurope/London\nAsia/Tokyo\n\nChanging this variable only affects the system time display and does not impact any functionality.\n\nProject Structure & Services\n\nThis template uses a straightforward architecture:\n\nSiYuan Application: Deployed using the official SiYuan Docker image\nPersistent Storage: Railway volume mounted to /siyuan/workspace/ to ensure your data persists across redeploys and upgrades\nAutomatic Updates: When new versions of SiYuan are released, you can easily redeploy to get the latest features\n\nThe Docker container exposes port 6806, which Railway automatically maps to a public URL for you to access.\n\nAdditional Resources\n\nSiYuan Official Documentation\nSiYuan Community Forum\nSiYuan GitHub Repository\nDocker Image Details\n\nDeveloped and maintained by the SiYuan community. Railway template by Mykal and team.',
    name: "SiYuan",
    category: "Other",
    health: 50,
    code: "EWaCNw",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "78d3f0a0-f981-49d4-bd73-8538ee738d57",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "Application web de gestion de finances personnelles et suivi de d√©penses.",
    readme:
      "Budget App\n\nUne application web moderne de gestion de finances personnelles construite avec Next.js 15. \n\nFonctionnalit√©s Principales\nTableau de bord avec visualisation des d√©penses et revenus\nSuivi des d√©penses par cat√©gories\nGestion des d√©penses r√©currentes\nInterface responsive adapt√©e mobile et desktop\nAuthentification s√©curis√©e\nTh√®me clair/sombre\n\nStack Technique\nFrontend: Next.js 15, React 19, Tailwind CSS, shadcn/ui\nBackend: API Routes Next.js, Prisma ORM\nBase de donn√©es: PostgreSQL\nAuthentification: NextAuth.js",
    name: "Budgetizer",
    category: "Other",
    health: null,
    code: "O8jlr9",
    languages: ["TypeScript", "CSS", "JavaScript", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "43e817c5-ee90-4c70-ad88-293df1fd8dc6",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "An open source project management platform.",
    readme:
      "An open source project management platform focused on simplicity and efficiency.\n\n‚ú® Features\nüöÄ Simple & Fast: Minimalist interface with powerful features\nüîí Self-hosted: Full control over your data\nüé® Customizable: Make it yours with extensive customization options\nü§ù Open Source: MIT licensed, free forever\n\nGITHUB",
    name: "kaneo:v0.1.0",
    category: "Other",
    health: null,
    code: "wQ4btp",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "381d04c5-207c-4955-b8f3-7f81cd95d31f",
    isApproved: false,
    activeProjects: 6,
    projects: 10,
    description: "Tool to automatically ensure high code quality, and security",
    readme:
      "SonarQube: Your Partner for Clean Code\n\nSonarQube is a self-managed, automatic code review tool that systematically helps you deliver Clean Code. It seamlessly integrates into your existing workflow, performing continuous code inspections and detecting issues across 30+ programming languages. By embedding SonarQube into your Continuous Integration (CI) pipeline on popular DevOps platforms, you ensure that your code consistently meets high-quality standards.\n\nKey Features\nSeamless Integration: Works with GitHub, GitLab, Jenkins, and more.\nQuality Gates: Prevent flawed code from progressing in your pipeline.\nRobust Analysis: Over 6,000 security rules for languages like Java, C#, and Python.\n\nGetting Started\nDefault login credentials:\nUser: admin\nPassword: admin\n\nFor more information, visit the SonarQube Documentation or explore the SonarSource Website.",
    name: "sonarqube",
    category: "Automation",
    health: 100,
    code: "S_qmV5",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "658fd440-a64c-4b0e-b7cb-8656ba292689",
    isApproved: false,
    activeProjects: 2,
    projects: 4,
    description: "Self hosted dashboard for your Flowise chatbots",
    readme:
      "üîó www.flowboard360.com\n\nSelf Hosted Dashboard for your Flowise Chatbots.\n\nEffortlessly track, monitor, and share Flowise chatbot reports with your clients using a branded dashboard.\n\n‚úÖ One click setup in under 6 minutes\n\n‚úÖ No technical knowledge required\n\n‚úÖ Add unlimited bots & clients\n",
    name: "Flowboard360 Setup Template - Flowise",
    category: "AI/ML",
    health: null,
    code: "2XlruV",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7697dff6-5b64-4e20-98e7-0b274fab0dae",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "A Slack bot for the Ragpi AI Assistant",
    readme:
      "Ragpi Slack Integration\n\nRagpi is an open-source AI assistant API that answers questions using your documentation, GitHub issues, and READMEs. It combines LLMs with intelligent search to provide relevant, documentation-backed answers through a simple API.\n\nThis is a template for the Ragpi Slack integration. You can find out more on how to deploy this integration on railway here: https://docs.ragpi.io/deployment/railway\n",
    name: "Ragpi Slack Intgration",
    category: "AI/ML",
    health: null,
    code: "aaWjR4",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a8db8f41-3b91-431e-a538-de925d433ead",
    isApproved: false,
    activeProjects: 3,
    projects: 12,
    description: "ü§ñ An AI assistant answering questions from your documentation",
    readme:
      "Ragpi is an open-source AI assistant API that answers questions using your documentation, GitHub issues, and READMEs. It combines LLMs with intelligent search to provide relevant, documentation-backed answers through a simple API.\n\nDocumentation | API Reference\n\nKey Features\n\nüìö Builds knowledge bases from docs, GitHub issues and READMEs\nü§ñ Agentic RAG system for dynamic document retrieval\nüîå Supports OpenAI, Ollama, Deepseek & OpenAI-Compatible models\nüí¨ Discord integration for community support\nüöÄ API-first design with Docker deployment\n\nConfiguring Deployment\n\nYou will need to configure the LLM providers you would like to use, i.e the CHAT_PROVIDER and EMBEDDING_PROVIDER environment variables. You will also need to configure any required variables for the provider you choose, e.g. OPENAI_API_KEY if you choose openai as your provider. You can find out more about configuring the providers in the provider documentation and the required environment variables for each provider under their respective pages.\n\nIf there are other environment variables you would like to configure that are not in the deployment template, you can add them to your services in the Railway project canvas after deploying the template.\n\nAfter deploying the core services, Railway will give you a public URL for the ragpi-api service which you can use to access the API. You can also enable API authentication by setting the RAGPI_API_KEY environment variable on the ragpi-api service and using it to authenticate requests to the API.\n\nDeploying Integrations\n\nEach Ragpi integration has its own Railway deployment template. Once you have deployed the core Ragpi services, you can deploy integrations like Slack and Discord by adding a new service to your project canvas. You can do this on your project's Architecture page by clicking the Create button, selecting the Template option, and searching for the integration you want to deploy, e.g., Ragpi Discord Integration or Ragpi Slack Integration.\n\nAfter selecting the integration template, you will need to configure the required environment variables for the integration. The RAGPI_BASE_URL environment variable should already be set to the URL of the ragpi-api service you deployed earlier. If you enabled API authentication, the RAGPI_API_KEY environment variable should also be set to the API key you configured for the ragpi-api service. You can find the required environment variables for each integration in the integration's documentation.",
    name: "Ragpi",
    category: "AI/ML",
    health: 100,
    code: "7ihedX",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5114008c-5b93-41d3-9122-4b4533d7fc13",
    isApproved: false,
    activeProjects: 21,
    projects: 108,
    description: "The #1 Open-Source CRM Modern, powerful, affordable.",
    readme:
      "TwentyCRM + MinIO S3\n\nStateless TwentyCRM with worker, Redis, Postgres & MinIO S3 as storage.\n\nTwenty\n\nThe #1 Open-Source CRM\n\nModern, powerful, affordable platform to manage your customer relationships\n\nFor additional configuration see the official env config guide available here\n\nMinIO \n\nMinIO service will create a default twenty bucket, so everything is configured but please have in mind it uses default credentials. It's recommended to create specific ones to the bucket. \n\n",
    name: "TwentyCRM + S3",
    category: "CMS",
    health: 100,
    code: "4_LQ-T",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d8f6ce35-1527-4620-8e20-27e8d05e0a73",
    isApproved: false,
    activeProjects: 47,
    projects: 78,
    description: "Crawl4AI is an AI-ready web crawler for LLMs, AI agents, & data pipelines.",
    readme:
      "Crawl4AI is the #1 trending GitHub repository, actively maintained by a vibrant community. It delivers blazing-fast, AI-ready web crawling tailored for large language models, AI agents, and data pipelines. Fully open source, flexible, and built for real-time performance, Crawl4AI empowers developers with unmatched speed, precision, and deployment ease.\n\nTo get started, follow the steps below:\n\nOptional: Add either your OpenAI API Key or Anthropic API Key\n\nDeploy\n\nYour Crawl4AI API Key will auto generate, you can find it in the variables section.\n\nCrawl4AI woks great with N8N, or other workflow apps.\n\nFor more information and documentation, checkout the project main page for details.\n\nhttps://docs.crawl4ai.com/ ",
    name: "Crawl4AI",
    category: "AI/ML",
    health: 100,
    code: "Owzyy8",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b300af55-bf5c-4a27-94e6-93937a599045",
    isApproved: false,
    activeProjects: 2,
    projects: 2,
    description: "compile typst markup remotely by a simple API call",
    readme:
      "Typst HTTP API\nTypst is a new markup-based typesetting system that is designed to be as powerful as LaTeX while being much easier to learn and use. I recommend that you check it out if you don't know it yet.\n\nThis project is a web server that allows users to compile typst markup remotely by a simple API call. This webserver is provided in the form of a docker container. For now there is no official image on any registry.\n\nI want to bring some elements to your attention:\n\nPlease be aware that while the container runs, I do not consider this project production-ready, more work is needed.\nAll contributions are welcome of course welcome.\nCurrently, there is no way to compile a file that loads external resources (images or other .typ files for example).\n",
    name: "Typst Compiler API",
    category: "Other",
    health: null,
    code: "fFq3fV",
    languages: ["Python", "Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "38a8f401-e270-4c7b-a8f3-c64da2e1166c",
    isApproved: false,
    activeProjects: 6,
    projects: 7,
    description: "A django  Postgres railway template with allauth authentication",
    readme:
      "A responsive Django landing page with Postgres Database and allauth authentication. Ready for quick deployment on Railway. Features a starter landing page,  a script for optimized images with WebP fallback, Bootstrap 5 design, and customizable components for a modern site.\n\n",
    name: "Django Postgres + allauth + landing page",
    category: "Other",
    health: 83,
    code: "-VPzAd",
    languages: ["HTML", "Python", "CSS", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0fd100dd-0121-4dea-86cd-b1ab7e821065",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "Making the unknown, known",
    readme:
      "Overview\nENSRainbow is an ENSNode sidecar service for healing millions of unknown ENS names.\n\nLearn more at https://ensrainbow.io and https://ensnode.io.\n\nHow to use\n\nPrivate network\nReference the RAILWAY_PRIVATE_DOMAIN variable connected to the ENSRainbow instance.\n\nConnect using HTTP to the application port (default 3223).\n\nPublic network\nFor safety reasons, by default, ENSRainbow is placed in a private network without public Internet access.\n\nIn order to allow public access to the service, please modify the instance network configuration accordingly.\n\nConnect to the service from outside of Railway using the TCP Proxy.\n\nReference the RAILWAY_PUBLIC_DOMAIN variable connected to the ENSRainbow instance.\n\nConnect using HTTP to the application port (default 3223).\n\nLearn More \n\nENSRainbow documentation\n\nENSNode GitHub repository\n\nENSRainbow GitHub subrepo\n\nService configuration\n\nService source\nThe service instance is using the latest Docker image from the official ENSRainbow application GitHub Container Repository:\n\nnamehash/ensnode/ensrainbow:latest\n\nEnvironment variables\nThe template contains the following environment variables:\n\nPORT - defines the HTTP listening port (default 3223).",
    name: "ENSRainbow",
    category: "Other",
    health: null,
    code: "Ddy-Qg",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "edcce88e-db04-4b98-969d-8bb3c378d07d",
    isApproved: false,
    activeProjects: 8,
    projects: 10,
    description: "FlowiseAI + PostgreSQL Database",
    readme:
      "This template integrates FlowiseAI with a PostgreSQL database.\n\nAll necessary variables are already pre-filled to help you get started instantly.\n\nSteps to get started:\n\nFill in values for these two variables for FlowiseAI:\n  FLOWISE_USERNAME\n  FLOWISE_PASSWORD\nDeploy\n\nVideo Guide: https://youtu.be/FQSqDQi9FOA",
    name: "FlowiseAI + PostgreSQL",
    category: "AI/ML",
    health: 100,
    code: "oBCbmw",
    languages: [
      "TypeScript",
      "JavaScript",
      "CSS",
      "SCSS",
      "HTML",
      "Dockerfile",
      "Shell",
      "Batchfile",
    ],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0f1c3df7-fed3-4f87-a8c2-b0e3e78f2432",
    isApproved: false,
    activeProjects: 1,
    projects: 1,
    description: "shrort description efvrevqrwfqrew",
    readme:
      "rgferqfgreqgerqgerftgbferdbgrfedbrgebrtegbtergttfeqghbtcfbhrdeqbhartbhrqbhqrhtrqghbtrqgbtgqerdbrqednbqerdbhtqerbhetqrghbrtgfvfedvfdvergetrgbhe4thbtebhetqhgbeqthgbeghbeghbebherthgbegeriohfvioeqrfvnoierfqmvimeqvirgferqfgreqgerqgerftgbferdbgrfedbrgebrtegbtergttfeqghbtcfbhrdeqbhartbhrqbhqrhtrqghbtrqgbtgqerdbrqednbqerdbhtqerbhetqrghbrtgfvfedvfdvergetrgbhe4thbtebhetqhgbeqthgbeghbeghbebherthgbegeriohfvioeqrfvnoierfqmvimeqvirgferqfgreqgerqgerftgbferdbgrfedbrgebrtegbtergttfeqghbtcfbhrdeqbhartbhrqbhqrhtrqghbtrqgbtgqerdbrqednbqerdbhtqerbhetqrghbrtgfvfedvfdvergetrgbhe4thbtebhetqhgbeqthgbeghbeghbebherthgbegeriohfvioeqrfvnoierfqmvimeqvi",
    name: "sparkling-spirit",
    category: "Other",
    health: null,
    code: "QpsUpi",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a12fddbc-f425-491b-8969-2ef42cb296ef",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "svix-webhooks based on official Dockerfile",
    readme:
      "Svix is an enterprise-ready webhook service that simplifies the process of sending webhooks for developers. Rather than building and maintaining complex webhook infrastructure, developers can make a single API call to Svix, which then handles all critical aspects of webhook delivery:\n\nKey Features:\nReliable deliverability with automatic retries\nBuilt-in security features including webhook signature verification\nSupport for both symmetric (default, faster) and asymmetric signatures\nComprehensive webhook management and monitoring\nSupport for multiple databases (PostgreSQL) and message queues (Redis)\n\nThe project provides official client libraries for multiple programming languages:\nGo\nPython\nTypeScript/JavaScript\nJava\nKotlin\nRuby\nC# (.NET)\nRust\nPHP\n\nTechnical Details:\nServer written in Rust\nRequires PostgreSQL for storage\nOptional Redis dependency (v6.2.0+) for task queue and caching\nConfigurable via environment variables, .env files, or config.toml\nSupport for OpenTelemetry for tracing and monitoring\nBuilt-in SSRF protection against internal IP addresses\nJWT-based authentication system\nOperational webhooks feature for monitoring system events\n\n\nThe project is open source under the MIT license and maintains active community support through:\nGitHub Issues for bug reports and feature requests\nCommunity Forum for discussions\nSlack community for real-time chat",
    name: "svix",
    category: "Other",
    health: null,
    code: "rHENwb",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0bff11ea-c4e5-4ef4-8810-a44107cbabe4",
    isApproved: false,
    activeProjects: 1,
    projects: 7,
    description: "Django and Dockerfile Boilerplate optimized for Railway Deployments",
    readme:
      "Django Container - Starter Boilerplate\n\nThis is a basic boilerplate template for deploying a Django project on Railway. \n\nInterested in Django x Next.js? Check out https://repo.djangonextjs.com.\n\nIncludes:\n\nMinimal Django app\nDjango-built Dockerfile for continuous deployments\nEndpoint for deployment health checks during Railway deploys\n\nCode: https://github.com/jmitchel3/django-container\nOne-Click Deploy: https://djangocontainer.com\nReference blog post on Coding for Entrepreneurs",
    name: "Django Container - Starter Boilerplate",
    category: "Starters",
    health: 100,
    code: "0kppYG",
    languages: ["Python", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a9409b14-1cd1-4258-8425-5264c147726e",
    isApproved: false,
    activeProjects: 10,
    projects: 15,
    description: "FastAPI and Dockerfile Boilerplate optimized for Railway Deployments",
    readme:
      "FastAPI Container - Starter Boilerplate\n\nFastAPI and Dockerfile starter code for optimized deployments on Railway.\n\nIncludes:\n\nMinimal FastAPI app\nFastAPI-built Dockerfile for continuous deployments\nEndpoint for deployment health checks during Railway deploys\n\nCode: https://github.com/jmitchel3/fastapi-container\nTemplate: https://fastapicontainer.com",
    name: "FastAPI Container - Starter Boilerplate",
    category: "Starters",
    health: 100,
    code: "xzLjtw",
    languages: ["Dockerfile", "Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9d6cbfde-14dd-470f-8718-356ee1db1d85",
    isApproved: false,
    activeProjects: 4,
    projects: 21,
    description: "n8n with Separate Worker & Webhook using External DB",
    readme:
      "This Railway template deploys n8n with a scalable architecture, separating the worker and webhook processes while utilizing an external database for persistence. This setup enhances performance, reliability, and scalability, making it ideal for production environments.\n\nüîß Features:\nSeparate Worker & Webhook: Ensures efficient load distribution.\nExternal Database Support: Uses PostgreSQL or MySQL for better persistence.\nOptimized for Railway: Pre-configured for seamless deployment.\nScalable & Modular: Easily expand to match your workflow needs.\n\nüöÄ Get Started:\nDeploy the template to Railway.\nConfigure environment variables.\nEnjoy a high-performance, scalable n8n setup!",
    name: "N8N + Worker + Webhook + External DB",
    category: "AI/ML",
    health: 83,
    code: "Gos_2q",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "342e867a-83b7-4925-a23b-8d211ec65e67",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "Mini ETL Data Platform - Starting ETL Fast and Easy",
    readme:
      "If you have been spent late night with data ingestion and data migration\n\nYou are finding the project, template, starting point includes:\n\nlightweight setup for creating the development environment, testing environment, Proof of Concept, Proof of Service or even support for Small Business.\n\nwith DataPods [DPs],  maximize the number of times to provision services for creating data transformations.\n\nCheckout and star the git repository at: https://github.com/longbuivan/datapods-oss",
    name: "datapods-mini-elt",
    category: "Analytics",
    health: null,
    code: "rRK6Ge",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8351719c-a326-4ab1-bfe4-5ec4704e44db",
    isApproved: false,
    activeProjects: 16,
    projects: 46,
    description: "All-in-one social media management tool",
    readme:
      "üö® NOTE: this will not work until my railway PR is merged into the postiz-app main branch üö®\n\nDeploys the postiz app from https://github.com/gitroomhq/postiz-app/.\n\nThis includes \na web dasboard\na redis instance for powering bullmq to schedule posts\na psql database to store app data\nan uploads volume to store uploads that go along with your posts",
    name: "postiz",
    category: "Automation",
    health: 95,
    code: "xWx2v4",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8f265e09-d5bf-4aea-b1fc-192bfb730de5",
    isApproved: false,
    activeProjects: 4,
    projects: 6,
    description: "Rocicorp's ZeroSync engine for local-first apps",
    readme:
      "Initial setup\n\nThis template creates both the Postgres instance and the Zero sync engine.\n\nAfter deploying for the first time,\n\nOpen the generated public endpoint in a new tab. If you see an ok it means everything is working.\nTo connect to Zero via your web application, you can use the ZERO_PUBLIC_URL.\n\nPermissions\n\nIn Zero, access is denied by default. To be able to sync data to your application, you will first need to set up permissions. It's best to read this page to understand how it works.\n\nAlthough you describe permissions by calling functions in Typescript, permissions are actually compiled into JSON and then uploaded to your Postgres instance. Once you defined your permissions, you will have to run the following command:\n\nnpx zero-deploy-permissions -p ./path/to/schema --upstream-db ${DATABASE_PUBLIC_URL}\n\nConfiguration\n\nYou may have to play around with the ZERO_NUM_SYNC_WORKERS to figure out what works best depending on the your service's allocated resources. Decrease/increase this value depending on how many upstream connections your service resources allow.",
    name: "ZeroSync + Postgres",
    category: "Other",
    health: 100,
    code: "2JIsM0",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ea9efe6a-e984-48bb-bcbc-44b9d6070cda",
    isApproved: false,
    activeProjects: 1,
    projects: 2,
    description: "Rocicorp's ZeroSync engine for local-first apps",
    readme:
      "Initial setup\n\nThis template only creates the sync engine. You will need to bring your own Postgres instance.\n\nBefore deploying for the first time,\n\nManually set the PG_DATABASE_URL environment variable. This should be the private URL.\nNext you will need to update your Postgres' instance WAL level to logical.\n  You can follow the official documentation here for a more detailed explanation on how to do it. If you are comfortable with Postgres and SQL, here is the short version:\n  Connect to your existing Postgres instance, and run \"ALTER SYSTEM SET wal_level = 'logical'. Next restart your running Postgres instance.\n\nAfter deploying for the first time,\n\nOpen the generated public endpoint in a new tab. If you see an ok it means everything is working.\nTo connect to Zero via your web application, you can use the ZERO_PUBLIC_URL.\n\nPermissions\n\nIn Zero, access is denied by default. To be able to sync data to your application, you will first need to set up permissions. It's best to read this page to understand how it works.\n\nAlthough you describe permissions by calling functions in Typescript, permissions are actually compiled into JSON and then uploaded to your Postgres instance. Once you defined your permissions, you will have to run the following command:\n\nnpx zero-deploy-permissions -p ./path/to/schema --upstream-db ${DATABASE_PUBLIC_URL}\n\nNote that DATABASE_PUBLIC_URL is the public URL to your database, not the private URL that you set up before deploying.\n\nConfiguration\n\nYou may have to play around with the ZERO_NUM_SYNC_WORKERS to figure out what works best depending on the your service's allocated resources. Decrease/increase this value depending on how many upstream connections your service resources allow.",
    name: "ZeroSync",
    category: "Other",
    health: 80,
    code: "Z-5ubo",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a7eaea87-12bb-4612-89bd-f59898354562",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "Manage, store, and distribute sensitive data.",
    readme:
      "OpenBao\nBasic template to get a development environment up and running. Usable for production, but a typical hardened production instance should be firewalled and only accessible from your internal hosts rather than exposing to the internet.\n\nHighlights\n\nOpenBao (one click deploy)\nPostgreSQL backed database\n\nUsage\n\nDeploy this template and follow the instructions on the OpenBao Web UI to get started.\n\nLicense\n\nOpenBao is licensed under MPLv2.0.\n\nHelpful Resources\n\nhttps://github.com/openbao/openbao\nhttp://openbao.org/docs",
    name: "OpenBao",
    category: "Storage",
    health: null,
    code: "HBKxeE",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c6536d59-5577-4dcd-ba9b-db13eae32402",
    isApproved: false,
    activeProjects: 2,
    projects: 3,
    description: "Slack bot for Optimism Governance events with auto reminders & summaries",
    readme:
      "This template deploys a Slack bot that keeps your community updated on Optimism Governance events. It features:\n\nAutomated weekly summaries (Mondays 9 AM EST)\nDaily event reminders (9 AM EST)\n/getevents command for on-demand updates\nRecurring event support\nEST timezone handling\nClean message formatting\n\nRequired Environment Variables:\nSLACK_BOT_TOKEN\nSLACK_SIGNING_SECRET\nSLACK_APP_TOKEN\nSLACK_CHANNEL_ID\n\nThe bot monitors the official Optimism Governance Google Calendar and sends notifications to your specified Slack channel. Perfect for DAOs and communities who want to stay engaged with Optimism governance.",
    name: "Optimism Governance Google Calendar Slack App",
    category: "Bots",
    health: null,
    code: "OZNDdx",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "be8ff7a8-6f9c-47cf-9104-7c802c3d41ad",
    isApproved: false,
    activeProjects: 4,
    projects: 10,
    description: "Open Source Zapier Alternative",
    readme:
      "Automatisch - Open Source Zapier Alternative\n\nüßê Automatisch is a business automation tool that lets you connect different services like Twitter, Slack, and more to automate your business processes.\n\nüí∏ Automating your workflows doesn't have to be a difficult or expensive process. You also don't need any programming knowledge to use Automatisch.\n\nPost-deployment instructions\n\nUse user@automatisch.io email address and sample password to login to Automatisch. Please do not forget to change your email and password from the settings page.\n\nAdvantages\n\nThere are other existing solutions in the market, like Zapier and Integromat, so you might be wondering why you should use Automatisch.\n\n‚úÖ One of the main benefits of using Automatisch is that it allows you to store your data on your own servers, which is essential for businesses that handle sensitive user information and cannot risk sharing it with external cloud services. This is especially relevant for industries such as healthcare and finance, as well as for European companies that must adhere to the General Data Protection Regulation (GDPR).\n\nü§ì Your contributions are vital to the development of Automatisch. As an open-source software, anyone can have an impact on how it is being developed.\n\nüíô No vendor lock-in. If you ever decide that Automatisch is no longer helpful for your business, you can switch to any other provider, which will be easier than switching from the one cloud provider to another since you have all data and flexibility.\n",
    name: "Automatisch",
    category: "Automation",
    health: 100,
    code: "NIbgNd",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0db33e24-0ee4-4a12-8eeb-1cb5f3238782",
    isApproved: false,
    activeProjects: 167,
    projects: 250,
    description: "Setup of n8n with internal Redis, Postgres and workers. Just deploy it",
    readme:
      "‚ö†Ô∏è Note:  \nI've requested support for connecting to Redis over Railway's IPv6-only internal network (n8n GitHub Issue #13117), and now it's fully supported by n8n.  \n\nWith this support in place, you won't be charged for egress usage anymore. Plus, it‚Äôs now more secure since your Redis is no longer exposed to the public network.\n\nQuick Start\n\nJust deploy it - no additional configuration required\nOpen the Primary node / instance\nGo to Settings, follow the Public Networking URL to access your n8n web UI\n\nTemplate changelog\nMarch 13, 2025\nAdded OFFLOAD_MANUAL_EXECUTIONS_TO_WORKERS set to true based on n8n GitHub PR #11284. This offloads manual workflow executions to worker nodes, improving performance distribution\n\nIf you have any questions or run into issues, feel free to reach out to me here - Railway Help Station\n\nBanner image\n\nn8n - Secure Workflow Automation for Technical Teams\n\nn8n is a workflow automation platform that gives technical teams the flexibility of code with the speed of no-code. With 400+ integrations, native AI capabilities, and a fair-code license, n8n lets you build powerful automations while maintaining full control over your data and deployments.\n\nn8n.io - Screenshot\n\nKey Capabilities\n\nCode When You Need It: Write JavaScript/Python, add npm packages, or use the visual interface\nAI-Native Platform: Build AI agent workflows based on LangChain with your own data and models\nFull Control: Self-host with our fair-code license or use our cloud offering\nEnterprise-Ready: Advanced permissions, SSO, and air-gapped deployments\nActive Community: 400+ integrations and 900+ ready-to-use templates\n\nResources\n\nüìö Documentation\nüîß 400+ Integrations\nüí° Example Workflows\nü§ñ AI & LangChain Guide\nüë• Community Forum\nüìñ Community Tutorials\n\nSupport\n\nNeed help? Our community forum is the place to get support and connect with other users:\ncommunity.n8n.io",
    name: "n8n (w/ workers + internal Redis)",
    category: "Automation",
    health: 92,
    code: "SicyT1",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "48a44b75-0b04-49a9-98ec-1b341a7daffc",
    isApproved: false,
    activeProjects: 79,
    projects: 167,
    description: "official open source version of Bolt.new",
    readme:
      "Features\nAI-powered full-stack web development for NodeJS based applications directly in your browser.\nSupport for multiple LLMs with an extensible architecture to integrate additional models.\nAttach images to prompts for better contextual understanding.\nIntegrated terminal to view output of LLM-run commands.\nRevert code to earlier versions for easier debugging and quicker changes.\nDownload projects as ZIP for easy portability.\n\nadd Features env:\n\nNODE_ENV=development\nVITE_HMR_PROTOCOL=ws\nVITE_HMR_HOST=localhost\nVITE_HMR_PORT=5173\nCHOKIDAR_USEPOLLING=true\nWATCHPACK_POLLING=true\nPORT=5173\nGROQ_API_KEY=${GROQ_API_KEY}\nHuggingFace_API_KEY=${HuggingFace_API_KEY}\nOPENAI_API_KEY=${OPENAI_API_KEY}\nANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}\nOPEN_ROUTER_API_KEY=${OPEN_ROUTER_API_KEY}\nXAI_API_KEY=${XAI_API_KEY}\nGOOGLE_GENERATIVE_AI_API_KEY=${GOOGLE_GENERATIVE_AI_API_KEY}\nOLLAMA_API_BASE_URL=${OLLAMA_API_BASE_URL}\nTOGETHER_API_KEY=${TOGETHER_API_KEY}\nTOGETHER_API_BASE_URL=${TOGETHER_API_BASE_URL}\nAWS_BEDROCK_CONFIG=${AWS_BEDROCK_CONFIG}\nVITE_LOG_LEVEL=${VITE_LOG_LEVEL:-debug}\nRUNNING_IN_DOCKER=true\nDEFAULT_NUM_CTX=${DEFAULT_NUM_CTX:-32768}\n\nDEFAULT_NUM_CTX=32768 # Consumes 36GB of VRAM\nDEFAULT_NUM_CTX=24576 # Consumes 32GB of VRAM\nDEFAULT_NUM_CTX=12288 # Consumes 26GB of VRAM\nDEFAULT_NUM_CTX=6144 # Consumes 24GB of VRAM\n\n",
    name: "Bolt.diy NEW",
    category: "AI/ML",
    health: 100,
    code: "abVHie",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "055079a5-fa6f-4a52-94e5-974de10c1944",
    isApproved: false,
    activeProjects: 4,
    projects: 5,
    description: "Self-hosted Error Tracking. Sentry-SDK compatible",
    readme:
      "Bugsink\n\nError tracking\n\nGet notified about errors in your applications as they happen.\n\nAll the information needed to triage and fix them in a single location.\n\nBuilt to self-host\n\nHave full control over your data by running Bugsink on servers that you own or rent yourself.\n\nInstallation is easy, and we provide detailed instructions to help you get started.\n\nSentry Compatible\n\nTo report errors to Bugsink, you only need to add a few lines of code to your application.\n\nBugsink is compatible with Sentry's open source SDKs which are available for most popular programming languages.\n\n",
    name: "Bugsink",
    category: "Analytics",
    health: 100,
    code: "5pE9hv",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e3f17e6c-3106-453a-81cd-8ec560982260",
    isApproved: false,
    activeProjects: 3,
    projects: 3,
    description: "PostgreSQL DB enabled with TimescaleDB and PostGIS",
    readme:
      "Overview\n\nA clone of the official Railway TimescaleDB + PostGIS template, but using Railway's Postgres 17 image instead of 16.\n\nPostgreSQL database service with TimescaleDB and PostGIS installed.  Deployed with Railway's SSL-enabled image.\n\nNote that postgis is installed but not enabled.  To enable it, simply connect to the DB and execute CREATE EXTENSION postgis;\n\nVersions\nPostgreSQL 16\nTimescaleDB 2.13\nPostGIS 3.4.1\n\nExtensions\n\nTimescaleDB \nA time-series database built on top of PostgreSQL. \n\nEngineered to efficiently handle resource-intensive workloads, like time series, event, and analytics data. Built on PostgreSQL, with expert support at no extra charge.\n\n  Timescale Documentation\n\nPostGIS\nExtends PostgreSQL by adding support for storing, indexing, and querying geographic data.\n\nPostGIS is an open source software program that adds support for geographic objects to the PostgreSQL object-relational database. PostGIS follows the Simple Features for SQL specification from the Open Geospatial Consortium\n\n  PostGIS Documentation",
    name: "TimescaleDB + PostGIS (PG17)",
    category: "Storage",
    health: 100,
    code: "ZZURpX",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e831c78b-de72-4db1-87b3-fe5d3cdcece9",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "Derailer helps test how services handle random dependency failures",
    readme:
      "Github Repository Header\n\nDerailer is a tool that helps test for how services handle random dependency failures,\non Railway. Inspired by Netflix's Chaos Monkey.\nDerailer randomly removes instances of running services. Allowing you to build more\nresilient services by finding missed opportunities to handle failures gracefully.\n\n**CAUTION]\nYou should avoid deploying this onto your customer facing environment, as it may have visible impact, we suggest sticking to staging!**\n\nIf you've read the above disclaimer and understand it, click to deploy\n\n‚ñ∂Ô∏è Derailment Process\n\nEvery so often (defined in FREQUENCY_CRON), the Derailer lists your Railway services and filters them to ones that\naren't in the configured blacklist.\n\nUsing this list, it chooses to 'Derail' a number of your services (using BLAST_RADIUS), this is done by **Aborting\nDeployments**, it will remove the currently active deployment of your service.\n\nAfter the defined DURATION_MINUTES, it will re-deploy any effected services.\n\n**The derailed services are stored in a persistent volume (on MongoDB), meaning re-deploying this service will restore\nany effected services when it comes online!**\n\nüëÄ User Interface\n\nUser Interface\n\n**[WARNING]\nThis user interface is not password protected, we suggest using [a cloudflare tunnel, or implementing your own authentication in a forked version.**\n\nDerailer comes with a (very primitive) user interface for controlling how the derailer behaves.\n\nFeatures:\nViewing an active derailment and what services it's impacting\nRollback an active derailment if it's causing a headache\nViewing when the next derailment will occur\nViewing a history of which services were impacted for each past derailment\nPausing derailments for a certain time period (to allow for some rest!)\n\nü§ñ Rest API\n**WARNING]\nThis API is not password protected, we suggest using [a cloudflare tunnel, or implementing your own authentication in a forked version.**\n\nFor ease of use, all the features mentioned in our user interface are supported within a REST API, check out the API\ndocumentation.\n\nüß© Configuration Options\n\nEnvironment Variables\n\n| Variable \t       | Description \t                                                                           | Default Value \t |\n|------------------|-----------------------------------------------------------------------------------------|-----------------|\n| RAILWAY_API_KEY  | Your Railway API key, required to list your services and fetch your running deployments |                 |\n| FREQUENCY_CRON   | A chron expression defining how often to run the derailer                               | 0 0 * * * ?     |\n| DURATION_MINUTES | How long (in minutes) to keep deployments aborted\t                                      | 60              |\n| BLAST_RADIUS     | How many services to impact in each run of the Derailer                                 | 2               |\n\nBlacklisting services\n\nBy default, the only service automatically blacklisted is the Derailer application. However, you may want to blacklist\nsome UIs, monitoring systems, or essential services (think carefully about how reliable they are!) to avoid everything\nfalling on its face.\n\nThis can be configured in src/main/resources/application.properties (derailment.blacklist)\n\nüíª Running Locally\n\nRunning locally allows you to quickly test your changes, using the Quarkus framework we can\n\nCopy .env-example into a file called .env and fill in all the environment vars\nRun ./gradlew quarkusDev from the gradle quarkus menu to run in dev mode\n",
    name: "Railway Derailer",
    category: "Observability",
    health: null,
    code: "FMEpOh",
    languages: ["Java", "HTML", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "cffef021-c178-4608-95ed-845d1fca0492",
    isApproved: false,
    activeProjects: 68,
    projects: 74,
    description: "Python Telegram bot using Long Polling",
    readme:
      "Telegram Bot with Long Polling Template\n\nPython\nTelegram\nPyCharm\n\nThis template provides a basic framework for creating a Telegram bot using Long Polling with the telebot\nlibrary.\n\nDeploy on Railway\n‚ú® Features\n\nTelebot: Easy and direct integration with Telegram's Bot API.\nLong Polling: Utilizes Telegram's Long Polling mechanism to efficiently receive updates.\nSimple Structure: Straightforward and easy-to-understand code, ideal for beginners and rapid prototyping.\n\nüíÅ‚Äç‚ôÄÔ∏è How to install\n\nCreate a new repository from this template: Click\n  the Use this template button on\n  this repository's main page (or clone the repository).\nInstall packages with pip using pip install -r requirements.txt\nRun locally using python main.py\n\nRepository: dangos-dev/TelegramBot.LongPolling",
    name: "Telegram Bot with Long Polling",
    category: "Bots",
    health: 50,
    code: "aOqPSI",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f67538ee-f75a-4478-bee9-7387e9167a4e",
    isApproved: false,
    activeProjects: 3,
    projects: 11,
    description: "Quickly save links, notes, and images",
    readme:
      "üîó Bookmark links, take simple notes and store images and pdfs.\n‚¨áÔ∏è Automatic fetching for link titles, descriptions and images.\nüìã Sort your bookmarks into lists.\nüîé Full text search of all the content stored.\n‚ú® AI-based (aka chatgpt) automatic tagging. With supports for local models using ollama!\nüéÜ OCR for extracting text from images.\nüîñ Chrome plugin and Firefox addon for quick bookmarking.\nüì± An iOS app, and an Android app.\nüì∞ Auto hoarding from RSS feeds.\nüîå REST API.\nüåê Multi-language support.\nüñçÔ∏è Mark and store highlights from your hoarded content.\nüóÑÔ∏è Full page archival (using monolith) to protect against link rot. Auto video archiving using youtube-dl.\n‚òëÔ∏è Bulk actions support.\nüîê SSO support.\nüåô Dark mode support.\nüíæ Self-hosting first.",
    name: "karakeep:v0.23.2",
    category: "AI/ML",
    health: 100,
    code: "lGB4F_",
    languages: ["Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0b4be169-dd1a-4860-9bd5-8f9a5c4e05ff",
    isApproved: false,
    activeProjects: 67,
    projects: 87,
    description: "A basic ASP.NET Core Web API template (.NET 8)",
    readme:
      '.NET8 Web API Template with Scalar Documentation\n\n.Net\nC#\n\nThis project demonstrates a simple Web API built with ASP.NET Core targeting .NET 8, showcasing interactive API\ndocumentation using Scalar.\n\nDeploy on Railway\n\nLive Demonstration\n\nThis template offers a live demonstration of the API\'s functionality through the integrated Scalar UI.  This interactive environment provides a hands-on experience for understanding and testing the API endpoints.\n\nAccess the Live API Demonstration: View Interactive Demo\n\nGetting Started\n\nFollow these steps to run the Web API example on your local machine.\n\nPrerequisites\n\n.NET SDK 8.0 - Make sure you have the .NET SDK 8.0 installed to build\n  and run ASP.NET Core applications. This project is built and tested using .NET 8.\n\nRunning the Application\n\nClone the repository: If you haven\'t already, clone this GitHub repository to your local machine.\n\ngit clone https://github.com/dangos-dev/DotNet8.ScalarWebApi.git\ncd DotNet8.ScalarWebApi\n\nRun the application: Execute the following dotnet CLI command to start the Web API:\n\ndotnet run\n\nAccess API Documentation: Once the application is running, you can access the API documentation through your web\n   browser:\n    Scalar UI: Open your browser and navigate to the /scalar endpoint. For example:\n      https://localhost:5001/scalar/v1 or http://localhost:5000/scalar/v1. The specific port will be shown in the console\n      output when you run the application.\n\n    OpenAPI JSON: The raw OpenAPI document in JSON format is available at /openapi/v1.json. For example:\n      https://localhost:5001/openapi/v1.json\n\nAPI Endpoints\n\nThe HelloWorldController in this example provides the following endpoints:\n\nGET /HelloWorld\n\n    Description: Returns a simple "Hello World! üç°" greeting message.\n    Response Example (200 OK):\n\n      Hello World! üç°\n\nGET /HelloWorld/echo\n\n    Description: This endpoint echoes back the message provided in the message query parameter.\n    Query Parameters:\n        message (string, required): The message you want to be echoed.\n    Request Example:\n\n        /HelloWorld/echo?message=YourTestMessage\n\n    Response Example (200 OK):\n\n        Echo: YourTestMessage\n\n    Error Response (400 Bad Request):\n        Condition: If the message query parameter is missing or empty.\n        Response Body:\n\n            Please provide a message to echo.\n\nKey Files\n\nHere are the key code files for this template:\n\nProgram.cs: The main application startup file, configuring services and middleware, including Scalar for API\n  documentation.\n\nControllers/HelloWorldController.cs: Defines the HelloWorldController with the API endpoints.\n\n  ApiController]  \n      Route("[controller]")]  \n      public class HelloWorldController(ILogger logger) : ControllerBase {  \n    \n          [HttpGet]// Matches GET requests to /HelloWorld  \n          public IActionResult GetHelloWorld() {  \n              logger.LogInformation("Hello World endpoint was hit.");  \n    \n              return Ok("Hello World! üç°");  \n          }\n      }\n\nScalar Configuration\n\nScalar API documentation is configured in Program.cs using the app.MapScalarApiReference extension method.\n\napp.MapScalarApiReference(\n    opt =&gt; {\n        opt.Title = "WebApi with Scalar Example";\n        opt.Theme = ScalarTheme.BluePlanet;\n        opt.DefaultHttpClient = new(ScalarTarget.Http, ScalarClient.Http11);\n    }\n);\n\nTitle: Sets the title of the documentation displayed in the Scalar UI (e.g., "WebApi Example").\nTheme: Applies the BluePlanet theme to customize the appearance of the Scalar UI.\nDefaultHttpClient: Configures the default HTTP client settings for Scalar.\n\nDependencies\n\nThis project relies on the following NuGet packages:\n\nScalar.AspNetCore:\n  For integrating Scalar API documentation into ASP.NET Core.\nSwashbuckle.AspNetCore.SwaggerGen &amp; Swashbuckle.AspNetCore.SwaggerUI:\n  Used by Scalar for OpenAPI document generation and UI.\n\nAuthor\n\nThis template is a basic example to help you get started with building ASP.NET Core Web APIs using .NET 8 and\ndocumenting them with Scalar. Feel free to use and modify it for your own projects.',
    name: ".NET8 Web API",
    category: "Starters",
    health: 93,
    code: "_R3Eu2",
    languages: ["C#", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e6e54297-2b7b-4503-822b-2c7bef90f6d8",
    isApproved: false,
    activeProjects: 4,
    projects: 22,
    description: "AI agent that deeply researches the web, using firecrawl and Reasoning LLM",
    readme:
      "Project Overview:\nOpen Deep Research is an open-source clone of OpenAI‚Äôs Deep Research experiment that combines AI reasoning with real-time web data extraction powered by Firecrawl. The project is built on a modern, serverless infrastructure leveraging Next.js with its App Router, React Server Components, and Server Actions to deliver dynamic, high-performance web experiences. It integrates a unified AI SDK to interface with various large language model providers (such as OpenAI, TogetherAI, and Deepseek) for generating text, structured outputs, and tool calls. The infrastructure also includes secure user authentication with NextAuth.js, data persistence through Vercel Postgres, and efficient file storage via Vercel Blob. Configurable environment variables allow seamless customization of the reasoning model and other operational parameters, ensuring the system is both flexible and scalable.\n\nFeatures:\n\t‚Ä¢\tFirecrawl Integration:\n\t‚Ä¢\tReal-time web data extraction and search capabilities.\n\t‚Ä¢\tNext.js Framework:\n\t‚Ä¢\tUtilizes App Router, React Server Components, and Server Actions for optimized routing and rendering.\n\t‚Ä¢\tAI SDK:\n\t‚Ä¢\tProvides a unified API for text generation, structured outputs, and easy switching between multiple LLM providers.\n\t‚Ä¢\tModern UI:\n\t‚Ä¢\tStyled with Tailwind CSS and built using accessible components from Radix UI.\n\t‚Ä¢\tData Persistence:\n\t‚Ä¢\tUses Vercel Postgres for database storage and Vercel Blob for efficient file storage.\n\t‚Ä¢\tAuthentication:\n\t‚Ä¢\tSecure sign-in and session management via NextAuth.js.\n\t‚Ä¢\tFlexible Reasoning Model:\n\t‚Ä¢\tConfigurable reasoning tasks enabled through environment variables for advanced research analysis.",
    name: "Open DeepResearch [by firecrawl]",
    category: "AI/ML",
    health: 100,
    code: "s9kj-n",
    languages: ["TypeScript", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "cc718aa3-87b7-46d8-ba9c-0192d8e9f430",
    isApproved: false,
    activeProjects: 2,
    projects: 9,
    description: "Loki is a horizontally scalable, log aggregation system",
    readme:
      "Loki is a horizontally scalable, multi-tenant log aggregation system created by Grafana Labs. It is designed for efficient and cost-effective log storage and retrieval and is often used alongside Grafana for visualization.\n\nLoki's Key Features\nIndex-Free Logging: Unlike traditional logging systems like Elasticsearch, Loki does not index the contents of logs. Instead, it indexes only the metadata (labels), making it much cheaper and faster for ingestion.\nLabel-Based Log Searching: Logs are identified using labels (like job, instance, namespace), making queries efficient without the complexity of full-text indexing.\nIntegration with Prometheus: Loki follows a design philosophy similar to Prometheus, using labels and supporting queries via LogQL (similar to PromQL for metrics).\nEfficient Storage: Loki compresses logs and stores them in chunks, often using object storage like S3, GCS, or Azure Blob Storage to reduce costs.\nMulti-Tenant & Scalable: Loki supports multi-tenancy and horizontally scales, meaning it can handle large volumes of logs across distributed systems.\n\nGuides\nSetup Loki with an open telemetry collector\nAdd Loki as a Grafana Data Source",
    name: "Loki",
    category: "Observability",
    health: 100,
    code: "0zMnS-",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3553d9ab-9ed5-4bcb-a685-f266d607f9c2",
    isApproved: false,
    activeProjects: 42,
    projects: 116,
    description: "Botpress is the ultimate platform for building next-generation chatbots.",
    readme:
      'After deploying, click on the main node, go to "Settings", scroll to the "Networking" section and click on "Custom Domain".\n\nSelect the port you need (:4000 for the Botpress studio) and click on "Generate Domain". Ideally, you should connect a domain for every single port.\n\nAfter that, configure your Admin account and you\'re done!',
    name: "Botpress",
    category: "AI/ML",
    health: 91,
    code: "yEID2r",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5fe56f14-61b7-4b80-82d0-3f8cc7881d09",
    isApproved: false,
    activeProjects: 2,
    projects: 6,
    description: "Grafana, with a volume attached to keep your configurations around",
    readme:
      "This Grafana template provides a starting point for building a powerful monitoring dashboard that helps administrators visualize key data for infrastructure, operations, and performance metrics.\n\nWhat's grafana?\nGrafana is an open-source tool that enables users to create dynamic, interactive dashboards for monitoring and analyzing time series data. It can pull data from a wide variety of sources, including databases (such as MySQL, PostgreSQL, and Prometheus), cloud services (like AWS and Azure), and custom applications, making it a versatile solution for consolidating data from multiple systems.\n\nWith Grafana, users can design visually rich dashboards using customizable panels such as graphs, tables, and gauges. These panels support different visualizations like line charts, bar charts, heatmaps, and more. In addition to displaying data, Grafana allows users to perform data transformations, aggregations, and set up alerts based on specific thresholds.\n\nThe platform also offers an interactive experience, allowing you to zoom in on time ranges, drill down into data points, and apply filters to focus on specific aspects of your data. Grafana dashboards support annotations, so you can add context, notes, and comments directly within the dashboard, helping to clarify insights.\n\nPersistent?\n\nTo ensure data persistence, we've mounted a volume at /var/lib/grafana. This setup guarantees that your data remains intact, even across system restarts.\n\nPlugins\n\nGrafana‚Äôs plugin ecosystem significantly extends its functionality. With the ability to integrate additional data sources, visualization types, and authentication options, Grafana can be tailored to fit any use case. You can easily explore and install community-developed plugins from the official Grafana Plugin Repository: Grafana Plugins.\n\nWidely adopted across industries, Grafana is ideal for infrastructure monitoring, application performance monitoring (APM), and business intelligence. Its flexibility, rich visualizations, and extensibility make it a go-to solution for anyone looking to extract valuable insights from their data.",
    name: "Grafana Persistent",
    category: "Observability",
    health: 100,
    code: "hn7jCZ",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "cb0e73af-1f28-4b6d-a5e9-87ae7da31a7a",
    isApproved: false,
    activeProjects: 4,
    projects: 5,
    description: "Private Django API server with a public Next.js app. Example use case.",
    readme:
      "Django x Next.js / an open source boilerplate is here. \n\nUsing:\nDjango-Ninja\nAPI forwarded requests via Next.js\nJWT Auth\nShadCN\nTailwind\n\nThe modern generative ai tooling for frontend is so much designed around Next.js (especially v0). This is for good reason, Next.js is a powerful frontend React.js framework with routing, data fetching support, server-side rendering, and more. \n\nDjango‚Äôs backend is here for whatever frontend changes AI might bring while giving you Python for backend logic, built-in user management, and a thriving third-party ecosystem. \n\nTailwindCSS and ShadCN are also excellent design libraries that I have baked in to this boilerplate. ",
    name: "Django x Next.js Boilerplate",
    category: "Other",
    health: 0,
    code: "LWkkqf",
    languages: ["JavaScript", "Python", "Dockerfile", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "075d325f-3c4e-4bae-a36d-597bba9ce4b6",
    isApproved: false,
    activeProjects: 10,
    projects: 21,
    description: "A modern, lightning-fast file sharing platform built for self-hosting",
    readme:
      "Flare is a modern, self-hostable file-sharing platform that makes sharing your files easier than ever. You can learn more about Flare's features here.\n\nThis Railway template is officially supported and lets you deploy Flare with just a few clicks‚Äîno complicated setup required. It comes pre-configured and ready to go, so you can get your instance up and running rapidly.",
    name: "Flare",
    category: "Storage",
    health: 100,
    code: "JVT41u",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "823b2ae8-7ddb-46c4-a2be-d4ab1aa81e24",
    isApproved: false,
    activeProjects: 0,
    projects: 19,
    description: "A CRM/ERP platform for rapid development of customizable web apps",
    readme:
      "Ozma is an open-source CRM/ERP platform that allows for the rapid development of customizable enterprise systems. Build and tailor CRM/ERP solutions quickly and efficiently to meet your business needs.\n\nFeatures\n\nLow-Code Development: Accelerate your system development;\nFully Customizable: Adaptable to any business process.\nDeveloper-Friendly: No expensive training required.",
    name: "ozma",
    category: "Other",
    health: null,
    code: "xgJwGP",
    languages: ["Vue", "TypeScript", "SCSS", "JavaScript", "HTML", "CSS", "Python", "Shell", "Nix"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "48e5d221-74d6-463d-bd3a-f717ce194905",
    isApproved: false,
    activeProjects: 1,
    projects: 4,
    description: "Postgres cluster for high availability and redundancy with pgvector",
    readme:
      "Deploy a PostgreSQL HA with Repmgr that extends the official Railway template and comes with the pgvector extension preinstalled.\n\nRun CREATE EXTENSION vector; after deploying the template to activate the pgvector extension.",
    name: "PostgreSQL HA Cluster (pgvector)",
    category: "Storage",
    health: 100,
    code: "1CQq0n",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9ecf7b96-21b6-4751-9948-98764649babf",
    isApproved: false,
    activeProjects: 0,
    projects: 7,
    description: "Encrypted file sharing and file/password vault service ",
    readme:
      "For more configuration options, refer to the documentation for the full list of environment variables.\n\nAbout\n\nYeetFile is a file vault and file/text transferring service, with both a\nweb and CLI\nclient officially supported.\nAll content is encrypted locally, and the server is incapable of decrypting any\ntransmitted content.\n\nFeatures\n\nYeetFile Send\n\nSend files and text with shareable links\n  Links don't require an account to open\nConfigurable upload settings\n  Expiration date/time configurable to X minutes/hours/days (max 30 days)\n  Number of downloads (max 10)\n  Optional password protection\nFree text transfers (up to 2000 characters)\n\nYeetFile Vault\n\nFile and password storage + folder creation\nFile/password/folder sharing w/ YeetFile users\n  Read/write permissions per user\nNo upload size limit\n\nAccounts\n\nEmail not required at signup\n  Account ID-only signup allowed\n  Signup not required for text-only transfers\nOptions to pay for vault/send upgrades\n  Payments handled via Stripe\n  BTC and XMR supported via BTCPay\n  Not required when self-hosting\n  Ability to recycle payment ID to remove record of payment\n\nOther\n\nServer-specific passwords (optional for self-hosting)\nEasily self-hosted\n  Official CLI can be configured to use any server\n",
    name: "YeetFile",
    category: "Other",
    health: null,
    code: "dxr3eJ",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7661fe2a-5493-4ed8-99e0-e1e4a935ae3b",
    isApproved: false,
    activeProjects: 375,
    projects: 394,
    description: "An open-source phishing simulation toolkit for pentesters & security teams.",
    readme:
      "Overview\nThis template deploys Gophish, an open-source phishing simulation toolkit for pentesters and security teams. You can create email templates, define user groups, launch campaigns, and track responses, to test your organization's exposure to phishing attacks.\n\nConfiguration\nThe template uses the Gophish Docker image with some environment variables pre-configured to work on Railway; if you want to understand (or change) environment variables, see the source here and the docs here.\n  \nOnce deployed, look for the admin credentials under the View Logs section of the Deployments tab - you'll find an entry similar to 'Please login with the username admin and the password 0f564d8fxd9161d25'.\n\nReferences\nPhishing Attack Simulation with Gophish\nGophish GitHub repo",
    name: "Gophish",
    category: "Other",
    health: 100,
    code: "gEmUp6",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "918a0034-30c2-4d63-92dc-ec29e5ce98d6",
    isApproved: false,
    activeProjects: 0,
    projects: 5,
    description: "The only database built from the ground up for the average developer‚Ñ¢",
    readme:
      "AvgDB is the only database built from the ground up for the average developer. Used by the fastest growing startups to large enterprises alike. You might be using an AvgDB wrapper without even knowing it...\n\nWith this template, you can run the same AvgDB that powers billions of users, devices, MRI machines, planes, robots, and space stations without an enterprise license (even if you're on K8s).",
    name: "AvgDB - averagedatabase.com",
    category: "Storage",
    health: null,
    code: "1hVRX4",
    languages: ["TypeScript", "Rust", "JavaScript", "Dockerfile", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "89b0fac5-df59-446f-b97b-0946d1058eaf",
    isApproved: false,
    activeProjects: 15,
    projects: 27,
    description: "n8n + postgres Low Memory",
    readme:
      "Optimiza n8n con PostgreSQL en entornos de baja memoria limitando la retenci√≥n de ejecuciones, configurando variables de entorno para reducir uso de RAM y ajustando par√°metros de PostgreSQL como el tama√±o de los buffers. ¬°Mant√©n todo ligero y eficiente!",
    name: "n8n+postgres",
    category: "Other",
    health: 100,
    code: "Bu9iFP",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d0e53b20-ed6c-4ac0-8d18-af684642b002",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "A robust backend with interactive RESTful API's for a video streaming",
    readme:
      "PlayNex is a robust backend for a YouTube-like video streaming application, integrating MongoDB for data persistence and Cloudinary for media management. It provides secure, RESTful API endpoints documented using Swagger for ease of development and testing.",
    name: "PlayNex",
    category: "Other",
    health: null,
    code: "zYfM2t",
    languages: ["JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "36081c18-b522-4c46-9961-e179549aa35d",
    isApproved: false,
    activeProjects: 8,
    projects: 12,
    description: "Single MongoDB replica set for use with clients needing a replica set.",
    readme:
      "This template deploys a single MongoDB instance for your data layer needs.\n\nNetwork Communication\n\nAll database communication is done over the private network.\n\nConfiguration tuning\n\nTo tune the configuration of your MongoDB instance, refer to the MongoDB documentation or the documentation page in Docker Hub.\n\nAuthentication\n\nThe MongoDB instance is deployed with standard authentication enabled.\n\nConnecting to MongoDB\n\nTo connect to MongoDB from another service in Railway, you should create a URI in the service's environment variables. As an example:\n\nMONGO_HOST=${{mongo.RAILWAY_PRIVATE_DOMAIN}}:27017\nMONGO_URI=mongodb://${{mongo.MONGO_INITDB_ROOT_USERNAME}}:${{mongo.MONGO_INITDB_ROOT_PASSWORD}}@${{MONGO_HOST}}\n\nWith these variables set, you can then reference the MONGO_URI environment variable when configuring the client in your service code.\n\nTemplate source\n\nThe source for this template can be found in the Railway Templates GitHub.\n\nThe MongoDB instance is built directly from the official MongoDB image in Docker Hub.\n\nResources\nMongoDB documentation\nTutorial: Deploy MongoDB on RailwayThis template deploys a single MongoDB instance for your data layer needs.\n\nNetwork Communication\n\nAll database communication is done over the private network.\n\nConfiguration tuning\n\nTo tune the configuration of your MongoDB instance, refer to the MongoDB documentation or the documentation page in Docker Hub.\n\nAuthentication\n\nThe MongoDB instance is deployed with standard authentication enabled.\n\nConnecting to MongoDB\n\nTo connect to MongoDB from another service in Railway, you should create a URI in the service's environment variables. As an example:\n\nMONGO_HOST=${{mongo.RAILWAY_PRIVATE_DOMAIN}}:27017\nMONGO_URI=mongodb://${{mongo.MONGO_INITDB_ROOT_USERNAME}}:${{mongo.MONGO_INITDB_ROOT_PASSWORD}}@${{MONGO_HOST}}\n\nWith these variables set, you can then reference the MONGO_URI environment variable when configuring the client in your service code.\n\nTemplate source\n\nThe source for this template can be found in the Railway Templates GitHub.\n\nThe MongoDB instance is built directly from the official MongoDB image in Docker Hub.\n\nResources\nMongoDB documentation\nTutorial: Deploy MongoDB on Railway",
    name: "MongoDB Single Replica",
    category: "Storage",
    health: 100,
    code: "dxhww9",
    languages: ["Shell", "JavaScript", "Python", "Dockerfile", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0f03f811-140a-4614-b80c-c0a244a05ca8",
    isApproved: false,
    activeProjects: 40,
    projects: 44,
    description: "ü§ó Êõ¥‰ºòÈõÖÁöÑÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ËÆ¢ÈòÖÊñπÂºèÔºåÊîØÊåÅÁßÅÊúâÂåñÈÉ®ÁΩ≤„ÄÅÂæÆ‰ø°ÂÖ¨‰ºóÂè∑RSSÁîüÊàê",
    readme:
      "\n\n\nWeWe RSS\n\nÊõ¥‰ºòÈõÖÁöÑÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ËÆ¢ÈòÖÊñπÂºè„ÄÇ\n\n‰∏ªÁïåÈù¢\n\nv2.xÁâàÊú¨‰ΩøÁî®ÂÖ®Êñ∞Êé•Âè£ÔºåÊõ¥Âä†Á®≥ÂÆö\nÊîØÊåÅÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ËÆ¢ÈòÖÔºàÂü∫‰∫éÂæÆ‰ø°ËØª‰π¶Ôºâ\nËé∑ÂèñÂÖ¨‰ºóÂè∑ÂéÜÂè≤ÂèëÂ∏ÉÊñáÁ´†\nÂêéÂè∞Ëá™Âä®ÂÆöÊó∂Êõ¥Êñ∞ÂÜÖÂÆπ\nÂæÆ‰ø°ÂÖ¨‰ºóÂè∑RSSÁîüÊàêÔºàÊîØÊåÅ.atom\\.rss\\.jsonÊ†ºÂºè)\nÊîØÊåÅÂÖ®ÊñáÂÜÖÂÆπËæìÂá∫ÔºåËÆ©ÈòÖËØªÊó†ÈöúÁ¢ç\nÊâÄÊúâËÆ¢ÈòÖÊ∫êÂØºÂá∫OPML",
    name: "WeWe RSS",
    category: "Other",
    health: 100,
    code: "9lIYng",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ea6a736d-5500-4529-b6aa-ed58f79fa264",
    isApproved: false,
    activeProjects: 2,
    projects: 7,
    description: "Lightweight server monitoring hub with Docker stats.",
    readme:
      "Beszel is a lightweight server monitoring platform that includes Docker statistics, historical data, and alert functions.\n\nIt has a friendly web interface, simple configuration, and is ready to use out of the box. It supports automatic backup, multi-user, OAuth authentication, and API access.\n\nDocumentation here for further details to connect remote agents.",
    name: "Beszel",
    category: "Observability",
    health: 100,
    code: "nJKarX",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "888e7339-898b-447a-8ce6-5baef5706b5a",
    isApproved: false,
    activeProjects: 2,
    projects: 8,
    description: "Open Source MongoDB drop-in replacement",
    readme:
      "FerretDB is an open-source alternative to MongoDB.\nIt is a proxy that converts MongoDB 5.0+ wire protocol queries to SQL and uses PostgreSQL with DocumentDB extension as a database engine.\n\nConnecting to FerretDB\n\nFerretDB is a drop-in replacement for MongoDB so you can simply construct a mongodb connection string like this: mongodb://{{postgres_username}}:{{postgres_password}}@{{railway_tcp_url}}:{{railway_tcp_port}}/\n\nFor {{postgres_username}} and {{postgres_password}}, they are autogenerated by the Postgres service deployed by the template.\n\nFor {{railway_tcp_url}} and {{railway_tcp_port}}, they are autogenerated by the FerretDB service deployed by the template.\n\nWhy do we need FerretDB?\n\nMongoDB was originally an eye-opening technology for many of us developers, empowering us to build applications faster than using relational databases.\nIn its early days, its ease-to-use and well-documented drivers made MongoDB one of the simplest database solutions available.\nHowever, as time passed, MongoDB abandoned its open-source roots;\nchanging the license to SSPL - making it unusable for many open-source and early-stage commercial projects.\n\nMost MongoDB users do not require any advanced features offered by MongoDB;\nhowever, they need an easy-to-use open-source document database solution.\nRecognizing this, FerretDB is here to fill that gap.",
    name: "FerretDB",
    category: "Storage",
    health: 100,
    code: "cMeXM0",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "bbabe1c1-1bf3-427a-acd0-394174968e1e",
    isApproved: false,
    activeProjects: 7,
    projects: 9,
    description: "An open-source Go implementation of the Expo Updates protocol",
    readme:
      "An open-source Go implementation of the Expo Updates protocol, designed for production with support for cloud storage like S3 and CDN integration, delivering fast and reliable OTA updates for React Native apps.\n\n\nFor detailed information and to explore the core functionalities of expo-open-ota, visit the main repository:\nexpo-open-ota on GitHub",
    name: "Expo-Open-OTA",
    category: "Other",
    health: null,
    code: "MGW3k1",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a2526d16-7390-44d4-89d6-b29429a9eec7",
    isApproved: false,
    activeProjects: 1,
    projects: 1,
    description: "A quick setup for PostgreSQL including the Wal2Json Plugin in the template",
    readme:
      "A PostgreSQL deployment template for Railway, enabling quick setup with the Wal2Json plugin.\n\nFor more details about the Wal2Json plugin -> https://github.com/eulerto/wal2json\n\nAbout Wal2Json\n\nPostgreSQL records all changes‚ÄîINSERTs, UPDATEs, and DELETEs‚Äîin a log called the Write-Ahead Log (WAL). This log ensures database consistency and allows for replication and recovery. However, WAL data is stored in a format optimized for internal database operations, not direct consumption.\n\nWal2Json bridges this gap by converting WAL changes into structured JSON output, making it easier for applications to process database updates in real time. This is especially useful for data replication, change auditing, event-driven architectures, and streaming data to external systems. The plugin works by using logical decoding, allowing applications to read database changes without requiring full physical replication.\n\nDepending on configuration, UPDATE and DELETE operations can include previous row versions, making it possible to track before-and-after states of data changes. Changes can be consumed via logical replication slots for continuous streaming or queried directly using a SQL API.",
    name: "PostgreSQL with Wal2Json Plugin",
    category: "Storage",
    health: 100,
    code: "FcaxSv",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6dd0a736-cfbd-4623-a3f5-47e14c055a08",
    isApproved: false,
    activeProjects: 12,
    projects: 25,
    description: "Browserless with Chrome not Chromium",
    readme:
      "These environment variables configure a secure Browserless server with Chrome for headless browsing. They define connection endpoints, token-based security, WebSocket/Playwright support, queue limits, concurrency, session timeouts, and public/private access.",
    name: "browserless-with-chrome",
    category: "Other",
    health: 83,
    code: "kXn4KF",
    languages: ["Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0f3d23a7-b4bc-4e32-9441-4fb9fb1e0e2e",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "A self-hosted visual website builder and CMS.",
    readme:
      "Nitropage is an entirely free and open source, extensible visual website builder based on SolidStart, offering a growing library of versatile building blocks.\n\nFeatures:\n\nPage revisions\nElement presets\nReusable layouts\nFocal point image cropping\nSelf and CDN hosted fonts\nAtom (RSS) feeds\nSupport for multiple projects\n\nLearn more at:\nhttps://nitropage.org",
    name: "Nitropage",
    category: "CMS",
    health: null,
    code: "G_8roH",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "aa0b8a80-81ad-4966-86be-7fcfd597bd47",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "Assistente de IA Bell'Arte ",
    readme:
      "O Assistente de Intelig√™ncia Artificial Bell'Arte √© uma ferramenta revolucion√°ria, projetada para oferecer suporte completo aos lojistas, representantes e clientes do Grupo Bell'Arte. Sua funcionalidade vai muito al√©m de um simples assistente virtual, integrando informa√ß√µes t√©cnicas, comerciais e estrat√©gicas em um √∫nico ambiente digital, acess√≠vel 24/7.",
    name: "assistentebellarteIA ",
    category: "Other",
    health: null,
    code: "4kBx76",
    languages: ["Python", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a2127f89-420b-44f2-af01-035d1fd3f7bd",
    isApproved: false,
    activeProjects: 1,
    projects: 4,
    description: "Bookmark manager designed be to be minimal, fast, and easy to set up.",
    readme:
      "Introduction \n\nLinkding is a bookmark manager that you can host yourself. It's designed be to be minimal, fast, and easy to set up.\n\nThis template implements a solution with postgres database, which can handle heavier, production-level workload if needed\n\nFeature Overview\n\nClean UI optimized for readability\nOrganize bookmarks with tags\nBulk editing, Markdown notes, read it later functionality\nShare bookmarks with other users or guests\nAutomatically provides titles, descriptions and icons of bookmarked websites\nAutomatically archive websites, either as local HTML file or on Internet Archive\nImport and export bookmarks in Netscape HTML format\nInstallable as a Progressive Web App (PWA)\nExtensions for Firefox and Chrome, as well as a bookmarklet\nSSO support via OIDC or authentication proxies\nREST API for developing 3rd party apps\nAdmin panel for user self-service and raw data access",
    name: "Linkding",
    category: "Other",
    health: null,
    code: "EG6_cW",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9df046e2-bcbf-4c01-8825-a8f3d7d1998a",
    isApproved: false,
    activeProjects: 79,
    projects: 103,
    description: "Deploy your own AI agent that can interact across clients using ElizaOS.",
    readme:
      'ElizaOS Starter\n\nA customizable AI agent framework that lets you create and deploy AI personalities across multiple platforms. Built with TypeScript and powered by your choice of AI models through OpenRouter.\n\nFeatures\nü§ñ Multi-platform support (Discord, Twitter)\nüé≠ Customizable AI personalities\n‚ö° Easy deployment and scaling\nüîí Secure credentials management\nüîå Extensible client system\n\nInstructions\n\nRequired Environment Variables:\n   OPENROUTER_API_KEY: Your OpenRouter API key\n   OPENROUTER_MODEL: Your preferred AI model (e.g., "anthropic/claude-3-sonnet")\n\nOptional Platform Credentials:\n   For Discord:\n   DISCORD_APPLICATION_ID\n   DISCORD_API_TOKEN\n\n   For Twitter:\n   TWITTER_USERNAME\n   TWITTER_PASSWORD\n   TWITTER_EMAIL\n\nThe build process will automatically:\nSet up the necessary dependencies\nConfigure your selected platforms\nDeploy your AI agent\n\nGet your OpenRouter API key at: https://openrouter.ai/',
    name: "ElizaOS",
    category: "AI/ML",
    health: 72,
    code: "aW47_j",
    languages: ["TypeScript", "Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "16b4ba09-c3a2-4901-9367-5eb043009b87",
    isApproved: false,
    activeProjects: 4,
    projects: 11,
    description: "powered up ChatGPT - Gennerative AI Suite with advanced multi-modal tools",
    readme:
      "üëâ Key Features ‚ú®\n\n| Advanced AI | 100+ AI Models | Flow-state UX | Privacy First | Advanced Tools |\n|---------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------|\n| ChatCallBeamDraw, ... | Local &amp; CloudOpen &amp; ClosedCheap &amp; HeavyGoogle, Mistral, ... | AttachmentsDiagramsMulti-ChatMobile-first UI | Stored LocallyEasy self-HostLocal actionsData = Gold | AI PersonasVoice ModesScreen CaptureCamera + OCR |\n\nbig-AGI screenshot\n\nYou can easily configure 100s of AI models in big-AGI:\n\n| AI models | supported vendors |\n|:--|:--|\n| Opensource Servers | LocalAI (multimodal) ¬∑ Ollama |\n| Local Servers | LM Studio |\n| Multimodal services | Azure ¬∑ Google Gemini ¬∑ OpenAI |\n| Language services | Anthropic ¬∑ Groq ¬∑ Mistral ¬∑ OpenRouter ¬∑ Perplexity ¬∑ Together AI |\n| Image services | Prodia (SDXL) |\n| Speech services | ElevenLabs (Voice synthesis / cloning) |\n\nYou can easily configure 100s of AI models in big-AGI:\n\n| AI models       | supported vendors                                                                                                                                                                                                             |\n|:--------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Opensource Servers  | LocalAI (multimodal) ¬∑ Ollama                                                                                                                                                     |\n| Local Servers       | LM Studio                                                                                                                                                                                               |\n| Multimodal services | Azure ¬∑ Google Gemini ¬∑ OpenAI                                                  |\n| Language services   | Anthropic ¬∑ Groq ¬∑ Mistral ¬∑ OpenRouter ¬∑ Perplexity ¬∑ Together AI | \n| Image services      | Prodia (SDXL)                                                                                                                                                                                            | \n| Speech services     | ElevenLabs (Voice synthesis / cloning)   \n\n\nAdd extra functionality with these integrations:\n\n| More     | integrations                                                                                                 |\n|:-------------|:---------------------------------------------------------------------------------------------------------------| \n| Web Browse   | Browserless ¬∑ Puppeteer-based                              |\n| Web Search   | Google CSE                                                     |\n| Code Editors | CodePen ¬∑ StackBlitz ¬∑ JSFiddle |\n| Sharing      | Paste.gg (Paste chats)                                                                    | \n| Tracking     | Helicone (LLM Observability)     ",
    name: "big-AGI",
    category: "AI/ML",
    health: 100,
    code: "BOIjs9",
    languages: ["TypeScript", "JavaScript", "CSS", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e5641b48-c473-4179-aaed-e99ac3bb965e",
    isApproved: false,
    activeProjects: 2,
    projects: 2,
    description: "‚ú® This Bot can Auto-react to Channel Posts, Groups and Private Chats. ",
    readme:
      'To ensure that your Telegram Auto-Reaction Bot operates correctly, you will need to configure several environment variables in your Cloudflare Worker settings:\n\nBOT_TOKEN: This is your bot\'s token, which you can generate from BotFather. This token allows your bot to authenticate and interact with the Telegram API.\nBOT_USERNAME: The username you have set for your bot. This is used within the script to identify messages intended for your bot.\nEMOJI_LIST: A string of emojis that the bot will use to react to messages. You can customize this list to include any emojis you prefer, such as üëç‚ù§üî•ü•∞üëèüòÅüéâü§©üôèüëåüïäüòçüê≥‚ù§‚Äçüî•üíØ‚ö°üèÜ.\nRANDOM_LEVEL: An integer that determines the randomness of reactions in group chats. Lower values result in more predictable reactions, while higher values increase randomness. Default is 0, meaning reactions are consistent by default.\nRESTRICTED_CHATS: A list of chat IDs where the bot should not react to messages (Optional). Split each chat ID by " , ". Example : -1001233434,343423hh',
    name: "Ajereactionbot",
    category: "Bots",
    health: 0,
    code: "GkpNNL",
    languages: ["JavaScript", "Dockerfile", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "31770579-d70b-4868-8582-aa5f25f236e6",
    isApproved: false,
    activeProjects: 39,
    projects: 73,
    description: "Stunning Status Pages, batteries included",
    readme:
      'Kener - A Stunning Status Page System, batteries included\n\n\n\t\n\n\n| "Star Repo" | Awesome | Docker |\n|:---:|:---:|:---:|\n| üëâ Live Demo | üëâ Quick Start | üëâ Documentation |\n\nWhat is Kener?\n\nKener is status page system built with Sveltekit and NodeJS. It does not try to replace the Datadogs and Atlassian of the world. It tries to help some who wants to come up with a status page that looks nice and minimum overhead, in a modern way.\n\nIt is carefully crafted to be easy to use and customize.\n\nIt comes with all the basic asks for a status page. It is open-source and free to use.\n\nKener name is derived from the word "Kene" which means "how is it going" in Assamese, then .ing because it was a cheaply available domain.\n\nHelpful Resources\n\nhttps://kener.ing/docs/quick-start/\nhttps://kener.ing/docs/deployment/\nhttps://kener.ing/docs/concepts/\nhttps://kener.ing/docs/kener-apis/\nFeatures\n\nHere are some of the features that you get out of the box. Please read the documentation to know how to use them.\n\nMonitoring and Tracking\n\nAdvanced application performance monitoring tools\nReal-time network monitor software capabilities\nPolls HTTP endpoint or Push data to monitor using Rest APIs\nAdjusts Timezones for visitors\nCategorize Monitors into different Sections\nCron-based scheduling for monitors. Minimum per minute\nConstruct complex API Polls - Chain, Secrets etc\nSupports a Default Status for Monitors\nSupports base path for hosting in k8s\nPre-built docker image for easy deployment\nAutomatically adjusts timezones for visitors\n\nCustomization and Branding\n\nCustomizable status page\nBadge generation for status and uptime of Monitors\nSupport for custom domains\nEmbed Monitor as an iframe or widget\nLight + Dark Theme\nInternationalization support\nBeautifully Crafted Status Page\n\nIncident Management\n\nIncident Management\nIncident Communication\nComprehensive APIs for Incident Management\n\nUser Experience and Design\n\nGood Accessibility Score\nEasy installation and setup\nUser-friendly interface\nResponsive design for various devices\nAuto SEO and Social Media ready\nServer Side Rendering\n\nTechnologies used\n\nSvelteKit\nshadcn-svelte\n\nSupport Me\n\nIf you are using Kener and want to support me, you can do so by sponsoring me on GitHub or buying me a coffee.\n\nSponsor Me Using Github\n\nBuy Me a Coffee\n\n',
    name: "Kener",
    category: "Observability",
    health: 88,
    code: "spSvic",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "dd0ccbc4-f36a-4046-a3f3-ec59b7da9753",
    isApproved: false,
    activeProjects: 2,
    projects: 13,
    description: "lite version LibreChat without RAG",
    readme:
      "\n‚ú® Features\n\nüñ•Ô∏è UI & Experience inspired by ChatGPT with enhanced design and features\n\nü§ñ AI Model Selection:  \n  Anthropic (Claude), AWS Bedrock, OpenAI, Azure OpenAI, Google, Vertex AI, OpenAI Assistants API (incl. Azure)\n  Custom Endpoints: Use any OpenAI-compatible API with LibreChat, no proxy required\n  Compatible with Local & Remote AI Providers:\n    Ollama, groq, Cohere, Mistral AI, Apple MLX, koboldcpp, together.ai,\n    OpenRouter, Perplexity, ShuttleAI, Deepseek, Qwen, and more\n\nüîß Code Interpreter API: \n  Secure, Sandboxed Execution in Python, Node.js (JS/TS), Go, C/C++, Java, PHP, Rust, and Fortran\n  Seamless File Handling: Upload, process, and download files directly\n  No Privacy Concerns: Fully isolated and secure execution\n\nüî¶ Agents & Tools Integration:  \n  LibreChat Agents:\n    No-Code Custom Assistants: Build specialized, AI-driven helpers without coding  \n    Flexible & Extensible: Attach tools like DALL-E-3, file search, code execution, and more  \n    Compatible with Custom Endpoints, OpenAI, Azure, Anthropic, AWS Bedrock, and more\n    Model Context Protocol (MCP) Support for Tools\n  Use LibreChat Agents and OpenAI Assistants with Files, Code Interpreter, Tools, and API Actions\n\nü™Ñ Generative UI with Code Artifacts:  \n  Code Artifacts allow creation of React, HTML, and Mermaid diagrams directly in chat\n\nüíæ Presets & Context Management:  \n  Create, Save, & Share Custom Presets  \n  Switch between AI Endpoints and Presets mid-chat\n  Edit, Resubmit, and Continue Messages with Conversation branching  \n  Fork Messages & Conversations for Advanced Context control\n\nüí¨ Multimodal & File Interactions:  \n  Upload and analyze images with Claude 3, GPT-4o, o1, Llama-Vision, and Gemini üì∏  \n  Chat with Files using Custom Endpoints, OpenAI, Azure, Anthropic, AWS Bedrock, & Google üóÉÔ∏è\n\nüåé Multilingual UI:  \n  English, ‰∏≠Êñá, Deutsch, Espa√±ol, Fran√ßais, Italiano, Polski, Portugu√™s Brasileiro\n  –†—É—Å—Å–∫–∏–π, Êó•Êú¨Ë™û, Svenska, ÌïúÍµ≠Ïñ¥, Ti·∫øng Vi·ªát, ÁπÅÈ´î‰∏≠Êñá, ÿßŸÑÿπÿ±ÿ®Ÿäÿ©, T√ºrk√ße, Nederlands, ◊¢◊ë◊®◊ô◊™\n\nüé® Customizable Interface:  \n  Customizable Dropdown & Interface that adapts to both power users and newcomers\n\nüó£Ô∏è Speech & Audio:  \n  Chat hands-free with Speech-to-Text and Text-to-Speech  \n  Automatically send and play Audio  \n  Supports OpenAI, Azure OpenAI, and Elevenlabs\n\nüì• Import & Export Conversations:  \n  Import Conversations from LibreChat, ChatGPT, Chatbot UI  \n  Export conversations as screenshots, markdown, text, json\n\nüîç Search & Discovery:  \n  Search all messages/conversations\n\nüë• Multi-User & Secure Access:\n  Multi-User, Secure Authentication with OAuth2, LDAP, & Email Login Support\n  Built-in Moderation, and Token spend tools\n\n‚öôÔ∏è Configuration & Deployment:  \n  Configure Proxy, Reverse Proxy, Docker, & many Deployment options  \n  Use completely local or deploy on the cloud\n\nüìñ Open-Source & Community:  \n  Completely Open-Source & Built in Public  \n  Community-driven development, support, and feedback\n",
    name: "LibreChat - Lite",
    category: "AI/ML",
    health: 0,
    code: "_fTxzh",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1961cd84-bf1f-4c9a-84c0-1fed1c6db5d4",
    isApproved: false,
    activeProjects: 4,
    projects: 5,
    description: "World best whtsapp bot VAJIRA MD",
    readme:
      "World best whatsapp bot VAJIRA MD \nDevelop by Vajira Rathnayaka\nContact us https://wa.me/94711453361\n\nùó•ùó¢ùó†ùóîùó°ùóñùóò/ùóîùóñùóßùóúùó¢ùó°/ùóîùóóùó©ùóòùó°ùóßùó®ùó•ùóò/ùóñùó¢ùó†ùóòùóóùó¨ ‡∂∏‡∑ö ‡∑Ñ‡∑ê‡∂∏ STYLE ‡∂ë‡∂ö‡∂∏ MOVE ‡∂∂‡∂Ω‡∂±‡∑ä‡∂± ‡∂Ö‡∂¥‡∑í‡∂≠‡∑ä ‡∂ë‡∂ö‡∑ä‡∂ö ‡∂ë‡∂ö‡∂≠‡∑î ‡∑Ä‡∑ô‡∂±‡∑ä‡∂±\n                                                      \n üìΩÔ∏è ùêìùêÉùêÉ ùêåùêéùêïùêàùêÑ ùêñùêéùêëùêãùêÉ üìΩÔ∏è ‚ù¨ 1 ‚ù≠\nhttps://chat.whatsapp.com/J4rWs3K2Y4dITPILnONKmP\n\n üìΩÔ∏è ùêìùêÉùêÉ ùêåùêéùêïùêàùêÑ ùêñùêéùêëùêãùêÉ üìΩÔ∏è ‚ù¨ 2 ‚ù≠\nhttps://chat.whatsapp.com/HR9gfaczPi837u67bykIDr\n\nüìΩÔ∏è ùêìùêÉùêÉ ùêåùêéùêïùêàùêÑ ùêñùêéùêëùêãùêÉ üìΩÔ∏è ‚ù¨ 3 ‚ù≠ https://chat.whatsapp.com/EpDiTMj0GGI1zqyKZwd4tG\n\nüìΩÔ∏è ùêìùêÉùêÉ ùêåùêéùêïùêàùêÑ ùêñùêéùêëùêãùêÉ üìΩÔ∏è ‚ù¨ 4 ‚ù≠ https://chat.whatsapp.com/ESDZgP0k1RgDadCecMvHDn\n\n....................................................................\n‚óè ‡∑É‡∑í‡∂∫‡∂Ω‡∑î‡∂∏ ‡∂∑‡∑è‡∑Å‡∑è ‡∑Ä‡∂Ω films ‡∑É‡∑Ñ tv series ‡∂∏‡∑ô‡∂∏ ‡∑É‡∂∏‡∑ñ‡∑Ñ‡∂∫ ‡∂≠‡∑î‡∂Ω ‡∂¥‡∂Ω ‡∂ö‡∑ô‡∂ª‡∑ö.\n....................................................................\nMOVES ‡∂∂‡∂Ω‡∂±‡∑ä‡∂± ‡∂ö‡∑ê‡∂∏‡∂≠‡∑í ‡∂Ö‡∂∫‡∂ß LINK ‡∂ë‡∂ö SHEAR ‡∂ö‡∂ª‡∂±‡∑ä‡∂±\n....................................................................\nMOVES ‡∂∂‡∂Ω‡∂± ‡∂Ö‡∂∫ ‡∑Ä‡∑í‡∂≠‡∂ª‡∂ö‡∑ä JOIN ‡∑Ä‡∑ô‡∂±‡∑ä‡∂±‚ÄºÔ∏è\n..............................................................\n\n\n",
    name: "VAJIRA-MD",
    category: "Bots",
    health: null,
    code: "_vD3X2",
    languages: ["JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3a9dc6d4-4737-4705-b49f-1c69ffe47c37",
    isApproved: false,
    activeProjects: 8,
    projects: 31,
    description: "Your own ZAP OWASP website vulnerbility scanner. ",
    readme:
      "ZAP OWASP Web Interface\nby, Funkyton\n\nKey Features\nAutomated deployment of the ZAP API in Docker with a custom-built web interface.\nPerform OWASP scans in the cloud without installing software locally or relying on untrusted third-party services.\nSchedule scans for regular security testing and meeting ISO27001 compliance requirements.\nExport scan results as PDF\nNo scan quota.\n",
    name: "ZAP OWASP web scanner",
    category: "Other",
    health: 80,
    code: "dCh187",
    languages: ["TypeScript", "CSS", "JavaScript", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1224cd48-21ec-4c64-ad22-70959a3e82d5",
    isApproved: false,
    activeProjects: 43,
    projects: 78,
    description: "OpenProject is a project management software with a focus on sovereignty",
    readme:
      'OpenProject\n\nOpenProject is a powerful open-source project management software that helps teams efficiently plan, track, and collaborate on their projects. It offers a wide range of features including task management, Gantt charts, agile boards, time tracking, budget management, and reporting tools.\n\nWith OpenProject, teams can manage their workflows using methodologies such as Agile, Scrum, and traditional project management techniques. It provides an intuitive user interface and robust collaboration features, making it ideal for organizations of all sizes.\n\nKey features of OpenProject include:\n\nProject Planning & Scheduling ‚Äì Define project goals, milestones, and timelines.\nAgile and Scrum Support ‚Äì Manage sprints, backlogs, and team velocity.\nTime and Cost Tracking ‚Äì Monitor project budgets and employee work hours.\nCollaboration Tools ‚Äì Share documents, comments, and updates with team members.\nSecurity and Permissions ‚Äì Role-based access controls to manage data security.\n\nTroubleshooting\n\nIn case the OpenProject UI is not displayed, check that the DB is correctly created with the tables, and restart the OpenProject service and look at the deployment logs until the message "Listen 0.0.0.0.0:8080" is displayed.\n\n\nFor detailed information and installation guides, visit the official documentation:\n\nOpenProject Documentation\n',
    name: "Openproject",
    category: "Other",
    health: 69,
    code: "OVnHpX",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "76e904fd-43a9-45a3-b361-3d2266faa035",
    isApproved: false,
    activeProjects: 44,
    projects: 63,
    description: "Mint NFTs & Cryptocurrencies with thirdweb in a single-page app.",
    readme:
      "\nTemplate\n\nThis is the official community Railway template for self-hosting your own NFT &amp; Cryptocurrency Minting page, maintained by the thirdweb community team. This template deploys a customized version of the NFT Minting Page from the thirdweb Examples repository. It provides a single-page application for minting NFTs and Cryptocurrencies, powered by thirdweb.\n\nRequirements\n\nthirdweb API Client ID. [Get it here]\nChain ID of the blockchain where your contract is deployed. [Find it here]\n\nOverview\n\nNFT Minting Page is a single-page application built with Next.js that allows users to mint NFTs and Cryptocurrencies by connecting their wallet or social media accounts. Utilizing the thirdweb SDK, it supports interaction with any EVM-compatible blockchain and supports ERC-721, ERC-1155, and ERC-20 token standards. The application is fully customizable and can be seamlessly integrated into any website.\n\nLive Demo\n\nDemo\n\nCheck out the live demo here: https://nft-minting-page.up.railway.app\n\nFeatures\n\nMint NFTs and Cryptocurrencies\nConnect wallet or social media accounts\nSupports ERC-721, ERC-1155, and ERC-20 token standards\nCustomizable upon deployment via environment variables\nPowered by thirdweb SDK\n\nInstallation\n\nLearn the installation of the template here.\n\nSupport\n\nIf you need help, please submit a ticket to our support site.\n\nContributing\n\nWe welcome contributions from the community! If you have any suggestions or improvements, please submit a pull request or open an issue.\n\nCommunity\n\nJoin the vibrant thirdweb community to stay updated and connect with fellow Web3 developers!\n\nDiscord: Engage in real-time discussions, get support, and share your projects.\nDailyDev Squad: Stay updated with the latest web3 development news and updates.\nReddit: Join our subreddit to participate in discussions, ask questions, and share insights.\n\nWe look forward to seeing you there!",
    name: "thirdweb: NFT Minting Page",
    category: "Starters",
    health: 64,
    code: "xyxkOh",
    languages: ["TypeScript", "CSS", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1d06c499-c3cc-4c99-926c-cee66c85f4ed",
    isApproved: false,
    activeProjects: 1,
    projects: 4,
    description: "Cost effective, self-hosted website analytics, based on Plausible",
    readme:
      "Vince Analytics Template\n\nThis template allows you to deploy Vince Analytics on Railway with minimal configuration.\n\nWhy is this cool?: Analytics services like Plausible require expensive to run dependencies like Clickhouse, which is overkill for most users. Vince Analytics is a lightweight alternative that runs on a single server, a Go binary that takes advantages of optimized storage technologies like roaring bitmaps.\n\nYou can save lots of money by using Vince Analytics instead of other analytics services if it's capable enough for your use case.\n\nDeployment Steps\n\nDeploy on Railway  \n   Click the button below to deploy:\n\nDeploy on Railway\n\nConfigure Environment Variables  \n   When deploying, set the following environment variables in the Railway dashboard, when prompted to during template deployment:\n\n   VINCE_ADMIN_NAME: The admin username for Vince Analytics.\n   VINCE_ADMIN_PASSWORD: The admin password for Vince Analytics, this is what you'll use to log in.\n\nAccess the Vince Analytics Dashboard  \n   Once the deployment is complete, a Railway managed domain with SSL and a subdomain will be generated to access Vince Analytics.\n\nLogin  \n   Use the credentials you configured in the environment variables to log in. You'll usually just be prompted for the password.\n\nYou'll then be able to add a domain for tracking, prompting you to add a tracking code to your website. Once a domain is added, you'll be able to view your data in the dashboard.\n\nVince Analytics Dashboard\n\nNotes\n\nRailway automatically manages container restarts and scaling.\nA volume is mounted to the container to persist data between server restarts.\nTo change your admin credentials, you'll need to update the environment variables in the Railway dashboard and redeploy.\n\nFor further information about Vince Analytics, visit the official website.\n",
    name: "Vince Analytics",
    category: "Analytics",
    health: 100,
    code: "j-tGRG",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d9278ebe-a428-4de9-b0ae-55d0d32f76a4",
    isApproved: false,
    activeProjects: 6,
    projects: 18,
    description: "Nextjs starter with Headless Wordpress ",
    readme:
      "Next.js Starter for WordPress Headless CMS\n\n&gt; Watch the Demo Video\n\nCleanShot 2025-01-07 at 23 18 41@2x\n\nThis is a starter template for building a Next.js application that fetches data from a WordPress site using the WordPress REST API. The template includes functions for fetching posts, categories, tags, authors, and featured media from a WordPress site and rendering them in a Next.js application.\n\nOverview\n\nWhat's included?\n\n‚úÖ Type-safe data layer with the WordPress RestAPI\n‚úÖ Granular access to revalidation and cache tags\n‚úÖ Setup for all basic WordPress options: Posts, Pages, Authors, Categories, Tags\n‚úÖ Easy integration with custom post types and ACF\n‚úÖ Dynamic routes for Posts and Pages\n‚úÖ Design system for layout and prose styling (craft-ds.com)\n‚úÖ Filter, Search, and Card components\n‚úÖ Dynamically rendered sitemap\n‚úÖ Dynamically generated metadata\n‚úÖ Dynamically generated OG/Twitter Cards for Posts and pages\n‚úÖ Responsive Nav and Footer components\n‚úÖ Site configuration file\n‚úÖ Menu configuration file\n‚úÖ Lite and dark mode support\n‚úÖ shadcn/ui components and theming\n‚úÖ Vercel analytics",
    name: "next-wp",
    category: "Blogs",
    health: 100,
    code: "QA-TYt",
    languages: ["TypeScript", "CSS", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "61571e20-995d-4204-b9b4-2522b4303eae",
    isApproved: false,
    activeProjects: 13,
    projects: 38,
    description: "A self-contained template for LiteLLM Proxy Server with  DB/Cache",
    readme:
      'LiteLLM Proxy Server Deployment Guide\n\nThis guide walks through deploying a LiteLLM Proxy Server instance with pre-configured setup for Postgres DB access, Redis cache, and UI panel access.\n\nConfiguration Management\n\nLiteLLM is designed to load configuration settings via config.yaml. Since Railway doesn\'t directly support file management while maintaining easy image deployment via the LiteLLM git repository, we\'ll use AWS S3 to host and manage the configuration file.\n\nFor complete configuration options, refer to the official LiteLLM documentation.\n\nSample Configuration File\n\nHere\'s a sample config.yaml that demonstrates configuring an OpenRouter model with Redis caching and Langfuse callbacks. This is what I personally used in my basic deployment:\n\nmodel_list:\n  model_name: gpt-4o-openrouter\n    litellm_params:\n      model: openrouter/openai/gpt-4o-2024-11-20\n      api_base: https://openrouter.ai/api/v1\n      api_key: your-openrouter-key\n      input_cost_per_token: 0.0000025\n      output_cost_per_token: 0.000010\n      rpm: 300\n\nlitellm_settings:\n  success_callback: "langfuse"]\n  cache: True\n  cache_params:\n    type: "redis"\n\nS3 Configuration Setup\n\nCreate S3 Bucket\n   Navigate to AWS S3 Console\n   Create new bucket with these settings:\n     Name: your-litellm-configs\n     Region: your-region\n     Object Ownership: ACLs disabled\n     Block Public Access: Enable all\n     Bucket Versioning: Enable\n     Default encryption: SSE-S3\n\nCreate IAM User and Policy\n   Go to AWS IAM Console\n   Create new user named litellm-config-user\n   Create this policy named litellm-config-access:\n     {\n         "Version": "2012-10-17",\n         "Statement": [\n             {\n                 "Effect": "Allow",\n                 "Action": [\n                     "s3:GetObject",\n                     "s3:ListBucket",\n                     "s3:PutObject"\n                 ],\n                 "Resource": [\n                     "arn:aws:s3:::your-litellm-configs",\n                     "arn:aws:s3:::your-litellm-configs/*"\n                 ]\n             }\n         ]\n     }\n   Attach policy to user\n   Create access keys for "Application running outside AWS"\n   Save both the Access Key ID and Secret Access Key\n\nUpload Configuration\n   Create your config.yaml file locally\n   Upload to your S3 bucket\n\nRailway Environment Setup\n\nConfigure these environment variables in your Railway project:\n\nLITELLM_CONFIG_BUCKET_NAME=your-litellm-configs\nLITELLM_CONFIG_BUCKET_OBJECT_KEY=config.yaml\nAWS_ACCESS_KEY_ID=your_access_key_id\nAWS_SECRET_ACCESS_KEY=your_secret_access_key\nAWS_REGION_NAME=your_region\n\nFor additional configuration options and advanced settings, please refer to the [LiteLLM Proxy documentation.',
    name: "LiteLLM Proxy Server",
    category: "AI/ML",
    health: 92,
    code: "Lm9gxI",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d9db62de-47f3-4f2b-b1a6-8cec4c0504db",
    isApproved: false,
    activeProjects: 2,
    projects: 5,
    description: "Temporal with S3 archive.",
    readme:
      "Integrate Temporal with S3 for seamless workflow execution and durable archiving. This setup ensures reliable storage of workflow history, enabling scalability, fault tolerance, and efficient data retrieval for long-running processes in distributed systems.",
    name: "Temporal with S3 Archive",
    category: "Other",
    health: 100,
    code: "aWCIba",
    languages: ["TypeScript", "JavaScript", "Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "115161a3-c4d9-4d67-8d28-1cd7840b0c5a",
    isApproved: false,
    activeProjects: 41,
    projects: 51,
    description: "Spark Stack is an tool for building web apps with prompts.",
    readme:
      "Spark Stack\n\nSpark Stack is an tool for building web applications through an AI-powered chat interface. Create quick MVPs and prototypes using natural language prompts. [Blog Post]\n\nFeatures\n\nü§ñ AI-powered code generation\n‚ö°Ô∏è Real-time development environment\nüé® Multiple arbitrary starter templates (see /images)\nüë• Team collaboration and management\nüìù Git version control\nüîÑ Live preview\nüß† Chain-of-Thought reasoning for complex asks\nüîå Support for OpenAI and Anthropic models\nüì± Multi-page app generation\nüì∏ Sketch and screenshot uploads\nüöÄ Deployment to GitHub (+ Netlify, Vercel, etc)\nüåô Dark mode support\nüîó Share chats and projects publicly",
    name: "spark-stack-template",
    category: "AI/ML",
    health: 100,
    code: "61t3xx",
    languages: ["JavaScript", "Python", "CSS", "Dockerfile", "Mako"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "72c39ac9-9891-44b2-b489-ce1bd8f0ed91",
    isApproved: false,
    activeProjects: 2,
    projects: 8,
    description: "Openblocks + PocketBase; Build internal apps easily ",
    readme:
      "What is PocketBlocks?\nOpenblocks + PocketBase = PocketBlocks.\n\nPocketBlocks is a integration between Openblocks and PocketBase.\n\nTraditionally, building an internal app requires complex frontend and backend interactions with hundreds and thousands lines of code, not to mention work on packaging, integration and deployment. PocketBlocks significantly reduces the work you need to do to build an app.\n\nIn PocketBlocks, all you need to do is drag and drop pre-built or self-customized components onto the What-You-See-Is-What-You-Get (WYSIWYG) canvas, PocketBlocks helps you build an app quickly and focus on business logic.\n\nWhy choose PocketBlocks?\nOpen source: Makes your ideas more feasible.\nHigh scalability: Allows to execute JavaScript almost anywhere you would like to customize your business processes and UI components.\nClean design: Follows the principles of Ant Design and supports display on screens of different sizes. We have a number of UI components, based on which you can freely build dashboard, admin panel, and content management system (CMS).\n",
    name: "PocketBlocks",
    category: "Automation",
    health: null,
    code: "nL4dT5",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c3e76483-7023-460a-b3d2-2779ac3b0fe6",
    isApproved: false,
    activeProjects: 1,
    projects: 4,
    description: "automatically analyze and tag your documents from paperless-ngx",
    readme:
      "Paperless-AI\n\nAn automated document analyzer for Paperless-ngx using OpenAI API, Ollama, and all OpenAI API-compatible services to analyze and tag your documents automatically.\n\nKey Features\n\nAutomated Document Management\nAutomatic Scanning: Detects and processes new documents within Paperless-ngx.  \nAI-Powered Analysis: Uses OpenAI API and Ollama (Mistral, Llama, Phi 3, Gemma 2) for accurate document insights.  \nMetadata Assignment: Automatically assigns titles, tags, and correspondent details.\n\nAdvanced Customization Options\nPredefined Processing Rules: Specify documents to process based on tags. üÜï  \nSelective Tag Assignment: Use selected tags for processing, bypassing prompts. üÜï  \nCustom Tagging: Add specific tags to AI-processed documents for easy identification. üÜï  \n\nManual Mode  \nAI-Assisted Analysis: Manually analyze documents using AI through the /manual endpoint. üÜï  \n\nInteractive Chat Functionality  \nDocument Querying: Ask questions about documents and get AI-generated answers. üÜï  \n\nIntuitive Web Interface  \nStreamlined Setup: Configure easily at the /setup endpoint.  \nDashboard Overview: Monitor and manage document processing with a clean dashboard.\n\nReliability and Security\nError Handling: Automatic restarts and health monitoring for stability.  \nHealth Checks: Ensures system integrity and raises alerts for issues.  \nDocker Integration: Full support for Docker, including health checks and persistent storage.\n\nNew Feature: Chrome Extension  \nWork directly from Paperless-ngx with the Document Chat feature!  \nDownload the Chrome Extension here.\n\nSimplify your document workflows with Paperless-AI!",
    name: "paperless-AI",
    category: "Other",
    health: 100,
    code: "4gBjPt",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b7d2bc02-8710-4f8c-b7de-2dc8a3865a49",
    isApproved: false,
    activeProjects: 5,
    projects: 8,
    description: "bookmark manaer -- save, organize, and search saved contents easily",
    readme:
      "Project Overview:\nHoarder is an open-source, self-hosted app designed to help users manage and organize their saved web content effectively. It prioritizes privacy and user control while leveraging AI for smarter content organization. Key functionalities include:\n\t‚Ä¢\tContent Saving: Easily save articles, links, and files for future reference.\n\t‚Ä¢\tAI-Powered Tagging: Automatically tag and categorize content using AI for better organization.\n\t‚Ä¢\tCustom Tagging and Categorization: Manually organize content with custom tags and categories for more control.\n\t‚Ä¢\tFull-Text Search: Find content quickly using powerful search capabilities.\n\t‚Ä¢\tCustomizable Organization: Structure your library to suit your unique needs and workflow.\n\t‚Ä¢\tUser-Friendly Interface: Navigate and manage your content with ease through an intuitive design.\n\nHoarder combines AI-driven functionality with privacy-focused self-hosting, making it ideal for users who want an intelligent yet secure solution for managing saved web content.",
    name: "hoader",
    category: "Other",
    health: null,
    code: "6cPpay",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "eed58baa-d498-4d80-a3f6-02296a3f584c",
    isApproved: false,
    activeProjects: 9,
    projects: 23,
    description: "Extensible voice assistant template built with the Realtime API and FastAPI",
    readme:
      "A template for building real-time voice assistants using OpenAI's realtime API. This project provides a foundation for creating web-based voice interfaces that can process speech in real-time and respond with both voice and text.\n\nIt uses the new WebRTC API from OpenAI and a FastAPI server to authenticate the client and handle tool calls. An example tool call to retrieve the current weather is included.\n\nIt uses a JavaScript helper library that simplifies the usage in the frontend and pulls tool signatures directly from the OpenAPI definition.\n\nWorks best in Chrome, Edge and Safari. Firefox WebRTC performance is not great at the moment.",
    name: "OpenAI Voice Assistant",
    category: "AI/ML",
    health: 75,
    code: "pCNq15",
    languages: ["JavaScript", "Python", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "79c33ce8-d1e5-4c42-837e-304b0db05b92",
    isApproved: false,
    activeProjects: 118,
    projects: 179,
    description: "n8n with postgres database",
    readme:
      "n8n is a workflow automation platform that gives technical teams the flexibility of code with the speed of no-code. With 400+ integrations, native AI capabilities, and a fair-code license, n8n lets you build powerful automations while maintaining full control over your data and deployments.\n\nNOTE: This is the official image + some community nodes!",
    name: "n8n",
    category: "Automation",
    health: 96,
    code: "nIAh-Q",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "df012c67-493e-4b21-adb6-de765926b846",
    isApproved: false,
    activeProjects: 1,
    projects: 3,
    description: "A lightweight, self-hosted, markdown-based note-taking web app.",
    readme:
      "Overview:\nFlatnotes is a minimalist, self-hosted note-taking application that emphasizes simplicity and efficiency. Designed to work with markdown-based notes, it provides an intuitive and user-friendly interface for creating, editing, and organizing your notes.\n\nKey features include:\n\t‚Ä¢\tSearch functionality to quickly locate specific notes.\n\t‚Ä¢\tTagging support for effective organization.\n\t‚Ä¢\tA clean web interface that is easy to navigate.\n\nThis lightweight solution is ideal for individuals or teams who value privacy and prefer to host their own data. By avoiding unnecessary complexity, Flatnotes offers a practical alternative to more cumbersome note-taking apps.",
    name: "Flatnotes",
    category: "Other",
    health: 0,
    code: "Hl9gkz",
    languages: ["Vue", "Python", "JavaScript", "SCSS", "Dockerfile", "Shell", "HTML", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1ec36627-3bec-445d-a41a-271095c0a7c5",
    isApproved: false,
    activeProjects: 4,
    projects: 20,
    description: "Vikunja is an open source, self-hosted, task management application.",
    readme:
      "Vikunja\n\nVikunja is an open source, self-hosted task management application. This template helps you deploy your own instance on Railway with a MySQL database.\n\nEverything is ready to go!\n\nFeatures\nTask and project management\nTeam collaboration\nCalendar view\nKanban boards\nAGPLv3",
    name: "Vikunja",
    category: "Other",
    health: 100,
    code: "1V8xnQ",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3839e05c-d6c4-45a8-b789-057e2532675d",
    isApproved: false,
    activeProjects: 2,
    projects: 5,
    description: "A self-hosted visual website builder and CMS.",
    readme:
      "Nitropage is an entirely free and open source, extensible visual website builder based on SolidStart, offering a growing library of versatile building blocks.\n\nFeatures:\n\nPage revisions\nElement presets\nReusable layouts\nFocal point image cropping\nSelf and CDN hosted fonts\nAtom (RSS) feeds\nSupport for multiple projects\n\nLearn more at:\nhttps://nitropage.org",
    name: "Nitropage with Postgres",
    category: "CMS",
    health: null,
    code: "gWj8Bm",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3f92655e-46df-406f-b55e-342c5eb5fbb8",
    isApproved: false,
    activeProjects: 12,
    projects: 13,
    description: "PostgreSQL database service",
    readme:
      "SSL-enabled Postgres DB image with DuckDB support\n\nThis repository contains the logic to build SSL-enabled Postgres images with DuckDB support.\n\nBy default, when you deploy the pgduckdb template on Railway, the image that is used is built from this repository!\n\nDeploy on Railway\n\nWhy though?\n\nThe official pgduckdb image in Docker hub does not come with SSL baked in.\n\nSince this could pose a problem for applications or services attempting to connect to Postgres services, we decided to roll our own pgduckdb image with SSL enabled right out of the box.\n\nHow does it work?\n\nThe Dockerfiles contained in this repository start with the official pgduckdb image as base. Then the init-ssl.sh script is copied into the docker-entrypoint-initdb.d/ directory to be executed upon initialization.\n\nCertificate expiry\n\nBy default, the cert expiry is set to 820 days. You can control this by configuring the SSL_CERT_DAYS environment variable as needed.\n\nCertificate renewal\n\nWhen a redeploy or restart is done the certificates expiry is checked, if it has expired or will expire in 30 days a new certificate is automatically generated.\n\nA note about ports\n\nBy default, this image is hardcoded to listen on port 5432 regardless of what is set in the PGPORT environment variable. We did this to allow connections to the postgres service over the RAILWAY_TCP_PROXY_PORT.  If you need to change this behavior, feel free to build your own image without passing the --port parameter to the CMD command in the Dockerfile.\n\nMoving from timescaledb to duckdb\n\nIf you are moving from timescaledb to duckdb, you will need update the source image of your service and then run the following SQL commands to enable duckdb:\n\nDROP EXTENSION IF EXISTS timescaledb CASCADE;\n\nALTER SYSTEM SET shared_preload_libraries = 'pg_duckdb';\n\nCREATE EXTENSION IF NOT EXISTS pg_duckdb;",
    name: "PostgreSQL DuckDB",
    category: "Storage",
    health: 75,
    code: "7MJ9UM",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "bea0055c-3dbc-4cb6-ae94-6e9c6765d917",
    isApproved: false,
    activeProjects: 7,
    projects: 11,
    description: "Kutt is a modern URL shortener with support for custom domains",
    readme:
      "Kutt\n\nKutt is a modern URL shortener with support for custom domains. Create and edit links, view statistics, manage users, and more.\n\nKey features\n\nCreated with self-host in mind:\n  Zero configuration needed\n  Easy setup with no build step\n  Supporting various databases (SQLite, Postgres, MySQL)\n  Ability to disable registration and anonymous links\nCustom domain support\nSet custom URLs, password, description, and expiration time for links\nView, edit, delete and manage your links\nPrivate statistics for shortened URLs\nAdmin page to manage users and links\nRESTful API\n\nAPI\n\nView API documentation ‚Üí\n\nConfiguration\n\nThe app is configured via environment variables. You can pass environment variables directly or create a .env file. View .example.env file for the list of configurations.\n\nAll variables are optional except JWT_SECRET which is required on production.\n\n| Variable | Description | Default | Example |\n| -------- | ----------- | ------- | ------- |\n| JWT_SECRET | This is used to sign authentication tokens. Use a long random string. | - | - |\n| PORT |  The port to start the app on | 3000 | 8888 |\n| SITE_NAME |  Name of the website | Kutt | Your Site |\n| DEFAULT_DOMAIN |  The domain address that this app runs on | localhost:3000 | yoursite.com |\n| LINK_LENGTH | The length of of shortened address | 6 | 5 |\n| DISALLOW_REGISTRATION | Disable registration. Note that if MAIL_ENABLED is set to false, then the registration would still be disabled since it relies on emails to sign up users. | true | false |\n| DISALLOW_ANONYMOUS_LINKS | Disable anonymous link creation | true | false |\n| DB_CLIENT |  Which database client to use. Supported clients: pg or pg-native for Postgres, mysql2 for MySQL or MariaDB, sqlite3 and better-sqlite3 for SQLite. NOTE: pg-native and better-sqlite3 are not installed by default, use npm to install them before use. | sqlite3 | pg |\n| DB_HOST | Database connection host. Only if you use Postgres or MySQL. | localhost | your-db-host.com |\n| DB_PORT | Database port. Only if you use Postgres or MySQL. | 5432 (Postgres) | 3306 (MySQL) |\n| DB_NAME | Database name. Only if you use Postgres or MySQL. | kutt | mydb |\n| DB_USER | Database user. Only if you use Postgres or MySQL. | postgres | myuser |\n| DB_PASSWORD | Database password. Only if you use Postgres or MySQL. | - | mypassword |\n| DB_SSL | Whether use SSL for the database connection. Only if you use Postgres or MySQL. | false | true |\n| DB_POOL_MIN | Minimum number of database connection pools. Only if you use Postgres or MySQL. | 0 | 2 |\n| DB_POOL_MAX | Maximum number of database connection pools. Only if you use Postgres or MySQL. | 10 | 5 |\n| REDIS_ENABLED | Whether to use Redis for cache | false | true |\n| REDIS_HOST | Redis connection host | 127.0.0.1 | your-redis-host.com |\n| REDIS_PORT | Redis port | 6379 | 6379 |\n| REDIS_PASSWORD | Redis passowrd | - | mypassword |\n| REDIS_DB | Redis database number, between 0 and 15. | 0 | 1 |\n| SERVER_IP_ADDRESS | The IP address shown to the user on the setting's page. It's only for display purposes and has no other use. | - | 1.2.3.4 |\n| SERVER_CNAME_ADDRESS | The subdomain shown to the user on the setting's page. It's only for display purposes and has no other use. | - | custom.yoursite.com |\n| CUSTOM_DOMAIN_USE_HTTPS | Use https for links with custom domain. It's on you to generate SSL certificates for those domains manually‚Äîat least on this version for now. | false | true |\n| ENABLE_RATE_LIMIT | Enable rate limitting for some API routes. If Redis is enabled uses Redis, otherwise, uses memory. | false | true |\n| MAIL_ENABLED | Enable emails, which are used for signup, verifying or changing email address, resetting password, and sending reports. If is disabled, all these functionalities will be disabled too. | false | true | \n| MAIL_HOST | Email server host | - | your-mail-server.com |\n| MAIL_PORT | Email server port | 587 | 465 (SSL) | \n| MAIL_USER | Email server user | - | myuser | \n| MAIL_PASSWORD | Email server password for the user | - | mypassword | \n| MAIL_FROM | Email address to send the user from | - | some.address@yoursite.com | \n| MAIL_SECURE | Whether use SSL for the email server connection | false | true | \n| REPORT_EMAIL | The email address that will receive submitted reports | - | some.address@yoursite.com | \n| CONTACT_EMAIL | The support email address to show on the app | - | some.address@yoursite.com | \n\nBrowser extensions\n\nDownload Kutt's extension for web browsers via below links.\n\nChrome\nFirefox\n\nVideos\n\nOfficial videos\n\nNext.js to htmx ‚Äì A Real World Example\n\nIntegrations\n\nThird-party packages\n\n\n| Language   | Link                                                                              | Description                                        |\n| ---------- | --------------------------------------------------------------------------------- | -------------------------------------------------- |\n| C# (.NET)  | KuttSharp                                 | .NET package for Kutt.it url shortener             |\n| C# (.NET)  | Kutt.NET                               | C# API Wrapper for Kutt\n| Python     | kutt-cli                               | Command-line client for Kutt written in Python     |\n| Ruby       | kutt.rb                                 | Kutt library written in Ruby                       |\n| Rust       | urlshortener                        | URL shortener library written in Rust              |\n| Rust       | kutt-rs                                  | Command line tool written in Rust                  |\n| Node.js    | node-kutt                            | Node.js client for Kutt.it url shortener           |\n| JavaScript | kutt-vscode                            | Visual Studio Code extension for Kutt              |\n| Java       | kutt-desktop                         | A Cross platform Java desktop application for Kutt |\n| Go         | kutt-go                                      | Go client for Kutt.it url shortener                |\n| BASH       | GitHub Gist | Simple BASH function to access the API             |\n| BASH       | url-shortener                     | Simple BASH script with GUI                        |\n\n",
    name: "Kutt",
    category: "Other",
    health: 100,
    code: "kFCDQY",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "388e4bda-0e95-45cf-8937-4c1ba7d524fb",
    isApproved: false,
    activeProjects: 1,
    projects: 3,
    description: "The checker service to ping external service.",
    readme:
      "The OpenStatus Checker is a lightweight service designed to monitor the availability of external services by regularly pinging them. It captures response data and seamlessly integrates with Tinybird for real-time data processing and analytics. This ensures that users can track the status of their services efficiently, gaining valuable insights into performance and uptime. With easy deployment options, including Docker and Render, the OpenStatus Checker is versatile and suitable for both small-scale monitoring and large, distributed infrastructures.",
    name: "openstatus-checker",
    category: "Analytics",
    health: 100,
    code: "6lMioC",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ac5d4ce8-e68c-460b-bb17-8b36da229cd4",
    isApproved: true,
    activeProjects: 132,
    projects: 223,
    description: "An open-source, self-hosted personal AI note tool prioritizing privacy",
    readme:
      "\nBlinko - Open Source, Self-hosted\n\n\nLive Demo ‚Ä¢\nDocs ‚Ä¢\nTelegram Chinese ‚Ä¢\nTelegram English\n\n&gt; username:blinko\n&gt; password:blinko\n\nBlinko is an innovative open-source project designed for individuals who want to quickly capture and organize their fleeting thoughts. Blinko allows users to seamlessly jot down ideas the moment they strike, ensuring that no spark of creativity is lost.\n\nüöÄMain Features\nü§ñAI-Enhanced Note Retrieval ÔºöWith Blinko's advanced AI-powered RAG (Retrieval-Augmented Generation), you can quickly search and access your notes using natural language queries, making it effortless to find exactly what you need.\n\nüîíData Ownership :Your privacy matters. All your notes and data are stored securely in your self-hosted environment, ensuring complete control over your information.\n\nüöÄEfficient and Fast :Capture ideas instantly and store them as plain text for easy access, with full Markdown support for quick formatting and seamless sharing.\n\nüí°Lightweight Architecture with Heavy Lifting :Built on Next.js, Blinko offers a sleek, lightweight architecture that delivers robust performance without sacrificing speed or efficiency.\n\nüîìOpen for Collaboration :As an open-source project, Blinko invites contributions from the community. All code is transparent and available on GitHub, fostering a spirit of collaboration and constant improvement.\n\nüì¶Start with Docker Compose in seconds\n\nüë®üèº‚ÄçüíªContribution\nContributions are the heart of what makes the open-source community so dynamic, creative, and full of learning opportunities. Your involvement helps drive innovation and growth. We deeply value any contribution you make, and we're excited to have you as part of our community. Thank you for your support! üôå\n\nSponsorship\nIf you find Blinko valuable, consider supporting us! Your contribution will enable us to continue enhancing and maintaining the project for everyone. Thank you for helping us grow!\n\nhttps://ko-fi.com/blinkospace\n\nhttps://afdian.com/a/blinkospace/plan\n\nStar History\n\nStar History Chart\n\n\n",
    name: "Blinko Official ",
    category: "AI/ML",
    health: 88,
    code: "InjVjN",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8c5abd81-ff0d-4702-b85b-3f0e7461ee30",
    isApproved: false,
    activeProjects: 1,
    projects: 4,
    description: "ephemeral, zero-knowledge, end-to-end encrypted sensitive data sharing",
    readme:
      "crypt.fyi - A zero-knowledge, end-to-end encrypted secret sharing platform that enables secure transmission of sensitive information.\n\nFeatures\n\nüîê End-to-end encryption using AES-256-GCM\nüõ°Ô∏è Strict Content Security Policy (CSP) to prevent XSS attacks and unauthorized resource loading\nüõ°Ô∏è Strict rate limits to mitigate brute-force attacks\nü§´ Zero-knowledge architecture - server never sees unencrypted data or decryption keys\nüî• Burn after reading w/ provisions to prevent erroneous burns from bots or url introspection\n‚è∞ Automatic expiration (Time-To-Live)\nüóùÔ∏è Password protection\nüìÅ File sharing support w/ drag and drop\nü™ù Webhook notifications for read success, read failure, and burn events\nüåê IP/CIDR allow-listing\nüî¢ Read count limits\nüì± QR code generation\n‚å®Ô∏è CLI for interacting with the API\nüß© Chrome Extension\nüê≥ Docker images for the api server and web client\nüåê Localization with a handful of supported languages (more to come - help wanted!)\n\nCI\nSecurity Headers\nMozilla HTTP Observatory Grade\nCII Best Practices\ni18n ‚úì",
    name: "crypt.fyi",
    category: "Other",
    health: null,
    code: "Pmkrsc",
    languages: ["TypeScript", "JavaScript", "HTML", "CSS", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7802e237-1a75-4e69-85b5-64ce7f5a188f",
    isApproved: false,
    activeProjects: 1,
    projects: 2,
    description: "balance-management to balance your incomes, expenses and budget",
    readme:
      "It's a project to control a companies' incomes, expenses and budget. You can create a plan for a certain period. And then you can see the analytics for plan. Also you will be informed through an email. It has easy template, it is user helper platform.",
    name: "ideal-vision",
    category: "Other",
    health: null,
    code: "NEJ3se",
    languages: ["Java", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d2e0c191-3241-4dea-aaa6-4a7a97c24dfc",
    isApproved: false,
    activeProjects: 1,
    projects: 3,
    description: "A bolt template made by Faisal for UndetectableAI",
    readme:
      "Just a template I made for undetectableAI team to try this coder, the cloud version is bolt.new.\n\nTo learn more about what UndetectableAI does, please visit this link. \n\n¬©2024 Undetectable Inc.. All Rights Reserved.\n\n1309 Coffeen Avenue, Sheridan, WY, US, 82801",
    name: "UndetectableAI-Coder",
    category: "AI/ML",
    health: null,
    code: "Akvll8",
    languages: ["TypeScript", "SCSS", "JavaScript", "Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "34d97699-acdc-47cd-b3e3-cc401086e9a1",
    isApproved: false,
    activeProjects: 15,
    projects: 22,
    description: "FlowiseAI + MySQL Database",
    readme:
      "This template integrates FlowiseAI with a MySQL database.\n\nAll necessary variables are already pre-filled to help you get started instantly.\n\nSteps to get started:\n\nFill in values for these two variables for FlowiseAI:\n  FLOWISE_USERNAME\n  FLOWISE_PASSWORD\nDeploy\n\nVideo guide: https://youtu.be/AXp4cI8Umm4",
    name: "FlowiseAI + MySQL",
    category: "AI/ML",
    health: 100,
    code: "XcRehu",
    languages: [
      "TypeScript",
      "JavaScript",
      "CSS",
      "SCSS",
      "HTML",
      "Dockerfile",
      "Shell",
      "Batchfile",
    ],
    tags: null,
  },
  {
    __typename: "Template",
    id: "bfa5d3a4-8556-42d4-adad-c4c349ec1de2",
    isApproved: false,
    activeProjects: 2,
    projects: 7,
    description: "Classic theme in TypeScript",
    readme:
      "Docusaurus v3 - Classic (TypeScript)\n\nDocusaurus is an open-source tool for building, deploying, and maintaining documentation websites. It was developed by Facebook and is designed to facilitate the creation of documentation websites for software projects in a way that is simple and scalable.\n\nFeatures and Benefits\n\nStatic Page Generation\n   Docusaurus creates websites using static page generation, meaning that the pages are generated at the build time rather than at the request time. This has benefits for performance and security.\n   \nMarkdown\n   It allows writing documentation using Markdown, a lightweight markup language that is easy to write and read.\n\nInternationalization (i18n)\n   Docusaurus has built-in support for internationalization, facilitating the translation of your documentation into various languages.\n\nVersioning\n   Docusaurus facilitates the versioning of your documentation, allowing different versions of your documentation to be available and easily accessible.\n\nIntegration with React\n   Docusaurus is built on React, a popular JavaScript library for building user interfaces. This allows great flexibility and power when customizing and extending your website.\n\nSearch\n   Docusaurus integrates a search function (often using Algolia DocSearch) to help users find the information they are looking for more quickly.\n\nStyles and Themes\n   Docusaurus allows you to customize the style and appearance of your documentation website with themes and style sheets.\n\nDocusaurus is widely used in the software development world and is an excellent choice for projects that need a simple and effective way to create and maintain documentation.\n",
    name: "Docusaurus v3",
    category: "Starters",
    health: 100,
    code: "0jPRDd",
    languages: ["TypeScript", "CSS", "Dockerfile", "MDX"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "14a3411e-b95c-43df-ae7b-a4405199760e",
    isApproved: false,
    activeProjects: 7,
    projects: 12,
    description: "A Hugging Face Transformer Railway Template",
    readme:
      "Hugging Face Transformer Example\n\nThis example starts up a FastAPI server which runs the Hugging Face Transformers.\n\nThis example runs an embedding model on the CPU which works great with railway as resources can scale per requests.\n\nNote: This won't work for GPU work flows and will crash.\n\n‚¨ÜÔ∏è Deploy\n\nDeploy on Railway\n\nor\n\nInstall the Railway CLI, then run railway up\n\n‚ú® Features\n\nTransformers\nFastAPI\nHypercorn\nPython 3.11\n\nUses Nixpacks to deploy on railway which runs Python 3.11 by default.\n\nüíÅ‚Äç‚ôÄÔ∏è How to use locally\n\nClone locally and install packages with pip using pip install -r requirements.txt\nRun locally using hypercorn main:app --reload\n\nüß© Background\n\nThe team at JigsawStack is launching an embedding model and we're experimenting with different infrastructure for scalable and affordable CPU usage. Check out the embedding model here\n\nCommon issues\n\nWhen deployed on Railway, your instance region might be deployed to a metal region which is currently in BETA and seem to be a lot slower than non-beta regions. Switch to US West (Oregon, USA) for the best performance on testing. Metal regions don't have volume attachments which could be the issue for caching data.\nYou can attach a volume if you switching models in a single instance, this would allow for better caching and faster switches\nIf you need a specific python version, you can set NIXPACKS_PYTHON_VERSION in the variables tab to the desired version",
    name: "hugging-face-transformer",
    category: "AI/ML",
    health: 33,
    code: "z52Exi",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f3bc9da7-00c6-4e83-acc8-7b7acd4c4801",
    isApproved: false,
    activeProjects: 9,
    projects: 31,
    description: "Template ajustado de bugs",
    readme:
      'Template ajustado de bugs.\n\nCaso ocorrer o erro ao conectar com API externas (Google, Webhook, etc), voc√™ deve adicionar o "https://" nas vari√°veis de ambiente do Railway.\n\nAs 2 que precisam ser modificadas s√£o as seguintes:\n\nN8N_EDITOR_BASE_URL \nWEBHOOK_URL\n\nDepois de fazer esse ajuste, s√≥ executar o deploy novamente.',
    name: "N8n - Comunidade Vision√°rios",
    category: "Automation",
    health: 50,
    code: "b_LXy3",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "cf602264-41bc-4975-8898-50a1f238b280",
    isApproved: false,
    activeProjects: 5,
    projects: 16,
    description: "Free Self-Hosted Zendesk & Help Scout Alternative",
    readme:
      "FreeScout is the super lightweight and powerful free open source help desk and shared inbox built with PHP (Laravel framework). Now you can enjoy free Zendesk & Help Scout without giving up privacy or locking yourself into a service you don't control. FreeScout has been developed from scratch and is not using any copyrighted Help Scout or Zendesk materials.\n\nRailway Instructions\n\nIf you are using a custom domain, update the SITE_URL to your custom domain's URL.\n\nFeatures\n\n  No limitations on the number of users, tickets, mailboxes, etc.\n  100% Mobile-friendly.\n  Multilingual: English, Chinese, Croatian, Czech, Danish, Dutch, Finnish, French, German, Italian, Japanese, Kazakh, Korean, Norwegian, Persian, Polish, Portuguese, Russian, Spanish, Slovak, Swedish, Turkish.\n  Seamless email integration.\n  Supports modern Microsoft Exchange authentication.\n  Fully supports screen readers (for visually impaired).\n  Built with strong focus on security.\n  Web installer & updater.\n  Starred conversations.\n  Forwarding conversations.\n  Merging conversations.\n  Moving conversations between mailboxes.\n  Phone conversations.\n  Sending new conversations to multiple recipients at once.\n  Collision detection ‚Äì notice is shown when two agents open the same conversation.\n  Push notifications.\n  Following a conversation.\n  Auto reply.\n  Internal notes.\n  Automatic refreshing of the conversations list without the need to reload the page.\n  Pasting screenshots from the clipboard into the reply area.\n  Configuring notifications on a per user basis.\n  Open tracking.\n  Editing threads.\n  Search.\n  And more‚Ä¶\n\nNeed anything else? Suggest features here.",
    name: "FreeScout",
    category: "Other",
    health: 100,
    code: "cgZiHc",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "690a645a-607f-47d3-a48d-0cc6a372980b",
    isApproved: false,
    activeProjects: 2,
    projects: 4,
    description: "Tag-based time tracking tool",
    readme:
      "Traggo is a tag-based time tracking tool. In Traggo there are no tasks, only tagged time spans.\n\nWith tags, Traggo tries to be as customizable as possible, f.ex. if you work on different projects you could add a project-tag.\nIf you like to see statistics from the different things you do, you could add a type-tag with values like email, programming, meeting. \nYou can do it just as you like.\n\nFeatures\n\neasy to setup\ntime tracking (obviously)\ncustomizable dashboards with diagrams\na list and calendar view of the tracked time\nsleek web ui with multiple themes\nsimple user management",
    name: "Traggo",
    category: "Other",
    health: 100,
    code: "e88vkn",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ef4ef889-012e-4e38-bf01-c0ac64dfddc0",
    isApproved: false,
    activeProjects: 10,
    projects: 28,
    description: "Strapi v5 + AWS S3 Starter Template",
    readme:
      "Strapi v5 + AWS S3 Starter Template\n\nNotes\n\nWhen this template is running on Railway, Strapi will connect to the Postgres Database through the private network, saving you on database egress fees.\n\nDeveloping Locally\n\nWhen developing locally, this Strapi template will connect to the Postgres server from its public TCP Proxy.\nEnable the feature flag Template Service Eject in the Feature Flags menu.\nWithin the service settings of the Strapi service, click the Eject button on the upstream repository.\nClone the newly created repository locally.\nInstall Strapi's dependencies with yarn install or npm install.\nInstall the Railway CLI (Instructions).\nIf this is your first time using the CLI, make sure to log in with railway login.\nWithin the local repository, run railway link to link the local repository to the Strapi service on Railway.\nStart Strapi for development with railway run yarn run develop or railway run npm run develop.\nThis command will run Strapi in development mode with the service variables available locally.\n\nOpen your browser to http://127.0.0.1:1337/admin\n\nAcknowledgments\n\nThis project was inspired by Szilard Koppel's project. A big thank you to Szilard for his amazing work!\n\nSzilard Koppel's GitHub repository: https://github.com/szilardkoppel/railway.app-strapi\nRailway template: https://railway.com/template/e10OW1\n\nPurpose\n\nThis project is a Strapi v5 + AWS S3 Starter Template. It is designed to work with just four parameters:\n\nAWS_ACCESS_KEY_ID\nAWS_ACCESS_SECRET\nAWS_BUCKET_NAME\nAWS_REGION\n\nThese parameters can also be provided as null. The project will still deploy, but media uploads (e.g., JPG, PNG) will not be functional without valid values.\n",
    name: "Strapi v5 + AWS S3 | Starter Template ",
    category: "Starters",
    health: 0,
    code: "5P18on",
    languages: ["TypeScript", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d376d5f1-a296-4bea-9e34-3b34e1f7e719",
    isApproved: false,
    activeProjects: 7,
    projects: 11,
    description: "ChromaDB from official docker",
    readme:
      'Directly from the official docker image: https://hub.docker.com/r/chromadb/chroma\n\nI just went to google, searched for "chroma docker image", saw the image, copied its name, asked perplexity how to create a template, copied some env variables from existing templates.\n\nHere I was asked to write 250 characters or more. In case you\'re wondering what you have just read :)',
    name: "ChromaDB 0.4.15",
    category: "Storage",
    health: 100,
    code: "w0D0Ei",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "bbac5c0a-c525-4847-9edd-305c0fe66c28",
    isApproved: false,
    activeProjects: 1,
    projects: 2,
    description: "A modern, open-source personal flight tracking system",
    readme:
      "AirTrail: Your Personal Flight Tracker\n\npreview\n\nAirTrail is a self-hosted, open-source platform designed to help you track and analyze your flight history. This modern application provides a user-friendly interface to log your journeys, visualize them on a world map, and gain insights into your travel patterns.\n\nWhy Use AirTrail?\n\nKeep a comprehensive record of your flights:  Never lose track of your travel experiences. \nVisualize your journeys: See your flights plotted on an interactive world map.\nGain insights from your travel data:  Uncover travel trends and statistics with built-in analytics.\nTake control of your data: Self-host AirTrail for maximum privacy and security.\nEnjoy a modern and customizable experience:  Benefit from a responsive design, dark mode, and multiple user support.\n\nKey Features\n\nInteractive World Map:  Plot your flights on a world map to visualize your travel history.\nDetailed Flight History:  Maintain a detailed log of all your flights, including dates, routes, and airlines.\nComprehensive Statistics:  Gain insights into your travel patterns with various statistics.\nMulti-User Support: Share AirTrail with others and manage flights across multiple users. Secure your data with user authentication and OAuth integration.\nResponsive Design: Access and use AirTrail seamlessly across various devices (desktops, tablets, and phones).\nDark Mode: Choose between light and dark themes for a personalized viewing experience.\nFlight Import: Easily import flight data from popular platforms like MyFlightRadar24, App in the Air, and JetLog.\n\nGetting Started\n\nAirTrail is designed to be easy to install and use, especially for those familiar with Docker.  \n\nAutomated Installation (Linux): A convenient installation script streamlines the setup process on Linux systems with Docker.\nDocker Compose:  Alternatively, use Docker Compose for manual installation on any platform that supports Docker.\n\nFor detailed installation instructions and further information, refer to the official AirTrail documentation and GitHub repository:\n\nWebsite: https://airtrail.johan.ohly.dk/\nGitHub: https://github.com/johanohly/AirTrail",
    name: "AirTrail",
    category: "Other",
    health: null,
    code: "d9pr8z",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b3d0e03f-4786-4926-ad54-5f87d76677e9",
    isApproved: false,
    activeProjects: 2,
    projects: 16,
    description: "Trello alternative. Kanban-style project maangement",
    readme:
      "Create projects, boards, lists, cards, labels and tasks\nAdd card members, track time, set due dates, add attachments, write comments\nMarkdown support in card description and comments\nFilter by members and labels\nCustomize project backgrounds\nReal-time updates\nInternal notifications\nMultiple interface languages\nSingle sign-on via OpenID Connect\n",
    name: "Planka + S3",
    category: "Other",
    health: 0,
    code: "8ttegs",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f7ca6741-35cf-495c-81c1-ed5a03005ae9",
    isApproved: false,
    activeProjects: 6,
    projects: 25,
    description: "Elegant open source project tracking",
    readme:
      "Planka\nElegant open source project tracking\n\nClient demo (without server features).\n\nFeatures\n\nCreate projects, boards, lists, cards, labels and tasks\nAdd card members, track time, set due dates, add attachments, write comments\nMarkdown support in card description and comments\nFilter by members and labels\nCustomize project backgrounds\nReal-time updates\nInternal notifications\nMultiple interface languages\nSingle sign-on via OpenID Connect\n\nDocumentation\n\nYou can find the documentation for Planka here:\nhttps://docs.planka.cloud/docs/intro",
    name: "Planka",
    category: "Other",
    health: 93,
    code: "qrBbxO",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ccd03cfb-c8e4-4a8f-9fa6-b1c76a74fa7a",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "Template for the MatureStack Boilerplate",
    readme:
      "MatureStack Boilerplate - A powerful, modular boilerplate designed for tech startups and micro SaaS. Featuring a NestJS backend with MongoDB and a Next.js frontend, it‚Äôs built for scalability, speed, and seamless API communication.\n\nFind us on: https://www.maturestack.com\n\nMatureStack is a paid boilerplate, you will only get access to the linked private repositories after purchasing access via the website.",
    name: "MatureStack",
    category: "Other",
    health: null,
    code: "kv-8cr",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6b1186fe-4e07-41d1-8659-85ccbd871f9e",
    isApproved: false,
    activeProjects: 3,
    projects: 9,
    description: "Simple Saas Starter in Nextjs",
    readme:
      "Next.js SaaS Starter\nThis is a starter template for building a SaaS application using Next.js with support for authentication, Stripe integration for payments, and a dashboard for logged-in users.\n\nDemo: https://next-saas-start.vercel.app/\n\nWhy did I make this?\nIn 2020, I made a course called \"React 2025\" which showed how to build a SaaS application with Next.js, Stripe, and other tools.\n\nWell, it's almost 2025 and React 19 has brought so many amazing new features I didn't predict! This repo is a demonstration of the latest React and Next.js patterns. These patterns can drastically simplify some common tasks in building your SaaS, like building forms, talking to your database, and more.\n\nFeatures\nMarketing landing page (/) with animated Terminal element\nPricing page (/pricing) which connects to Stripe Checkout\nDashboard pages with CRUD operations on users/teams\nBasic RBAC with Owner and Member roles\nSubscription management with Stripe Customer Portal\nEmail/password authentication with JWTs stored to cookies\nGlobal middleware to protect logged-in routes\nLocal middleware to protect Server Actions or validate Zod schemas\nActivity logging system for any user events",
    name: "nextjs-saas-starter",
    category: "Starters",
    health: 0,
    code: "BAwWpG",
    languages: ["TypeScript", "CSS", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4df9a27d-5792-458d-9126-29ca0e965ed5",
    isApproved: false,
    activeProjects: 10,
    projects: 14,
    description: "Simple but complete and scalable FastAPI & PostgreSQL API.",
    readme:
      "What's Included\nüîÑ Complete CRUD operations for heroes\nüìä Async SQLAlchemy with PostgreSQL\nüîÑ Automatic Alembic migrations\nüèóÔ∏è Clean architecture with repository pattern\n‚ö†Ô∏è Custom exception handling\nüîç CI and testing pipeline\nüßπ Linter setup with pre-commit hooks\nüöÇ One-click Railway deployment\n\nProject Structure üìÅ\napi/\n‚îú‚îÄ‚îÄ core/              # Core functionality\n‚îÇ   ‚îú‚îÄ‚îÄ config.py      # Environment and app configuration\n‚îÇ   ‚îú‚îÄ‚îÄ database.py    # Database connection and sessions\n‚îÇ   ‚îú‚îÄ‚îÄ exceptions.py  # Global exception handlers\n‚îÇ   ‚îú‚îÄ‚îÄ logging.py     # Logging configuration\n‚îÇ   ‚îî‚îÄ‚îÄ security.py    # Authentication and security\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îú‚îÄ‚îÄ heroes/        # Heroes module\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py      # Database models\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repository.py  # Data access layer\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes.py      # API endpoints\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py     # Pydantic models\n‚îÇ   ‚îî‚îÄ‚îÄ users/         # Users module\n‚îÇ       ‚îú‚îÄ‚îÄ models.py      # User models\n‚îÇ       ‚îú‚îÄ‚îÄ repository.py  # User data access\n‚îÇ       ‚îú‚îÄ‚îÄ routes.py      # User endpoints\n‚îÇ       ‚îî‚îÄ‚îÄ schemas.py     # User schemas\n‚îú‚îÄ‚îÄ utils/            # Utility functions\n‚îî‚îÄ‚îÄ main.py          # Application entry point\n\n\nNote: Railway will automatically detect the Python requirements and set up the necessary infrastructure.",
    name: "minimalistic-fastapi",
    category: "Starters",
    health: 100,
    code: "wbTudS",
    languages: ["Python", "Mako"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a3ee70f6-17cb-4280-81d0-1cba4a5f4b0a",
    isApproved: false,
    activeProjects: 2,
    projects: 4,
    description: "Upload, serve, and process images. On-the-fly image optimization and more. ",
    readme:
      "Image Processing Service for Railway\n\nA self-hosted alternative to services like Cloudinary, Imgix, and others that helps you\nmove faster and pay less when you need to manage image content.\n\nUpload, serve, and process images on Railways. Includes on-the-fly image resizing, cropping, automatic AVIF/WebP, and more.\n\nFeatures\n\nx] On-the-fly image processing (resize, crop, etc.) from any allowlisted domain or Railway volume\n[x] Automatic AVIF/WebP conversion\n[x] Uses [libvips for fast image processing\nx] S3-ish blob storage (PUT, GET, DELETE) protected by an API key\n[x] Secure image serving with URLs protected by SHA256-HMAC signatures\n[x(https://github.com/jaredLunde/railway-image-service/tree/main/js#react-api), Node.js client, URL builder, and Go client for easy integration\n\nExamples\nAstro site A web demo using the Astro web framework\n",
    name: "Image Service",
    category: "Storage",
    health: 100,
    code: "MF8Rcp",
    languages: ["Go", "TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6cfa0ac5-fd6e-4057-8031-ff9208ad8393",
    isApproved: false,
    activeProjects: 23,
    projects: 34,
    description: "Deploy Ghost to Railway with ease. Almost no configuration needed.",
    readme:
      'No configuration is needed to spin up your Ghost blog with persistent volumes. You can go to URL attached to the "ghost" service to see it in action.\n\nAfter deployment, you probably want to change the URL of your blog. You can do so by changing the URL environment variable to whatever your URL is on the ghost service. Redeploy your service to propagate the changes.\n\nDo not worry! Your blogs, uploaded themes and images will still be available after redeployment due to the use of Docker volumes. Happy blogging!\n\nAre you happy with this template? Please share your thoughts on my blog.\n\n',
    name: "Ghost",
    category: "Blogs",
    health: 100,
    code: "AGPkfv",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2ebd5f5a-0849-4e71-934f-3df28e767137",
    isApproved: false,
    activeProjects: 24,
    projects: 70,
    description: "Moodle is a free and open-source learning management system.",
    readme:
      "Moodle is a free and open-source learning management system written in PHP and distributed under the GNU General Public License. Moodle is used for blended learning, distance education, flipped classroom and other online learning projects in schools, universities, workplaces and other sectors.",
    name: "moodle",
    category: "CMS",
    health: 92,
    code: "Fez1Se",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "87f63c8f-0f9f-45c5-b986-506ce61d6963",
    isApproved: false,
    activeProjects: 3,
    projects: 11,
    description: "ecommerce template using Stripe Products & Checkout",
    readme:
      "This template offers a modern, fully functional e-commerce solution built with Next.js 14, React, and Stripe integration. It's designed to help developers quickly set up an online store with a seamless checkout process.\n\nKey Features:\n\nResponsive Design: A mobile-friendly layout that adapts to various screen sizes, ensuring a great shopping experience on all devices.\nProduct Showcase: Dynamically display your Stripe products with images, names, and prices.\nStripe Integration: Seamless integration with Stripe for secure and efficient payment processing.\nServer-Side Rendering: Utilizes Next.js for improved performance and SEO.\nTypeScript Support: Built with TypeScript for enhanced code quality and developer experience.\nCustomizable UI: Styled with Tailwind CSS and shadcn/ui components for easy customization.\nAccessibility: Implements best practices for web accessibility, ensuring your store is usable by all.\n\nThis template is perfect for developers looking to launch an e-commerce site quickly without compromising on quality or scalability. Whether you're building a small boutique store or laying the foundation for a larger e-commerce platform, this template provides a solid starting point with best practices baked in.",
    name: "Nextjs-Ecommerce",
    category: "Starters",
    health: 0,
    code: "Mfh7ho",
    languages: ["TypeScript", "CSS", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "53b1309a-bec1-4300-924b-442be8aff24a",
    isApproved: false,
    activeProjects: 2,
    projects: 9,
    description: "Retrieval Augmented Generation (RAG) chatbot powered by Weaviate",
    readme:
      "Verba, developed by Weaviate, is an open-source Retrieval-Augmented Generation (RAG) application designed to provide personalized, AI-driven answers using your own data. Its modular architecture allows for easy customization and integration with various AI models and data sources.\n\nKey Features:\n\t‚Ä¢\tData Ingestion: Verba supports importing various data formats, including text files, PDFs, and GitHub repositories. It utilizes tools like UnstructuredIO for seamless data ingestion.\n\t‚Ä¢\tData Chunking: The application offers multiple chunking strategies, such as token-based and sentence-based chunking, to segment documents into manageable pieces for efficient processing. \n\t‚Ä¢\tEmbedding and Retrieval: Verba integrates with embedding models from providers like OpenAI, Cohere, and Hugging Face. It uses Weaviate‚Äôs vector database for storing and retrieving data based on semantic relevance. Ôøº\n\t‚Ä¢\tAnswer Generation: The platform supports various language models, including GPT-4o to generate accurate and contextually relevant answers.\n\t‚Ä¢\tUser Interface: Verba features a user-friendly web interface that allows for easy data upload, management, and interaction. Users can view sources directly in the UI, with highlighted chunks for transparency. ",
    name: "Verba (RAG Chatbot)",
    category: "AI/ML",
    health: 100,
    code: "QFa7Oq",
    languages: ["TypeScript", "Python", "HTML", "GLSL", "JavaScript", "Dockerfile", "CSS", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9b59f824-4b41-4b61-a45c-df1fc241d29a",
    isApproved: false,
    activeProjects: 7,
    projects: 13,
    description: "Template for ChromaDB vector database",
    readme:
      "ChromaDB\n\nThe AI-native embedding database\n\nThis template is based on a other version : Railway template. I have try to use it but the configuration didn't work so a update it and make my own template.\n\nThis is a public accessible Vector DB with Bearer Auth.\n\nThis template use the latest version of the docker container\n\nAny question and remarks can be said in the forum",
    name: "ChromaDB",
    category: "Storage",
    health: 100,
    code: "Vlo43b",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "acf7e28b-a6e9-41ae-9521-c1e41a73edbf",
    isApproved: false,
    activeProjects: 165,
    projects: 189,
    description: "Python Telegram bot using FastAPI and Webhooks",
    readme:
      "Telegram Bot with Webhooks Template\n\nThis template provides a basic framework for creating a Telegram bot using FastAPI, connecting it to Telegram's Webhook system.\n\n‚ú® Features\n\nFastAPI: Lightweight, fast web framework for building APIs.\nPython Telegram Bot: Seamless integration with Telegram's Bot API.\nWebhook Support: Automatic webhook setup and processing of Telegram updates using the telegram.ext.Application.\n\nü§ñ Example\nYou can visit @dango_webhook_bot on Telegram to see a running example.\n\nRepository: dangos-dev/TelegramBot.Webhook\n\nSee also: Docuementation",
    name: "Telegram Bot with Webhooks",
    category: "Bots",
    health: 95,
    code: "5kprwG",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "60e73703-6b9c-472f-b492-ebfaf209c623",
    isApproved: false,
    activeProjects: 25,
    projects: 49,
    description: "Python Jupyter Notebooks Server. Customizable Dockerfile! By Justin Mitchel",
    readme:
      "The goal of this template is two fold:\n\nCustomizable Jupyter environment\nShell-like interactivity with Railway resources (private and public)\n\nThe official JupyterLab template is great but... it's overly complex for simple Jupyter tasks. That's what this template is for.\n\nThe code is open source so feel free to fork and customize as you see fit. In our case, we can use it to:\n\nVerify private Railway resource connections -- such as calling non-internet connected APIs\nRun various analytics with private databases\nUse numpy, pandas, scikit-learn, and many other Data Science tools\n\nDo you have ideas to improve? Please share them with me https://x.com/justinmitchel or on the GitHub Repo attached to this template. \n\nAll code is available at: https://github.com/jmitchel3/jupyter-container",
    name: "Jupyter Container - Interactive Python",
    category: "Other",
    health: 100,
    code: "JEeFjP",
    languages: ["Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d694ff5f-f7db-487b-b3f6-c0961643c520",
    isApproved: false,
    activeProjects: 117,
    projects: 175,
    description: "Build, run, and deploy full-stack web apps using any LLM of your choice!",
    readme:
      "Bolt.diy is the open-source version of Bolt.new, providing developers with a customizable platform for AI-driven coding assistance. With bolt.diy, users can dynamically select their preferred LLM (Large Language Model) for each prompt. The platform supports multiple AI providers, including OpenAI, Anthropic, Ollama, OpenRouter, Gemini, LMStudio, Mistral, xAI, HuggingFace, DeepSeek, Groq, and any model compatible with the Vercel AI SDK.\n\nbolt.diy Features\n\nAI-powered full-stack web development directly in your browser.\nSupport for multiple LLMs with an extensible architecture to integrate additional models.\nAttach images to prompts for better contextual understanding.\nIntegrated terminal to view output of LLM-run commands.\nRevert code to earlier versions for easier debugging and quicker changes.\nDownload projects as ZIP for easy portability.\nIntegration-ready Docker support for a hassle-free setup.\n\nSetup bolt.diy \n\nSimply input the API key(s) for the providers you wish to use, deploy the app, and you're ready to go!\n",
    name: "Bolt.DIY",
    category: "AI/ML",
    health: 50,
    code: "YaqTB9",
    languages: ["TypeScript", "SCSS", "Dockerfile", "JavaScript", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "83f0439a-54ba-408a-ab08-0e0929ab507d",
    isApproved: false,
    activeProjects: 6,
    projects: 30,
    description: "High-performance Vector Database and Vector Search Engine",
    readme:
      "\n  \n\n\n\n    Vector Search Engine for the next generation of AI applications\n\n\nQdrant (read: quadrant) is a vector similarity search engine and vector database.\nIt provides a production-ready service with a convenient API to store, search, and manage points‚Äîvectors with an additional payload\nQdrant is tailored to extended filtering support. It makes it useful for all sorts of neural-network or semantic-based matching, faceted search, and other applications.\n\nQdrant is written in Rust ü¶Ä, which makes it fast and reliable even under high load. See benchmarks.\n\nWith Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!\n\nFeatures\n\nFiltering and Payload\n\nQdrant can attach any JSON payloads to vectors, allowing for both the storage and filtering of data based on the values in these payloads.\nPayload supports a wide range of data types and query conditions, including keyword matching, full-text filtering, numerical ranges, geo-locations, and more.\n\nFiltering conditions can be combined in various ways, including should, must, and must_not clauses,\nensuring that you can implement any desired business logic on top of similarity matching.\n\nHybrid Search with Sparse Vectors\n\nTo address the limitations of vector embeddings when searching for specific keywords, Qdrant introduces support for sparse vectors in addition to the regular dense ones.\n\nSparse vectors can be viewed as an generalization of BM25 or TF-IDF ranking. They enable you to harness the capabilities of transformer-based neural networks to weigh individual tokens effectively.\n\nVector Quantization and On-Disk Storage\n\nQdrant provides multiple options to make vector search cheaper and more resource-efficient.\nBuilt-in vector quantization reduces RAM usage by up to 97% and dynamically manages the trade-off between search speed and precision.\n\nDistributed Deployment\n\nQdrant offers comprehensive horizontal scaling support through two key mechanisms:\nSize expansion via sharding and throughput enhancement via replication\nZero-downtime rolling updates and seamless dynamic scaling of the collections\n\nHighlighted Features\n\nQuery Planning and Payload Indexes - leverages stored payload information to optimize query execution strategy.\nSIMD Hardware Acceleration - utilizes modern CPU x86-x64 and Neon architectures to deliver better performance.\nAsync I/O - uses io_uring to maximize disk throughput utilization even on a network-attached storage.\nWrite-Ahead Logging - ensures data persistence with update confirmation, even during power outages.\n\nAPI\n\nREST\n\nOnline OpenAPI 3.0 documentation is available here.\nOpenAPI makes it easy to generate a client for virtually any framework or programming language.\n\nYou can also download raw OpenAPI definitions.\n\ngRPC\n\nFor faster production-tier searches, Qdrant also provides a gRPC interface. You can find gRPC documentation here.\n\nClients\n\nQdrant offers the following client libraries to help you integrate it into your application stack with ease:\n\nOfficial:\n  Go client\n  Rust client\n  JavaScript/TypeScript client\n  Python client\n  .NET/C# client\n  Java client\nCommunity:\n  Elixir\n  PHP\n  Ruby\n  Java\n\nWhere do I go from here?\n\nQuick Start Guide\nEnd to End Colab Notebook demo with SentenceBERT and Qdrant\nDetailed Documentation are great starting points\nStep-by-Step Tutorial to create your first neural network project with Qdrant",
    name: "Qdrant Cluster",
    category: "AI/ML",
    health: 100,
    code: "dbhF-C",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f653b417-6575-4471-bc86-9531c7589629",
    isApproved: true,
    activeProjects: 15,
    projects: 20,
    description: "Make your Railway Template Kickback public!",
    readme:
      "Make your Railway Template Kickback public!\n\nThis project is a simple and effective Railway template designed to host a public page showcasing your templates and earnings. It‚Äôs perfect for creators who sell templates online (e.g., Gumroad) and want to provide transparency about their work and income. With this template, you can display a list of your templates, including their titles, descriptions, and the total revenue earned from each. The dashboard updates automatically using data from an API, making it easy to keep your page accurate and up-to-date.  Deployment is quick and straightforward using Railway, allowing you to set up your page in minutes. Just provide your Railway token!",
    name: "Railway Template Kickback",
    category: "Other",
    health: 100,
    code: "Wjoi4m",
    languages: ["TypeScript", "JavaScript", "CSS", "Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6fb4c8b6-12e6-481a-b39e-f100b392b0d9",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "Turns your postgres db into an REST api",
    readme:
      "Postgres HTTP (Canary)\n\nBeaware this is canary version with. Use the stable one if you dont wanna see bugs: https://railway.com/template/UYtPO2?referralCode=lasse\n\nTurns your postgres db into an http server. Great for beginners or just small projects and testing.\n\nYou can find the source code here: github.com/lassejlv/postgres_http\n\nAPI reference\n\nPOST /query\n  body: { query: string, args: any[] }\n  headers: { Authorization: Bearer  }\n  response: { rows: any[] }\n\nGET /status\n   headers: { Authorization: Bearer  }\n   response: { ok: boolean, ping: number  }\n\nI cant run...\n\nBy default you cannot run: DELETE, DROP, TRUNCATE.\nUpdate the env variable ALLOW_DANGEROUS_SQL_COMMANDS and set it to true if you wanna be doing that.\n\nAPI key\nYou will find the api under the variables tab. It's randomly generated under creation.",
    name: "Postgres HTTP (Canary)",
    category: "Other",
    health: null,
    code: "v4zFIs",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "bbbad939-eef9-4308-a713-590028d64230",
    isApproved: true,
    activeProjects: 51,
    projects: 213,
    description: "Supabase without Functions, Logflare and Storage (Read Overview)",
    readme:
      "\nNot a complete Supabase deployment!\n\nSupabase\n\nThe open source Firebase alternative. Supabase gives you a dedicated Postgres database to build your web, mobile, and AI applications.\n\nThis template contains Supabase Studio, Postgrest, Supabase Auth, Supabase Realtime, and PostgreSQL ONLY. Features that require logs, edge functions and/or file storage will not work with this deployment. These features are not compatible with Railway yet and will be added in a future release. Some core Supabase functions may require these features, and errors may appear in Supabase Studio when trying to access these. Use in production at your own risk - this deployment is based on the examples in the Supabase GitHub repository.\n\nHighlights\n\nSupabase Studio\nGotrue Authentication Layer\nREST PostgreSQL Access\nPostgreSQL Database with Plugin Support\nRealtime database access\n\nUsage\n\nDeploy this template and configure the secrets for Supabase JWT tokens. Configure the authentication service if desired; if not, you can remove the deployment. To remove the auth service completely, set the AUTH_HOST variable in Kong to not_present.\n\nThe dashboard can be accessed utilizing the USERNAME and PASSWORD in Kong's environment variables.\n\nLicense\n\nSupabase is licensed under the Apache License 2.0.\n\nHelpful Resources\n\nhttps://github.com/6ixfalls/supabase\nhttps://github.com/supabase/supabase\n https://github.com/supabase/auth - README contains environment variables for the auth service",
    name: "Supabase (Studio, DB, Auth)",
    category: "Storage",
    health: 92,
    code: "supabase",
    languages: ["PLpgSQL", "Shell", "Elixir", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1d6d4fb3-59e7-43ce-b6ec-c424a93c5aac",
    isApproved: false,
    activeProjects: 3,
    projects: 10,
    description: "Application Webhook receiver for Front",
    readme:
      "A Front Application Webhook processing application template optimized for deployment on Railway.\n\nThis template provides a robust foundation for handling events received from an Application Webhook with payload validation, integrity checking and built-in queue processing to allow you to process events asynchronously at scale.",
    name: "Front.com Application Webhook Receiver",
    category: "Starters",
    health: 67,
    code: "Ry0Mh9",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "62bdcd20-1a1e-4ad7-be6d-2a75a76a2535",
    isApproved: false,
    activeProjects: 10,
    projects: 18,
    description: "Open source analytics & monitoring solution for every database",
    readme:
      "Dashboard anything. Observe everything.\n\nQuery, visualize, alert on, and understand your data no matter where it‚Äôs stored. With Grafana you can create, explore, and share all of your data through beautiful, flexible dashboards.\n\nCreate, explore, and share beautiful dashboards that combine data from multiple sources to foster a data-driven culture within your team.",
    name: "Grafana",
    category: "Analytics",
    health: 100,
    code: "l-CsZl",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a353e539-2365-403e-92c6-8bd4663514c7",
    isApproved: false,
    activeProjects: 5,
    projects: 9,
    description: "Boilerplate http server in golang",
    readme:
      "This template has the basic code and structure to start a basic Http server. The code is extendable to add other features such as a database, middleware and other business logic.\nThis template comes with a basic health check route and cors config to handle requests coming in from different origins. ",
    name: "golang-rest-api",
    category: "Starters",
    health: 0,
    code: "5PIs7x",
    languages: ["Go"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "39ec99e4-26e9-4704-b35a-a8642277ed9f",
    isApproved: false,
    activeProjects: 6,
    projects: 18,
    description: "Wiki.js + Postgres configured template",
    readme:
      "Wiki.js + Postgres configured template.\n\nConfigureated based on  offical WikiJS documentation.\n\nAbout:\nWiki.js is an open source project that has been made possible due to the generous contributions by community backers. \n\nWiki.js site: https://js.wiki",
    name: "wikijs:2.5 setup",
    category: "Other",
    health: 83,
    code: "mS67ic",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "cfc63f5a-7eb2-42e4-9633-f2469f9ccda8",
    isApproved: false,
    activeProjects: 2,
    projects: 21,
    description: "Backend Infrastructure for the Ethereum Follow Protocol",
    readme:
      "This template will setup all the necessary services for processing, storing and reading data for the Ethereum Follow Protocol.  It includes the following services:\n\n   Database (Postgres)\n   PGBouncer (a connection pooler for Postgres)\n   Indexers for Base, Optimism and Ethereum Mainnet\n   Service Manager (updates ens data, leaderboard, cache, mutuals counts)\n   API (Can be deployed as a cloudflare worker)\n   Redis Cache for the API\n\nFurther explanation and deployment instructions can be found in the EFP docs:\n\nhttps://docs.ethfollow.xyz/production/silo",
    name: "EFP-Silo",
    category: "Other",
    health: null,
    code: "pDGEZm",
    languages: ["PLpgSQL", "TypeScript", "Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d0b9d0bf-f62c-4ec2-94df-1fc4d25d5ba5",
    isApproved: false,
    activeProjects: 150,
    projects: 204,
    description: "Deploy a Letta server (uses the latest Letta Docker image)",
    readme:
      'Letta\n\nüëæ Letta is an open source framework for building stateful LLM applications. You can use Letta to build stateful agents with advanced reasoning capabilities and transparent long-term memory. The Letta framework is white box and model-agnostic.\n\nFor more information see: https://github.com/letta-ai/letta\n\nUsage\n\nFor a tutorial on how to deploy a Letta server on Railway, see our docs page: https://docs.letta.com/guides/server/railway\n\nDeploy the Railway template.\nTo use the Letta ADE, go to https://app.letta.com and connect to a remote development server. Use the IP address exposed by Railway as the server URL, and use the password set in the "Variables" section of your Railway deployment.\nThe Letta server will need to be configured with at least one LLM API provider, to do so set your environment variables (e.g. OPENAI_API_KEY) in the "Variables" section.\n\nAdding additional environment variables\n\nTo help you get started, when you deploy the template you have the option to fill in the example environment variables OPENAI_API_KEY (to connect your Letta agents to GPT models), ANTHROPIC_API_KEY (to connect your Letta agents to Claude models), and COMPOSIO_API_KEY (to connect your Letta agents to Composio\'s library of over 7k pre-made tools).\n\nThere are many more providers you can enable on the Letta server via additional environment variables (for example vLLM, Ollama, etc). For more information on available providers, see our documentation: https://docs.letta.com/guides/server/docker\n\nTo connect Letta to an additional API provider, you can go to your Railway deployment (after you\'ve deployed the template), click Variables to see the current environment variables, then click + New Variable to add a new variable. Once you\'ve saved a new variable, you will need to restart the server for the changes to take effect.',
    name: "letta",
    category: "AI/ML",
    health: 92,
    code: "jgUR1t",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1498b855-e636-438c-b23f-2cb706ed4939",
    isApproved: false,
    activeProjects: 1,
    projects: 5,
    description: "Connect to Tailscale nodes from Railway.",
    readme:
      "railtail is a HTTP/TCP proxy for Railway workloads connecting to Tailscale\nnodes. It listens on a local address and forwards traffic it receives on\nthe local address to a target Tailscale node address.\n\nüì£ This is a workaround until there are full VMs available in Railway. Please upvote the thread if you want this feature!\n\nMore information available at https://github.com/half0wl/railtail",
    name: "railtail",
    category: "Other",
    health: 100,
    code: "railtail",
    languages: ["Go"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9bd7c002-cbe0-486f-96e5-ac500694ee19",
    isApproved: false,
    activeProjects: 2,
    projects: 8,
    description: "Simple & customizable endpoints for querying rich blockchain data.",
    readme:
      "\nTemplate\n\nThis is the official community Railway template for thirdweb Insight maintained by the thirdweb community team. This template deploys thirdweb Insight, lets you retrieve blockchain data from any EVM chain, enrich it with metadata, and transform it using custom logic. This template also deploys a modified Clickhouse Server database to create pre-defined tables for Insight to store data.\n\nAttention\nTo successfully deploy this template your account must be on the hobby plan or higher. If you are on the free plan, you can still deploy this template, but it will not work as expected. You can upgrade your account by going to the Railway billing page.\n\nRequirements\n\nCustom Clickhouse Server (v24.11+)\nthirdweb API Client. [Get it here]\nRPC URL of the blockchain you want to index. [Get it here]\n\nOverview\n\nInsight is a powerful tool that lets you retrieve blockchain data from any EVM chain, enrich it with metadata, and transform it using custom logic. Whether you're building a gaming inventory system, tracking DeFi metrics, or analyzing NFT collections, Insight makes it easy to get the data you need with simple API calls.\n\nWhy use Insight?\n\nIt gives developers an easily understandable data API to query blockchain data.\nNo need to index blockchains yourself or manage infrastructure and RPC costs.\nTransform and enrich data with custom Blueprints.\nInsight is open source.\n\nCloud-Hosted Version\n\nAre you looking for a managed thirdweb Insight? Try Cloud-Hosted!\n\nDocumentation\n\nFor the complete documentation, please visit the thirdweb Insight documentation.\n\nSupport\n\nIf you need help, please submit a ticket to our support site.\n\nCommunity\n\nJoin the vibrant thirdweb community to stay updated and connect with fellow Web3 developers!\n\nDiscord: Engage in real-time discussions, get support, and share your projects.\nDailyDev Squad: Stay updated with the latest web3 development news and updates.\nReddit: Join our subreddit to participate in discussions, ask questions, and share insights.\n\nWe look forward to seeing you there!",
    name: "thirdweb Insight",
    category: "Other",
    health: null,
    code: "Dyj5IJ",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c037ceb7-52ef-4d72-b1a8-cc8068155e91",
    isApproved: false,
    activeProjects: 7,
    projects: 7,
    description: "Drosera operator and delegation client for testnet. Checkout dev.drosera.io",
    readme:
      "Operators\n\nOperators are crucial players in Drosera, consisting of organizations and solo stakers who run the Drosera Operator Client software to help maintain and protect the DeFi ecosystem. These dedicated individuals are responsible for executing Traps and performing on-chain response actions, ensuring the security and stability of the network.\n\nTo execute a Trap, an Operator must first gain permission by opting into the specific Trap. Once opted in, the Operator gains access to the off-chain Trap and the current peers in the network. This allows them to actively participate in monitoring and evaluating every new block based on the conditions set by the Trap.\n\nIn the event that the conditions of a Trap are met, the Operator will promptly execute the on-chain response function. This swift action helps to mitigate potential threats and exploits.\n\nDelegation Client\n\nThe Delegation Client is a tool used to automatically opt your Operator node into Traps. The Delegation Client is a separate application from the Operator node and requires the same private key used for the Operator node.\n\nIt works by querying Drosera's Delegation server which delegates traps to registered Operators as they are created. It is a convenience service that is only used in the testnet environment because it is expected for Operators to manually opt into Traps in a mainnet environment that is based on real value incentives.\n\nDeploying the drosera-operator (testnet) template\nPopulate the 2 required environment variables in both the drosera-operator and drosera-delegation-client services.  The environment variables with the same name should have the same values.\n  DRO__ETH__RPC_URL\n  DRO__ETH__PRIVATE_KEY\nDeploy the operator\n\nAfter deployment steps\nEnable Networking\nIn order for liveness data for this operator to be seen on the frontend, we need to add an http proxy.\nOpen the Settings tab of your service.\nNavigate to the Networking section of the settings tab.\nClick the Generate Domain button.\nSelect port 31314 port from the dropdown list (if you changed the DRO__SERVER__PORT variable, choose the value you set).\nClick the Generate Domain button again.\n\nRedeploy the Operator\nNow we need to redeploy the service to pick up the networking changes\nSelect the Deployments tab of your service.\nIn the green active deployment box, click the vertical 3 dot menu.\nClick Redeploy",
    name: "drosera-operator (testnet)",
    category: "Other",
    health: 100,
    code: "0OtXZl",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e732693d-d71a-42b9-82ec-925b529fa4cd",
    isApproved: false,
    activeProjects: 26,
    projects: 43,
    description: "Drosera solo operator node for running traps. Checkout dev.drosera.io",
    readme:
      "Operators\n\nOperators are crucial players in Drosera, consisting of organizations and solo stakers who run the Drosera Operator Client software to help maintain and protect the DeFi ecosystem. These dedicated individuals are responsible for executing Traps and performing on-chain response actions, ensuring the security and stability of the network.\n\nTo execute a Trap, an Operator must first gain permission by opting into the specific Trap. Once opted in, the Operator gains access to the off-chain Trap and the current peers in the network. This allows them to actively participate in monitoring and evaluating every new block based on the conditions set by the Trap.\n\nIn the event that the conditions of a Trap are met, the Operator will promptly execute the on-chain response function. This swift action helps to mitigate potential threats and exploits.\n\nDeploying the drosera-operator template\nPopulate the 2 required environment variables\n  DRO__ETH__RPC_URL\n  DRO__ETH__PRIVATE_KEY\nDeploy the operator\n\nAfter deployment steps\nEnable Networking\nIn order for liveness data for this operator to be seen on the frontend, we need to add an http proxy.\nOpen the Settings tab of your service.\nNavigate to the Networking section of the settings tab.\nClick the Generate Domain button.\nSelect port 31314 port from the dropdown list (if you changed the DRO__SERVER__PORT variable, choose the value you set).\nClick the Generate Domain button again.\n\nRedeploy the Operator\nNow we need to redeploy the service to pick up the networking changes\nSelect the Deployments tab of your service.\nIn the green active deployment box, click the vertical 3 dot menu.\nClick Redeploy",
    name: "drosera-operator",
    category: "Other",
    health: 100,
    code: "Ndyq3N",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c75f5c62-cb69-476b-a95d-d3cf9bcac7d9",
    isApproved: false,
    activeProjects: 1,
    projects: 3,
    description: "Turns your postgres db into an REST api",
    readme:
      "Postgres HTTP\n\nTurns your postgres db into an http server. Great for beginners or just small projects and testing.\n\nYou can find the source code here: github.com/lassejlv/postgres_http\n\nAPI reference\n\nPOST /query\n  body: { query: string, args: any[] }\n  headers: { Authorization: Bearer  }\n  response: { rows: any[] }\n\nGET /status\n   headers: { Authorization: Bearer  }\n   response: { ok: boolean, ping: number  }\n\nI cant run...\n\nBy default you cannot run: DELETE, DROP, TRUNCATE.\nUpdate the env variable ALLOW_DANGEROUS_SQL_COMMANDS and set it to true if you wanna be doing that.\n\nAPI key\nYou will find the api under the variables tab. It's randomly generated under creation.",
    name: "Postgres HTTP",
    category: "Other",
    health: 100,
    code: "UYtPO2",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "55987300-318f-431c-b0c3-bbaaf0751a3d",
    isApproved: false,
    activeProjects: 40,
    projects: 52,
    description: "Easily deploy an MSSQL Server 2017 instance with pre-configured settings",
    readme:
      'MSSQL Server 2017 \n\nThis template sets up an MSSQL Server 2017 container on Railway, pre-configured with essential environment variables and a secure autogenerated password for the SA user. Follow the instructions below to connect to the database using SQL Server Management Studio (SSMS).\n\nFeatures  \nPreconfigured Environment Variables:  \n  ACCEPT_EULA="Y": Accept the MSSQL Server End User License Agreement.  \n  MSSQL_SA_PASSWORD: Secure password autogenerated upon deployment.  \n  MSSQL_DATA_DIR="/var/opt/mssql": Data storage directory.  \nMSSQL Server 2017, perfect for development or production use.  \nAccessible via SQL Server Management Studio or other SQL tools.\n\nDeployment Instructions  \n\nFork or Deploy Template  \n   Use this template to deploy an MSSQL Server 2017 container on Railway.  \n   During deployment, provide a secure password for the SA user by setting the \'MSSQL_SA_PASSWORD\' env variable\n\nRetrieve Connection Details  \n   Go to your Railway project dashboard.  \n   Note down the following environment variables:  \n     TCP Proxy URL: You can see this from the settings tab of the service\n     Username: SA (system administrator).  \n     Password: Autogenerated in the MSSQL_SA_PASSWORD variable.  \n\nConnecting via SQL Server Management Studio (SSMS)  \n\nOpen SQL Server Management Studio (SSMS).  \nIn the "Connect to Server" dialog box, enter the following details:  \n   Server Type: Database Engine.  \n   Server Name: Use the Railway-provided TCP Proxy URL (e.g., autorack.proxy.rlwy.net,43433). NOTE: use \',\' and not \':\'   to separate the url from the port\n   Authentication: SQL Server Authentication.  \n   Login: SA.  \n   Password: Use the value from MSSQL_SA_PASSWORD in Railway environment settings.  \n\nClick "Connect" to access your MSSQL instance.  \n\nAdditional Notes  \n\nThe MSSQL_DATA_DIR specifies the storage location for your database files. Customize it if needed.  \nEnsure your Railway service exposes port 1433 to allow external connections.  \nSecure your deployment by restricting access and rotating passwords regularly.  \n\nEnjoy using MSSQL Server 2017 on Railway! üéâ',
    name: "MS SQL Server 2017",
    category: "Storage",
    health: 20,
    code: "aNgXG5",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e5bcb2cc-70be-487c-8436-87ef67a69215",
    isApproved: false,
    activeProjects: 27,
    projects: 128,
    description: "Open source observability and analytics for LLM applications",
    readme:
      "Langfuse is an open source observability & analytics solution for LLM-based applications. It is mostly geared towards production usage but some users also use it for local development of their LLM applications.\n\nLangfuse is focused on applications built on top of LLMs. Many new abstractions and common best practices evolved recently, e.g. agents, chained prompts, embedding-based retrieval, LLM access to REPLs & APIs. These make applications more powerful but also unpredictable for developers as they cannot fully anticipate how changes impact the quality, cost and overall latency of their application. Thus Langfuse helps to monitor and debug these applications.\n\nUsing this template, you can deploy Langfuse to Railway. It automatically creates Postgres, Clickhouse, and Redis databases and Minio instance to store your production data.\n\nIn case of errors, try restarting the application container or join the Discord to get help: https://langfuse.com/discord",
    name: "Langfuse v3",
    category: "Other",
    health: 96,
    code: "exma_H",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d519f0f0-4936-48e3-a36a-aa1b4bdf1de2",
    isApproved: false,
    activeProjects: 3,
    projects: 5,
    description: "Deploy a GRPC reverse proxy with Caddy.",
    readme:
      "gRPC Reverse Proxy on Railway using Caddy Server\n\nDeploy a gRPC reverse proxy with Caddy on Railway. Ensure SERVICE_URL (e.g., grpc.railway.internal:1234) and PORT are set in the environment variables. Service is exposed by default.\n\nBy default, the Caddyfile is configured to reverse proxy gRPC requests.",
    name: "caddy-on-railway-grpc",
    category: "Other",
    health: null,
    code: "wlxtbV",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a9930208-4fd6-4194-904f-2e1b53774154",
    isApproved: false,
    activeProjects: 45,
    projects: 86,
    description: "Langflow is a low-code app builder for RAG and multi-agent AI applications",
    readme:
      "\nLangflow is a low-code app builder for RAG and multi-agent AI applications. It‚Äôs Python-based and agnostic to any model, API, or database.\n\n‚ú® Core features\n\nPython-based and agnostic to models, APIs, data sources, or databases.\nVisual IDE for drag-and-drop building and testing of workflows.\nPlayground to immediately test and iterate workflows with step-by-step control.\nMulti-agent orchestration and conversation management and retrieval.\nFree cloud service to get started in minutes with no setup.\nPublish as an API or export as a Python application.\nObservability with LangSmith, LangFuse, or LangWatch integration.\nEnterprise-grade security and scalability with free DataStax Langflow cloud service.\nCustomize workflows or create flows entirely just using Python.\nEcosystem integrations as reusable components for any model, API or database.\n",
    name: "Langflow",
    category: "AI/ML",
    health: 100,
    code: "-spvZa",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "42864a6d-cc70-49a8-b145-a8458a1269a0",
    isApproved: false,
    activeProjects: 4,
    projects: 12,
    description: "Nextjs starter with simple auth by Pocketbase ",
    readme:
      "The Next.js PocketAuth project is a boilerplate application that integrates Next.js with PocketBase to provide a robust authentication system. It offers pre-built authentication pages, including sign-up and login, and utilizes Material-UI for responsive design. The project is fully typed with TypeScript, ensuring type safety across the application.\n\nKey Features:\n\t‚Ä¢\tPocketBase Integration: Manages user authentication seamlessly using PocketBase.\n\t‚Ä¢\tPre-built Authentication Pages: Includes ready-to-use sign-up and login pages.\n\t‚Ä¢\tMaterial-UI Styling: Applies Material-UI components for a responsive and modern user interface.\n\t‚Ä¢\tTypeScript Support: Ensures type safety and reliability throughout the codebase.",
    name: "Nextjs-pocketauth",
    category: "Authentication",
    health: 0,
    code: "ZqVg5k",
    languages: ["TypeScript", "CSS", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "013aae4b-c512-48b5-9153-4470fbf67f5a",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "Feature-rich yet lightweight backend",
    readme:
      "bknd\n\nbknd simplifies app development by providing fully functional backend for data management, \nauthentication, workflows and media. Since it's lightweight and built on Web Standards, it can \nbe deployed nearly anywhere, including running inside your framework of choice. No more \ndeploying multiple separate services!\n\nFor documentation and examples, please visit https://docs.bknd.io.\n\n[!WARNING]\nPlease keep in mind that bknd is still under active development\nand therefore full backward compatibility is not guaranteed before reaching v1.0.0.\n\n‚ú® Features\nüìä Data: Define, query, and control your data with ease. \n  Define entities with fields and relationships, synced directly to your database.  \n  Supported field types: primary, text, number, date, boolean, enum, json, jsonschema.  \n  Relationship types: one-to-one, many-to-one, many-to-many, and polymorphic.  \n  Advanced querying with the Repository: filtering, sorting, pagination, and relational data handling.\n  Seamlessly manage data with mutators and a robust event system.  \n  Extend database functionality with batching, introspection, and support for multiple SQL dialects.\n\nüîê Auth: Easily implement reliable authentication strategies.\n  Built-in user entity with customizable fields.  \n  Supports multiple authentication strategies:  \n    Email/password (with hashed storage).  \n    OAuth/OIDC (Google, GitHub, and more).  \n  Secure JWT generation and session management.\n\nüñºÔ∏è Media: Effortlessly manage and serve all your media files.\n  Upload files with ease.  \n  Adapter-based support for S3, S3-compatible storage (e.g., R2, Tigris), and Cloudinary.\n\nüîÑ Flows (UI integration coming soon!): Design and run workflows with seamless automation.\n  Create and run workflows with trigger-based automation:  \n    Manual triggers or events from data, auth, media, or server actions.  \n    HTTP triggers for external integrations.  \n  Define tasks in sequence, parallel, or loops, with conditional execution.  \n  Use reusable sub-workflows to organize complex processes.  \n  Leverage OpenAPI specifications for API-based tasks.",
    name: "bknd",
    category: "Authentication",
    health: null,
    code: "p4nTYL",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "32bbec1f-a771-461c-aed2-fd38ad166904",
    isApproved: false,
    activeProjects: 27,
    projects: 112,
    description: "Complete Postgres database with realtime capabilities and REST API",
    readme:
      "Supabase PostgreSQL Railway Template\n\nComplete Postgres database with realtime capabilities and REST API. Includes:\nAuto-generated API\nRow level security\nAuthentication\nDatabase backups\nReal-time subscriptions\nDashboard UI\nConnection pooling\nDatabase branching\nMulti-region support\nFull-text search\nVector embeddings\nAudit trails\nEdge functions\n\nBuilt on top of PostgreSQL 15, providing enterprise-grade database features with modern developer experience.\n\nIdeal for web applications, mobile apps, and services requiring reliable, scalable database with built-in development tools.",
    name: "Supabase Postgres",
    category: "Other",
    health: 0,
    code: "MGUlUB",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "048ca997-09e4-4080-9d6e-87d100787f4e",
    isApproved: false,
    activeProjects: 0,
    projects: 3,
    description: "Self-hosted photo management that auto-organizes your photos using AI",
    readme:
      "PhotoPrism Railway Template\n\nSelf-hosted photo management powered by AI that automatically organizes and tags your photo collection. The software uses advanced machine learning to detect faces, objects, locations, and scenes in your photos. Features include facial recognition to group photos by people, location detection to map your photos, powerful search capabilities through both visual elements and metadata, customizable albums and sharing options, and a responsive interface that works on all devices. Built with privacy in mind, all processing happens locally on your server.\n\nKey features:\nFace recognition and people organization\nObject and scene detection with AI tagging\nLocation mapping and geolocation support\nAdvanced search by visual content or metadata\nCustomizable albums and sharing options\nMobile-friendly responsive interface\nRAW photo processing support\nAutomatic image classification\nPrivacy-focused with local processing",
    name: "Photoprism",
    category: "Other",
    health: null,
    code: "4FjVW0",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2d0ab3ef-49fd-44b6-bc2f-2a7d3e3ffb3b",
    isApproved: false,
    activeProjects: 10,
    projects: 18,
    description: "Template mariaDB and Adminer",
    readme:
      'Steps to Install the Template\n\nSign in to Railway\n   Go to Railway and log in to your account.\n\nCreate a New Project\n   Click on "New Project" and select "Start From Template".\n\nSearch for the Template\n   Find the template for MariaDB and Adminer. If you don\'t see it, you can create a custom setup with the necessary services.\n\nConfigure Environment Variables\n   Once the project is set up, navigate to the "Environment Variables" section.\n   Add the following variables to configure MariaDB:\n\n     | Variable Name       | Description                     |\n     |---------------------|---------------------------------|\n     | MYSQL_ROOT_PASSWORD | The root password for MariaDB. |\n     | MYSQL_DATABASE      | The default database name.     |\n     | MYSQL_USER          | The database user.             |\n     | MYSQL_PASSWORD      | The password for the database user. |\n\n   Replace the placeholders with your desired values:\n     MYSQL_ROOT_PASSWORD=\n     MYSQL_DATABASE=\n     MYSQL_USER=\n     MYSQL_PASSWORD=\n\nDeploy the Template\n   After setting up the environment variables, click "Deploy" to start the project.\n   Railway will provision MariaDB and Adminer as part of your project.\n\nAccess Adminer\n   Once the deployment is complete, locate the Adminer service URL from your Railway dashboard.\n   Open the Adminer URL in your browser and use the credentials you set up in the environment variables to log in.\n\nTips\nUse a strong password for MYSQL_ROOT_PASSWORD and MYSQL_PASSWORD to enhance security.\nRegularly back up your MariaDB database to prevent data loss.\nCustomize additional Railway configurations if needed (e.g., project domains or resources).\n',
    name: "MariaDB",
    category: "Other",
    health: null,
    code: "ZJZedY",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3959f602-2305-4a83-a0bf-f3e8bd118182",
    isApproved: false,
    activeProjects: 1,
    projects: 5,
    description: "Next.js frontend with Apollo Client already configured to use with GraphQL.",
    readme:
      'This is the frontend solution of my backend service, "Express+GraphQL+Prisma", I made them separate so that people could use their own frontend solution or opt to use the one I made. It is simply Next.js with some basic configuration to properly set up the client dependency. \n\nCheck out the backend service here: https://railway.app/template/vCAGzF?referralCode=B4Nuxy',
    name: "Next.js with Apollo Client",
    category: "Starters",
    health: null,
    code: "y1l7kq",
    languages: ["TypeScript", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8ff64f4e-8f26-41f6-9b7c-861db8a61f62",
    isApproved: false,
    activeProjects: 0,
    projects: 4,
    description: "Clean template using Express.js, Prisma, GraphQL, SQLite, and Apollo Server",
    readme:
      "This template is a backend service built with Express.js, Prisma ORM, and Apollo Server for GraphQL. Ideal for developers who want to focus on backend functionality while having the option to add their own frontend. If you want to see my frontend solution, check it out here: https://railway.app/template/y1l7kq?referralCode=B4Nuxy\n",
    name: "Express+GraphQL+Prisma",
    category: "Starters",
    health: null,
    code: "vCAGzF",
    languages: ["TypeScript", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1f2a8e5f-cb45-4aba-acb8-adf5bda17f69",
    isApproved: false,
    activeProjects: 2,
    projects: 3,
    description: "a simaple private DNS, work at DoH",
    readme:
      "This project aims to develop a simple yet efficient private DNS service that supports DNS over HTTPS (DoH) protocol. By implementing DoH, we can provide DNS resolution services while ensuring user privacy and security. This private DNS solution effectively prevents DNS hijacking and eavesdropping, while also enhancing resolution speed and optimizing the overall network experience. Users can easily configure and utilize the service, making it suitable for individuals and small businesses alike. Our goal is to offer users a reliable and secure online environment, ensuring that every DNS query remains private and protected.",
    name: "doh",
    category: "Other",
    health: null,
    code: "gUgRJT",
    languages: ["Go", "JavaScript", "HTML", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6494111c-fbc8-4e7f-89bb-66d2f7c000f9",
    isApproved: false,
    activeProjects: 130,
    projects: 285,
    description: "Full ecommerce solution, manage products, inventory, orders, etc.",
    readme:
      'This boilerplate is a all in one medusajs 2.0 e-commerce webshop solution, it comes preconfigured with both backend + admin dashbord and connected to the "storefront" (webshop frontend). \n\nLimited to 5 services, for free users!\n\nFor full version, checkout: https://railway.com/template/gkU-27\n\nUpdated to v2.6.1 ü§© 3rd April 2025\n\nVideo instructions\nalt text\n\nAdditional information and instructions\nInstructions: https://funkyton.com/medusajs-2-0-is-finally-here/\n\nGitHub: https://github.com/rpuls/medusajs-2.0-for-railway-boilerplate\n\n\n',
    name: "Medusajs 2.0 + Storefront (TRIAL)",
    category: "Other",
    health: 68,
    code: "Fb6KUX",
    languages: ["TypeScript", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e982715d-bd6f-4cea-8543-0fa15383328c",
    isApproved: false,
    activeProjects: 10,
    projects: 19,
    description: "Latest apache superset...",
    readme:
      "Apache Superset has Docker images for deployment but the setting of the admin user requires executing code in the container. That is not possible to set up in a Railway template. This modification supports the creation of the admin user through setting of environment variables.\n",
    name: "apache-superset-v2",
    category: "Observability",
    health: 100,
    code: "954W6r",
    languages: ["Dockerfile", "Shell", "Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "eedab5eb-292f-479f-a579-2df686a216d0",
    isApproved: false,
    activeProjects: 94,
    projects: 170,
    description: "Open Source Browser API for AI Agents & Apps.",
    readme:
      "Steel.dev is an open-source browser API that makes it easy to build AI apps and agents that interact with the web. Instead of building automation infrastructure from scratch, you can focus on your AI application while Steel handles the complexity.\n\nThe only things that need to be changed for this to be easily spun out and used in prod is custom subdomain/domain mapping after launching.\n\nYou can do that in the settings for either the UI service, the API service, or both!",
    name: "Steel Browser",
    category: "Automation",
    health: 80,
    code: "FQG9Ca",
    languages: ["TypeScript", "EJS", "CSS", "JavaScript", "Shell", "Dockerfile", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "997f372b-8344-4d90-9c98-df958a50bd61",
    isApproved: false,
    activeProjects: 2,
    projects: 8,
    description: "A railway template to deploy Phase Secrets Manager.",
    readme:
      "Phase is an open source platform for fast-moving engineering teams to secure and deploy application secrets ‚Äî from development to production.\n\nWebsite: https://phsae.dev\n\nGitHub: https://github.com/phasehq/console\n\nDocs: https://docs.phase.dev\n\nSlack: https://slack.phase.dev\n",
    name: "Phase Console",
    category: "Other",
    health: 100,
    code: "FgdM-Z",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c73af923-9b35-4c73-8e6c-589940b93089",
    isApproved: false,
    activeProjects: 1,
    projects: 2,
    description: "Transform your Bento profile with a personalized domain name",
    readme:
      "Create a Railway account if you don't have one.\nClick the button below to deploy using this repo as a template:\nDeploy on Railway\nRailway will automatically detect the project and set up the necessary environment.\nYou'll be prompted to configure environment variables:\n   BENTO_USERNAME: Your Bento username\nClick \"Deploy\" to start the deployment process.\nOnce deployed, you'll get a URL to access your Bento profile with a custom domain.",
    name: "bento",
    category: "Blogs",
    health: null,
    code: "6fVSiZ",
    languages: ["TypeScript", "Dockerfile", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "fae49c2b-3a6c-45a1-bdfa-f057ae73643f",
    isApproved: false,
    activeProjects: 3,
    projects: 3,
    description: "A Tool that generates a customized SVG for in your Github profile readme",
    readme:
      "Deploy this app on Railway, fill in the .env variables with your GitHub info, and use the generated URL in your GitHub repository. Create a README.md file in a repo matching your GitHub username, and add:\n\nHeader\n\nCustomize further using environment variables. Feel free to contribute on Github!",
    name: "GithubReadmeGenerator",
    category: "Other",
    health: null,
    code: "FA69vd",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "110e4a52-7210-4f70-9c6c-2b4b5b0e2aa7",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "Generate a Zoom Cobrowse SDK JWT to join Zoom Cobrowse SDK sessions",
    readme:
      'Zoom Cobrowse SDK Auth Endpoint sample\n\nUse of this sample app is subject to our Terms of Use.\n\n\nThis is a Node.js / Express server that generates a Cobrowse SDK JWT via an HTTP request for authorized use of the Zoom Cobrowse SDK.\n\nUsage\n\nMake a POST request to http://localhost:4000 (or your deployed url) with the following request body:\n\n| Property                 | Type     | Required? | Validation Rule(s)                                                    |\n| ------------------------ | -------- | --------- | --------------------------------------------------------------------- |\n| role                   | number | Yes   | - Required  - Must equal to 1 or 2                            |\n| expirationSeconds      | number | No        | - Must be between 1800 (30 minutes) and 172800 (48 hours) seconds |\n| userId                 | string | No        | - Please ensure that the user ID is not repeated within a session     |\n| userName               | string | No        |                                                                       |\n\n&gt; Note: userId is required to create a JWT, if not provided a random string will be used.\n\nExample Request\n\nPOST http://localhost:4000\n\nRequest Body:\n\n{\n  "role": 1,\n  "userId": "user123",\n  "userName": "ekaansh"\n}\n\nIf successful, the response body will be a JSON representation of your token:\n\n{\n  "token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhcHBfa2V5IjoiM2YzV0pkZ0FTZC0xN1VZTl9ZSmFQQSIsInJvbGVfdHlwZSI6MCwiaWF0IjoxNzI5MTU5MDkyLCJleHAiOjE3MjkxNjYyOTIsInVzZXJfaWQiOiJ1c2VyMTIzIn0.cVMgCnb5fJzhGr2nTowlYWojAdYiH2INMUhh5v2WTos"\n}\n\nIn the Cobrowse SDK, for the agent you can pass in the token to the ACCESS_TOKEN in your iframe. \n\n\n`html\n',
    name: "Zoom CobrowseSDK Auth Sample",
    category: "Other",
    health: null,
    code: "OjTGvs",
    languages: ["JavaScript", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4e0fa886-a35a-438b-9fe0-a7a8f486a986",
    isApproved: false,
    activeProjects: 6,
    projects: 10,
    description: "Indonesia administrative area API üáÆüá© built with Nest.js + Prisma",
    readme:
      "Overview\n\nidn-area is an API that provides information on the administrative areas of Indonesia, from the province, regency, district, to village levels. It also provides island data since version 1.1.0.\n\nBuilt with NestJS framework and writen in TypeScript. Prisma is used as the ORM to interact with any kind of databases*\n\nIn this template, *PostgreSQL** is used by default. You can replace it with another supported database providers. Don't forget to update the environment variables!\n\nLearn More\n\nDocumentation",
    name: "idn-area API",
    category: "Starters",
    health: 33,
    code: "9Tcyq9",
    languages: ["TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "48413eb9-0cf1-45a6-8ead-f57f55dfe714",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "A Lightweight, Production-Ready Remix Stack for your next SaaS Application.",
    readme:
      "\n  üõçÔ∏è Remix SaaS\n\n\n\n  \n  A Lightweight, Feature-Rich, and Production-Ready Remix Stack for your next SaaS application.\n  \n\n\n\n  \n    Live Demo\n    ¬∑\n    Documentation\n    ¬∑\n    Twitter\n  \n\n\nnpx create-remix-saas@latest\n\nLive Demo\n\nDeploy on Railway\n\nWe've created a simple demo that displays all template-provided features.\n\n&gt; !NOTE]\n&gt; Remix SaaS is an Open Source Template that shares common bits of code with: [Indie Stack, Epic Stack, Supa Stripe Stack, and some other amazing Open Source Remix resources. Check them out, please!\n\nGetting Started\n\nPlease, read the Getting Started Documentation to successfully initialize your Remix SaaS Template.\n\nSupport\n\nIf you found Remix SaaS helpful, consider supporting it with a ‚≠ê Star. It helps the repository grow and provides the required motivation to continue maintaining the project. Thank you!\n\nAcknowledgments\n\nSpecial thanks to @mw10013 who has been part of the Remix SaaS development.",
    name: "remix-saas",
    category: "Starters",
    health: null,
    code: "Bw4Gck",
    languages: ["TypeScript", "JavaScript", "CSS", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d4847efe-0b06-4586-9330-625744baa623",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "A lightweight API for identicon generation.",
    readme:
      "Altar is a tiny API that generates identicons.\n\nüìò Read the docs here: https://github.com/berrysauce/altar\n\nIdenticons are visual representations of data, that serve the purpose of identifying someone or something (Wikipedia).\n\nAltar always generates the same image from the same input through hashing and simple calculations. This means that you can use Altar to generate profile pictures for users based on their username or any other unique identifier.\n\nAltar was built from the ground up with minimal dependencies but is inspired by GitHub's Identicons and minidenticons.",
    name: "altar",
    category: "Other",
    health: null,
    code: "acMcnw",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d38b8533-4f51-4650-b958-12b2e6a3a632",
    isApproved: false,
    activeProjects: 6,
    projects: 18,
    description: "new & improved strapi official demo app, deployed in 1 click",
    readme:
      "LaunchPad: The new Official Strapi Demo App\nLaunchPad isn‚Äôt just an upgrade to Strapi 5 and Nextjs 14 ‚Äîit‚Äôs a complete redesign of the frontend with TailwindCSS and Aceternity. Built with a cleaner structure and more modern UI components LaunchPad gives you a great overview of what using Strapi looks and feels like for backend, frontend development and content management. Whether you're new to Strapi or have been using it for a while, LaunchPad will help you better understand how Strapi can adapt to fit projects of all sizes.\n\nWhat LaunchPad Offers and How It Improves on FoodAdvisor\nLaunchPad is packed with essential features to help you explore Strapi, along with several key improvements over FoodAdvisor. Here‚Äôs what you can expect:\n\nWhat‚Äôs Included in LaunchPad:\nPre-configured Strapi setup: LaunchPad is ready to use out of the box, with everything you need to get started, from content creation to API interactions.\nComplete content workflows: It comes with built-in demonstrations of Strapi‚Äôs collection and single types, components, dynamic zones, internationalization (i18n), and media library. Everything is pre-configured so you can explore without any extra setup.\nRole-based access control (RBAC): Manage user permissions with ease, simulating how you would control access in a real-world application.\nInternationalization (i18n): Create and manage content in multiple languages and regions, with pre-configured examples to show you how it works in practice.\nWhat‚Äôs Improved Over FoodAdvisor:\nNew Strapi 5 Features: LaunchPad introduces key updates like Content History, letting you easily track changes and revert to previous versions of your content. The upgraded Draft & Publish system allows for smoother content management‚Äîwork on drafts and only publish when everything‚Äôs ready. These tools give you more control over your workflow, making revisions and publishing simpler.\nRebuilt Next.js Application: We've reworked the demo app using the Aceternity UI to show what a Strapi-powered site can really do. In collaboration with Manu Arora, founder of Aceternity , we built a brand-new frontend with a theme that better reflects Strapi today. This custom app connects seamlessly with Strapi to power the new official Strapi 5 demo.\n100% TypeScript: Unlike FoodAdvisor which is full JavaScript, LaunchPad is fully written in TypeScript as it's based on Strapi 5 which has moved from being written in plain JavaScript to being almost entirely TypeScript.\nThese updates make LaunchPad a more powerful, flexible, and practical demo for developers who want to see Strapi‚Äôs full capabilities in action.\n\nAnd the best part is that it's fully open source. Check out the LaunchPad repository on GitHub and feel free to give it a ‚≠ê if you like what you see!",
    name: "LaunchPad [Strapi Starter]",
    category: "Other",
    health: 0,
    code: "84HU7D",
    languages: ["TypeScript", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "982c0cf9-1cea-4c7a-826d-1a663a17b31a",
    isApproved: false,
    activeProjects: 5,
    projects: 19,
    description: "Open source implementation of the Turborepo custom remote cache server.",
    readme:
      'üöÇ Self-Hosted Turborepo Remote Cache on Railway\n\nDeploy a secure, self-hosted Turborepo remote cache on Railway with just a few clicks. This alternative provides you full control over your build cache infrastructure. üîí\n\nSetup Guide \n\n1. Deploy to Railway with One Click üéØ  \nDeploy to Railway by clicking the big purple Deploy Now button \n\n2. Configure Turborepo Project üõ†Ô∏è\n\nAfter deploying, you\'ll need to configure your Turborepo project to use the new remote cache:\n\nOpen your Railway project we just deployed\nSelect the service with the Turborepo logo\nNavigate to the "Variables" tab\nCopy these required environment variables:\n  TURBO_TOKEN: Authentication token\n  TURBO_API_URL: Remote cache endpoint\n\n3. Update Turborepo Configuration üìù\n\nTime to modify your code to use the remote cache, but trust me, it\'s easy.  \nSet the following environment variables that you copied from the Railway project we just deployed:\n\nWhen deploying your code on the same Railway project as this template, you can use ${{"Turborepo Remote Cache".TURBO_TOKEN}}\nTURBO_TOKEN={TURBO_TOKEN}\nWhen deploying your code on the same Railway project as this template, you can use ${{"Turborepo Remote Cache".TURBO_API_URL}}\nTURBO_API={TURBO_API_URL}\nLeave this as is\nTURBO_TEAM=railway-remote-cache\n\nAnd in case you prefer .env file instead of filling out those env variables in your shell everytime, you can use the dotenv-cli package.  \nModify the build script in your package.json root to include the following:\n\ndotenv -e .env -- turbo build\n\n4. Use Remote Cache üéâ\n\nRun your Turborepo commands as normal. The remote cache will be automatically utilized:\n\nturbo build\nYou can verify the remote cache is working by checking your Turborepo build logs. When successful, you\'ll see:\n\nRemote caching enabled\n\nTroubleshooting üîç\n\nCommon Issues\nVerify Railway deployment is running and accessible\nDouble-check that your token and API URL are correctly configured\nTest the setup using the example reference project to validate configuration and rule out any potential template-specific issues\n\nNeed More Help?\nJoin Railway\'s Discord community for additional support and troubleshooting. ',
    name: "Turborepo Remote Cache",
    category: "Other",
    health: 100,
    code: "tRFTHR",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "dd17f6c1-c91f-4a5d-8864-8c502c09c443",
    isApproved: false,
    activeProjects: 1,
    projects: 6,
    description: "Build your own web3 individual blog",
    readme:
      "PenX is an open-source platform designed to create self-hosted Web3 blogs within the Ethereum ecosystem. When you build a blog site on PenX, you'll have access to a wide range of exciting features and opportunities.\n\nFor instance, we provide a more efficient transaction environment. Moreover, with your Web3 blogs, you'll enjoy greater autonomy in interactions and content monetization. You can independently integrate ads, gaining a higher share of revenue. Through equity distribution, you and your community can participate in the blog's growth, enhancing interaction and loyalty.",
    name: "PenX",
    category: "Blogs",
    health: 100,
    code: "wuSyrf",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0c500eec-0096-4de1-962b-beec636a4a90",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "A free and open source design feedback and presentation platform.",
    readme:
      "One click install\n\nPresentator is free and open source design feedback and presentation platform.\n\nIt can be used directly via the free hosted service at app.presentator.io or self host it on your own server via a single executable.\n\nStep 1:\nInstall template\n\nStep 2:\nSetup super user account \n/_\n\nStep 3:\nGo to Pocketbase mail settings \n/_/#/settings/mail\n\nStep 4:\nCreate your first user account ``\n\nDocs:\nhttps://github.com/presentator/presentator/blob/master/README.md\n",
    name: "Presentator",
    category: "Other",
    health: null,
    code: "jeXlHI",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "97de9743-45bb-437b-9c54-e986d9a5e33e",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "A Docker to backup your PostgreSQL database to Minio via a cron.",
    readme:
      'Postgres Minio backups\n\nA Docker to backup your PostgreSQL database to Minio via a cron.\n\nOverview\n\nThe template use Docker and Bash Scripting to dump your PostgreSQL data to a file and then upload the file to Minio.\n\nConfiguration\n\nMINIO_ENDPOINT - Minio endpoint. Example: http://minio:9000.\n\nACCESS_KEY - Minio access key.\n\nSECRET_KEY - Minio secret key.\n\nMINIO_BUCKET - Minio bucket. Example my-bucket.\n\nBACKUP_DATABASE_URL - The connection string of the database to backup. Example: "postgresql://username:password@host:port/database"\n\nCRON_SCHEDULE - The cron schedule to run the backup on. Example: 0 5 * * * the cron runs at 5 AM every day\n\nRestore data\n\nRestore your data to the target database with pg_restore\n\npg_restore -v -d postgres_connection_string filename.bak\n',
    name: "Postgres Minio Backups",
    category: "Automation",
    health: null,
    code: "7VQo0T",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "51bcfb88-c8b6-4e93-b0ae-db3ab95f1522",
    isApproved: false,
    activeProjects: 169,
    projects: 306,
    description: "AI-Powered Full-Stack Web Development in the Browser",
    readme:
      "Bolt.new - AI-Powered Full-Stack Web Development\nTLDR: Build complete websites/apps by chatting with AI assistnat - no coding experience needed.\n\nWhat is Bolt.new?\nImagine having a smart coding assistant that understands plain English and can build websites for you right in your browser. That's Bolt.new! No need to install anything on your computer - just open your browser, tell it what you want to build, and watch it happen.\n\nCore Features Explained Simply\n\nüìù Talk to Build\nJust describe what you want to build in plain English\nThe AI understands and creates the code for you\nNeed changes? Simply ask, and it will modify the code\n\nüîß Everything Happens in Your Browser\nNo complicated setup needed\nSee your website come to life instantly\nMake changes and watch them update in real-time\nShare your work with others using a simple link\n\nüöÄ Complete Website Building\nCreates both what users see (frontend) and how it works (backend)\nCan add features like user login, databases, and more\nInstalls all necessary tools automatically\nCan put your website online with one click\n\n‚≠ê What's Enhanced in This Version?\nNo Limits: Use it as much as you want without restrictions\nMultiple AI Options: Choose from OpenAI, Anthropic, Groq, Gemini, OpenRouter, or Ollama\nQuick Setup: Just add your preferred AI service key and start building\n\nWho Is It For?\nBeginners learning to code\nAnyone wanting to build websites quickly\nDevelopers trying out new ideas\nTeams needing quick website prototypes\n",
    name: "bolt.diy",
    category: "AI/ML",
    health: 56,
    code: "C--NRV",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "22d06e28-a863-4668-9f89-69fc34a1debf",
    isApproved: false,
    activeProjects: 85,
    projects: 134,
    description: "A simple ExpressJS app starter.",
    readme:
      "Overview\n\nExpress is a Fast, unopinionated, minimalist web framework for  Node.js. \n\nWith a myriad of HTTP utility methods and middleware at your disposal, creating a robust API is quick and easy.\n\nExpress provides a thin layer of fundamental web application features, without obscuring Node.js features that you know and love.\n\nHighlights\nStarts an ExpressJS server",
    name: "ExpressJS",
    category: "Starters",
    health: 95,
    code: "Y6zLKF",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0ba7cdf4-4ecc-4ac3-bf4c-986162f327cb",
    isApproved: false,
    activeProjects: 10,
    projects: 39,
    description: "A Django app connected to a Postgres database with Celery and Celery Beat.",
    readme:
      "Overview\n\nDjango is a high-level Python web framework that encourages rapid development and clean, pragmatic design. Built by experienced developers, it takes care of much of the hassle of web development, so you can focus on writing your app without needing to reinvent the wheel. It‚Äôs free and open source.\n\nThis Django starter template deploys a Django app as a majestic monolith that is connected to a PostgreSQL database and Redis Cache on Railway.\n\nIt spins up 5 services (with the same codebase) in one project. They are:\n\napp service: This runs the app.\n\nworker service: This runs the Celery workers.\n\ncron service: This runs Celery Beat and takes care of all cron tasks.\n\nPostgres: This is the PostgreSQL database that the app is connected to.\n\nRedis: This is the queue and cache store/database that the app is connected to.\n\nHighlights\nRidiculously fast\nReassuringly secure\nExceedingly scalable\nFully loaded\nIncredibly versatile",
    name: "Django Monolith",
    category: "Starters",
    health: null,
    code: "yZDfUu",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a06b9e03-0756-4ebd-932c-429a12f2a117",
    isApproved: false,
    activeProjects: 64,
    projects: 79,
    description: "An ExpressJS app using the Pug view engine connected to a Postgres database",
    readme:
      "ExpressJS Example\n\nThis example starts an ExpressJS server using a Pug view engine connected to a Postgres database.\n\n‚ú® Features\n\nExpress\nJavaScript\nPug\nDatabase\n\nüíÅ‚Äç‚ôÄÔ∏è How to use\n\nInstall dependencies npm install\nConnect to your Railway project railway link\nStart the server railway run npm start\n\nüìù Notes\n\nThe server started returns a timestamp from the database via a page using the Pug view engine.",
    name: "ExpressJS",
    category: "Starters",
    health: 100,
    code: "BC51z6",
    languages: ["JavaScript", "Pug", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "81d16c9f-45b0-4a1e-a254-d3515a6ef0a3",
    isApproved: false,
    activeProjects: 1,
    projects: 10,
    description: "Unify files from all devices and clouds in a single, easy-to-use explorer.",
    readme:
      "Spacedrive is an open source cross-platform file explorer, powered by a virtual distributed filesystem written in Rust.\n\nOrganize files across many devices in one place. From cloud services to offline hard drives, Spacedrive combines the storage capacity and processing power of your devices into one personal distributed cloud, that is both secure and intuitive to use.\n\nFor independent creatives, hoarders and those that want to own their digital footprint, Spacedrive provides a free file management experience like no other.\n\nDocumentation:\nFor more information, Visit Spacedrive Docs\n\nFeatures\n\nExperience the ultimate in file management with Spacedrive. Below is a detailed list of our current features and what we're bringing to you in the near future.\n\nLibraries: Create and manage Libraries.\n\nExplorer: Navigate files by Locations, Tags, Spaces, Albums, or via Search.\n\nLocations: Designate Spacedrive's search locations. Any file detected in a Location gets incorporated into your Library database, subject to customizable filtering rules.\n\nCloud Locations: Integrate cloud accounts into a Library.\n\nOverview Statistics: Analyze unique file categories via the Overview screen.\n\nTags: Design and attach them to files, or explore tagged files directly from the sidebar.\n\nSpaces: A collaborative tool to organize and showcase files.\n\nPhoto Albums:\n  Importing albums from Google Photos, Apple Photos.\n  Create albums from scratch.\n\nLibrary statistics: Gain insights into total capacity, database size, preview media space, and available storage.\n\nSearch: Instantly look up your Library via the search bar or using CTRL+F.\n\nSpacedrop: A user-friendly method to transfer files across devices, either locally or over the internet. \\*\n\nThemes: Light and dark modes available with an option for system synchronization.\n\nA collection of 48 distinct icons tailored for different file types.\n\nCompatible with over 250 file types, powered by \"magic byte\" recognition.\n\nIntegrated update installer for seamless software upgrades.\n\nOptional telemetry and local logs.",
    name: "SpaceDrive",
    category: "Storage",
    health: 100,
    code: "oZ13es",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "871934a1-ff8c-41f3-8ca4-630db3443471",
    isApproved: false,
    activeProjects: 7,
    projects: 17,
    description: "Basic Sveltekit and Pocketbase Starter with Docker",
    readme:
      "Basic Sveltekit and Pocketbase Starter with Docker and Svelte 5 + Sveltekit 2.\n\nSveltekit comes with:\nTypescript\neslint & prettier\nTailwindCSS\nHusky for pre-commit hooks\n\nIf you have any questions regarding setup or you have trouble starting this just email me: jarmo@exord.de\n\nHappy coding!",
    name: "Sveltekit Pocketbase Starter",
    category: "Other",
    health: 100,
    code: "dyM12l",
    languages: ["JavaScript", "Dockerfile", "TypeScript", "HTML", "Svelte", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a8a29e6e-8641-48e0-9d65-7a384fa3b2e3",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "Build, document, and showcase your React components in a UI library",
    readme:
      "Storybook Template\n\nOverview\nA production-ready template that turns your React (NextJS) components into a static component library, giving your team a permanent URL to browse and reference your UI components.\n\nHighlights\nZero-configuration deployment\nAutomatic rebuilds on every push\nStatic hosting for fast component browsing\nPre-configured Storybook 8 setup\nBuilt on Next.js 14 with TypeScript and Tailwind\nFull component isolation and documentation\nPerfect for teams needing a component showcase\n\nLocal Development\n\nInstall dependencies\nnpm install\n\nRun Storybook development server\nnpm run storybook\n\nBuild Storybook for production\nnpm run build-storybook\n\nLearn More\nStorybook\nDocumentation\n\nNote\nThe template deploys as a static build, meaning your component library loads instantly without any server-side rendering or database needs. Each deploy creates a new static build, ensuring your component library always stays in sync with your codebase.",
    name: "Storybook",
    category: "Starters",
    health: null,
    code: "kIt8FT",
    languages: ["TypeScript", "MDX", "CSS", "Dockerfile", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8b621b32-e00e-4c26-958a-30fd7f1aa65f",
    isApproved: false,
    activeProjects: 20,
    projects: 47,
    description: "A simple Symfony app that is connected to a Postgres database",
    readme:
      'Symfony Starter App\n\nThis is a Symfony starter app that connects to a Postgres database.\n\nDeploy on Railway\n\n‚ú® Features\n\nPHP\nSymfony\nPostgres\n\nThis setup deploys your Symfony app on Railway, ensuring that your database, scheduled tasks (crons), and queue workers are all fully operational.\n\nThe deployment structure follows a "majestic monolith" architecture, where the entire Symfony app is managed as a single codebase but split into four separate services on Railway:\nApp Service: Handles HTTP requests and user interactions.\nCron Service: Manages scheduled tasks (e.g., sending emails or running reports).\nWorker Service: Processes background jobs from the queue.\nDatabase Service: Stores and retrieves your application\'s data.\n\nSymfony architecture\n',
    name: "Symfony",
    category: "Starters",
    health: 63,
    code: "4tnH_D",
    languages: ["PHP", "Shell", "JavaScript", "Twig", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "56ebdf27-9a49-4f9b-9885-191934552d60",
    isApproved: false,
    activeProjects: 2,
    projects: 9,
    description: "AI-powered search, perplexity-clone, works with openrouter API",
    readme:
      "morphic [w/ openrouter]\n\nA powerful AI search assistant that combines real-time web search with multiple AI models, similar to Perplexity.ai. Get accurate, up-to-date answers powered by leading language models through a single unified interface.\n\n‚ú® Features\n\nüîç AI-Powered Search: Utilizes Tavily's advanced search API for real-time, accurate web results\nü§ñ Multiple AI Models: Access leading AI models through OpenRouter:\n  OpenAI GPT models\n  Anthropic Claude\n  Google Gemini\nüí° Smart Context: Combines search results with AI responses for comprehensive answers\nüöÄ One-Click Deploy: Easy setup on Railway.app\n\nüîß Requirements\n\nOpenRouter API key (for accessing multiple AI models) https://openrouter.ai\nTavily API key (for web search capabilities) https://tavily.com",
    name: "morphic [with openrouter]",
    category: "Other",
    health: 100,
    code: "4VuDks",
    languages: ["TypeScript", "CSS", "JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "75158a90-e887-42c6-b343-04e880e23c13",
    isApproved: false,
    activeProjects: 21,
    projects: 45,
    description: "virtual hand-drawn style whiteboard. Collaborative and end-to-end encrypted",
    readme:
      "1-Click Excalidraw with Collaboration\n\nOverview:\n\nDeploy Excalidraw with real-time collaboration powered by excalidraw-room in one click. This setup includes both the Excalidraw frontend and the excalidraw-room server, fully configured and ready for secure, private sketching sessions with end-to-end encryption.\n\nComponents:\n\t‚Ä¢\tExcalidraw Frontend: A web-based drawing application for sketches and diagrams.\n\t‚Ä¢\tExcalidraw-Room Server: Enables collaborative sessions by relaying encrypted messages between users.",
    name: "Excalidraw (with collaboration)",
    category: "Other",
    health: 92,
    code: "f7vLxp",
    languages: ["TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "32a3abfe-49e5-4226-89fb-cafaa60c3d83",
    isApproved: false,
    activeProjects: 3,
    projects: 7,
    description: "simple & secured file sharing - (minio S3 included)",
    readme:
      "Send + MinIO\n\nThis template sets up a full deployment of the ‚ÄúSend‚Äù file-sharing service on Railway, designed for quick and secure sharing of files. It includes MinIO, an open-source object storage solution with an S3-compatible API, for file storage and management, allowing for robust and scalable storage similar to AWS S3.\n\nFeatures:\n\n\t‚Ä¢\tSend File Sharing Service: A privacy-focused file-sharing service based on Mozilla‚Äôs Send, enabling secure and temporary file sharing.\n\t‚Ä¢\tMinIO S3 Storage: Provides scalable object storage with an S3-compatible API, offering seamless storage integration for Send‚Äôs file uploads.\n\t‚Ä¢\tEase of Deployment: Quickly deploy Send with MinIO using Railway‚Äôs infrastructure, allowing easy setup and management without handling servers.\n\nConfiguration:\n\n\tAccess the MinIO Console: After deploying, navigate to the MinIO console (usually accessible through Railway‚Äôs dashboard) to manage storage settings.\n\tCreate a New Bucket: In the MinIO console, create a bucket for storing uploaded files. This bucket will serve as the storage location for Send‚Äôs file uploads.\n\tConfigure Send with MinIO Bucket Information:\n\t‚Ä¢\tTake note of the bucket name, access key, secret key, and endpoint information from the MinIO console.\n\t‚Ä¢\tIn Railway, go to the environment variables for Send and enter these details:\n\tAdjust Additional Settings: Customize settings such as file size limits and expiry times in the Railway environment variables for Send to meet your specific needs.",
    name: "Send",
    category: "Other",
    health: 83,
    code: "_-SCIg",
    languages: ["JavaScript", "HTML", "CSS", "Kotlin", "Swift", "Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d83cf8cd-5255-4d5d-9f0f-ba07f74d099c",
    isApproved: false,
    activeProjects: 1,
    projects: 1,
    description: "A simple Beego app connected to a Postgres database.",
    readme:
      "Beego Starter\n\nA Beego (Golang) starter app connected to a Postgres database.\n\n‚ú® Features\n\nBeego\nGo\n\nüíÅ‚Äç‚ôÄÔ∏è How to run locally\n\nRun go mod tidy to install all the dependencies.\nRun bee run to start the app.\n\nüìù Notes\n\nOnce the app is run, a user table is created and seeded with data. You can find the details in the main.go file.",
    name: "Beego",
    category: "Starters",
    health: null,
    code: "CPq9Ry",
    languages: ["Smarty", "Go"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "86eaf02b-9b7c-4b33-8ab3-d58a8aebe8f1",
    isApproved: false,
    activeProjects: 5,
    projects: 31,
    description: "Open-source notification infrastructure",
    readme:
      "Novu Self-Hosted Template for Railway\n\nOverview\nNovu is an open-source notification infrastructure designed for developers who need powerful, flexible notification capabilities in their applications. This template deploys a self-hosted version of Novu, providing complete control over your notification infrastructure while maintaining the ease of use that Novu is known for. Perfect for teams that need to manage complex notification workflows across multiple channels while keeping their data within their own infrastructure.\n\nFeatures\nPowerful Workflow Engine: Build code-first notification workflows that run within your infrastructure\nMulti-Channel Support: Send notifications across email, SMS, push, and in-app channels through a single API\nBuilt-in Component Library: Ready-to-use notification components including a customizable inbox\nNo-Code Editor: Enable product teams to manage notification content without developer intervention\nType-Safe Operations: End-to-end validation with custom JSON schemas\nUser Preference Management: Built-in support for user notification preferences including language and timezone\nDeveloper-First Architecture: API-first design with complete workflow control\nOpen Source: Full access to the source code with community backing\n\nDeployment Instructions\nClick the \"Deploy on Railway\" button\nConfigure the required environment variables (see below)\nDeploy the service\nAccess your Novu dashboard\n\nImportant Post-Deployment Steps\nNavigate to the Project Settings in Railway\nGo to the \"Networking\" tab\nFind the \"NovuWeb\" service\nLook for the automatically generated public URL\nIf the URL doesn't work:\n   Delete the current public URL\n   Click \"Generate Domain\" to create a fresh public URL\n   Alternatively, attach your custom domain if you prefer\nUse this URL to access your Novu dashboard\nSet up your notification channels and providers\nIntegrate Novu into your application using the provided SDKs\n\nGetting Started\nAfter successful deployment and URL configuration:\nAccess your Novu dashboard through the working public URL\nCreate your first notification template\nSet up your preferred notification providers\nIntegrate the Novu SDK into your application\nSend your first notification using the provided code:\n\nawait novu.trigger('workflow-name', {\n  to: {\n    subscriberId: 'user-id',\n    email: 'user@example.com'\n  },\n  payload: {\n    name: 'John Doe',\n    message: 'Hello world!'\n  }\n});\n\nSecurity Considerations\nSecure your MongoDB and Redis instances\nSet a strong JWT_SECRET\nConfigure appropriate access controls\nEnable authentication for the dashboard\nRegularly update to the latest version\nMonitor your notification workflows\n\nCustomization\nAdd custom notification providers\nImplement custom notification templates\nConfigure workflow rules and conditions\nSet up digest and delay steps\nCustomize the in-app notification center\nImplement custom authentication logic\n\nSupport\nFor issues with the template itself, please each out to me at youssef@reflectfy.com. For Novu-specific questions, refer to the official documentation or join the Novu community.\n\nTroubleshooting\nIf you can't access the dashboard after deployment, verify that the public URL is properly generated\nEnsure all environment variables are correctly set\nCheck Railway logs for any deployment errors\nVerify that both the API and Web services are running\nIf using a custom domain, ensure DNS settings are properly configured\n\nBuild powerful notification experiences with Novu!",
    name: "Novu",
    category: "Other",
    health: 94,
    code: "U3QiXi",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "86ddf8ae-c86e-40a0-ae7b-ba71c61521df",
    isApproved: false,
    activeProjects: 91,
    projects: 271,
    description: "Preconfigured as website builder CMS. Using postgreSQL",
    readme:
      'This is a payload CMS V3 created using npx create-payload-app@latest with the "website" starter, and have been updated to 3.4.0 on 07th December 2024.\n\nVideo demo and tutorial\nalt text\n\nThis template has been adjusted to use a postgreSQL database instead of mongodb.\n\nRead more: https://funkyton.com/payload-cms/\nAbout Payload: https://payloadcms.com/',
    name: "Payload CMS V3 (website builder)",
    category: "CMS",
    health: 92,
    code: "L8TUlT",
    languages: ["TypeScript", "JavaScript", "CSS", "SCSS", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0daa60a3-7b58-459a-ba59-366b77096b88",
    isApproved: false,
    activeProjects: 4,
    projects: 6,
    description: "A simple Play framework app connected to a Postgres database.",
    readme:
      "Scala Play Framework Starter\n\nThis is a simple Scala Play framework starter app.\n\nPlay Framework makes it easy to build web applications with Java & Scala.\n\nPlay is based on a lightweight, stateless, web-friendly architecture.\n\nBuilt on Pekko (Play 3) and Akka (Play 2), Play provides predictable and minimal resource consumption (CPU, memory, threads) for highly-scalable applications.\n\n‚ú® Features\n\nPlay\nScala\nPostgres",
    name: "Scala Play",
    category: "Starters",
    health: 100,
    code: "my9q_q",
    languages: ["Scala", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e9c99e9f-a0ea-4ca0-bfad-a354901653ce",
    isApproved: false,
    activeProjects: 12,
    projects: 18,
    description: " A ShareX/file upload server that is easy to use, packed with features!",
    readme:
      '\n  \n\nA ShareX/file upload server that is easy to use, packed with features, and with an easy setup!\n\nFeatures\nConfigurable\nFast\nBuilt with Next.js &amp; React\nToken protected uploading\nImage uploading\nImage compression\nPassword Protected Uploads\nURL shortening\nText uploading\nURL Formats (uuid, dates, random alphanumeric, original name, zws, gfycat -&gt; animals adjectives)\nDiscord embeds (OG metadata)\nGallery viewer, and multiple file format support\nCode highlighting\nFully customizable Discord webhook notifications\nOAuth2 registration (Discord and GitHub)\nTwo-Factor authentication with Google Authenticator, Authy, etc (totp services).\nUser invites\nFile Chunking (for large files)\nFile deletion once it reaches a certain amount of views\nAutomatic video thumbnail generation\n\nDefault Credentials\nThe default credentials are "administrator" and "password". Once you login please immediately change the details to something more secure. You can do this by clicking on the top right corner where it says "administrator" with a gear icon and clicking Manage Account.',
    name: "Zipline",
    category: "Storage",
    health: 85,
    code: "vBGKg3",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4c30f5d1-e3c7-4518-bc48-3aa4137c240c",
    isApproved: false,
    activeProjects: 12,
    projects: 48,
    description: "HeyForm is an open-source form builder",
    readme:
      "HeyForm is an open-source form builder that allows anyone to create engaging conversational forms for surveys, questionnaires, quizzes, and polls. No coding skills required.\n\nFeatures\n\nHeyForm simplifies the creation of conversational forms, making it accessible for anyone to gather information or feedback through engaging surveys, quizzes, and polls. We are committed to enhancing HeyForm with regular updates, including bug fixes, new features, and performance improvements.\n\nBuild Forms with Ease\n\nüìù Versatile Inputs: From basic text, email, and phone number fields to advanced options like picture choices, date pickers, and file uploads, HeyForm supports a wide array of input types.\nüß† Smart Logic: Conditional logic and URL redirections for dynamic, adaptable forms.\nüîó Powerful Integrations: Connect with webhooks, analytics, marketing platforms, and tools like Zapier and Make.com.\n\nCustomize to Your Brand\n\nüé® Visual Themes: Tailor the look and feel of your forms to match your brand identity with customizable fonts, colors, backgrounds, and more.\n‚ú® Advanced Theming: Gain greater control with extensive customization options, including custom CSS for deeper personalization.\n\nAnalyze and Act on Data\n\nüìä Insightful Analytics: Gain insights with detailed analytics, including drop-off rates and completion rates.\nüì§ Data Export: Easily export your form results to CSV for further analysis or integration into your systems.\n\nLicense\n\nHeyForm is open-source under the GNU Affero General Public License v3.0 (AGPL-3.0), you will find more information about the license and how to comply with it here.\n",
    name: "HeyForm",
    category: "Other",
    health: 95,
    code: "qmXJnq",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2c8df328-f0ac-494b-84e1-8a0a5b1e9a7a",
    isApproved: false,
    activeProjects: 1,
    projects: 3,
    description: "A lightweight next-gen data explorer",
    readme:
      "Description\nWhoDB is a lightweight (~20MB), powerful, and user-friendly database management tool designed to streamline your database administration tasks.\nCombining the simplicity of Adminer with enhanced UX and performance, WhoDB is built with GoLang to deliver optimal speed and efficiency.\nWith features like interactive schema visualization and inline editing, WhoDB caters to both small projects and complex enterprise systems.\n\n**WhoDB offers you the opportunity to talk to your data using natural language thanks to our integration with Ollama, ChatGPT, and Anthropic.\nThis feature allows you to perform queries and manage your data through conversation instead of complex SQL.**\n\nKey Features\nConversate With Your Data: No more wasting time crafting complex SQL queries - ask away!\nEnhanced UX: A clean, intuitive interface that‚Äôs easy to navigate.\nBlazing Fast Performance: Built with GoLang for exceptional speed, including table virtualization on the frontend.\nSchema Visualization: Interactive graphs to easily visualize your database schema.\nInline Editing & Preview: Edit and preview data directly in the interface.\nBroad Database Support: Compatible with PostgreSQL, MySQL, SQLite3, MongoDB, Redis, MariaDB, & ElasticSearch.\nScratchpad: A Jupyter notebook-like interface for performing database queries.\n\nFor AI capabilities deploy the Ollama template and consult the WhoDB docs",
    name: "WhoDB",
    category: "Observability",
    health: null,
    code: "AbKZJq",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d1c15cc4-db0e-4a96-a4fb-07644242b4ad",
    isApproved: false,
    activeProjects: 2,
    projects: 2,
    description: "A simple Clojure Luminus app connected to Postgres database",
    readme:
      "Clojure Luminus Starter\n\nThis is a Luminus starter app that connects to a Postgres database on Railway.\n\nDeploy on Railway\n\n‚ú® Features\n\nClojure\nLuminus\nPostgres",
    name: "Clojure Luminus",
    category: "Starters",
    health: 75,
    code: "DsDYI2",
    languages: ["Clojure", "HTML", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "81c43ee5-0ec2-4b1c-b1ee-3ebedd6d9ede",
    isApproved: false,
    activeProjects: 0,
    projects: 3,
    description: "A quick setup for syncing data from PostgreSQL to Meilisearch",
    readme:
      "Railway Template: Meilisync Integration\n\nThis template provides a streamlined setup for integrating PostgreSQL with a Meilisearch instance using Meilisync for data synchronization. It is designed for straightforward configuration, enabling a quick connection between a PostgreSQL database and Meilisearch without extra dependencies like an admin-dashboard or Redis for progress tracking.\n\nKey Features:\nConfigurable Setup: Modify the configuration file located at /sync/config.yml in GitHub to adjust synchronization parameters for specific data and indexing needs.\nIndexing with Meilisearch: Ensures that the target index is created and synchronized in the connected Meilisearch service or instance using Meilisync\nDatabase Compatibility: Includes PostgreSQL pre-requisites, based on Railways PostgreSQL 16 with SSL Template\nBring Your Own Meilisearch Instance: This template requires an existing Meilisearch instance, so users will need to connect their own service.\n\nSetup Instructions:\nConfigure: Follow the setup instructions from Meilisync's GitHub repository to configure and verify the setup.\n\nVerify: Ensure that the required table exists in PostgreSQL and that /sync/config.yml is correctly configured for synchronization requirements. You might get a strange error & service crash if this is not done.\n\nAdditional Information\n\nFor more details on using templates and deploying services on Railway, see Railway's Documentation. To modify the config.yml file for Meilisync, consider ejecting the repository under settings.\n\nThis template is a straightforward setup for synchronizing PostgreSQL data with Meilisearch while utilizing Railway‚Äôs deployment infrastructure. Hope you enjoy!",
    name: "PostgreSQL to Meilisearch Sync",
    category: "Storage",
    health: null,
    code: "GWvjtt",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8098b041-e8e6-4754-b936-db1993cf0b71",
    isApproved: false,
    activeProjects: 1,
    projects: 9,
    description: "Open-source database diagrams editor, and visualize DB with a single query",
    readme:
      '\n  \n\n\n\n  Open-source database diagrams editor \n  No installations ‚Ä¢ No Database password required.\n\n\n\n  Community  ‚Ä¢\n  Website  ‚Ä¢\n  Demo\n\nüéâ ChartDB\n\nChartDB is a powerful, web-based database diagramming editor.\nInstantly visualize your database schema with a single "Smart Query." Customize diagrams, export SQL scripts, and access all features‚Äîno account required. Experience seamless database design here.\n\nWhat it does:\n\nInstant Schema Import\n    Run a single query to instantly retrieve your database schema as JSON. This makes it incredibly fast to visualize your database schema, whether for documentation, team discussions, or simply understanding your data better.\n\nAI-Powered Export for Easy Migration\n    Our AI-driven export feature allows you to generate the DDL script in the dialect of your choice. Whether you‚Äôre migrating from MySQL to PostgreSQL or from SQLite to MariaDB, ChartDB simplifies the process by providing the necessary scripts tailored to your target database.\nInteractive Editing\n    Fine-tune your database schema using our intuitive editor. Easily make adjustments or annotations to better visualize complex structures.\n\nStatus\n\nChartDB is currently in Public Beta. Star and watch this repository to get notified of updates.\n\nSupported Databases\n\n‚úÖ PostgreSQL\n‚úÖ MySQL\n‚úÖ SQL Server\n‚úÖ MariaDB\n‚úÖ SQLite\n‚úÖ ClickHouse\n\nTry it on our website\n\nGo to ChartDB.io\nClick "Go to app"\nChoose the database that you are using.\nTake the magic query and run it in your database.\nCopy and paste the resulting JSON set into ChartDB.\nEnjoy Viewing &amp; Editing!\n\nüíö Community &amp; Support\n\nDiscord (For live discussion with the community and the ChartDB team)\nGitHub Issues (For any bugs and errors you encounter using ChartDB)\nTwitter (Get news fast)\n\nLicense\n\nChartDB is licensed under the GNU Affero General Public License v3.0',
    name: "ChartDB",
    category: "Automation",
    health: 100,
    code: "fnMtKA",
    languages: ["TypeScript", "JavaScript", "CSS", "HTML", "Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "87320c97-720b-4d3d-92db-a69de83685e6",
    isApproved: false,
    activeProjects: 4,
    projects: 71,
    description: "Create beautiful forms and share them anywhere.",
    readme:
      "OpnForm\n\n‚ö†Ô∏è After deploying, add a public domain in ingress pointing to port 80. Also restart the ingress container as it might fail because it depends on the other ones ‚ö†Ô∏è\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpnForm is an open-source form builder.\n\nGet Started\n\nThe easiest way to get started with OpnForm is to sign up for our managed service in the Cloud. You get support, backups, upgrades, and more. Your data is safe and secure, and you don't need to worry about maintenance or infrastructure. Check out our quick overview of cloud vs self-hosting.\n\nKey Features\n\nüöÄ No-code builder with unlimited forms &amp; submissions\nüìù Various input types: Text, Date, URL, File uploads &amp; much more\nüåê Embed anywhere\nüìß Email notifications\nüí¨ Integrations (Slack, Webhooks, Discord)\nüß† Form logic &amp; customization\nüõ°Ô∏è Captcha protection\nüìä Form analytics\n\nFor a complete list of features and detailed documentation, visit our Technical Documentation.\n\nQuick Start\n\nThe easiest way to get started with OpnForm is through our official managed service in the Cloud.\n\nFor self-hosted installations, please refer to our Deployment Guides. For detailed instructions on setting up a local environment, check out our Local Deployment Documentation.\n\nSupport &amp; Community\n\nIf you need help or have questions, please join our Discord community. For more information and assistance, check out the following resources:\n\nProduct Helpdesk\nTechnical Documentation\n\nLicense\n\nOpnForm is open-source under the GNU Affero General Public License Version 3 (AGPLv3) or any later version. You can find it here.",
    name: "OpnForm",
    category: "Other",
    health: 100,
    code: "SAr5Ox",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "df76d655-7738-45d6-96f6-5ea308f36dac",
    isApproved: false,
    activeProjects: 3,
    projects: 4,
    description: "Web Recon Tool üîç An efficient reconnaissance tool for security researchers",
    readme:
      "Web Recon Tool üîç ‚Äì A robust reconnaissance solution tailored for security researchers, ethical hackers, and developers to conduct in-depth information gathering on target websites. This tool provides essential features like IP resolution, open port scanning, vulnerability assessment, and seamless Shodan API integration, all within a streamlined CLI interface. Designed for professional-grade intelligence gathering, Web Recon Tool empowers users with powerful data insights in real-time. Effortlessly analyze targets to detect open ports, potential vulnerabilities, and more, enabling proactive cybersecurity measures and effective threat assessment in any security-focused workflow.",
    name: "website recon tool",
    category: "Other",
    health: 0,
    code: "oLZ6QO",
    languages: ["Go"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5b877f66-8417-461c-bcb6-d576b0eb82a1",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "MySQL Backup to Cloudflare R2",
    readme:
      "A Docker container that provides automated MySQL database backups to Cloudflare R2 storage using rclone. This solution offers secure, scheduled backups with compression, retention policy management, and multi-database support. Perfect for maintaining reliable database backups in a cloud environment with minimal configuration required.",
    name: "MySQL Gzip backup to Cloudflare R2",
    category: "Automation",
    health: null,
    code: "wYvGYt",
    languages: ["Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b7c5b6b8-9ba1-46f2-9a1c-a2f2b0ecf7b2",
    isApproved: false,
    activeProjects: 1,
    projects: 12,
    description: "MollySocket allows getting signal notifications via UnifiedPush.",
    readme:
      '\nMollySocket\n\nMollySocket allows getting signal notifications via UnifiedPush. It works like a linked device, which doesn\'t have an encryption key, connected to the Signal server. Everytime it receives an encrypted event, it notifies your mobile via UnifiedPush.\n\nVapid Key\n\nYou can generate a private vapid key here or here. Copy the "privateKey" and use it for the MOLLY_VAPID_PRIVKEY variable. \n\nAndroid Setup\n\nYou need the right flavor of Molly to use UnifiedPush: https://github.com/mollyim/mollyim-android-unifiedpush.\n\nA distributor app (easiest is ntfy)\n\nComplete the setup in the Molly app; go to Settings &gt; Notifications &gt; Push Strategy &gt; Unified Push and enter the Server URL https://your-project.up.railway.app or your custom domain.\n\nMollySocket - GitHub',
    name: "MollySocket",
    category: "Other",
    health: null,
    code: "QhKRXF",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "fffbeb24-d873-4d6e-9bd7-9c3498adb9d2",
    isApproved: false,
    activeProjects: 0,
    projects: 12,
    description: "Single-node Confluent Kafka with Golang example consumer and producer.",
    readme:
      "Single-node, persistent Kafka using Confluent's best-practice Kafka image. Uses the built-in KRaft controller for a lighter deployment that doesn't require zookeeper.\n\nThe project deploys an example producer and consumer, written in Go and following Confluent's examples. They can be removed once you've deployed the template.\n\n",
    name: "Lightweight Kafka with volume",
    category: "Storage",
    health: null,
    code: "PhV3c8",
    languages: ["Go", "Dockerfile", "Makefile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6865f6df-99d2-45e6-8c8e-f0470fe8ccc4",
    isApproved: false,
    activeProjects: 7,
    projects: 38,
    description: "Ready-to-use Spree Commerce store with admin dashboard",
    readme:
      "Spree Commerce Starter\n\nA production-ready e-commerce platform built with Spree Commerce on Ruby on Rails.\n\nWhat is Spree?\n\nSpree Commerce is a complete, modular e-commerce solution built with Ruby on Rails. It offers:\n\nüõçÔ∏è Full-featured shopping cart\nüé® Customizable products, variants, and options\nüí≥ Multiple payment gateway integrations\nüì¶ Advanced shipping methods configuration\nüîç Powerful product search and filtering\nüë• Customer accounts and order management\nüì± Mobile-responsive design out of the box\n\nWhat's Included\n\nThis template sets up:\nA Spree Commerce application\nPostgreSQL database for data persistence\nRedis for caching and background jobs\n\nEnvironment Variables\n\nThis template automatically sets up most requirements, but you can customize these variables:\n\nRequired \nADMIN_EMAIL\nPassword is auto generated, check env tab.\n\nAuto-generated secrets:\nSECRET_KEY_BASE\nSPREE_AUTH_SECRET_KEY\n\nDefaults set by template:\nRAILS_ENV=production\nRAILS_SERVE_STATIC_FILES=true\nRAILS_LOG_TO_STDOUT=true\n\nOptional customization:\nSPREE_MAIL_FROM=your@email.com\nSPREE_STORE_NAME=\"Your Store Name\"\n\nAdditional Features\n\nMulti-Store: Support for running multiple stores from a single installation\nMulti-Currency: Built-in support for multiple currencies\nMulti-Language: Internationalization ready\nSEO-Friendly: Built-in SEO best practices\nAPI-First: Complete REST API for headless commerce\n\nSecurity\n\nAll necessary security configurations are pre-configured\nEnvironment variables for sensitive data\nSecure password management\nCSRF protection enabled\nXSS protection enabled\n\nCustomization\n\nSpree is highly customizable. You can:\nInstall additional Spree extensions\nOverride default views\nCustomize the admin interface\nAdd custom models and controllers\n\nSupport\n\nFor issues with:\nThe template itself: Open an issue in the template repository\nSpree Commerce: Visit [Spree's documentation]",
    name: "Spree eCommerce",
    category: "Other",
    health: 100,
    code: "06UrFL",
    languages: ["Ruby", "HTML", "SCSS", "Dockerfile", "JavaScript", "CSS", "Shell", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8a9d2048-d9dd-4b56-92ed-9b8e2ee6898a",
    isApproved: false,
    activeProjects: 21,
    projects: 67,
    description: "Creates a Neo4j graph database + volume (upd 5/9/25 works with Metal now!).",
    readme:
      '(5/9/24 updated to work with Metal!)\n\nThis template starts an instance of Neo4j with attached storage. This is a very basic configuration that allows client (such as Neo4j Desktop) to connect via Bolt to the TCP proxy. \n\nThe NEO4J_AUTH variable configures the initial password for the default user "neo4j".\n\nNeo4j tends to overestimate the memory requirements when deployed via Docker, so he memory size variables are required. They can be tweaked depending on the size of your application.\n\nWARNING: This cannot be run on a Trial account because the VMs are too small to support running Neo4j.',
    name: "neo4j",
    category: "AI/ML",
    health: 47,
    code: "ZVljtU",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f85b51a5-cb9d-4c7a-926f-66b69b4b529a",
    isApproved: false,
    activeProjects: 4,
    projects: 5,
    description: "A simple Phoenix app deployed with Distillery and connected to PostgreSQL",
    readme:
      "Phoenix with Distillery Starter Example\n\nThis is a Phoenix starter app with Distillery that connects to a Postgres database on Railway.\n\nDeploy on Railway\n\n‚ú® Features\n\nElixir\nPhoenix Distillery\nPostgres",
    name: "Phoenix Distillery",
    category: "Starters",
    health: 100,
    code: "_qWFnI",
    languages: ["Elixir", "HTML", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "959fe9cb-77f1-478e-b5a1-4ef045a4d4aa",
    isApproved: false,
    activeProjects: 8,
    projects: 15,
    description: "The simplest way to build internal tools without building UIs",
    readme:
      "Build internal tools with just backend code\n\nInterval generates full web apps just from backend Node.js code. If you love writing code but hate building UIs, you'll love building with Interval.\n\nAnd all of your important data are keep secure in your own infrastructure.\n\nBest of all, Interval is fully open-source, giving you complete transparency through code auditing.\n\nGetting started\nSee getting started guide from Interval's docs.\n\nFAQ\n\nHow much does it cost to run a Interval instance?\nAs Railway charges per usage it highly depends on your traffic, for me it costs about 5-7$ per month for about five users",
    name: "Interval",
    category: "Other",
    health: 100,
    code: "tFqAVW",
    languages: [
      "TypeScript",
      "SCSS",
      "JavaScript",
      "CSS",
      "Handlebars",
      "Shell",
      "HTML",
      "PLpgSQL",
      "Dockerfile",
    ],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b018a907-565e-4bbe-90d3-53a0ea0b6a9b",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "Create and play fun trivia games with friends!",
    readme:
      "Trivyal\n\nTrivyal is a trivia game app that everyone can use to play trivia games.\nUsers can sign up for an account to be able to create games and host them, or just play hosted live games without creating an account\n\nDeploy on Railway\n\nOriginal Blog Post on Railway\n\nDeploying a Dart app in Railway\n\nFeatures\n\nRealtime: All players see the same questions simultaneously and have a chance to answer during the question time\n\nSpeed Boost: Fast answers are rewarded with bonus points.\n\nYou're the Maestro: As the host, control the pace and reveal answers at your command.\n\nBig Screen, Small Screen: Hosts can display the game on a big screen, while players answer on their phones.\n\nPodium Showdown: Players can see how they stack up against each other after each question.\n\nScreenshots\n\nLogin Screen\nEdit Game with questions\nFull demo\n",
    name: "trivyal",
    category: "Other",
    health: null,
    code: "4fD3YO",
    languages: ["Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f2f6deb6-8f83-4af5-b44d-856d6183f73e",
    isApproved: false,
    activeProjects: 7,
    projects: 25,
    description: "Director is an open source framework for creating AI agents.",
    readme:
      'Director provides a advance AI first framework for developing intelligent agents that can interact with your audio/video collection in natural language. Whether you\'re dealing with social content, lectures, movies, youtube videos, TV shows, talks, music, or other digital content, Director offers variety of tools to build powerful AI-powered assistants.\n\nIt uses the VideoDB‚Äôs scalable "video as data" infrastructure to create agentic workflows. For example, in natural language you can give commands like ‚Äúupload this video and send the bullet point summary on my slack‚Äù and the agent will handle the rest.\n\nGitHub: https://github.com/video-db/Director',
    name: "Director by VideoDB",
    category: "AI/ML",
    health: 100,
    code: "QJbo7o",
    languages: [
      "Python",
      "JavaScript",
      "Shell",
      "Makefile",
      "Vue",
      "TypeScript",
      "CSS",
      "Dockerfile",
      "HTML",
    ],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8fc97ad9-5fb2-45aa-8c7d-71d6631099d5",
    isApproved: false,
    activeProjects: 118,
    projects: 355,
    description: "A powerful and user-friendly platform for running LLMs",
    readme:
      "‚ÑπÔ∏è This template also includes an optional user-friendly web interface to configure Ollama, visit their repository for related assistance\n\nOllama - Banner image\n\nOllama - AI model deployment platform\n\nOllama is a platform designed for deploying and managing AI models. It provides a user-friendly interface for integrating AI into applications, offering tools to streamline the deployment process. Ollama supports various model types and allows customization to fit specific needs. Its flexible architecture ensures scalability and efficiency, making it suitable for both small projects and large-scale implementations.\n\nOllama - Banner image\n\nAvailable models\n\nOllama has over 100 models across various parameter sizes.\n\nThe list can be found on:\nollama.com/library\n\nDocumentation\n\nThe official Ollama documentation can be found on the repository.\n\nBlog posts and release information can be found in the blog.\n\nLicense\n\nOllama is distributed under the\nMIT License.",
    name: "Ollama",
    category: "AI/ML",
    health: 88,
    code: "T9CQ5w",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "36f454e4-f90c-44e8-abf6-c582212d94a4",
    isApproved: false,
    activeProjects: 73,
    projects: 194,
    description: "A powerful workflow automation tool for technical people",
    readme:
      "‚ÑπÔ∏è This template is an extension of the N8N (w/ workers template, with the addition of a list of compatible AI products and components to get you started building AI workflows.\n\nOllama credential url: http://ollama:11434\n\nQdrant credential url: http://qdrant:6333\n\nn8n - Banner image\n\nWith your n8n instance, you‚Äôll have access to over 400 integrations and a\nsuite of basic and advanced AI nodes such as\nAI Agent,\nText classifier,\nand Information Extractor\nnodes. To keep everything local, just remember to use the Ollama node for your\nlanguage model and Qdrant as your vector store.\n\nThis starter kit is designed to help you get started with self-hosted AI workflows. While it‚Äôs not fully optimized for production environments, it combines robust components that work well together for proof-of-concept projects.\n\nYou can customize it to meet your specific needs. Feel free to visit the starter kit documentation or repository for tutorials, documentations, and examples.",
    name: "N8N (AI Starter Kit)",
    category: "AI/ML",
    health: 100,
    code: "Vea_Pb",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1408fcb5-e3b1-4887-95a8-02fe41b2092f",
    isApproved: false,
    activeProjects: 19,
    projects: 26,
    description: "A simple Phoenix app connected to a PostgreSQL database.",
    readme:
      "Phoenix Starter Example\n\nThis is a Phoenix starter app that connects to a Postgres database on Railway.\n\nDeploy on Railway\n\n‚ú® Features\n\nElixir\nPhoenix\nPostgres",
    name: "Phoenix",
    category: "Starters",
    health: 76,
    code: "0LSBzw",
    languages: ["Elixir", "HTML", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4bd1cff8-9a2b-4ff5-a70c-54fd3ed510c0",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "Unite your frontend and serverpod backend under one domain",
    readme:
      "Based on Brody's Reverse Proxy with support for Serverpod websocket paths\n\nAllows you to have both frontend and backend under one domain with different ports and/hosts\n\nHosts your frontend at /,backend at /api/ while still preserving /v1/websocket and /websocket paths for Serverpod realtime connections",
    name: "Serverpod reverse proxy",
    category: "Other",
    health: null,
    code: "fiqpE3",
    languages: ["Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8d427aee-39b8-49f7-ad7e-f2e69f15833b",
    isApproved: true,
    activeProjects: 21,
    projects: 42,
    description: "A Bun + Hono Starter with Health Check, Route Grouping, Cors and more!",
    readme:
      "Bun + Hono Starter Template\n\nThis is a barebones starter template for a Bun project using the Hono web framework. It provides a simple foundation to build a web application with binary compilation, route grouping, CORS setup, and health check endpoints. This template is ready to be deployed on Railway.\n\nFeatures\n\nBun.js: Ultra-fast JavaScript runtime with built-in bundler and test runner.\nHono.js: A fast and minimal web framework.\nBinary Compilation: Compiles to a single executable for production.\nCORS Middleware: Enabled for all routes by default.\nLogger Middleware: Built-in request logging.\nRoute Grouping: Cleanly organize routes in separate modules.\nHealth Check: A simple endpoint to monitor the uptime of the service.\n\nWe utilize a multi-stage Dockerfile to compile the application into a binary for optimal production performance. The development environment supports hot reloading for a better developer experience.",
    name: "Bun + Hono",
    category: "Starters",
    health: 60,
    code: "wOsrk0",
    languages: ["TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "509608c0-5ce9-4281-bca6-5d4664dfe592",
    isApproved: false,
    activeProjects: 7,
    projects: 24,
    description: "Next 15 Starter Template with App Routing",
    readme:
      "To learn more about the new Next.js 15 updates, take a look at the following resources:\nNext.js 15 Updates - learn about Next.js features and API.\nNextJS 15 Railway Template\nRailway - deploy your Next.js app in seconds.\n\nYou can check out the Next.js GitHub repository - your feedback and contributions are welcome!\n",
    name: "Next 15 App Router",
    category: "Starters",
    health: 100,
    code: "U-HNN5",
    languages: ["TypeScript", "CSS", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "45c4e9fa-2064-4c64-bfe5-19fb38280e3a",
    isApproved: false,
    activeProjects: 4,
    projects: 9,
    description: "The high-performance database for modern applications",
    readme:
      "\n      \n      \n      \n\n\nThe Only Native GraphQL Database With A Graph Backend.\n\nNote: The default ACL userId is groot and the password is password -- please log in and change the password immediately.\n\nDgraph is a horizontally scalable and distributed GraphQL database with a graph backend. It provides ACID transactions, consistent replication, and linearizable reads. It's built from the ground up to perform \na rich set of queries. Being a native GraphQL database, it tightly controls how the\ndata is arranged on disk to optimize for query performance and throughput,\nreducing disk seeks and network calls in a cluster.\n\nDgraph's goal is to provide Google production-level scale and throughput,\nwith low enough latency to serve real-time user queries over terabytes of structured data.\nDgraph supports GraphQL query syntax, and responds in JSON and Protocol Buffers over GRPC and HTTP. Dgraph is written using the Go Programming Language.\n\nGet Started\nTo get started with Dgraph, follow:\n\nInstallation to queries in 3 steps via dgraph.io/docs/.\nA longer interactive tutorial via dgraph.io/tour/.\nTutorial and\npresentation videos on YouTube channel.\n\nClient Libraries\nThe Dgraph team maintains several officially supported client libraries. There are also libraries contributed by the community unofficial client libraries.",
    name: "Dgraph",
    category: "Storage",
    health: 0,
    code: "GsNlbj",
    languages: ["Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "65e73530-5bb9-4fee-b09a-1fdc6540734d",
    isApproved: false,
    activeProjects: 172,
    projects: 285,
    description: "An example NextJS app. Zero config required.",
    readme:
      "Deploy Next.js to Railway\n\nThis is a Next.js template which can be deployed to Railway with zero configuration.\n\nDeploying to Railway\n\nRailway automatically configures your Next.js application to run as a Node.js server (through next start). \n\nYou can deploy to Railway using the Railway CLI or via GitHub.\n\nDeploy on Railway\n\nFor more information, see our deployment quickstarts.\n",
    name: "NextJS",
    category: "Starters",
    health: 96,
    code: "yDom4a",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "fdd21d88-8704-4fd4-b237-3a30c8d1f1ff",
    isApproved: false,
    activeProjects: 330,
    projects: 452,
    description: "A Spring Boot starter app",
    readme:
      "Spring Boot Starter Example\n\nThis is a Spring Boot starter app that deploys to Railway.\n\nDeploy on Railway\n\n‚ú® Features\n\nJava\nSpring Boot\nSpring",
    name: "Spring Boot (Java)",
    category: "Starters",
    health: 92,
    code: "-NFGrr",
    languages: ["Java", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f6845ee2-dd14-4879-91e4-0c65ec0a16a0",
    isApproved: false,
    activeProjects: 2,
    projects: 8,
    description: "API service that generates chart images for emails, reports, and dashboards",
    readme:
      "QuickChart: Open-Source Chart Generation API\n\nQuickChart is a powerful, open-source chart image generation API that has served over 4 billion charts worldwide. Built on Chart.js, the most popular open-source charting library, QuickChart enables developers to generate customizable charts through simple URL parameters or client libraries.\n\nKey Features\n\nRESTful API for generating chart images via URL parameters\nSupport for multiple chart types: bar, line, pie, radar, and more\nOfficial client libraries for Python, JavaScript, Java, C#, Ruby, PHP, and Go\nCustomizable styling, colors, gradients, and animations\nBuilt-in support for responsive designs and retina displays\nCompatible with email clients, markdown documents, and any platform that displays images\nEasy integration with no-code tools like Zapier, Make, Airtable, and Google Sheets\n\nTechnical Specifications\n\nCore Technology\nBuilt on Node.js and Chart.js\nSupports Chart.js 2.9.4 configurations\nOutputs PNG images by default\n\nDeployment\nDocker-ready for easy deployment\nMemory-efficient image rendering\nHorizontally scalable architecture\nAGPLv3 licensed with commercial license option\n\nWhy Self-Host QuickChart?\n\nSelf-hosting QuickChart gives you complete control over your chart generation infrastructure, ensuring:\nData privacy and security\nCustomization flexibility\nOn-premise deployment options\nScalable chart generation\n\nGet started with one-click deployment on Railway and join thousands of developers and businesses already using QuickChart for their data visualization needs.\n\nQuick Start\n\n// Example usage\nconst chartUrl = 'https://quickchart.io/chart?c={type:\"bar\",data:{labels:[\"Q1\",\"Q2\",\"Q3\",\"Q4\"], datasets:[{label:\"Users\",data:[50,60,70,180]}]}}';\nIntegration Examples\npythonCopyfrom quickchart import QuickChart\n\nqc = QuickChart()\nqc.width = 500\nqc.height = 300\nqc.config = {\n    'type': 'bar',\n    'data': {\n        'labels': ['Q1', 'Q2', 'Q3', 'Q4'],\n        'datasets': [{\n            'label': 'Users',\n            'data': [50, 60, 70, 180]\n        }]\n    }\n}\n\nGet chart URL or save as image\nprint(qc.get_url())\nqc.to_file('chart.png')",
    name: "Quick Chart",
    category: "Other",
    health: 100,
    code: "GxnTq-",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3179a59f-e3a6-41bb-8e91-3b2a2e27cf81",
    isApproved: false,
    activeProjects: 5,
    projects: 18,
    description: "Roundcube with MySQL as Database",
    readme:
      "Deploy Roundcube with MySQL\n\nRoundcube is a web-based IMAP email client. Roundcube's most prominent feature is the pervasive use of Ajax technology. Roundcube is free and open-source software subject to the terms of the GNU General Public License (GPL-3.0-or-later), with exceptions for skins and plugins\n\nUsing this template, you can easily deploy a Roundcube with MySQL on Railway.",
    name: "Roundcube E-Mail Client with MySQL DB",
    category: "Other",
    health: 100,
    code: "VgpEjU",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7fd1fc1e-ce6f-4e84-b0bd-a6661bec64c0",
    isApproved: false,
    activeProjects: 30,
    projects: 42,
    description: "An advanced fully modular, extendable Discord bot writen in python!",
    readme:
      "Customizable Discord Bot\n\nOverview\n\nWarning: This is an unofficial Railway template for the Red Discord Bot. Please refer to the official documentation for authoritative information.\n\nRed is a fully modular Discord bot that offers a variety of features, including music, moderation, trivia, and stream alerts. This self-hosted bot allows you to customize its capabilities, enabling you to turn it into an admin assistant, a music player, a trivia master, or all of these at once!\n\nGetting started is straightforward, and you don‚Äôt need any coding knowledge! Most of the setup and management can be done directly from within Discord.\nNext Steps to Get Up and Running\n\nCreate a Discord Bot Account: Follow this guide to set up your bot account: How to create a Discord Bot Account.\n\nDeploy the Bot: Use the button to deploy Red on Railway effortlessly.\n\nConfigure Your Bot: After deployment, customize your bot's settings and modules to fit your server‚Äôs needs.\n\nDefault Modules Include:\n\nModeration Tools: Manage your server with kick, ban, softban, mod-log, filters, and chat cleanup.\nTrivia Games: Engage users with built-in trivia lists and easy customization.\nMusic Features: Stream from YouTube, SoundCloud, local files, and more.\nStream Alerts: Get notifications for Twitch, YouTube, and Picarto.\nBanking System: Enjoy fun features like slot machines and user credits.\nCustom Commands: Tailor commands to your community's needs.\nMedia Search: Quickly find images and GIFs.\nAdmin Automation: Self-role assignments, cross-server announcements, and mod-mail reports.\nCustomizable Permissions: Control who can use which commands.\n\nRed supports a vibrant community, where you can find additional plugins (cogs) to enhance its capabilities.\nJoin the Community!\n\nRed is actively developed and supported by a community that continuously creates new content (cogs/plugins) for everyone to enjoy. If you can‚Äôt find a specific cog, consult our guide on building your own!\n\nDiscover more about this open-source Discord bot here: https://github.com/Cog-Creators/Red-DiscordBot/tree/V3/develop\n\nfootnote: This deployment is a simplifed version",
    name: "Customizable Discord bot (RedBot)",
    category: "Bots",
    health: 18,
    code: "Ux74pW",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1f8c2acf-cb59-4abb-9c9c-b33ea8c2550d",
    isApproved: false,
    activeProjects: 53,
    projects: 87,
    description: "Nestjs + Redis + Postgres + Cron",
    readme:
      "The template features a Nestjs application at its core, coupled with Redis instead of in-memory caching, PostgresDB for database and Nestjs cron service for interval-activities. You can get setup faster, overcoming the long process of setting up on Railway from scratch. ",
    name: "rail-nest",
    category: "Starters",
    health: 100,
    code: "nvnuEH",
    languages: ["TypeScript", "JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ade3f5e5-f2b4-44b4-b30e-96314626a248",
    isApproved: false,
    activeProjects: 5,
    projects: 6,
    description: "Turn your PostgreSQL database into a RESTful API",
    readme:
      "Simple template to deploy a PostgREST service.\n\nSet the PGRST_DB_URI variables to your Postgres connection string or reference, for example ${{Postgres.DATABASE_PRIVATE_URL}}.\n\nExample on how to get a basic working service running (copied from the PostgREST documentation):\n\nCreate a schema for database objects that will be exposed in our API:\n\ncreate schema api;\n\nCreate a todos table:\n\ncreate table api.todos (\n  id int primary key generated by default as identity,\n  done boolean not null default false,\n  task text not null,\n  due timestamptz\n);\n\ninsert into api.todos (task) values\n  ('finish tutorial 0'), ('pat self on back');\n\nMake a role to use for anonymous web requests:\n\ncreate role web_anon nologin;\n\ngrant usage on schema api to web_anon;\ngrant select on api.todos to web_anon;\n\nSet the PGRST_DB_SCHEMAS variable to api (the schema you created).\n\nSet the PGRST_DB_ANON_ROLE variable to web_anon (the role we created).\n\nDeploy the service and visit your service's HTTP endpoint at /todos to view your todos.\n\nBecause the role we created only grants select access on the api.todos table, anonymous users will not be able to modify the table.\n\nAuthentication\n\nTo authenticate users with the API generate a JWT secret and set the PGRST_JWT_SECRET variable.\n\nFor example with OpenSSL:\n\nopenssl rand -base64 32\n\nStore the output in the PGRST_JWT_SECRET variable and set the PGRST_JWT_SECRET_IS_BASE64 to true.\n\nFollow the PostgREST tutorial on how to use this secret to enable authentication for a user.",
    name: "PostgREST",
    category: "Other",
    health: 100,
    code: "0cbz2v",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1896d9c5-b21e-408d-932a-0e8439e35a1c",
    isApproved: false,
    activeProjects: 7,
    projects: 22,
    description: "üßë‚ÄçüöÄ The better identity infrastructure for developers",
    readme:
      "üßë‚ÄçüöÄ The better identity infrastructure for developers and the open-source alternative to Auth0.\n\nHomepage URL: https://logto.io/\nRepository: https://github.com/logto-io/logto\n\nThis auth app allows registering arbitrary many OAuth 2 applications even in free OSS version",
    name: "Logto (Auth)",
    category: "Authentication",
    health: 80,
    code: "07_f_Z",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a7ded89c-4cce-455b-b33e-8ef6e149c4ad",
    isApproved: false,
    activeProjects: 23,
    projects: 40,
    description: "AI Observability & Evaluation",
    readme:
      "Phoenix is an open-source AI observability platform designed for experimentation, evaluation, and troubleshooting. It provides:\n\nüî≠ Tracing - Trace your LLM application's runtime using OpenTelemetry-based instrumentation.\n\nüß† Evaluation - Leverage LLMs to benchmark your application's performance using response and retrieval evals.\n\nüóÑÔ∏è Datasets - Create versioned datasets of examples for experimentation, evaluation, and fine-tuning.\n\nüß™ Experiments - Track and evaluate changes to prompts, LLMs, and retrieval.\n\nPhoenix is vendor and language agnostic with out-of-the-box support for popular frameworks (ü¶ôLlamaIndex, ü¶ú‚õìLangChain, Haystack, üß©DSPy) and LLM providers (OpenAI, Bedrock, MistralAI, VertexAI, LiteLLM, and more). For details on auto-instrumentation, check out the OpenInference project.\n\nPhoenix is built by Arize AI, the company behind the the industry-leading AI observability platform, and a set of core contributors.\n\nJoin our community to connect with thousands of AI builders.\n\nFind us at:\n\nhttps://github.com/Arize-ai/phoenix\nhttps://docs.arize.com/phoenix\nhttps://x.com/ArizePhoenix\nhttps://phoenix.arize.com\n\nLike what you see? Give us a ‚òÖ on GitHub!\n\n\n",
    name: "arize-phoenix",
    category: "AI/ML",
    health: 100,
    code: "PTHRoq",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "256c155e-298b-4d00-a83e-a8f0693598e5",
    isApproved: false,
    activeProjects: 2,
    projects: 15,
    description: "Stream data out of your Postgres database with Sequin.",
    readme:
      "Sequin streams data out of your Postgres database.\n\nYou can use it to replicate data from your existing tables to other apps, databases, caches, materialized views, or frontend clients. Or you can use it to build event processing workflows, such as triggering side effects when data in Postgres changes.",
    name: "Sequin",
    category: "Other",
    health: 90,
    code: "TXSiv2",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b50f1f49-e75d-464d-a2bf-25c376fe6561",
    isApproved: false,
    activeProjects: 8,
    projects: 18,
    description: "Simple hello world app using Serverpod, Flutter, and Dart",
    readme:
      "Hello Serverpod\n\nSimple hello world app using Serverpod, Flutter, and Dart\n\nDeploy on Railway\n\nOriginal Blog Post on Railway\n\nDeploying a Dart app in Railway\n",
    name: "hello-serverpod",
    category: "Starters",
    health: 100,
    code: "SJzxFe",
    languages: [
      "C++",
      "CMake",
      "Dart",
      "PLpgSQL",
      "Swift",
      "C",
      "HTML",
      "Dockerfile",
      "Kotlin",
      "Objective-C",
      "Shell",
    ],
    tags: null,
  },
  {
    __typename: "Template",
    id: "57c480ff-bb4c-4d04-818c-0c2df3af30a0",
    isApproved: false,
    activeProjects: 13,
    projects: 25,
    description: "Open Source backend for your SaaS and Mobile app in 1 file. ",
    readme:
      "\n    \n        \n    \n\n\nPocketBase is an open source Go backend, consisting of:\n\nembedded database (SQLite) with realtime subscriptions\nbuilt-in files and users management\nconvenient Admin dashboard UI\nand simple REST-ish API\n\nFor documentation and examples, please visit https://pocketbase.io/docs.\n\n&gt; !WARNING]\n&gt; Please keep in mind that PocketBase is still under active development\n&gt; and therefore full backward compatibility is not guaranteed before reaching v1.0.0.\n\nAPI SDK clients\n\nThe easiest way to interact with the API is to use one of the official SDK clients:\n\nJavaScript - [pocketbase/js-sdk (browser and node)\nDart - pocketbase/dart-sdk (web, mobile, desktop)\n\nOverview\n\nUse as standalone app\n\nYou could download the prebuilt executable for your platform from the Releases page.\nOnce downloaded, extract the archive and run ./pocketbase serve in the extracted directory.\n\nThe prebuilt executables are based on the examples/base/main.go file and comes with the JS VM plugin enabled by default which allows to extend PocketBase with JavaScript (for more details please refer to Extend with JavaScript).\n\nSecurity\n\nIf you discover a security vulnerability within PocketBase, please send an e-mail to support at pocketbase.io.\n\nAll reports will be promptly addressed, and you'll be credited accordingly.\n\nContributing\n\nPocketBase is free and open source project licensed under the MIT License.\nYou are free to do whatever you want with it, even offering it as a paid service.\n\nYou could help continuing its development by:\n\nContribute to the source code\nSuggest new features and report issues\n\nPRs for new OAuth2 providers, bug fixes, code optimizations and documentation improvements are more than welcome.\n\nBut please refrain creating PRs for new features without previously discussing the implementation details.\nPocketBase has a roadmap and I try to work on issues in specific order and such PRs often come in out of nowhere and skew all initial planning with tedious back-and-forth communication.\n\nDon't get upset if I close your PR, even if it is well executed and tested. This doesn't mean that it will never be merged.\nLater we can always refer to it and/or take pieces of your implementation when the time comes to work on the issue (don't worry you'll be credited in the release notes).\n",
    name: "pocketbase",
    category: "Storage",
    health: 100,
    code: "73ofk1",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0ea5b202-e5a1-48cd-8392-1c2ec952b395",
    isApproved: false,
    activeProjects: 7,
    projects: 11,
    description: "A minimal Deno 2 web server starter template",
    readme:
      "This template deploys a minimal Deno 2 web server. The default path serves a static file and /greet path will output a message containing an environment variable.\nDefault port of an Deno 2 web server is 8000, but it can be overriden it via the PORT env variable.\nGitHub repo: https://github.com/rares04/deno2-web-server-template",
    name: "Deno 2 Web server",
    category: "Starters",
    health: 100,
    code: "CAPR-V",
    languages: ["HTML", "TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c68440b8-afdb-4930-abc7-38d946bbacb7",
    isApproved: false,
    activeProjects: 6,
    projects: 20,
    description: "Connect to data, visualize, create dashboards, and share insights easily.",
    readme:
      "\n  \n\n\nRedash is designed to enable anyone, regardless of the level of technical sophistication, to harness the power of data big and small. SQL users leverage Redash to explore, query, visualize, and share data from any data sources. Their work in turn enables anybody in their organization to use the data. Every day, millions of users at thousands of organizations around the world use Redash to develop insights and make data-driven decisions.\n\nRedash features:\n\nBrowser-based: Everything in your browser, with a shareable URL.\nEase-of-use: Become immediately productive with data without the need to master complex software.\nQuery editor: Quickly compose SQL and NoSQL queries with a schema browser and auto-complete.\nVisualization and dashboards: Create beautiful visualizations with drag and drop, and combine them into a single dashboard.\nSharing: Collaborate easily by sharing visualizations and their associated queries, enabling peer review of reports and queries.\nSchedule refreshes: Automatically update your charts and dashboards at regular intervals you define.\nAlerts: Define conditions and be alerted instantly when your data changes.\nREST API: Everything that can be done in the UI is also available through REST API.\nBroad support for data sources: Extensible data source API with native support for a long list of common databases and platforms.\n\nGetting Started\n\nDocumentation.\n\nSupported Data Sources\n\nRedash supports more than 35 SQL and NoSQL data sources. It can also be extended to support more. Below is a list of built-in sources:\n\nAmazon Athena\nAmazon CloudWatch / Insights\nAmazon DynamoDB\nAmazon Redshift\nArangoDB\nAxibase Time Series Database\nApache Cassandra\nClickHouse\nCockroachDB\nCouchbase\nCSV\nDatabricks\nDB2 by IBM\nDgraph\nApache Drill\nApache Druid\ne6data\nEccenca Corporate Memory\nElasticsearch\nExasol\nMicrosoft Excel\nFirebolt\nDatabend\nGoogle Analytics\nGoogle BigQuery\nGoogle Spreadsheets\nGraphite\nGreenplum\nApache Hive\nApache Impala\nInfluxDB\nInfluxDBv2\nIBM Netezza Performance Server\nJIRA (JQL)\nJSON\nApache Kylin\nOmniSciDB (Formerly MapD)\nMariaDB\nMemSQL\nMicrosoft Azure Data Warehouse / Synapse\nMicrosoft Azure SQL Database\nMicrosoft Azure Data Explorer / Kusto\nMicrosoft SQL Server\nMongoDB\nMySQL\nOracle\nApache Phoenix\nApache Pinot\nPostgreSQL\nPresto\nPrometheus\nPython\nQubole\nRockset\nRisingWave\nSalesforce\nScyllaDB\nShell Scripts\nSnowflake\nSPARQL\nSQLite\nTiDB\nTinybird\nTreasureData\nTrino\nUptycs\nVertica\nYandex AppMetrrica\nYandex Metrica\n\nGetting Help\n\nIssues: https://github.com/getredash/redash/issues\nDiscussion Forum: https://github.com/getredash/redash/discussions/\nDevelopment Discussion: https://discord.gg/tN5MdmfGBp",
    name: "Redash",
    category: "Other",
    health: 96,
    code: "mb8XJA",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "dc99b06f-0d1f-4f38-86b0-cd7a646393d6",
    isApproved: false,
    activeProjects: 2,
    projects: 11,
    description: "A Deno 2 + Hono Starter with Health Check, Route Grouping, Cors and more!",
    readme:
      "Deno 2 + Hono Starter Template\n\nThis is a barebones starter template for a Deno 2 project using the Hono web framework. It provides a simple foundation to build a web application with route grouping, CORS setup, and health check endpoints. This template is ready to be deployed on Railway.\n\nFeatures\nHono.js: A fast and minimal web framework for Deno.\nCORS Middleware: Enabled for all routes by default.\nRoute Grouping: Cleanly organize routes in separate modules.\nHealth Check: A simple endpoint to monitor the uptime of the service.\n\nLogging wasn't included since it is currently marked as UNSTABLE, add your own or use the one linked at your own risk.\n\nWe also utilize a Dockerfile as Railway only provides Deno 1 at the moment.",
    name: "Deno 2 + Hono",
    category: "Starters",
    health: null,
    code: "zWmKrg",
    languages: ["TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0d63d16a-c1fd-41b1-abda-ce7a0ff6a06e",
    isApproved: false,
    activeProjects: 6,
    projects: 13,
    description: "Lightweight server that emulates the iOS HomeKit API",
    readme:
      'Source: https://github.com/homebridge/homebridge\n\nHomebridge is a lightweight Node.js server you can run on your home network that emulates the iOS HomeKit API. It supports Plugins, which are community-contributed modules that provide a basic bridge from HomeKit to various 3rd-party APIs provided by manufacturers of "smart home" devices. \n\nSince Siri supports devices added through HomeKit, this means that with Homebridge you can ask Siri to control devices that don\'t have any support for HomeKit at all. For instance, using just some of the available plugins, you can say:\n\n Siri, unlock the back door. pictured to the right]\n Siri, open the garage door.\n Siri, turn on the coffee maker. \n Siri, turn on the living room lights.\n Siri, good morning!\n\nYou can explore all available plugins at the NPM website by [searching for the keyword homebridge-plugin.',
    name: "Homebridge",
    category: "Automation",
    health: 100,
    code: "_6Yzzm",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "cf2717e0-1c79-413c-8c25-0ab0c9785ced",
    isApproved: false,
    activeProjects: 2,
    projects: 2,
    description: "A Sails starter app with React, Postgres, Redis, Inertia & Tailwind",
    readme:
      "The Boring JavaScript Stack\n\nSails\nInertia\nTailwind CSS\nVue, React, or Svelte\n\nThe ethos of The Boring JavaScript Stack is this üëáüèæ\n\nYou can use your favorite frontend framework and build Modern Single Page Applications(SPA) without the hassle of the complexities that building SPA the traditional way bring to the table.\n\nWith The Boring JavaScript Stack, you don't need üëáüèæ\n\nClient-side state management - your application state lives in your database which is where it belongs.\nYou don't need an API for your SPA - the data each page needs gets sent to it as props thanks to Inertia\nNo double routing - The routing for your app is handled at the backend level with Sails\n\nDocs\n\nRead the docs.",
    name: "The Boring JavaScript Stack (Sails, React, Postgres, Redis, Inertia)",
    category: "Other",
    health: 100,
    code: "ia84_3",
    languages: ["EJS", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "121bdd20-172a-43bd-bd06-e22456cb7dec",
    isApproved: false,
    activeProjects: 2,
    projects: 9,
    description: "A scheduled Playwright test runner, using Lambdatest",
    readme:
      "You need to provide username and access key for a valid LambdaTest account, with a subscrtiption that allows for automated browser tests.\n\nOptionally, set UTC_SCHEDULED_START (14:30) and the tests wil run every day at that time. If left empty, tests will run just once after successful deploy.\n\nTo write your own test, eject the github repo and clone your copy. Write test and push.",
    name: "LambdaTest Playwright",
    category: "Automation",
    health: 100,
    code: "O6ga73",
    languages: ["HTML", "JavaScript", "TypeScript", "C#", "Python", "Java", "Gherkin"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8bcdc09f-62da-400a-83bf-34a0c22913a3",
    isApproved: false,
    activeProjects: 12,
    projects: 38,
    description: "LobeChat, GitHub-based auth, ChatGPT, GPT-4, Bing, Anthropic, DALL-E-3",
    readme:
      "LobeChat is an open-source, AI-powered chatbot platform designed for seamless and customizable conversational experiences. Built with modern technologies, it supports multi-channel integration and GitHub-based authentication via NextAuth, making it easy to deploy across various platforms. Whether for personal use or business applications, LobeChat enables efficient AI-driven communication with robust functionality and scalability.",
    name: "LobeChat",
    category: "AI/ML",
    health: 100,
    code: "XJrbIL",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d9c1a8ef-33f0-485c-9770-28b3b9598db7",
    isApproved: false,
    activeProjects: 8,
    projects: 28,
    description: "Redis Stack is an enhanced version of Redis. (Legacy)",
    readme:
      "Redis Stack is an enhanced version of Redis, designed to provide additional features and modules to meet modern application needs. It extends the core Redis functionalities, such as caching, key-value storage, and message brokering, by including built-in modules and capabilities for real-time analytics, search, and more.\n\nKey Features of Redis Stack:\n\nSearch and Query with RediSearch:\nOffers full-text search capabilities.\nSupports secondary indexing, complex querying, and querying JSON documents.\nMakes Redis suitable for use cases that require fast and powerful search.\n\nJSON Support with RedisJSON:\nAllows efficient storage and manipulation of JSON data structures.\nEnables document-oriented use cases, such as storing and querying complex data objects.\nDirectly integrates with RediSearch for advanced querying.\n\nTime-Series Data with RedisTimeSeries:\nSpecialized module for time-series data.\nOptimized for storing and analyzing time-stamped data (e.g., metrics, IoT data, financial data).\nProvides built-in aggregation, down-sampling, and querying functionalities.\n\nGraph Queries with RedisGraph:\nSupports graph database queries using Cypher query language.\nIdeal for relationship-heavy data use cases, such as social networks, recommendation engines, and fraud detection.\n\nStreams and Pub/Sub:\nNative support for data streams and publish-subscribe mechanisms.\nHelps in building real-time applications like chat systems, notifications, and event processing.\n\nAI/ML Integration with RedisAI:\nEnables running AI/ML inference directly in Redis using models trained in popular frameworks like TensorFlow, PyTorch, and ONNX.\nReduces latency by bringing AI processing closer to the data.",
    name: "Redis Stack",
    category: "Storage",
    health: 100,
    code: "675ZtP",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f7f2e78b-6924-41bf-84da-a4d871dab287",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "DenoKV is a fast, simple key-value DB for persistent storage in Deno apps",
    readme:
      'DenoKV is a built-in key-value database designed for the Deno runtime, allowing developers to store and retrieve simple data structures in a persistent and scalable manner. It supports both local and remote databases, making it flexible for various application needs. With a minimalistic API and seamless integration into Deno, DenoKV is ideal for projects requiring fast and efficient data storage.\n\nHow to Connect with a Custom URL\n\nTo connect to a DenoKV instance using a custom URL, use the following example:\n\n// Connect to the DenoKV instance using a custom URL\nconst kv = await Deno.openKv("http://denokv.railway.internal");\n\n// Set a value with the specified key\nawait kv.set(["key"], "value");\n\n// Retrieve and log the value associated with the key\nconsole.log(await kv.get(["key"])); // Output: value\n\nPublic Access on Railway\n\nNote: To make your DenoKV instance publicly accessible, you need to add a custom domain on Railway. This step ensures external applications can interact with your DenoKV instance. You can configure this by setting up a custom domain within your Railway project settings and pointing it to your DenoKV service. This allows for easy public access to your database via the provided URL.',
    name: "Deno KV",
    category: "Storage",
    health: null,
    code: "qdi8HH",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "bf2d4cb5-7949-4149-95a7-991fbc03d7aa",
    isApproved: false,
    activeProjects: 4,
    projects: 4,
    description: "A complete Sails starter app connected to a PostgreSQL database.",
    readme:
      "A simple Sails.js starter app connected to a Postgres database and Redis store for saving sessions.\n\nSails Starter Example\n\nThis is a Sails starter app that connects to a Railway Postgres database.\n\nDeploy on Railway\n\n‚ú® Features\n\nNode\nSails\nPostgres\nRedis",
    name: "sails",
    category: "Starters",
    health: 83,
    code: "t3sAEH",
    languages: ["JavaScript", "EJS", "Less"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "64a817e6-f7a9-4126-b3be-659b3909cb46",
    isApproved: false,
    activeProjects: 7,
    projects: 25,
    description: "MindsDB is the platform for building AI from enterprise data",
    readme:
      "This supports persistent models and configurations.\n\nThis is the lightweight Docker image of MindsDB that comes with base integrations preloaded.\n\n-p 47334:47334 publishes port 47334 to access MindsDB GUI and HTTP API.\n\n-p 47335:47335 publishes port 47335 to access MindsDB MySQL API.\n\nNote: \n\nIf you experience any issues related to MKL or your training process does not complete, please add the MKL_SERVICE_FORCE_INTEL environment variable, as below.\n\nMKL_SERVICE_FORCE_INTEL=1",
    name: "MindsDB",
    category: "AI/ML",
    health: 100,
    code: "otiqwz",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0de56c55-3d59-40a0-94f1-ccf2ab1a3aff",
    isApproved: false,
    activeProjects: 2,
    projects: 6,
    description: "An open-source, developer-oriented translation and localization tool",
    readme:
      "Accent is an open source, developer-oriented localization and translation tool developed by Mirego. \n\nThis deployment is configured with dummy auth enabled to allow users to log in for evaluation. \n\nIn production, it is recommended to configure any of the available authentication providers: https://github.com/mirego/accent?tab=readme-ov-file#authentication-setup",
    name: "accent",
    category: "Other",
    health: 100,
    code: "WO-S6B",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "83a827e2-9513-44ea-aaeb-9c2e55e38ba8",
    isApproved: false,
    activeProjects: 10,
    projects: 20,
    description: "A scalable, distributed, collaborative, document-graph database",
    readme:
      "\n    \n        \n    \n\n\nSurrealDB is the ultimate cloud  database for tomorrow's applications\n\n\nDevelop easier. &nbsp; Build faster. &nbsp; Scale quicker.\n\nWhat is SurrealDB?\n\nSurrealDB is an end-to-end cloud-native database designed for modern applications, including web, mobile, serverless, Jamstack, backend, and traditional applications. With SurrealDB, you can simplify your database and API infrastructure, reduce development time, and build secure, performant apps quickly and cost-effectively.\n\nKey features of SurrealDB include:\n\nReduces development time: SurrealDB simplifies your database and API stack by removing the need for most server-side components, allowing you to build secure, performant apps faster and cheaper.\nReal-time collaborative API backend service: SurrealDB functions as both a database and an API backend service, enabling real-time collaboration.\nSupport for multiple querying languages: SurrealDB supports SQL querying from client devices, GraphQL, ACID transactions, WebSocket connections, structured and unstructured data, graph querying, full-text indexing, and geospatial querying.\nGranular access control: SurrealDB provides row-level permissions-based access control, giving you the ability to manage data access with precision.\n\nFeatures\n\nx] Database server, or embedded library\n[x] Multi-row, multi-table ACID transactions\n[x] Single-node, or highly-scalable distributed mode\n[x] Record links and directed typed graph connections\n[x] Store structured and unstructured data\n[x] Incrementally computed views for pre-computed advanced analytics\n[x] Realtime-api layer, and security permissions built in\n[x] Store and model data in any way with tables, documents, and graph\n[x] Simple schema definition for frontend and backend development\n[x] Connect and query directly from web-browsers and client devices\n[x] Use embedded JavaScript functions for custom advanced functionality\n\nDocumentation\n\nFor guidance on development, and administration, see Their [documentation.",
    name: "SurrealDB 2.x",
    category: "Other",
    health: 100,
    code: "RLin57",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9337edba-f5a8-4696-a286-7b1f9f5c3503",
    isApproved: false,
    activeProjects: 2,
    projects: 7,
    description: "Powerfull PDF editor, with persistent passwords and ALL languages for OCR",
    readme:
      "With this template you do have a login authentification by default :\n\nDefault login /password : admin / stirling\n\nPlease make sure to change it after deploy !\n\nBut you also have ALL languages for OCR recognition integrated (not just English)\n\nWith the persistent storage, you will not loose your created accounts on redeploy.\n\nEnjoy ! :)",
    name: "stirling_pdf_improved",
    category: "Other",
    health: 100,
    code: "EZDbH1",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e1aa4ed0-6fd5-4e30-a912-f426b4300888",
    isApproved: false,
    activeProjects: 1,
    projects: 8,
    description: "A painless self-hosted Git service.",
    readme:
      "\nNotes\n\nIn my experience, Gitea, which is a fork of Gogs, typically uses about 200MB of memory. Gogs, on the other hand, averages around 50MB, so I chose to go with Gogs instead.\n\nSetup Instructions\n\nTo deploy the Gogs project on Railway, simply click through the process; everything is configured and ready to be deployed. Once deployed, visit your domain to start setting up your instance.",
    name: "Gogs",
    category: "Other",
    health: 100,
    code: "krzBbF",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f98b1088-4a29-4cb0-88fc-6705e9f8c5b1",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "Deploy River UI easily for managing background jobs in Go applications",
    readme:
      "Running the River UI\n\nRiver includes a graphical user interface called River UI, which allows users to view and manage background jobs without manually querying the database or using the command line.\n\nKey Features\n\nView and manage jobs visually\nMonitor queue depth and throughput\nControl jobs and queues (cancel, retry, delete jobs; pause queues)\nIdentify slow, stuck, or erroring jobs\nFaster development with real-time job status\nOpen source and self-hosted\nDark mode support\n\nDeployment Instructions\n\nEnsure you have a working River database and the DATABASE_URL is set in your environment.\n\nAccess the River UI through the specified port (default is 8080)\n\nNote: River UI does not include built-in authentication. Ensure it's deployed in a secure, private network and you can use the Oauth2 Proxy Template for that.\n\nFor issues with the template itself, please each out to me at youssef@reflectfy.com. For River specific questions, refer to the River documentation.",
    name: "riverui",
    category: "Queues",
    health: null,
    code: "2vnBb4",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2eeb6a67-746c-4d6f-b94f-e10dddab1f6f",
    isApproved: false,
    activeProjects: 151,
    projects: 402,
    description: "Open WebUI + Pipelines is an extendable, user friendly self-hosted LLM UI.",
    readme:
      "Open WebUI üëã\n\nGitHub stars\nGitHub forks\nGitHub watchers\nGitHub repo size\nGitHub language count\nGitHub top language\nGitHub last commit\nHits\nDiscord\n\n\nOpen WebUI is an extensible, feature-rich, and user-friendly self-hosted WebUI designed to operate entirely offline. It supports various LLM runners, including Ollama and OpenAI-compatible APIs. For more information, be sure to check out our Open WebUI Documentation.\n\nOpen WebUI Demo\n\nKey Features of Open WebUI ‚≠ê\n\nüöÄ Effortless Setup: Install seamlessly using Docker or Kubernetes (kubectl, kustomize or helm) for a hassle-free experience with support for both :ollama and :cuda tagged images.\n\nü§ù Ollama/OpenAI API Integration: Effortlessly integrate OpenAI-compatible APIs for versatile conversations alongside Ollama models. Customize the OpenAI API URL to link with LMStudio, GroqCloud, Mistral, OpenRouter, and more.\n\nüß© Pipelines, Open WebUI Plugin Support: Seamlessly integrate custom logic and Python libraries into Open WebUI using Pipelines Plugin Framework. Launch your Pipelines instance, set the OpenAI URL to the Pipelines URL, and explore endless possibilities. Examples include Function Calling, User Rate Limiting to control access, Usage Monitoring with tools like Langfuse, Live Translation with LibreTranslate for multilingual support, Toxic Message Filtering and much more.\n\nüì± Responsive Design: Enjoy a seamless experience across Desktop PC, Laptop, and Mobile devices.\n\nüì± Progressive Web App (PWA) for Mobile: Enjoy a native app-like experience on your mobile device with our PWA, providing offline access on localhost and a seamless user interface.\n\n‚úíÔ∏èüî¢ Full Markdown and LaTeX Support: Elevate your LLM experience with comprehensive Markdown and LaTeX capabilities for enriched interaction.\n\nüé§üìπ Hands-Free Voice/Video Call: Experience seamless communication with integrated hands-free voice and video call features, allowing for a more dynamic and interactive chat environment.\n\nüõ†Ô∏è Model Builder: Easily create Ollama models via the Web UI. Create and add custom characters/agents, customize chat elements, and import models effortlessly through Open WebUI Community integration.\n\nüêç Native Python Function Calling Tool: Enhance your LLMs with built-in code editor support in the tools workspace. Bring Your Own Function (BYOF) by simply adding your pure Python functions, enabling seamless integration with LLMs.\n\nüìö Local RAG Integration: Dive into the future of chat interactions with groundbreaking Retrieval Augmented Generation (RAG) support. This feature seamlessly integrates document interactions into your chat experience. You can load documents directly into the chat or add files to your document library, effortlessly accessing them using the # command before a query.\n\nüîç Web Search for RAG: Perform web searches using providers like SearXNG, Google PSE, Brave Search, serpstack, serper, Serply, DuckDuckGo, TavilySearch and SearchApi and inject the results directly into your chat experience.\n\nüåê Web Browsing Capability: Seamlessly integrate websites into your chat experience using the # command followed by a URL. This feature allows you to incorporate web content directly into your conversations, enhancing the richness and depth of your interactions.\n\nüé® Image Generation Integration: Seamlessly incorporate image generation capabilities using options such as AUTOMATIC1111 API or ComfyUI (local), and OpenAI's DALL-E (external), enriching your chat experience with dynamic visual content.\n\n‚öôÔ∏è Many Models Conversations: Effortlessly engage with various models simultaneously, harnessing their unique strengths for optimal responses. Enhance your experience by leveraging a diverse set of models in parallel.\n\nüîê Role-Based Access Control (RBAC): Ensure secure access with restricted permissions; only authorized individuals can access your Ollama, and exclusive model creation/pulling rights are reserved for administrators.\n\nüåêüåç Multilingual Support: Experience Open WebUI in your preferred language with our internationalization (i18n) support. Join us in expanding our supported languages! We're actively seeking contributors!\n\nüåü Continuous Updates: We are committed to improving Open WebUI with regular updates, fixes, and new features.\n\nWant to learn more about Open WebUI's features? Check out our Open WebUI documentation for a comprehensive overview!\n\nüîó Also Check Out Open WebUI Community!\n\nDon't forget to explore our sibling project, Open WebUI Community, where you can discover, download, and explore customized Modelfiles. Open WebUI Community offers a wide range of exciting possibilities for enhancing your chat interactions with Open WebUI! üöÄ\n",
    name: "Open WebUI with Pipelines",
    category: "AI/ML",
    health: 96,
    code: "Hez7Hu",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "36656207-1b6a-4d9f-8a4c-7e790df5483a",
    isApproved: false,
    activeProjects: 6,
    projects: 8,
    description: "Reverse proxy that provides auth with Google and more identity providers",
    readme:
      'OAuth2 Proxy Template for Railway\n\nOverview\nThis template deploys OAuth2 Proxy, a reverse proxy and static file server that provides authentication using Providers (Google, GitHub, and others) to validate accounts by email, domain or group. It\'s particularly useful for adding authentication to legacy applications or implementing single sign-on (SSO) across multiple services.\n\nFeatures\nActs as a reverse proxy for your internal services\nProvides authentication via Google OAuth2\nRestricts access to specific email domains\nEasy to configure and deploy\n\nDeployment Instructions\nClick the "Deploy on Railway" button\nConfigure the required environment variables (see below)\nDeploy the service\nSet up your Google OAuth2 credentials in the Google Cloud Console\nConfigure your internal service to work with the proxy\n\nEnvironment Variables\nConfigure the following environment variables:\n\nOAUTH2_PROXY_PROVIDER: Set to "google" for Google OAuth\nOAUTH2_PROXY_EMAIL_DOMAINS: Set to your company\'s email domain (e.g., "yourcompany.com")\nOAUTH2_PROXY_COOKIE_SECRET: A secret string to encrypt cookies (generate a random string)\nOAUTH2_PROXY_CLIENT_ID: Your Provider OAuth Client ID\nOAUTH2_PROXY_CLIENT_SECRET: Your Provider OAuth Client Secret\nOAUTH2_PROXY_REDIRECT_URL: The callback URL for OAuth (e.g., "https://your-proxy-domain/oauth2/callback")\nOAUTH2_PROXY_UPSTREAMS: The internal service URL to proxy (e.g., "http://internal-service:8080")\n\nGetting Started\nAfter deployment, access your OAuth2 Proxy URL provided by Railway\nAttempt to access your service; you\'ll be redirected to Google for authentication\nSign in with your company Google account\nUpon successful authentication, you\'ll be proxied to your internal service\n\nSecurity Considerations\nEnsure your Google OAuth credentials are kept secret\nRegularly rotate your OAUTH2_PROXY_COOKIE_SECRET\nLimit the OAUTH2_PROXY_EMAIL_DOMAINS to your company\'s domain\n\nCustomization\nAdjust the OAUTH2_PROXY_HTTP_ADDRESS if you need to change the listening port\nAdd additional OAuth2 Proxy flags as environment variables if needed\n\nSupport\nFor issues with the template itself, please each out to me at youssef@reflectfy.com. For OAuth2 Proxy specific questions, refer to the official documentation.\n\nEnjoy secure access to your internal services with OAuth2 Proxy!\n',
    name: "oauth2-proxy",
    category: "Authentication",
    health: 100,
    code: "RfKH-J",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1a640fdd-a0a2-42fc-97c9-a6ee4fbe02d5",
    isApproved: false,
    activeProjects: 12,
    projects: 34,
    description: "Self Hosted Docker Registry",
    readme:
      "Hosting your own Docker Registry can be rewarding. With this template, you get to do just that, running your own private registry on Railway.\n\nTo use the registry once deployed, run the following commands\n\n$ docker pull \n$ docker tag  /\n$ docker push /",
    name: "Registry",
    category: "Storage",
    health: 67,
    code: "FCYzGQ",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "650d8d57-3012-47eb-9bad-ea89d8091737",
    isApproved: false,
    activeProjects: 3,
    projects: 7,
    description: "Collection of handy online tools for developers, with great UX as a web app",
    readme:
      "\n    \n\n\nUseful tools for developer and people working in IT. Have a look !.\n\nFunctionalities and roadmap\n\nYou have an idea of a tool? Submit a feature request!\n\nContributors\n\nBig thanks to all the people who have already contributed!\n\ncontributors\n\nCredits\n\nCoded with ‚ù§Ô∏è by Corentin Thomasset.\n\nThis project is continuously deployed using vercel.com.\n\nContributor graph is generated using contrib.rocks.\n\nLicense\n\nThis project is under the GNU GPLv3.\n",
    name: "IT Tools",
    category: "Other",
    health: 100,
    code: "zY5dh2",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7d4d00ac-8494-4dba-a682-e97e9d9a7079",
    isApproved: false,
    activeProjects: 11,
    projects: 30,
    description: "FreshRSS is a self-hosted RSS feed aggregator.",
    readme:
      "\n\nFreshRSS is a self-hosted RSS feed aggregator.\n\nIt is lightweight, easy to work with, powerful, and customizable.\n\nIt is a multi-user application with an anonymous reading mode. It supports custom tags.\nThere is an API for (mobile) clients, and a Command-Line Interface.\n\nThanks to the WebSub standard,\nFreshRSS is able to receive instant push notifications from compatible sources, such as Friendica, WordPress, Blogger, Medium, etc.\n\nFreshRSS natively supports basic Web scraping,\nbased on XPath, for Web sites not providing any RSS / Atom feed.\nAlso supports JSON documents.\n\nFreshRSS offers the ability to reshare selections of articles by HTML, RSS, and OPML.\n\nDifferent login methods are supported: Web form (including an anonymous option), HTTP Authentication (compatible with proxy delegation), OpenID Connect.\n\nFinally, FreshRSS supports extensions for further tuning.\n",
    name: "Fresh RSS",
    category: "Blogs",
    health: 100,
    code: "QxGTsX",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1438dfb7-d01b-4359-8b5b-f8c187dfdf7b",
    isApproved: false,
    activeProjects: 3,
    projects: 6,
    description: "Starter for your backend AI-powered app",
    readme:
      "The Anthropic FastAPI Service is a FastAPI-based application that provides a RESTful API interface to the Anthropic Claude AI model, utilizing the anthropic-sdk-python. This setup enables developers to integrate Claude‚Äôs conversational AI capabilities into their applications seamlessly.\n\nKey Features:\n\t‚Ä¢\tRESTful API Interface: Facilitates interaction with the Claude AI model through standard HTTP methods, allowing for easy integration into various applications.\n\t‚Ä¢\tFastAPI Framework: Leverages FastAPI for high performance and straightforward API development.\n\t‚Ä¢\tAnthropic SDK Integration: Utilizes anthropic-sdk-python to communicate effectively with the Claude AI model.\n",
    name: "Anthropic x FastAPI",
    category: "AI/ML",
    health: 0,
    code: "5o0WPC",
    languages: ["Python", "Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "50036b4a-8892-4ee3-904a-0f7db9a2f8a4",
    isApproved: false,
    activeProjects: 3,
    projects: 6,
    description: "Open-Source Form backend for sending form data to email easily",
    readme:
      "Easily self-host FormBee's open-source form backend. This template allows you to easily send form data submitted on your websites to your email. Visit the FormBee Website to learn more about FormBee. Official FormBee Docs for more info about using the service. FormBee GitHub to check out the source code, and contribute if you'd like to!",
    name: "FormBee Email Only",
    category: "Other",
    health: 100,
    code: "NR9kSH",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "09b75935-4e8e-46c9-93ae-eb6c044d804f",
    isApproved: false,
    activeProjects: 2,
    projects: 8,
    description: "View and query your Postgres instance with a sleek and minimalistic UI.",
    readme:
      "Features\n\nCross-platform\n\nPgweb runs on OSX, Linux and Windows operating systems without a hustle. Binaries are cross-complied with Go and available for 32/64 bit systems. You can even run it on RaspberryPi\n\nEasy to Install\n\nPgweb comes as a single binary file that's ready to go. You can install it manually, via Docker or using Homebrew on OSX which is updated regularly and is super convenient.\n\nZero Dependencies\n\nNo need to install anything on your machines or services. Just download and run. To get started Pgweb just needs a browser and a PostgreSQL server to connect to.\n\nPostgreSQL 9.1+\n\nMost versions of PostgreSQL are supported, starting with official support for 9.1. Older versions could also be compatible but not guaranteed.\n\nSimple and Clean\n\nPgweb was designed to be very simple and clean UI to browse database tables or run and analyze SQL queries. Export query results or table rows to CSV/JSON/XML. Multiple schemas are supported. Records query history.\n\nFlexible Sessions\n\nPgweb can work with any local or remote PostgreSQL server (Heroku supported) as well as any server behind a firewall by using native SSH tunnelling with passwords or ssh keys. Quick-connect with server bookmarks.\n\nInstructions for use\nSimple one click install. Does not come with a predefined database so you can easily import into an existing project.\n\nAdd your database URL and you're good to go!",
    name: "pgweb | Postgres UI",
    category: "Observability",
    health: 75,
    code: "sZ09XT",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0fba8406-9e60-4b05-b26b-4c711148f6a1",
    isApproved: false,
    activeProjects: 7,
    projects: 20,
    description: "Effortless PostgreSQL backups with a user-friendly web interface!",
    readme:
      "PG Back Web isn't just another backup tool. It's your trusted ally in ensuring the security and availability of your PostgreSQL data:\n\nüéØ Designed for everyone: From individual developers to teams.\n‚è±Ô∏è Save time: Automate your backups and forget about manual tasks.\n‚ö° Plug and play: Don't waste time with complex configurations.\n\nFeatures\nüì¶ Intuitive web interface: Manage your backups with ease, no database expertise required.\nüìÖ Scheduled backups: Set it and forget it. PG Back Web takes care of the rest.\nüìà Backup monitoring: Visualize the status of your backups with execution logs.\nüì§ Instant download &amp; restore: Restore and download your backups when you need them, directly from the web interface.\nüñ• Multi-version support: Compatible with PostgreSQL 13, 14, 15, and 16.\nüìÅ Local &amp; S3 storage: Store backups locally or add as many S3 buckets as you want for greater flexibility.\n‚ù§Ô∏è‚Äçü©π Health checks: Automatically check the health of your databases and destinations.\nüîî Webhooks: Get notified when a backup finishes, failed, health check fails, or other events.\nüîí Security first: PGP encryption to protect your sensitive information.\nüõ°Ô∏è Open-source trust: Open-source code under MIT license, backed by the robust pg_dump tool.\nüåö Dark mode: Because we all love dark mode.\n\nScreenshot\n\nJoin the Community\nGot ideas to improve PG Back Web? Contribute to the project! Every suggestion and pull request is welcome.\n\nüíñ Love PG Back Web? Give us a ‚≠ê on GitHub and share the project with your colleagues. Together, we can make PostgreSQL backups more accessible to everyone!",
    name: "PG Back Web",
    category: "Other",
    health: 100,
    code: "vT0tcc",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c81b2485-46a5-4903-9e71-cc6e53e4b26d",
    isApproved: false,
    activeProjects: 7,
    projects: 17,
    description: "A simple, yet powerful dashboard for your server.",
    readme:
      "Simplify the management of your server with Homarr - a sleek, modern dashboard that puts all of your apps and services at your fingertips. With Homarr, you can access and control everything in one convenient location. Homarr seamlessly integrates with the apps you've added, providing you with valuable information and giving you complete control. Installation is a breeze, and Homarr supports a wide range of deployment methods.\n\nHomarr Demo\n\nFeatures:\nüñåÔ∏è Highly customizable with an extensive drag and drop grid system\n‚ú® Integrates seamlessly with your favorite self-hosted applications\nüìå Easy and fast app management - no YAML involved\nüôä Advanced secrets' management system for enhanced security\nüìÑ Detailed documentation and active community\nüîç Search through the web or supported integrations in an instant\nüè¥Û†ÅßÛ†Å¢Û†ÅÆÛ†Å©Û†Å≤Û†Åø Monitor your application with a built-in status system\nü¶û Comprehensive built-in icon picker with over 7000 icons\nüê≥ Easy deployment with Docker, unRAID, and Synology\nüöÄ Compatible with any major consumer hardware (x86, Raspberry Pi, old laptops, ...)\n\nDocumentation:\nFor more information, Visit Homarr Docs\n\nhttps://homarr.dev/\n",
    name: "Homarr",
    category: "Other",
    health: null,
    code: "_c4Kr9",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "56d56b3f-ea3c-4123-8aa8-628bdd1a4a24",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "Webhook payload delivery service",
    readme:
      "Usage\n\nSmee is a webhook payload delivery service - it receives webhook payloads, and sends them to listening clients. You can generate a new channel by visiting deployed url, and get a unique URL to send payloads to.\n\nHeads up! Smee.io is intended for use in development, not for production. It's a way to inspect payloads through a UI and receive them on a local machine, not as a proxy for production applications.\n\nHow it works\n\nSmee works with two components: the public self-hosted website and the smee-client. They talk to each other via Server-Sent Events, a type of connection that allows for messages to be sent from a source to any clients listening.\n\nThis means that channels are just an abstraction - all Smee does is get a payload and sends it to any actively connected clients.\n\nDeploying your own Smee.io\n\nSmee.io is a simple Node.js application. You can deploy it with this template!\n\nDon't forget to point smee-client to your instance of smee.io:\n\nsmee --url https://your-smee.up.railway.app/channel\n\nFAQ\n\nHow long do channels live for?\n\nChannels are always active - once a client is connected, Smee will send any payloads it gets at /:channel to those clients.\n\nShould I use this in production?\n\nNo! Smee is not designed for production use - it is a development and testing tool. Note that channels are not authenticated, so if someone has your channel ID they can see the payloads being sent, so it is not secure for production use.\n\nAre payloads ever stored?\n\nWebhook payloads are never stored on the server, or in any database; the Smee.io server is simply a pass-through. However, we do store payloads in localStorage in your browser, so that revisiting https://smee.io/:channel will persist the payloads you saw there last.",
    name: "smee.io",
    category: "Other",
    health: null,
    code: "woCyed",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "beea2e90-a1bc-4a89-b4c2-e3bd6b5c1e8a",
    isApproved: false,
    activeProjects: 5,
    projects: 23,
    description: "Infisical - Secure and Cost-Optimized for Railway",
    readme:
      "_EN\n\nInfisical is a simple and effective solution to centralize and securely manage API keys, secrets, and environment variables.\n\nWhy choose our Railway template for Infisical?\n\nCost Optimization: The internal private network between services allows you to keep your URLs unexposed and eliminates the costs of traffic generated between them.\n\nEnhanced Security: No need to make your services public, significantly reducing potential attack risks.\n\nEmbrace Digital Sobriety\nRemember to use \"sleep mode\" and adjust the resources of each of your services for responsible and efficient management!\n\n_FR\n\nInfisical est une solution simple et efficace pour centraliser et g√©rer en toute s√©curit√© les cl√©s API, secrets et variables d'environnement.\n\nPourquoi choisir notre template Railway pour Infisical ?\n\nOptimisation des co√ªts : Le r√©seau priv√© interne entre les services permet de ne pas exposer vos URL et de supprimer les frais de trafic g√©n√©r√© entre eux.\n\nS√©curit√© renforc√©e : Aucun besoin de rendre vos services publics, r√©duisant ainsi les risques d'attaques potentielles.\n\nAdopter une d√©marche de sobri√©t√© num√©rique\nN'oubliez pas d'utiliser le \"sleep mode\" et d'ajuster les ressources de chacun de vos services pour une gestion responsable et efficace !",
    name: "infisical",
    category: "Automation",
    health: 87,
    code: "iN2RVh",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "795dad7f-eb41-4fea-9617-57be081c9aed",
    isApproved: false,
    activeProjects: 1,
    projects: 2,
    description: "Backup your MySQL or MariaDB database to S3 via a cron.",
    readme:
      "Overview\n\nThe template uses node-cron or Railway cron, written in TypeScript to dump your MySQL or MariaDB data to a file and then upload the file to S3.\n\nHighlights\n\nConfigurable backup schedule: By default, the cron runs at 5 AM every day but is configurable via the BACKUP_CRON_SCHEDULE environment variable.\n\nSupport for custom buckets: The script also supports using a AWS_S3_ENDPOINT environment variable to use any S3 compliant storage bucket (eg: Wasabi).\n\nConfiguration\n\nAWS_ACCESS_KEY_ID - AWS access key ID.\n\nAWS_SECRET_ACCESS_KEY - AWS secret access key, sometimes also called an application key.\n\nAWS_S3_BUCKET - The name of the bucket that the access key ID and secret access key are authorized to access.\n\nAWS_S3_REGION - The name of the region your bucket is located in, set to auto if unknown.\n\nBACKUP_DATABASE_HOST - The host of the database to backup.\n\nBACKUP_DATABASE_PORT - The port of the database to backup.\n\nBACKUP_DATABASE_NAME - The name of the database to backup.\n\nBACKUP_DATABASE_USERNAME - The username of the database to backup.\n\nBACKUP_DATABASE_PASSWORD - The password of the database to backup.\n\nBACKUP_CRON_SCHEDULE - The cron schedule to run the backup on. Example: 0 5 * * *\n\nAWS_S3_ENDPOINT - The S3 custom endpoint you want to use. Applicable for 3-rd party S3 services such as Cloudflare R2 or Backblaze R2.\n\nAWS_S3_FORCE_PATH_STYLE - Use path style for the endpoint instead of the default subdomain style, useful for MinIO. Default false\n\nRUN_ON_STARTUP - Run a backup on startup of this application then proceed with making backups on the set schedule.\n\nBACKUP_FILE_PREFIX - Add a prefix to the file name.\n\nBUCKET_SUBFOLDER - Define a subfolder to place the backup files in.\n\nSINGLE_SHOT_MODE - Run a single backup on start and exit when completed. Useful with the platform's native CRON schedular.\n\nSUPPORT_OBJECT_LOCK - Enables support for buckets with object lock by providing an MD5 hash with the backup file.\n",
    name: "mysql-s3-backups",
    category: "Automation",
    health: 100,
    code: "BZJOmR",
    languages: ["TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "94cac334-b76c-4d56-87c8-5455439b65b8",
    isApproved: false,
    activeProjects: 2,
    projects: 4,
    description: "S3 Compatible Server ontop SeaweedFS (Apache-2.0 license)",
    readme:
      "Minio is nice but is AGPL licensed, which is a no-go for any commercial project. If you still want to use S3-compatible API and store files SeaweedFS is your savior.\n\nSetup:\nMake sure to add port 8333 as a binding to your HTTP networking for it to work.\nimage\n\n\nTaken from official docker image:\nhttps://hub.docker.com/r/chrislusf/seaweedfs\n\nMore reference links:\nhttps://github.com/seaweedfs/seaweedfs/wiki/Amazon-S3-API",
    name: "SeaweedFS",
    category: "Storage",
    health: 67,
    code: "PbH9L1",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7589107c-a544-4d7b-9034-862c00917c2b",
    isApproved: false,
    activeProjects: 2,
    projects: 6,
    description: "An effortless open-source localization platform.",
    readme:
      'Tolgee is a developer-focused platform, so it is easy to integrate with your application. No more looking for keys in your source code, no more editing localization files, and no more manual exporting data for translators.\n\nFeatures\n\nDeveloper-friendly - Tolgee is designed to be easy to integrate with your application. There are number of integrations with JavaScript frameworks, such as React, Angular, Vue, and many more with the use of Tolgee JS SDK.\nEasy to use - Tolgee is easy to use for developers, but also for translators, so you can easily involve your translators into your localization process.\nOpen-source - Tolgee is open-source, you can contribute to the project on our GitHub repository.\nFree - Our cloud version includes Business plan with 20 000 strings is free for any open-source projects. For commercial projects, you can use Tolgee for free up to 1000 strings.\nIn-context editor - Tolgee provides in-context editor, so translators can easily translate your application without leaving your application.\nTolgee AI translator - Tolgee Translator can make software localization much faster and more autonomous. It provides more accurate translations than general translators as it gathers context through Tolgee\'s native JS SDKs, which provide in-context dialogs.\n\nConfiguration Options\n\nSee https://tolgee.io/platform/self_hosting/configuration for full configuration options.\n\nSet environment variables to enable the following options:\n\nSMTP (Password reset links or notifications)\n\nTOLGEE_SMTP_AUTH=true\nTOLGEE_SMTP_FROM="Tolgee "\nTOLGEE_SMTP_PORT=465\nTOLGEE_SMTP_HOST="email-smtp.region-example.amazonawss.com"\nTOLGEE_SMTP_SSL_ENABLED=true\nTOLGEE_SMTP_USERNAME=**\nTOLGEE_SMTP_PASSWORD=**\n\n\n',
    name: "Tolgee (Single Service Deployment)",
    category: "Other",
    health: 100,
    code: "gpEPyD",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7b7a5041-138f-4045-b27e-9613ab85ec75",
    isApproved: false,
    activeProjects: 1,
    projects: 8,
    description: "Open source Airtable alternative & backend as a service",
    readme:
      "Github: https://github.com/undb-io/undb\n\nFeatures\n\n‚ö° No-code platform, easy to use\nüóÑÔ∏è Based on SQLite, a lightweight database\nüîê Private and local first\nüì¶ Can be packaged into a binary file using Bun\nü™ú Progressive deployment, from local in single file to cloud complicated stacks.\nüê≥ Supports Docker deployment\nüõ†Ô∏è Provides a UI for table management",
    name: "undb",
    category: "Other",
    health: null,
    code: "gbEeq4",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "99b06b21-f9b8-4d14-a020-b7216fe7db6a",
    isApproved: false,
    activeProjects: 2,
    projects: 10,
    description: "A performance dashboard for Postgres",
    readme:
      "A simple performance dashboard for Postgres. For documentation and guides check out: https://github.com/ankane/pghero\n\nRequirements: enable pg_stat_statements\n\nSteps:\nStart your postgres service with a custom start command to enabled pg_stat_statements: /usr/local/bin/docker-entrypoint.sh postgres --port=5432 -c 'shared_preload_libraries=timescaledb,pg_stat_statements'\nOnce restarted, run CREATE EXTENSION IF NOT EXISTS pg_stat_statements;",
    name: "PgHero",
    category: "Observability",
    health: 96,
    code: "QUJmGE",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9d0e0db1-7217-4d85-816f-748047ef5960",
    isApproved: false,
    activeProjects: 8,
    projects: 9,
    description: "A project renders at scale GTFS files on the browser without backend",
    readme:
      "A project renders at scale GTFS files on the browser without backend\n\nMain feature is is completely browser based using Duckdb Wasm to process the gtfs data at scale in the browser without a backend.\n\nFeel free to contribute to the project by making a PR or opening an issue.\n\nGTFS Viz\n\nStack\nFramework\nVite\n\nData Processing ‚öôÔ∏è‚öôÔ∏è\nDuckDB\n\nStyle üé®\nTailwindcss\nShadcn\n",
    name: "GTFS Viz üöâ",
    category: "Other",
    health: 100,
    code: "nJ-5yD",
    languages: ["TypeScript", "JavaScript", "HTML", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "413ef863-0230-4a83-947f-6f2ec0db296c",
    isApproved: false,
    activeProjects: 3,
    projects: 28,
    description: "Open-source time-tracking tool designed for freelancers and teams",
    readme:
      "solidtime\n\nSolidtime is an open-source time-tracking tool designed for freelancers and teams. It offers features like granular roles and permissions, cross-platform compatibility via a PWA, and system notifications. Users can import data from other time trackers like Toggl and Clockify. The platform also plans to include billing and invoicing features soon. Solidtime can be used as a hosted SaaS solution or set up on-premise, with support for enterprise installations.\n\nFor more information, visit Solidtime.\n\nFeatures\n\nRedis\nPostgres\nS3\n\nSetting up\n\nThis install is literally one click, but you'll need to configure things if you want it to work in production.  \n  \n1\\. Setup your custom SMTP - if you don't you won't be able to activate your accounts.\n\n2\\. If you don't setup a custom SMTP, you must register an account, then edit that account on the Postgres instance (through the data tab).\n\n‚Äì Editing the user is easy, just click your name, and add a timestamp to email_verified_at. Once that's done, save and refresh your app. You should be able to login no problem.  \nAdmin Access\n\nEdit the variable ‚ÄúSUPER\\_ADMINS‚Äù and add your email(s). Separated by commas.\n\nS3\n\nJust add your variables to the environment and you should be good, although I haven't tested it myself personally ‚Äì let's hope for the best ;)\n\nAdditional Documentation and Configuration\nhttps://docs.solidtime.io/self-hosting/intro\n\nONE CLICK INSTALL\n\nscreenshot",
    name: "solidtime ‚ÅÇ Postgres, Redis, S3",
    category: "Analytics",
    health: 86,
    code: "WaxghR",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5afd9a1b-e942-4721-9a05-79402fa1cba0",
    isApproved: false,
    activeProjects: 247,
    projects: 651,
    description: 'A popular self-hosted "headless" CMS',
    readme:
      "NEWEST V5.11.3 VERSION!!!\n\n\n\nThe Railway.app Strapi template streamlines the process of getting Strapi up and running on the Railway platform. Whether you're a solo developer or working in a team, this template allows you to focus on building your content and services rather than worrying about deployment complexity.\n\nKey Features:\n\nInstant Deployment: The template allows you to deploy Strapi on Railway with a single click. This makes the setup process fast and effortless, perfect for developers who want to start building immediately.\n\nFully Configurable: You can modify the Strapi project to suit your specific needs, whether it's creating custom APIs, managing data, or adding new functionalities through plugins.\n\nScalable: Built on Railway's infrastructure, the template ensures that your Strapi instance can scale as your project grows. You can adjust resources like CPU, memory, and storage on the go, making it a versatile solution for projects of all sizes.\n\nDatabase Integration: Strapi needs a database, and Railway makes it easy to set up PostgreSQL or MySQL, depending on your preference. Database configuration is handled automatically, so you can spend more time developing.\n\nCI/CD Friendly: The template integrates with Railway‚Äôs continuous deployment features, ensuring that every change is automatically pushed live with zero downtime.\n\n\nIn summary, the Railway.app Strapi template provides a seamless and efficient way to manage content and applications, making it an ideal choice for developers who value simplicity and scalability in their development workflow.\n\nNOTES\n\nWhen this template is running on Railway Strapi will connect to the Postgres Database through the private network, saving you on database egress fees\n\nDeveloping locally\nWhen developing locally this Strapi template will connect to the Postgres server from its public TCP Proxy\n\nEnable the feature flag Template Service Eject in the Feature Flags menu\nWithin the service settings of the Strapi service click the Eject button on the upstream repository\nClone that newly created repository locally\nInstall Strapi's dependencies with yarn install or npm install\nInstall the Railway CLI\n\nInstructions for that can be found here\nIf this is your first time using the CLI make sure to login with railway login\n\n\nWithin the local repository run railway link to link the local repository to the Strapi service on Railway\nStart Strapi for development with railway run yarn run develop or railway run npm run develop\n\nThis command will run Strapi in development mode with the service variables available locally\n\n\nOpen your browser to http://127.0.0.1:1337/admin",
    name: "Strapi 5",
    category: "CMS",
    health: 68,
    code: "e10OW1",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e40a49da-79c4-4989-b776-5ef74f54c122",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "German Werks LTD Template",
    readme:
      "Railway is a cloud deployment platform that simplifies the process of deploying and managing web applications. It offers a user-friendly interface and handles infrastructure provisioning, scaling, and maintenance. Key features include:\n\nZero-configuration builds: Railway uses Nixpacks to build container images from your source code.\nQuick deployment: Push your code to a repository, and Railway will build and deploy it to a live URL.\nScalability: Easily scale your application's resources based on demand.\nManaged services: Railway offers managed databases, cron jobs, and other services.\nTemplate marketplace: Choose from pre-built templates for common web applications.",
    name: "German Werks",
    category: "Other",
    health: null,
    code: "-hjLx0",
    languages: ["TypeScript", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c7096409-b90d-4647-b638-3da6bd400bf9",
    isApproved: false,
    activeProjects: 7,
    projects: 9,
    description: "A starter project for Dart Frog, a fast, minimal backend framework for Dart",
    readme:
      "Dart Frog is a fast, minimalistic backend framework for Dart. It enables you to write backend logic deployed to the server in the same language you know and love from Flutter.\n\nThis template contains a starter project for Dart Frog. Duplicate this project and begin coding your next API.\n\nFor more information, check out how to deploy Dart Frog on Railway.",
    name: "dart_frog_starter",
    category: "Starters",
    health: null,
    code: "w3Bek-",
    languages: ["Dart", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "07466f6d-ab94-4fbd-a547-1aec02050f95",
    isApproved: false,
    activeProjects: 11,
    projects: 17,
    description: "Template simples Flowise AI. Defina usu√°rio, senha e fa√ßa o deploy.",
    readme:
      "FlowiseAI\n\nüöÄ Template Flowise AI - Deploy em Minutos\n\nEste template do Flowise AI foi projetado para voc√™ iniciar rapidamente. O Flowise √© uma plataforma no-code com uma interface intuitiva de arrastar e soltar para criar fluxos de trabalho personalizados com Modelos de Linguagem de Grande Escala (LLMs).\n\nüîë Configura√ß√£o Simples: A √∫nica coisa que voc√™ precisa fazer √© definir o usu√°rio e a senha para autentica√ß√£o no arquivo .env. \n\n‚ö° Passos:\nConfigure o usu√°rio e senha.\nFa√ßa o deploy.\nComece a criar seus fluxos de trabalho personalizados! üí°\n\nSem complica√ß√µes, sem configura√ß√µes avan√ßadas. Comece agora e aproveite o poder do Flowise para automatizar seus processos em poucos minutos! ‚è≥‚ú®",
    name: "FlowiseAI üáßüá∑",
    category: "AI/ML",
    health: 100,
    code: "DC2bT-",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d666c95b-7632-46d1-a175-878b2c66a08b",
    isApproved: false,
    activeProjects: 8,
    projects: 18,
    description: "Google search results without ads and tracking",
    readme:
      "Get Google search results, but without any ads, JavaScript, AMP links, cookies, or IP address tracking. Easily deployable and customizable. Quick and simple to implement as a primary search engine replacement on both desktop and mobile.\n\nFeatures\nNo ads or sponsored content\nNo JavaScript*\nNo cookies**\nNo tracking/linking of your personal IP address*\nNo AMP links\nNo URL tracking tags (i.e. utm=%s)\nNo referrer header\nTor and HTTP/SOCKS proxy support\nAutocomplete/search suggestions\nPOST request search and suggestion queries (when possible)\nView images at full res without site redirect (currently mobile only)\nLight/Dark/System theme modes (with support for custom CSS theming)\nRandomly generated User Agent\nEasy to install/deploy\nDDG-style bang (i.e. ! ) searches\nOptional location-based searching (i.e. results near )\nOptional NoJS mode to view search results in a separate window with JavaScript blocked",
    name: "Whoogle",
    category: "Other",
    health: null,
    code: "66dg_S",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "156acffe-b4a1-4be6-afb5-4e592e6a8042",
    isApproved: false,
    activeProjects: 28,
    projects: 89,
    description: "metasearch engine - easily integrate with your AI apps",
    readme:
      "SearxNG is an open-source metasearch engine that ensures user privacy by not tracking searches. Self-hosting offers complete data control, customization options, an ad-free experience, and no reliance on third-party servers. It allows integration with other services and benefits from community support, making it a strong choice for privacy-conscious users.",
    name: "SearXNG - metasearch",
    category: "Other",
    health: 95,
    code: "oEGdc4",
    languages: [
      "Python",
      "Shell",
      "HTML",
      "Less",
      "JavaScript",
      "CSS",
      "Emacs Lisp",
      "Dockerfile",
      "Makefile",
      "Lua",
    ],
    tags: null,
  },
  {
    __typename: "Template",
    id: "519f6420-bfee-4db2-99bf-0e2af02300b7",
    isApproved: false,
    activeProjects: 5,
    projects: 13,
    description: "g1: Using Llama-3.1 70b on Groq to create o1-like reasoning chains",
    readme:
      "g1: Using Llama-3.1 70b on Groq to create o1-like reasoning chains\n\nThis is an early prototype of using prompting strategies to improve the LLM's reasoning capabilities through o1-like reasoning chains. This allows the LLM to \"think\" and solve logical problems that usually otherwise stump leading models. Unlike o1, all the reasoning tokens are shown, and the app uses an open source model.\n\ng1 is experimental and being open sourced to help inspire the open source community to develop new strategies to produce o1-like reasoning. This experiment helps show the power of prompting reasoning in visualized steps, not a comparison to or full replication of o1, which uses different techniques. OpenAI's o1 is instead trained with large-scale reinforcement learning to reason using Chain of Thought, achieving state-of-the-art performance on complex PhD-level problems. \n\ng1 demonstrates the potential of prompting alone to overcome straightforward LLM logic issues like the Strawberry problem, allowing existing open source models to benefit from dynamic reasoning chains and an improved interface for exploring them.\n\nHow it works\n\ng1 powered by Llama3.1-70b creates reasoning chains, in principle a dynamic Chain of Thought, that allows the LLM to \"think\" and solve some logical problems that usually otherwise stump leading models.\n\nAt each step, the LLM can choose to continue to another reasoning step, or provide a final answer. Each step is titled and visible to the user. The system prompt also includes tips for the LLM. There is a full explanation under Prompt Breakdown, but a few examples are asking the model to ‚Äúinclude exploration of alternative answers‚Äù and ‚Äúuse at least 3 methods to derive the answer‚Äù.\n\nThe reasoning ability of the LLM is therefore improved through combining Chain-of-Thought with the requirement to try multiple methods, explore alternative answers, question previous draft solutions, and consider the LLM‚Äôs limitations. This alone, without any training, is sufficient to achieve ~70% accuracy on the Strawberry problem (n=10, \"How many Rs are in strawberry?\"). Without prompting, Llama-3.1-70b had 0% accuracy and ChatGPT-4o had 30% accuracy.\n\nExamples\n\n&gt; !IMPORTANT]\n&gt; g1 is not perfect, but it can perform significantly better than LLMs out-of-the-box. From initial testing, g1 accurately solves simple logic problems 60-80% of the time that usually stump LLMs. However, accuracy has yet to be formally evaluated. See examples below.\n\nHow many Rs are in strawberry?\nPrompt: How many Rs are in strawberry?\n\nResult:\n\nStrawberry example\n\nPrompt: Which is larger, .9 or .11?\n\nResult:\n\n0.9 or 0.11 example\n\nPrompting Strategy\n\nThe prompt is as follows:\n\nYou are an expert AI assistant that explains your reasoning step by step. For each step, provide a title that describes what you're doing in that step, along with the content. Decide if you need another step or if you're ready to give the final answer. Respond in JSON format with 'title', 'content', and 'next_action' (either 'continue' or 'final_answer') keys. USE AS MANY REASONING STEPS AS POSSIBLE. AT LEAST 3. BE AWARE OF YOUR LIMITATIONS AS AN LLM AND WHAT YOU CAN AND CANNOT DO. IN YOUR REASONING, INCLUDE EXPLORATION OF ALTERNATIVE ANSWERS. CONSIDER YOU MAY BE WRONG, AND IF YOU ARE WRONG IN YOUR REASONING, WHERE IT WOULD BE. FULLY TEST ALL OTHER POSSIBILITIES. YOU CAN BE WRONG. WHEN YOU SAY YOU ARE RE-EXAMINING, ACTUALLY RE-EXAMINE, AND USE ANOTHER APPROACH TO DO SO. DO NOT JUST SAY YOU ARE RE-EXAMINING. USE AT LEAST 3 METHODS TO DERIVE THE ANSWER. USE BEST PRACTICES.\n\nExample of a valid JSON response:\njson\n{\n    \"title\": \"Identifying Key Information\",\n    \"content\": \"To begin solving this problem, we need to carefully examine the given information and identify the crucial elements that will guide our solution process. This involves...\",\n    \"next_action\": \"continue\"\n}\n\nBreakdown\n\nFirst, a persona is added:\n\n&gt; You are an expert AI assistant that explains your reasoning step by step.\n\n\n\nThen, instructions to describe the expected step-by-step reasoning process while titling each reasoning step. This includes the ability for the LLM to decide if another reasoning step is needed or if the final answer can be provided.\n\n&gt; For each step, provide a title that describes what you're doing in that step, along with the content. Decide if you need another step or if you're ready to give the final answer. \n\n\n\nJSON formatting is introduced with an example provided later.\n\n&gt; Respond in JSON format with 'title', 'content', and 'next_action' (either 'continue' or 'final_answer') keys. \n\n\n\nIn all-caps to improve prompt compliance by emphasizing the importance of the instruction, a set of tips and best practices are included.\n\nUse as many reasoning steps as possible. At least 3. -&gt; This ensures the LLM actually takes the time to think first, and results usually in about 5-10 steps.\nBe aware of your limitations as an llm and what you can and cannot do. -&gt; This helps the LLM remember to use techniques which produce better results, like breaking \"strawberry\" down into individual letters before counting.\nInclude exploration of alternative answers. Consider you may be wrong, and if you are wrong in your reasoning, where it would be. -&gt; A large part of the gains seem to come from the LLM re-evaluating its initial response to ensure it logically aligns with the problem.\nWhen you say you are re-examining, actually re-examine, and use another approach to do so. Do not just say you are re-examining. -&gt; This encourages the prevention of the LLM just saying it re-examined a problem without actually trying a new approach. \nUse at least 3 methods to derive the answer. -&gt; This helps the LLM come to the right answer by trying multiple methods to derive it.\nUse best practices. -&gt; This is as simple as the \"Do better\" prompts which improve LLM code output. By telling the LLM to use best practices, or do better, it generally performs better!\n\n\n&gt; USE AS MANY REASONING STEPS AS POSSIBLE. AT LEAST 3. BE AWARE OF YOUR LIMITATIONS AS AN LLM AND WHAT YOU CAN AND CANNOT DO. IN YOUR REASONING, INCLUDE EXPLORATION OF ALTERNATIVE ANSWERS. CONSIDER YOU MAY BE WRONG, AND IF YOU ARE WRONG IN YOUR REASONING, WHERE IT WOULD BE. FULLY TEST ALL OTHER POSSIBILITIES. YOU CAN BE WRONG. WHEN YOU SAY YOU ARE RE-EXAMINING, ACTUALLY RE-EXAMINE, AND USE ANOTHER APPROACH TO DO SO. DO NOT JUST SAY YOU ARE RE-EXAMINING. USE AT LEAST 3 METHODS TO DERIVE THE ANSWER. USE BEST PRACTICES.\n\n\n\nFinally, after the problem is added as a user message, an assistant message is loaded to provide a standardized starting point for the LLM's generation.\n\n&gt; Assistant: Thank you! I will now think step by step following my instructions, starting at the beginning after decomposing the problem\n\nTop Forks\nMult1: Using multiple AI providers to create o1-like reasoning chains ([GitHub Repository)\n\nCredits\n\nThis app was developed by Benjamin Klieger.",
    name: "G1",
    category: "AI/ML",
    health: 100,
    code: "ZHW92m",
    languages: ["Python", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b3a1b199-2b22-4332-9d63-78528d27a63a",
    isApproved: false,
    activeProjects: 6,
    projects: 27,
    description: "Perplexity-like answer engine powered with AI,",
    readme:
      "Morphic + Redis, \nRequired:\nOpenAI API Key, \nTavily API key,\n\nThis project is designed to make AI-powered search easy and improve user experience. It lets users ask questions and get fast, AI-generated answers. Features like search history, video search, and the ability to pull answers from specific websites make it more useful. You can also use it as a regular search engine.\n",
    name: "Morphic AI",
    category: "AI/ML",
    health: 100,
    code: "I7-4De",
    languages: ["TypeScript", "CSS", "JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3d5231ee-af7b-4684-a38e-442eb99319f1",
    isApproved: false,
    activeProjects: 42,
    projects: 75,
    description: "Everything is RSSible. The world's largest RSS network.",
    readme:
      "RSSHub is the world's largest RSS network, consisting of over 5,000 global instances.\n\nRSSHub delivers millions of contents aggregated from all kinds of sources, our vibrant open source community is ensuring the deliver of RSSHub's new routes, new features and bug fixes.",
    name: "RSSHub",
    category: "Other",
    health: 100,
    code: "Gpp7EW",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6c94df22-b793-43d5-b26a-db2c797eddc2",
    isApproved: false,
    activeProjects: 4,
    projects: 12,
    description: "A simple Astro blog starter",
    readme:
      "Astro Starter Kit: Blog\n\nFeatures:\n\n‚úÖ Minimal styling (make it your own!)\n‚úÖ 100/100 Lighthouse performance\n‚úÖ SEO-friendly with canonical URLs and OpenGraph data\n‚úÖ Sitemap support\n‚úÖ RSS Feed support\n‚úÖ Markdown & MDX support\n\nüöÄ Project Structure\n\nInside of your Astro project, you'll see the following folders and files:\n\n‚îú‚îÄ‚îÄ public/\n‚îú‚îÄ‚îÄ src/\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ components/\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ content/\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ layouts/\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ pages/\n‚îú‚îÄ‚îÄ astro.config.mjs\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ package.json\n‚îî‚îÄ‚îÄ tsconfig.json\n\nAstro looks for .astro or .md files in the src/pages/ directory. Each page is exposed as a route based on its file name.\n\nThere's nothing special about src/components/, but that's where we like to put any Astro/React/Vue/Svelte/Preact components.\n\nThe src/content/ directory contains \"collections\" of related Markdown and MDX documents. Use getCollection() to retrieve posts from src/content/blog/, and type-check your frontmatter using an optional schema. See Astro's Content Collections docs to learn more.\n\nAny static assets, like images, can be placed in the public/ directory.\n\nüßû Commands\n\nAll commands are run from the root of the project, from a terminal:\n\n| Command                   | Action                                           |\n| :------------------------ | :----------------------------------------------- |\n| npm install             | Installs dependencies                            |\n| npm run dev             | Starts local dev server at localhost:4321      |\n| npm run build           | Build your production site to ./dist/          |\n| npm run preview         | Preview your build locally, before deploying     |\n| npm run astro ...       | Run CLI commands like astro add, astro check |\n| npm run astro -- --help | Get help using the Astro CLI                     |\n\nüëÄ Want to learn more?\n\nCheck out our documentation or jump into our Discord server.\n\nCredit\n\nThis theme is based off of the lovely Bear Blog.\n",
    name: "Astro Blog Starter",
    category: "Starters",
    health: 0,
    code: "C0NgiM",
    languages: ["Astro", "CSS", "MDX", "JavaScript", "Dockerfile", "TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e3f9e485-aac4-476e-8ff2-184d3b80c5aa",
    isApproved: false,
    activeProjects: 12,
    projects: 18,
    description: "A local hosted web based PDF editor",
    readme:
      "Stirling PDF\n\nThis is a robust, locally hosted web-based PDF manipulation tool using Docker. It enables you to carry out various operations on PDF files, including splitting, merging, converting, reorganizing, adding images, rotating, compressing, and more. This locally hosted web application has evolved to encompass a comprehensive set of features, addressing all your PDF requirements.\n\nStirling PDF does not initiate any outbound calls for record-keeping or tracking purposes.\n\nAll files and PDFs exist either exclusively on the client side, reside in server memory only during task execution, or temporarily reside in a file solely for the execution of the task. Any file downloaded by the user will have been deleted from the server by that point.\n\nFeatures\n\nDark mode support.\nCustom download options\nParallel file processing and downloads\nCustom 'Pipelines' to run multiple features in a queue\nAPI for integration with external scripts\nOptional Login and Authentication support (see here for documentation)\nDatabase Backup and Import (see here for documentation)",
    name: "Stirling PDF",
    category: "Other",
    health: 90,
    code: "Rn4VSj",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e737ddc4-b3cc-4d07-be8c-9cf391f6e871",
    isApproved: false,
    activeProjects: 11,
    projects: 36,
    description: "SuperTokens ‚Äî User Authentication",
    readme:
      "Add secure login and session management to your apps. SDKs available for popular languages and front-end frameworks e.g. Node.js, Go, Python, React.js, React Native, Vanilla JS, etc.\n\nThree building blocks of SuperTokens architecture\n\nFrontend SDK: Manages session tokens and renders login UI widgets\nBackend SDK: Provides APIs for sign-up, sign-in, signout, session refreshing, etc. Your Frontend will talk to these APIs\nSuperTokens Core: The HTTP service for the core auth logic and database operations. This service is used by the Backend SDK",
    name: "SuperTokens",
    category: "Authentication",
    health: 100,
    code: "i1xFfT",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "74c31cec-221d-4f3c-8571-53577b315d4e",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "Test internal-only apps and APIs for performance and reliability.",
    readme:
      "Checkly Agent\n\nThe Checkly Agent is a container that you need to deploy to run a Private Location in Checkly. The agent needs to be deployed on your infrastructure and executes checks on behalf of the Checkly application. For configuration details, check the agent configuration guide.\n\nUpdating the agent container\n\nNew versions of the Checkly Agent are released regularly. To have access to the latest improvements, you can simply redeploy the service.\n\nUsing private locations\n\nPlease read Checkly's getting started guide.\n\n",
    name: "Checkly Agent",
    category: "Observability",
    health: null,
    code: "checkly",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4980db9f-4656-472c-b6a3-d5cc96244b96",
    isApproved: false,
    activeProjects: 0,
    projects: 4,
    description: "Twitch Event Subs Webhook + API integration ",
    readme:
      "A Full-Stack app for hosting and sharing widgets. For setup just add your TWITCH_CLIENT_ID and TWITCH_CLIENT_SECRET enviroment variables and thats it!\n\n-Twitch Auth with passport.js\n\n-User access tokens stored in Redis DB\n\n-Twitch sub events with webhook\n\n-Dashboard with Follower & Subscriber goal bar widget examples\n\n-Event data sent to widgets via Server Sent Events\n",
    name: "Twitch Widget Dashboard",
    category: "Starters",
    health: null,
    code: "UvkJaG",
    languages: ["JavaScript", "HTML", "TypeScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e0a6793a-a72b-4e9d-b520-8f83d2b3f0ee",
    isApproved: false,
    activeProjects: 9,
    projects: 21,
    description: "A minimal Bun web application.",
    readme:
      "Overview\nBun is an all-in-one JavaScript runtime & toolkit designed for speed, complete with a bundler, test runner, and Node.js-compatible package manager.\n\nUsing the provided Dockerfile, this template deploys a minimal web application based on the Bun runtime. \n\nLearn More\nBun web application GitHub repo",
    name: "Bun",
    category: "Starters",
    health: 67,
    code: "PnQkK-",
    languages: ["TypeScript", "HTML", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3d92c2a7-4034-4c0a-9ff8-427c89fac7f9",
    isApproved: false,
    activeProjects: 7,
    projects: 16,
    description: "This is AI Chatbot you need to experience",
    readme:
      "The Financial Assistance Chatbot is an AI-driven solution designed to enhance customer service and streamline operations within the financial services sector. Deployed across banking platforms, financial institutions, and fintech apps, this chatbot provides users with immediate and accurate assistance regarding their financial needs, ensuring a seamless and efficient interaction experience.\n\nThe chatbot offers real-time support for a wide array of financial services, including account inquiries, balance checks, transaction histories, and fund transfers. It allows customers to perform routine banking operations, such as paying bills or checking loan statuses, without needing to wait for human assistance. By using natural language processing (NLP), the chatbot understands customer queries, whether spoken or typed, in a conversational manner, making it easy for users of all ages to interact.\n\nAdditionally, the Financial Assistance Chatbot can help customers with more complex financial topics, such as understanding different investment options, guiding through loan applications, explaining mortgage plans, and even offering personalized financial advice based on the user‚Äôs profile and financial goals. The chatbot is integrated with the bank‚Äôs core systems, ensuring secure and real-time updates on customer accounts and services.\n\nSecurity is a top priority, with the chatbot adhering to strict encryption protocols and multi-factor authentication for sensitive transactions, such as fund transfers or updates to personal information. It also provides assistance in fraud detection, by notifying customers about suspicious transactions and guiding them on securing their accounts.\n\nWith multilingual capabilities and 24/7 availability, the Financial Assistance Chatbot reduces the need for extensive customer support staff, improves service efficiency, and enhances customer satisfaction by providing timely, accurate, and personalized financial assistance. Future enhancements may include deeper integration with AI-powered financial planning tools and voice biometrics for even more secure user identification.",
    name: "Interactive_Chatbot",
    category: "AI/ML",
    health: 0,
    code: "HqQk1G",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a6848f5a-ac8e-40d7-b077-94974d563df0",
    isApproved: false,
    activeProjects: 19,
    projects: 25,
    description: "Minimalistic web app designed for sending private and secure notes.",
    readme:
      "Demo - Docs - CLI\n\nEnclosed is a minimalistic web application designed for sending private and secure notes.\n\nAll notes are end-to-end encrypted, ensuring that the server and storage have zero knowledge of the content. Users can set a password, define an expiration period (TTL), and choose to have the note self-destruct after being read.\n\nA live instance is available at enclosed.cc.\n\nFeatures:\nEnd-to-End Encryption: Your notes are encrypted on the client side, using AES-GCM with a 256-bit key derived using PBKDF2.\nFile Attachments: Share files securely with your notes.\nZero Knowledge: The server does not have access to the content of the notes or files.\nConfigurable Security Options: Set a password, expiration time, and choose self-destruction after the note is read.\nMinimalistic UI: Simple and intuitive user interface for quick note sharing.\ni18n Support: Available in multiple languages.\nAuthentication: Optional email/password authentication to create notes.\nDark Mode: A dark theme for late-night note sharing.\nResponsive Design: Works on all devices, from desktops to mobile phones.\nOpen Source: The source code is available under the Apache 2.0 License.\nSelf-Hostable: Run your instance of Enclosed for private note sharing.\nCLI: A command-line interface for creating notes from the terminal.",
    name: "Enclosed",
    category: "Other",
    health: 100,
    code: "5gOoRm",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "be5a1b13-5f3f-4ed8-8360-7c9314dae7c5",
    isApproved: false,
    activeProjects: 7,
    projects: 26,
    description: "Verdaccio ‚Äî a lightweight Node.js private proxy registry",
    readme:
      "Verdaccio is a simple, zero-config-required local private NPM registry. No need for an entire database just to get started. Verdaccio comes out of the box with its own tiny database, and the ability to proxy other registries (eg. npmjs.org), also introduces caching the downloaded modules along the way. For those who are looking to extend their storage capabilities, Verdaccio supports various community-made plugins to hook into services such as Amazon's S3, Google Cloud Storage or create your own plugin.",
    name: "Verdaccio (npm private registry)",
    category: "Other",
    health: 50,
    code: "BK-Q7H",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ef5218dd-ba4a-4655-943f-fb25a5c424f7",
    isApproved: false,
    activeProjects: 55,
    projects: 98,
    description: "Standalone audio sending node based on Lavaplayer.",
    readme:
      "Lavalink\n\n\n\nA standalone audio sending node based on Lavaplayer and Koe.\nAllows for sending audio without it ever reaching any of your shards.\n\nBeing used in production by FredBoat, Dyno, LewdBot, and more.\n\nLearn more here ‚Üí",
    name: "Lavalink",
    category: "Bots",
    health: 77,
    code: "Mjb1E0",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "fc03f133-9a7d-4a16-8970-183d4bd1c232",
    isApproved: false,
    activeProjects: 8,
    projects: 34,
    description: "Teable Enterprise Edition, Airtable alternative with database power",
    readme:
      "Teable Enterprise Edition\n\nThe Teable Enterprise Edition offers a more comprehensive solution for enterprise users. In addition to the basic features of the community edition, it includes AI Field, Automation, Authority Matrix, and backend management functionalities to help enterprises manage projects and teams more efficiently.\n\nMain Features\n\nFor Community Edition features, please refer to Github\n\nBuilding upon the community edition, the enterprise edition adds the following advanced features:\n\nAI Field\nText and images are automatically generated through prefabricated or custom prompts, and the generated content can be updated automatically, making it suitable for batch AI generative tasks\n\nAutomation\n\nWith the automation feature, you can set rules and triggers to automate repetitive tasks, improving team efficiency.\n\nAuthority Matrix\n\nThe advanced permission management feature allows you to have more granular control over team members' permissions, ensuring data security and operational standards.\n\nAdmin Panel\n\nThe Admin Panel feature provides administrators with a powerful set of tools for managing users, projects, and system settings.\n\nHow to get License Key?\nvisite https://app.teable.io/setting/license-plan to subscribe to the License\n\nPricing\nhttps://app.teable.io/public/pricing?host=self-hosted\n",
    name: "Teable EE",
    category: "CMS",
    health: 77,
    code: "NtH5uD",
    languages: ["Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "270fa4e6-a33d-466b-b29e-4b7baafd03d7",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "A minimalistic application designed for sending private and secure notes.",
    readme:
      "See https://docs.enclosed.cc/self-hosting/configuration for more env variables that you can set including restricting public access.\n\nThe attached volume is necessary so that notes remain in tact on re-deploy.\n\nGithub: https://github.com/CorentinTh/enclosed",
    name: "Enclosed",
    category: "Other",
    health: null,
    code: "0sqPWB",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ded033fd-b1ea-48b2-bab1-bcb2aa341686",
    isApproved: false,
    activeProjects: 10,
    projects: 33,
    description: "Nextjs starter with Auth.js for user authentication",
    readme:
      "A Next.js starter project set up with Auth.js for user authentication and protected routes. The project includes:\n\nHusky: Pre-configured for Git hooks to enforce code quality before commits.\nPlaywright: Installed for end-to-end (e2e) testing to ensure application functionality.\nESLint and Prettier: Configured for consistent code formatting and linting.\nshadcn/ui: Integrated as the primary UI component library.\nTailwind CSS: Used for styling, offering rapid and responsive design capabilities.\nNx: Set up for monorepo management, streamlining project organization and scalability.\nServerless Redis: Integrated for authentication, compatible with Upstash Redis, ensuring fast and scalable session storage.\n\nThis starter is equipped with a robust development environment and a complete toolset for building scalable, maintainable applications with smooth authentication and testing setups.",
    name: "Next.js with Auth.js",
    category: "Starters",
    health: null,
    code: "DI0Aax",
    languages: ["TypeScript", "JavaScript", "CSS", "Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "bf9b15d3-897a-4c73-b735-d1b6f797b810",
    isApproved: false,
    activeProjects: 9,
    projects: 20,
    description: "üïµÔ∏è‚Äç‚ôÇÔ∏è All-in-one OSINT tool for analysing any website",
    readme:
      "Web-Check\n\n\n\nComprehensive, on-demand open source intelligence for any website\n\nüåê web-check.xyz\n\nContents\n\nAbout\n  Screenshot\n  Live Demo\n  Mirror\n  Features\nUsage\n  Deployment\n    Option#1: Netlify\n    Option#2: Vercel\n    Option#3: Docker\n    Option#4: Source\n  Configuration Options\n  Developer Setup\nCommunity\n  Contributing\n  Bugs\n  Support\nLicense\n\nAbout\nGet an insight into the inner-workings of a given website: uncover potential attack vectors, analyse server architecture, view security configurations, and learn what technologies a site is using.\n\nCurrently the dashboard will show: IP info, SSL chain, DNS records, cookies, headers, domain info, search crawl rules, page map, server location, redirect ledger, open ports, traceroute, DNS security extensions, site performance, trackers, associated hostnames, carbon footprint. Stay tuned, as I'll add more soon!\n\nThe aim is to help you easily understand, optimize and secure your website.\n\nScreenshot\n\n\n      Expand Screenshot\n\nScreenshot\n      \n\n\nScreenshot\n\nLive Demo\nA hosted version can be accessed at: web-check.as93.net\n\nMirror\nThe source for this repo is mirrored to CodeBerg, available at: codeberg.org/alicia/web-check\n\nFeatures\n\n\nClick to expand / collapse section\n\nNote this list needs updating, many more jobs have been added since...\n\nThe following section outlines the core features, and briefly explains why this data might be useful for you to know, as well as linking to further resources for learning more.\n\n\nIP Info\n\nDescription\nAn IP address (Internet Protocol address) is a numerical label assigned to each device connected to a network / the internet. The IP associated with a given domain can be found by querying the Domain Name System (DNS) for the domain's A (address) record.\n\nUse Cases\nFinding the IP of a given server is the first step to conducting further investigations, as it allows us to probe the server for additional info. Including creating a detailed map of a target's network infrastructure, pinpointing the physical location of a server, identifying the hosting service, and even discovering other domains that are hosted on the same IP address.\n\nUseful Links\nUnderstanding IP Addresses\nIP Addresses - Wiki\nRFC-791 Internet Protocol\nwhatismyipaddress.com\n\n\n\nSSL Chain\n\nDescription\nSSL certificates are digital certificates that authenticate the identity of a website or server, enable secure encrypted communication (HTTPS), and establish trust between clients and servers. A valid SSL certificate is required for a website to be able to use the HTTPS protocol, and encrypt user + site data in transit. SSL certificates are issued by Certificate Authorities (CAs), which are trusted third parties that verify the identity and legitimacy of the certificate holder.\n\nUse Cases\nSSL certificates not only provide the assurance that data transmission to and from the website is secure, but they also provide valuable OSINT data. Information from an SSL certificate can include the issuing authority, the domain name, its validity period, and sometimes even organization details. This can be useful for verifying the authenticity of a website, understanding its security setup, or even for discovering associated subdomains or other services.\n\nUseful Links\nTLS - Wiki\nWhat is SSL (via Cloudflare learning)\nRFC-8446 - TLS\nSSL Checker\n\n\n\nDNS Records\n\nDescription\nThis task involves looking up the DNS records associated with a specific domain. DNS is a system that translates human-readable domain names into IP addresses that computers use to communicate. Various types of DNS records exist, including A (address), MX (mail exchange), NS (name server), CNAME (canonical name), and TXT (text), among others.\n\nUse Cases\nExtracting DNS records can provide a wealth of information in an OSINT investigation. For example, A and AAAA records can disclose IP addresses associated with a domain, potentially revealing the location of servers. MX records can give clues about a domain's email provider. TXT records are often used for various administrative purposes and can sometimes inadvertently leak internal information. Understanding a domain's DNS setup can also be useful in understanding how its online infrastructure is built and managed.\n\nUseful Links\nWhat are DNS records? (via Cloudflare learning)\nDNS Record Types\nRFC-1035 - DNS\nDNS Lookup (via MxToolbox)\n\n\n\nCookies\n\nDescription\nThe Cookies task involves examining the HTTP cookies set by the target website. Cookies are small pieces of data stored on the user's computer by the web browser while browsing a website. They hold a modest amount of data specific to a particular client and website, such as site preferences, the state of the user's session, or tracking information.\n\nUse Cases\nCookies can disclose information about how the website tracks and interacts with its users. For instance, session cookies can reveal how user sessions are managed, and tracking cookies can hint at what kind of tracking or analytics frameworks are being used. Additionally, examining cookie policies and practices can offer insights into the site's security settings and compliance with privacy regulations.\n\nUseful Links\nHTTP Cookie Docs (Mozilla)\nWhat are Cookies (via Cloudflare Learning)\nTesting for Cookie Attributes (OWASP)\nRFC-6265 - Coolies\n\n\n\nCrawl Rules\n\nDescription\nRobots.txt is a file found (usually) at the root of a domain, and is used to implement the Robots Exclusion Protocol (REP) to indicate which pages should be ignored by which crawlers and bots. It's good practice to avoid search engine crawlers from over-loading your site, but should not be used to keep pages out of search results (use the noindex meta tag or header instead).\n\nUse Cases\nIt's often useful to check the robots.txt file during an investigation, as it can sometimes disclose the directories and pages that the site owner doesn't want to be indexed, potentially because they contain sensitive information, or reveal the existence of otherwise hidden or unlinked directories. Additionally, understanding crawl rules may offer insights into a website's SEO strategies.\n\nUseful Links\nGoogle Search Docs - Robots.txt\nLearn about robots.txt (via Moz.com)\nRFC-9309 -  Robots Exclusion Protocol\nRobots.txt - wiki\n\n\n\n&gt; You can read more at https://github.com/Lissy93/web-check",
    name: "Web Check",
    category: "Automation",
    health: 67,
    code: "7Cspyb",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "fa8e4a31-e5d3-4788-8bc5-0a9af7d8f90f",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "A easy way to deploy your own graph node for LUKSO blockchain.",
    readme:
      "This template deploys:\n\nPostgres databased (required to run the graph-node)\nIPFS node (required to run the graph-node)\nThe graph-node itself connected to the Postgres database and to the IPFS node.\n\nDisclaimers:\n\nExposing port 5001 for IPFS is a security issue, it's the API of the IPFS daemon and should not be exposed to other than localhost.\n\nExposing the port 8020 for the graph-node is a security issue, it's an administration port, used to manage the subgraphs deployments, it should be kept locked down.",
    name: "lukso-graph-node",
    category: "Other",
    health: null,
    code: "qgkIko",
    languages: ["Go", "Shell", "Makefile", "Dockerfile", "Python", "PureBasic"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3054d66b-e6b4-48b4-b55e-b76248f30696",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "Application that helps manage Individualized Curriculum Plans.",
    readme:
      "Spectrum is a comprehensive Individualized Curriculum Plan (ICP) management system designed to streamline the process of creating, managing, and tracking ICPs for students with diverse learning needs.\n\nThis template is created just so any school who wants can deploy this through railway without having to be given access.",
    name: "spectrum",
    category: "Other",
    health: null,
    code: "bNfoqV",
    languages: ["Python", "HTML", "CSS", "Dockerfile", "Shell", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0a09bc31-40e9-4a8b-a4d9-757a811f51f7",
    isApproved: false,
    activeProjects: 12,
    projects: 47,
    description: "Authentication and User Management by Supabase",
    readme:
      "Auth is a user management and authentication server written in Go that powers Supabase's features such as:\n\nIssuing JWTs\nRow Level Security with PostgREST\nUser management\nSign in with email, password, magic link, phone number\nSign in with external providers (Google, Apple, Facebook, Discord, ...)\n\nIt is originally based on the excellent GoTrue codebase by Netlify, however both have diverged significantly in features and capabilities.\n\nSee https://github.com/supabase/auth for a full list of environment variables and the different endpoints of the Auth service.",
    name: "Supabase Auth",
    category: "Authentication",
    health: 77,
    code: "vKtend",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "38b43bdc-2320-4684-a004-6d82187c65d0",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "Django REST Framework with postgres, redis and whitenoise",
    readme:
      "Introducing a streamlined Django template for seamless deployment on Railway! This setup features the Django Rest Framework (DRF) for building robust APIs, Redis for caching, PostgreSQL for database management, and Whitenoise for efficient static file handling. Ideal for developers looking to accelerate project launches with minimal configuration, this template provides a ready-to-use environment, ensuring a smooth development experience. Perfect for API-driven applications, it leverages the full power of DRF while simplifying the complexities of infrastructure setup with Redis and PostgreSQL integration. Start building and deploying faster than ever!",
    name: "Django REST Framework",
    category: "Starters",
    health: null,
    code: "-gX--G",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "80a49e1d-b3ce-430f-b8fa-bb1bb7a7fa3c",
    isApproved: false,
    activeProjects: 34,
    projects: 52,
    description: "Easily download your Railway volume data as a ZIP file.",
    readme:
      'Railway volume dump\n\nEasily download your Railway volume data as a ZIP file.\n\nUsage\n\nMount volume\n\nYou will first need to "disconnect the volume" from the original service you want to dump the volume from, and "mount" it to this service.\n\nRun curl command\n\nThe following curl command will download a ZIP file on your machine, replace GENERATED_ENDPOINT and GENERATED_PASSWORD with the generated values from this service.\n\ncurl -OJ https://GENERATED_ENDPOINT -H "password: GENERATED_PASSWORD"\n\nRe-mount volume\n\nOnce you have downloaded the ZIP file, you can re-mount the volume to the original service.\n\nNotes\n\nThe template will automatically pick up your volume path and name.\nDownloading the ZIP file will occur egress fees.\nCheck the service deploy logs for progress and additional information.',
    name: "Railway volume dump",
    category: "Storage",
    health: 100,
    code: "EBwdAh",
    languages: ["JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ad1dbf77-d64b-44da-bec2-c04247dc19dd",
    isApproved: false,
    activeProjects: 3,
    projects: 14,
    description: "Bun, Hono, and DuckDB API for high-performance data analysis.",
    readme:
      "An analytical API built with TypeScript, leveraging Bun for high-performance runtime, Hono for efficient routing, and DuckDB for in-memory analytical processing. This project showcases:\n\nOptimized sales data analysis with endpoints for comprehensive, summary, and daily sales reports\nType-safe query handling with custom interfaces for robust data management\nEfficient BigInt serialization for accurate representation of large numerical values\nModular architecture separating database operations, route handling, and application setup\n\nIdeal for scenarios requiring rapid data analysis and API responses, this setup demonstrates the power of combining modern web technologies with analytical databases for building high-performance data-driven applications.\n\nThis example uses DuckDB in-memory store.",
    name: "Hono + DuckDB API",
    category: "Starters",
    health: 100,
    code: "i3i9G7",
    languages: ["TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "30b6cd5c-dcb9-48ed-8111-125083e92f72",
    isApproved: false,
    activeProjects: 4,
    projects: 9,
    description: "The API server for ente photos & auth (2fa). ",
    readme:
      '\nOverview\n\nEnte is a fully open-source, end-to-end encrypted platform designed for storing data in the cloud without requiring trust in the service provider. Built on this platform are two apps: Ente Photos (an alternative to Apple and Google Photos) and Ente Auth (a 2FA alternative to the deprecated Authy).\n\nLearn more at ente.io.\n\nConfiguration\n\nEnvironment Variables\n\nS3 Storage\n\nConfigure the S3 variables S3_ACCESS_KEY_ID, S3_ACCESS_KEY_SECRET, S3_ENDPOINT, S3_BUCKET, and S3_REGION if you want to use Ente Photos. Leave these variables empty if you\'re only planning to use Ente Auth.\n\nCryptographic Keys\n\nFor a quick start, you can leave the ENTE_KEY_ENCRYPTION, ENTE_KEY_HASH, and ENTE_KEY_JWT variables empty, although it\'s recommended to generate new keys. See details here.\n\nVerification Code\n\nCreating an account typically requires confirming it with a verification code sent via email. To complete the verification, you have two options: either set values for the optional variables ENTE_INTERNAL_HARDCODED-OTT_LOCAL-DOMAIN-SUFFIX and ENTE_INTERNAL_HARDCODED-OTT_LOCAL-DOMAIN-VALUE, or retrieve the code from the deployment logs.\n\nClient App\n\nOnce the server is deployed, Railway will automatically generate a public URL listening on port 8080. The URL will look like "https://your-project.up.railway.app". To connect the client app to your server, tap 7 times on the onboarding screen to bring up a page where you can configure this URL as your endpoint. For more details, see here.\n\nCreate an account and use the verification code as described above.\n\nIncrease Storage Quota\n\nBy default, the storage quota is set to 5GB. To increase it to 1TB, go to the Postgres service and view the database under "Data". Navigate to the "users" table, select the user you want to update, and change the following fields:\n\nbonus_id: self-hosted-myself\nstorage: 1099511627776\ntype: ADD_ON_SUPPORT\nvalid_till: 0\n\nShared Albums\n\nYou can enable shared folders with a self-hosted instance. However, for simplicity, this template doesn\'t include that configuration. For more details, see here.',
    name: "ente",
    category: "Storage",
    health: 100,
    code: "O5gHP2",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2a70d970-04e6-45f5-aae3-16f87dd4a60c",
    isApproved: false,
    activeProjects: 3,
    projects: 5,
    description: "A merchant API server for Payme",
    readme:
      "This project is a simple API server that allows merchants to accept payments from customers using the Payme payment gateway. It provides two endpoints: one for the Payme merchant callback and another for the payment request and generating the payment URL. payme develop\n\n",
    name: "payme-merchant-api",
    category: "Other",
    health: 100,
    code: "iOjVDR",
    languages: ["Python", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "10ec2da3-9595-4026-92e4-9499214c0188",
    isApproved: false,
    activeProjects: 12,
    projects: 27,
    description: "The Enterprise File Management Solution",
    readme:
      "Here's a markdown version tailored for developers:\n\nFilestash: A Versatile Web-Based File Manager\n\nFilestash is a powerful and flexible web application designed to function as a comprehensive file manager, allowing users to manage their data across multiple protocols and services. It provides a unified, intuitive interface for accessing and organizing files, making it a suitable tool for developers, teams, and enterprises looking to streamline their file management workflows.\n\nKey Features and Supported Protocols\n\nFilestash supports a wide range of protocols and services, allowing for seamless integration with various storage solutions:\n\nFTP, FTPS, SFTP: Manage and transfer files securely over traditional file transfer protocols, ideal for accessing files on remote servers.\nWebDAV: Extend HTTP for direct file editing and management on remote servers.\nGit: Manage Git repositories, providing an easy interface for version control and collaboration on projects.\nAmazon S3, Backblaze B2, Minio: Integrate with cloud storage solutions, enabling management of cloud-based files from a single location.\nDropbox, Google Drive: Access and organize files stored in popular cloud services without switching between multiple applications.\nLDAP: Utilize Lightweight Directory Access Protocol for managing user authentication and permissions, enhancing security in enterprise environments.\nMySQL: Manage database files and perform backup operations easily through an integrated interface.\nCardDAV, CalDAV: Support for contact and calendar data management, adding to Filestash‚Äôs versatility beyond just file handling.\n\nWhy Use Filestash?\n\nCentralized Management: Filestash consolidates access to multiple storage systems, making it a one-stop solution for managing files across different platforms.\nEase of Use: Its web-based interface provides drag-and-drop functionality, file previews, and search capabilities, simplifying navigation and organization of files.\nEnhanced Productivity: Developers and teams can manage version control, file transfers, cloud storage, and even personal productivity data (like contacts and calendars) from one interface.\nSecurity and Integration: With support for secure protocols like FTPS and SFTP, along with LDAP for user management, Filestash offers robust security features suitable for enterprise use.\n\nGetting Started\n\nFilestash can be easily deployed in various environments, and it is customizable to fit specific needs. You can run it as a standalone application or integrate it into your existing infrastructure using Docker or other deployment methods.\n\nExample Deployment Using Docker\n\ndocker run -d \\\n  --name filestash \\\n  -p 8334:8334 \\\n  machines/filestash\n\nFor more detailed installation instructions and customization options, visit the Filestash GitHub repository.\n\nFilestash is an excellent tool for developers who need a versatile, secure, and easy-to-use file management solution that integrates with a wide range of protocols and services. Whether you're managing code repositories, server files, cloud storage, or personal data, Filestash provides the flexibility and functionality needed to streamline your workflow.",
    name: "filestash",
    category: "Storage",
    health: 100,
    code: "uIibtY",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "eba2c586-3854-468c-97e2-35c660d42d7e",
    isApproved: false,
    activeProjects: 41,
    projects: 160,
    description: "LibreChat is a free, open source AI chat platform.",
    readme:
      "https://github.com/danny-avila/LibreChat\n\nüìÉ Features\n\nüñ•Ô∏è UI matching ChatGPT, including Dark mode, Streaming, and latest updates\nü§ñ AI model selection:\n  OpenAI, Azure OpenAI, BingAI, ChatGPT, Google Vertex AI, Anthropic (Claude), Plugins, Assistants API (including Azure Assistants)\n‚úÖ Compatible across both Remote & Local AI services:\n  groq, Ollama, Cohere, Mistral AI, Apple MLX, koboldcpp, OpenRouter, together.ai, Perplexity, ShuttleAI, and more\nü™Ñ Generative UI with Code Artifacts\n   Create React, HTML code, and Mermaid diagrams right in chat\nüíæ Create, Save, & Share Custom Presets\nüîÄ Switch between AI Endpoints and Presets, mid-chat\nüîÑ Edit, Resubmit, and Continue Messages with Conversation branching\nüåø Fork Messages & Conversations for Advanced Context control\nüí¨ Multimodal Chat:\n    Upload and analyze images with Claude 3, GPT-4 (including gpt-4o and gpt-4o-mini), and Gemini Vision üì∏\n    Chat with Files using Custom Endpoints, OpenAI, Azure, Anthropic, & Google. üóÉÔ∏è\n    Advanced Agents with Files, Code Interpreter, Tools, and API Actions üî¶\n      Available through the OpenAI Assistants API üå§Ô∏è\n      Non-OpenAI Agents in Active Development üöß\nüåé Multilingual UI:\n  English, ‰∏≠Êñá, Deutsch, Espa√±ol, Fran√ßais, Italiano, Polski, Portugu√™s Brasileiro,\n  –†—É—Å—Å–∫–∏–π, Êó•Êú¨Ë™û, Svenska, ÌïúÍµ≠Ïñ¥, Ti·∫øng Vi·ªát, ÁπÅÈ´î‰∏≠Êñá, ÿßŸÑÿπÿ±ÿ®Ÿäÿ©, T√ºrk√ße, Nederlands, ◊¢◊ë◊®◊ô◊™\nüé® Customizable Dropdown & Interface: Adapts to both power users and newcomers\nüìß Verify your email to ensure secure access\nüó£Ô∏è Chat hands-free with Speech-to-Text and Text-to-Speech magic\n  Automatically send and play Audio\n  Supports OpenAI, Azure OpenAI, and Elevenlabs\nüì• Import Conversations from LibreChat, ChatGPT, Chatbot UI\nüì§ Export conversations as screenshots, markdown, text, json\nüîç Search all messages/conversations\nüîå Plugins, including web access, image generation with DALL-E-3 and more\nüë• Multi-User, Secure Authentication with Moderation and Token spend tools\n‚öôÔ∏è Configure Proxy, Reverse Proxy, Docker, & many Deployment options:\n  Use completely local or deploy on the cloud\nüìñ Completely Open-Source & Built in Public\nüßë‚Äçü§ù‚Äçüßë Community-driven development, support, and feedback",
    name: "LibreChat",
    category: "AI/ML",
    health: 92,
    code: "HxvQtm",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a898bdf9-c08e-46bf-8ff8-7345aa569437",
    isApproved: false,
    activeProjects: 10,
    projects: 50,
    description: "Appflowy cloud services for self-hosting. ",
    readme:
      "This template contains all the services needed to deploy an instance of the appflowy cloud. \n\nOnce deployed, you can use the URL of the caddy instance as the URL for your appflowy cloud api in the desktop application. \n\nReach out to zahin.dev@gmail.com for assistance, or the  official appflowy discord!",
    name: "appflowy-cloud",
    category: "Other",
    health: 80,
    code: "Pnu7Xd",
    languages: [
      "Shell",
      "PLpgSQL",
      "Dockerfile",
      "Rust",
      "HTML",
      "CSS",
      "JavaScript",
      "Makefile",
      "RenderScript",
    ],
    tags: null,
  },
  {
    __typename: "Template",
    id: "48f716aa-4dfa-4d15-9fa8-f8c54406ebc5",
    isApproved: false,
    activeProjects: 169,
    projects: 235,
    description: "Free, open-source game server management panel.",
    readme:
      "Logo Image\n\nGitHub Workflow Status\nDiscord\nGitHub Releases\nGitHub contributors\n\nPterodactyl Panel\n\nPterodactyl¬Æ is a free, open-source game server management panel built with PHP, React, and Go. Designed with security\nin mind, Pterodactyl runs all game servers in isolated Docker containers while exposing a beautiful and intuitive\nUI to end users.\n\nStop settling for less. Make game servers a first class citizen on your platform.\n\nImage\n\nDocumentation\n\nPanel Documentation\nWings Documentation\nCommunity Guides\nOr, get additional help via Discord\n\nSupported Games\n\nPterodactyl supports a wide variety of games by utilizing Docker containers to isolate each instance. This gives\nyou the power to run game servers without bloating machines with a host of additional dependencies.\n\nSome of our core supported games include:\n\nMinecraft ‚Äî including Paper, Sponge, Bungeecord, Waterfall, and more\nRust\nTerraria\nTeamspeak\nMumble\nTeam Fortress 2\nCounter Strike: Global Offensive\nGarry's Mod\nARK: Survival Evolved\n\nIn addition to our standard nest of supported games, our community is constantly pushing the limits of this software\nand there are plenty more games available provided by the community. Some of these games include:\n\nFactorio\nSan Andreas: MP\nPocketmine MP\nSquad\nXonotic\nStarmade\nDiscord ATLBot, and most other Node.js/Python discord bots\nand many more...\n\nLicense\n\nPterodactyl¬Æ Copyright ¬© 2015 - 2022 Dane Everitt and contributors.\n\nCode released under the MIT License.",
    name: "Pterodactyl",
    category: "Other",
    health: 100,
    code: "JOypuO",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "fdfb4198-9557-488c-81ea-c4a92c90ae75",
    isApproved: false,
    activeProjects: 6,
    projects: 12,
    description: "Node / Express server to receive Zoom Platform and Zoom Video SDK Webhooks",
    readme:
      'This is a Node.js / Express server that receives Zoom Platform Webhooks and Zoom Video SDK Webhooks.\n\nUsage\n\nTrigger the respective Webhook.\n\n   For example, if you chose the Start Meeting Webhook, start a Zoom Meeting. You will see the Webhook headers and payload logged in terminal.\n\n   {\n     "host": "abc123.ngrok.io",\n     "user-agent": "Zoom Marketplace/1.0a",\n     "content-length": "335",\n     "authorization": "{LEGACY_WEBHOOK_VERIFICATION_TOKEN}",\n     "clientid": "{CLIENT_ID}",\n     "content-type": "application/json; charset=utf-8",\n     "x-forwarded-for": "{X_FORWARDED_FOR}",\n     "x-forwarded-proto": "https",\n     "x-zm-request-timestamp": "X_ZM_REQUEST_TIMESTAMP",\n     "x-zm-signature": "v0={HASHED_WEBHOOK_SECRET_TOKEN}",\n     "x-zm-trackingid": "{X_ZM_TRACKINGID}",\n     "accept-encoding": "gzip"\n   }\n\n   {\n     "event": "meeting.started",\n     "payload": {\n       "account_id": "{ACCOUNT_ID}",\n       "object": {\n         "duration": 0,\n         "start_time": "2021-11-02T20:43:19Z",\n         "timezone": "America/Denver",\n         "topic": "{TOPIC}",\n         "id": "{MEETING_ID}",\n         "type": 4,\n         "uuid": "{MEETING_UUID}",\n         "host_id": "{HOST_ID}"\n       }\n     },\n     "event_ts": 1635885799302\n   }\n\nNeed help?\n\nIf you\'re looking for help, try Developer Support or our Developer Forum. Priority support is also available with Premier Developer Support plans.\n\n\nUse of this sample app is subject to our Terms of Use.\n\nNOTE: This Sample App has been updated to use the Webhook Secret Token instead of the Webhook Verification Token to validate requests are sent from Zoom.\n\nFrom: https://github.com/zoom/webhook-sample/',
    name: "Zoom Webhook Sample",
    category: "Other",
    health: null,
    code: "ERSEbO",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "af002653-91ac-4d8d-8fc2-452af892296e",
    isApproved: false,
    activeProjects: 27,
    projects: 55,
    description: "OpenProject is a project management software with a focus on sovereignty",
    readme:
      "Open Project\n\nThis templates includes Open project containers with Memecached and Postgres as Database. \n\nGo to https://www.openproject.org/docs/installation-and-operations/installation/docker/ for additional instructions\n\nNext steps \n\nSome additional envs are required for sending emails.\n\nMicro-services\n\nIf you'd like to deploy a worker based installation refers to \nhttps://railway.app/template/8HXd2f?referralCode=rSsrie",
    name: "OpenProject",
    category: "Other",
    health: 100,
    code: "_Ozucr",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "57033541-9048-4c4d-85c1-5e84a2a6f8aa",
    isApproved: false,
    activeProjects: 0,
    projects: 3,
    description: "Infisical is the open-source secret management platform.",
    readme:
      "Infisical\n\n‚ôæ Infisical is the open-source secret management platform: Sync secrets across your team/infrastructure, prevent secret leaks, and manage internal PKI\n\nInfisical dashboard screenshot\n\nDocs\nSecurity",
    name: "Infisical",
    category: "Automation",
    health: null,
    code: "wBMgxA",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "44fda966-96a2-4073-ac20-5904ad19268a",
    isApproved: false,
    activeProjects: 1,
    projects: 4,
    description: "A simple GraphQL API using Drizzle schemas",
    readme:
      "Overview\n\nDrizzle ORM is a lightweight, type-safe, and performant TypeScript ORM for SQL databases. It offers a fluent query builder, automatic SQL generation, and seamless integration with popular databases, enabling developers to write efficient and maintainable database interactions with full TypeScript support.\n\nPair the power of Drizzle schemas with GraphQL to easily access the exact data you need in a standardised format.\n\nThis template combines GraphQL, Drizzle and Typescript to make a perfect starter for building APIs, prototyping with GraphQL and early development.\n\nHighlights\n\nGraphQL\nDrizzle schemas\nTypescript\nEnvironment variable setup using dotenv\n\nLearn More\n\nGraphQL\nDrizzle\ndrizzle-graphql\nTypescript",
    name: "Drizzle GraphQL Postgres Starter",
    category: "Starters",
    health: 100,
    code: "4KBHfo",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d942e1b1-bfb5-4a9a-98b6-806cb4eda661",
    isApproved: false,
    activeProjects: 3,
    projects: 10,
    description: "Open Project is project management software with a focus on sovereignty",
    readme:
      'Open Project\n\nThis templates includes Open project containers with Memecached and Postgres as Database. \n\nGo to https://www.openproject.org/docs/installation-and-operations/installation/docker/ for additional instructions\n\nNext steps \n\nSome additional envs are required for persisting files and images or sending emails.\n\nS3 Storage Config\n\nOPENPROJECT_ATTACHMENTS__STORAGE: "fog"\nOPENPROJECT_FOG_DIRECTORY: "¬´s3-bucket-name¬ª"\nOPENPROJECT_FOG_CREDENTIALS_PROVIDER: "AWS"\nOPENPROJECT_FOG_CREDENTIALS_AWS__ACCESS__KEY__ID: "¬´access-key-id¬ª"\nOPENPROJECT_FOG_CREDENTIALS_AWS__SECRET__ACCESS__KEY: "¬´secret-access-key¬ª"\nOPENPROJECT_FOG_CREDENTIALS_REGION: "¬´us-east-1¬ª" # Must be the region that you created your bucket in',
    name: "OpenProject (Micro-services)",
    category: "Other",
    health: 71,
    code: "8HXd2f",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2e9a5fee-d977-4133-b468-b87d326070a0",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "A simple GraphQL API using Drizzle schemas",
    readme:
      "Overview\n\nDrizzle ORM is a lightweight, type-safe, and performant TypeScript ORM for SQL databases. It offers a fluent query builder, automatic SQL generation, and seamless integration with popular databases, enabling developers to write efficient and maintainable database interactions with full TypeScript support.\n\nPair the power of Drizzle schemas with GraphQL to easily access the exact data you need in a standardised format.\n\nThis template combines GraphQL, Drizzle and Typescript to make a perfect starter for building APIs, prototyping with GraphQL and early development.\n\nHighlights\n\nGraphQL\nDrizzle schemas\nTypescript\nEnvironment variable setup using dotenv\n\nLearn More\n\nGraphQL\nDrizzle\ndrizzle-graphql\nTypescript",
    name: "Drizzle GraphQL MySQL Starter",
    category: "Starters",
    health: null,
    code: "hSPrmq",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "cd1f70b3-407e-488d-a1ea-e698ee537523",
    isApproved: false,
    activeProjects: 15,
    projects: 19,
    description: "A Discord.NET bot template for making bots with C# using Docker deployments",
    readme:
      'Discord.NET Bot Template\nThis is a great starting point for making C# Discord bots with the Discord.NET framework in a containerized fashion (Docker).\n\nDiscord Bot Setup Guide\n\nThis guide will walk you through setting up a simple Discord bot and deploying it to Railway.\n\nPrerequisites\n\nBefore starting, make sure you have the following:\nA Discord account with permissions to create a bot.\n\nStep 1: Set Up the Environment Variables\nGo to your project settings and add the following environment variable:\n\n   DISCORD_TOKEN=your-discord-bot-token\n\nStep 2: Inviting Your Bot to a Server\n\nGo to the Discord Developer Portal and select your bot.\nUnder the "OAuth2" tab, go to the "URL Generator".\nUnder "OAuth2 Scopes", check the bot box.\nUnder "Bot Permissions", select the necessary permissions for your bot.\nCopy the generated URL and paste it into your browser.\nSelect the server you want to add the bot to and authorize it.\n\nStep 3: Test Your Bot\n\nOnce the bot is running, you can test it by typing the following commands in your Discord server:\n\n/ping - Check the bot\'s latency.\n/hi @username - Say hi to a specific user.\n/random coin-toss - Flip a coin.\n/random dice-roll - Roll a 6-sided die.\n\nStep 4: Monitor and Manage Your Bot\n\nRailway provides logs and management tools to monitor your bot\'s performance and status.\n\nLogs: You can view logs from the Railway dashboard.\nScaling: Adjust the resources allocated to your bot if necessary.\n\nStep 5: Add Your Features!\nYou are all set, time to add your own commands to make the Discord bot your own!',
    name: "(C#) Discord.NET Bot",
    category: "Bots",
    health: null,
    code: "inw1EU",
    languages: ["C#", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "842a5281-53c7-45f8-9e40-b0b74d3c90e4",
    isApproved: false,
    activeProjects: 2,
    projects: 4,
    description: "Grafana Tempo server for visualization and analysis of tracing data",
    readme:
      "Grafana Tempo for railway.app\n\nDeploy Grafana Tempo on Railway with one click.\nGrafana Tempo is a high-performance, scalable, and easy-to-operate distributed tracing solution. It is designed to be compatible with the most popular tracing protocols and offers seamless integration with other tools in the Grafana ecosystem, enabling efficient visualization and analysis of distributed tracing data.\n\nDeploy on Railway\n\n‚ú® Features\n\nDistributed tracing with high scalability\nMulti-tenancy support\nIntegration with Grafana for visualization\nSupport for multiple tracing protocols (Jaeger, Zipkin, OpenTelemetry)\nEfficient data compression and storage\n\nüêç How to Deploy\n\nClick Deploy on Railway.\nWait for Build & Deployment to Finish.\nAccess the custom URL for Grafana Tempo (available in your Railway dashboard).\nFollow the instructions below to configure Grafana and integrate with Tempo.\n\nüë©‚Äçüíª How to Use Grafana Tempo in Grafana\n\nAdd Tempo as a Data Source:\n   Open your Grafana instance, go to Configuration (gear icon) ‚Üí Data Sources ‚Üí Add data source.\n   Search for ‚ÄúTempo‚Äù and select it.\n   Set the URL to http://railway-tempo:3200.\n   Click Save & Test to verify the connection.\nQuery Traces:\n   Go to the Explore tab (compass icon).\n   Select the Tempo data source and explore your traces using the query editor.\nVisualize Service Dependencies:\n   In Dashboards, create or import a dashboard, add a panel, and select Service Graph to visualize how services interact.\n\nü™≤ Bug Reporting\n\nIf you find a bug in the template for railway, you can submit an issue to the GitHub Repository. Even better you can submit a Pull Request with a fix. \n",
    name: "Tempo",
    category: "Observability",
    health: null,
    code: "qtu0ha",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "248ace9d-afbc-452c-9829-421d00b5487a",
    isApproved: false,
    activeProjects: 2,
    projects: 6,
    description: "Easily host and programmatically transform your own images.",
    readme:
      'What is this template?\n\nPicsur is a self-hostable image-sharing service inspired by Imgur, designed for ease of use. \n\nPicsur supports various image formats, including QOI, JPG, PNG, and GIF, with built-in features like image conversion, editing, and EXIF data stripping. The service allows anonymous uploads, user accounts, role-based permissions, and provides a public gallery and albums. It also supports expiring images and offers a ShareX endpoint. It even offers a fully documented API. \n\nQuick start Guide \nClick the "Deploy on Railway" button above or click here\nYou should not need to configure any variables in railway, you should just be able to click "deploy" \nMonitor your services as they come up; wait until both the database and Picsur are up. \nOpen the Picsur service in Railway.\n  Copy the default admin password from the environment variables.\n  Navigate to the domain for your Picsur service.\n  Login with the username "admin" and the password yo u copied.\nYou\'re good to go ü•≥\n\nAdditional Resources\n\nOfficial demo\nPostman API Schema Docs\nFor more information, see the GitHub Repository.\n\nFeedback \nIf you experience any issues or have any feedback at all, please reach out to me on GitHub. ',
    name: "Picsur",
    category: "Storage",
    health: 100,
    code: "pZCRcv",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1e890ee5-16d3-48f3-a182-f76d405a7b44",
    isApproved: false,
    activeProjects: 3,
    projects: 11,
    description: "For individuals needing essential social media management tool.",
    readme:
      "Mixpost Lite is a streamlined social media management tool designed specifically for individuals who need a simple yet effective way to manage their social media presence. The template provides a user-friendly interface, enabling users to schedule posts, track engagement, and manage multiple social media accounts.\n\nEasy Content Scheduling: A calendar view that allows users to schedule posts across multiple platforms. Users can drag and drop posts to reschedule, view upcoming posts, and adjust timings.\n\nPlatform-Specific Customization: Ability to tailor posts for each social media platform.\n\nContent Library: A repository for storing frequently used images, hashtags, and post templates for quick access.\nEngagement Tracking:",
    name: "Mixpost Lite",
    category: "Other",
    health: 50,
    code: "7XSvks",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c68f4cc9-258f-402d-870b-bce4518bbf0f",
    isApproved: false,
    activeProjects: 39,
    projects: 99,
    description: "Fault-tolerant EVM RPC Proxy",
    readme:
      "eRPC is a fault-tolerant EVM RPC proxy and permanent caching solution. It is built with read-heavy use-cases in mind such as data indexing and high-load frontend usage.\n\nGetting Started\n\nCheck the docs for deployment instructions.",
    name: "erpc",
    category: "Other",
    health: 82,
    code: "10iW1q",
    languages: ["Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f4a82913-2be1-4c66-8c14-5c9d51c8646d",
    isApproved: false,
    activeProjects: 2,
    projects: 17,
    description: "A Line LLM Bot with FastAPI.",
    readme:
      "Key Features and Integrations üéâ\nKey features:\n\nü§ñ LINE Bot Integration: Easily create and manage LINE bots with built-in event handling and messaging capabilities.\n‚ö° FastAPI API Documentation and Authentication: Leverage FastAPI's powerful documentation tools and secure authentication mechanisms.\nüß† LLM Integration (OpenAI): Implement advanced chatbot logic using Large Language Models, with support for text and image modalities.\n\nWhy This Template ? üöÄ\nüìù API-Driven Logging: This template uses API calls to log data, ensuring better modularity and flexibility.\n‚öôÔ∏è Async Non-Blocking Operations: Designed to handle multiple user inputs simultaneously, making the bot responsive and efficient even under heavy load.\nüåê LLM Omniversal Integration: Supports various input modalities (text, image, audio) for a more versatile and interactive chatbot experience.",
    name: "LineBot FastAPI",
    category: "Bots",
    health: 100,
    code: "yNppuu",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9575503b-7bfb-49a5-8a5b-9500fc7893ac",
    isApproved: false,
    activeProjects: 42,
    projects: 215,
    description: "Deploy latest version of Twenty CRM (v0.*)",
    readme:
      "Twenty is the #1 Open-Source CRM. (https://twenty.com)\n\nPlease check the following Twenty docs for more info on setting up the self-hostable version: \nhttps://twenty.com/developers/section/self-hosting/self-hosting-var\nhttps://twenty.com/developers/section/self-hosting/upgrade-guide\n\nMore about Twenty\n\nModern, powerful, affordable platform to manage your customer relationships\n\nAn Operating System for your customer data\n\nBuilt on your customer data and adaptable to your unique workflows. \n\nDesigned to fit the evolving business requirements of fast-growing companies.",
    name: "Twenty CRM",
    category: "Automation",
    health: 84,
    code: "nAL3hA",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a7766207-90ad-486b-b489-4e40e1069372",
    isApproved: false,
    activeProjects: 42,
    projects: 48,
    description: "Generate JWTs for Zoom Meeting SDK",
    readme:
      'Zoom Meeting SDK Auth Endpoint sample\n\nUse of this sample app is subject to our Terms of Use.\n\nNOTE: This sample app has been updated to use Meeting SDK app type credentials instead of JWT app type type credentials.\n\nThis is a Node.js / Express server that generates a Meeting SDK JWT via an HTTP request for authorized use of the Zoom Meeting SDK.\n\nIf you would like to skip these steps and just deploy the finished code to Heroku, click the Deploy to Heroku button. (You will still need to configure a few simple things, so skip to Deployment.)\n\nDeploy\n\nInstallation\n\nIn terminal, run the following command to clone the repo:\n\n$ git clone https://github.com/zoom/meetingsdk-auth-endpoint-sample.git\n\nSetup\n\nIn terminal, cd into the cloned repository:\n\n   $ cd meetingsdk-auth-endpoint-sample\n\nThen install the dependencies:\n\n   $ npm install\n\nRename .env.example to .env, edit the file contents to include your Zoom Meeting SDK key and secret, save the file contents, and close the file.\n\nStart the server:\n\n   $ npm run start\n\nUsage\n\nMake a POST request to http://localhost:4000 (or your deployed url) with the following request body:\n\n| Property            | Type     | Required?  | Validation Rule(s)                                                                          |\n| ------------------- | -------- | ---------- | ------------------------------------------------------------------------------------------- |\n| meetingNumber     | string | Yes (web)* | - Required if generating a web JWT, optional for native.                                    |\n| role              | number | Yes (web)* | - Required if generating a web JWT, optional for native.  - Must be equal to 0 or 1 |\n| expirationSeconds | number | No         | - Must be between 1800 (30 minutes) and 172800 (48 hours) seconds                       |\n\n&gt; !IMPORTANT]\n&gt; If meetingNumber or role are supplied in the request body, the other must be present as well. If both are supplied, the JWT will be valid for web, otherwise it will be valid for native.\n\nExample Request\n\nPOST http://localhost:4000\n\nRequest Body:\n\n{\n  "meetingNumber": "123456789",\n  "role": 0\n}\n\nIf successful, the response body will be a JSON representation of your Meeting SDK JWT:\n\n{\n  "signature": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzZGtLZXkiOiJhYmMxMjMiLCJtbiI6IjEyMzQ1Njc4OSIsInJvbGUiOjAsImlhdCI6MTY0NjkzNzU1MywiZXhwIjoxNjQ2OTQ0NzUzLCJhcHBLZXkiOiJhYmMxMjMiLCJ0b2tlbkV4cCI6MTY0Njk0NDc1M30.UcWxbWY-y22wFarBBc9i3lGQuZAsuUpl8GRR8wUah2M"\n}\n\nIn the [Meeting SDK, pass in the signature to the join() function:\n\n// Make http request to your auth endpoint to get the Meeting SDK JWT\n\n// Meeting SDK - web - Client View - example:\nZoomMtg.join({\n  signature: signature,\n  sdkKey: sdkKey,\n  userName: userName,\n  meetingNumber: meetingNumber,\n  passWord: password\n})\n\n// Meeting SDK - web - Component View - example:\nclient.join({\n  signature: signature,\n  sdkKey: sdkKey,\n  userName: userName,\n  meetingNumber: meetingNumber,\n  password: password\n})\n\nDeployment\n\nHeroku (button)\n\nAfter clicking the "Deploy to Heroku" button, enter a name for your app (or leave it blank to have a name generated for you), and insert your Zoom Meeting SDK credentials:\n\n   ZOOM_MEETING_SDK_KEY (Your Zoom Meeting SDK Key or Client ID for Meeting SDK app type\'s created after February 11, 2023, found on your Zoom Meeting SDK App Credentials page)\n   ZOOM_MEETING_SDK_SECRET (Your Zoom Meeting SDK Secret or Client Secret for Meeting SDK app type\'s created after February 11, 2023, found on your Zoom Meeting SDK App Credentials page)\n\nThen click "Deploy App".\n\nUse your Heroku URL as your Meeting SDK Auth Endpoint.\n\n   Example: https://abc123.herokuapp.com/\n\nHeroku (CLI)\n\nIf you cloned this repo, you may use the Heroku CLI to deploy your server. Remember to set your config vars (envoirnment variables).\n\nUse your Heroku URL as your Meeting SDK Auth Endpoint.\n\n   Example: https://abc123.herokuapp.com/\n\nOther Server Hosting\n\nFor Other Server Hosting information, see this tutorial.\n\nUse your deployed URL as your Meeting SDK Auth Endpoint.\n\n   Example: https://abc123.compute-1.amazonaws.com/\n\nNow you can generate your Meeting SDK JWT.\n\nNeed help?\n\nIf you\'re looking for help, try Developer Support or our Developer Forum. Priority support is also available with Premier Developer Support plans.\n\nFrom: https://github.com/zoom/meetingsdk-auth-endpoint-sample/',
    name: "Zoom Meeting SDK Auth Sample",
    category: "Other",
    health: 100,
    code: "JsX6Pk",
    languages: ["JavaScript", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6328630a-8536-4ea6-9557-b43d839c19e2",
    isApproved: false,
    activeProjects: 90,
    projects: 223,
    description: "A simple Laravel starter app connected to a MySQL database, Redis cache",
    readme:
      "This complete Laravel starter template deploys a Laravel Breeze app as a majestic monolith that is connected to a MySQL database and Redis Cache on Railway.\n\nIt spins up 5 services (with the same codebase) in one project. They are:\nweb service: This runs the app.\nworker service: This runs the Laravel queue worker.\ncron service: This runs the Laravel scheduler and takes care of all cron tasks.\nMySQL: This is the MySQL database that the app is connected to.\nRedis: This is the queue and cache store/database that the app is connected to.",
    name: "Laravel Complete (Breeze, Blade, MySQL, Redis)",
    category: "Starters",
    health: 96,
    code: "Gkzn4k",
    languages: ["PHP", "Blade", "JavaScript", "Shell", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "95e326a5-0c61-42a4-ad66-fa8eaff35101",
    isApproved: false,
    activeProjects: 6,
    projects: 23,
    description: "Drizzle Studio but with multiple connections",
    readme:
      "Drizzle Studio Gateway\n\nThis is drizzle's new beta gateway. It's the drizzle studio but where you can have multiple database connections at once. See these X posts about how to get a license. \n\nhttps://x.com/DrizzleORM/status/1822261051452273056\nhttps://x.com/DrizzleORM/status/1816789492230942941",
    name: "Drizzle Studio Gateway",
    category: "Other",
    health: 100,
    code: "VT5SfC",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5597643f-b17d-41da-841d-9024ffe5e8ed",
    isApproved: false,
    activeProjects: 11,
    projects: 50,
    description: "Simple Kafka Setup For Small Projects",
    readme:
      'Simple Kafka Template\n\nThis template provides a straightforward setup for Kafka and Zookeeper, perfect for small projects with minimal configuration.\n\nHow to setup\nYou can connect to Kafka by using the KAFKA_URL environment variable under the "Kafka Broker" service. After connecting, simply create your topics in your code.\n\nNOTE: Ensuring you check if a topic already exists before attempting to create it.\n\nServices\nKafka Broker: Uses the apache/kafka:latest image.\n\nKafka Broker Environment Variables\nKAFKA_NODE_ID="1"  \n  Defines the broker ID for Kafka. It\'s set to "1" for simplicity. Only change if you have multiple brokers.\n\nKAFKA_PROCESS_ROLES="broker,controller"  \n  Specifies the roles for the Kafka process. It\'s set as both a broker and controller. Leave unchanged unless necessary.\n\nKAFKA_LISTENERS="PLAINTEXT://:9092,CONTROLLER://:9093"  \n  Defines the listeners for Kafka. The broker listens on port 9092 and the controller on port 9093. No need to modify these.\n\nKAFKA_ADVERTISED_LISTENERS="PLAINTEXT://${{RAILWAY_PRIVATE_DOMAIN}}:9092"  \n  Advertises the Kafka listener on your private domain at port 9092. This should remain as is for the template to work.\n\nKAFKA_CONTROLLER_LISTENER_NAMES="CONTROLLER"  \n  Specifies the listener names for the controller. Leave this unchanged.\n\nKAFKA_LISTENER_SECURITY_PROTOCOL_MAP="CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT"  \n  Maps the security protocols for the listeners. Default is PLAINTEXT, which is fine for small projects.\n\nKAFKA_CONTROLLER_QUORUM_VOTERS="1@${{RAILWAY_PRIVATE_DOMAIN}}:9093"  \n  Configures the controller quorum voters. Keep this as is unless working with a more complex setup.\n\nKAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR="1"  \n  Sets the replication factor for the offsets topic. A value of "1" is fine for small-scale use.\n\nKAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR="1"  \n  Defines the replication factor for transaction state logs. Default of "1" is suitable for basic projects.\n\nKAFKA_TRANSACTION_STATE_LOG_MIN_ISR="1"  \n  Sets the minimum in-sync replicas for transaction state logs. Keep it at "1" for simplicity.\n\nKAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS="0"  \n  Configures the initial rebalance delay for consumer groups. Default is "0", which is appropriate for most cases.\n\nKAFKA_NUM_PARTITIONS="3"  \n  Sets the number of partitions for topics. The default is "3", which provides a balanced setup for most small projects.\n\nNote:  \nIt\'s recommended not to change these environment variables unless you are familiar with Kafka configurations.\n\nBy: Bello Shehu Ango  \nEmail: angobello0@gmail.com  \nGitHub: github.com/BelloAngo\n',
    name: "Simple Kafka",
    category: "Queues",
    health: 78,
    code: "NyB5Jd",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9638d35f-52d9-42d6-b46d-0965e32ff986",
    isApproved: false,
    activeProjects: 1,
    projects: 3,
    description: "Open Source Pastebin Alternative",
    readme:
      "Haste\n\nHaste is an open-source pastebin software written in node.js, which is easily\ninstallable in any network.  It can be backed by either redis or filesystem,\nand has a very easy adapter interface for other stores.  A publicly available\nversion can be found at hastebin.com\n\nMajor design objectives:\n\nBe really pretty\nBe really simple\nBe easy to set up and use\n\nDeployment Details\n\nThis Railway template uses file storage. File storage currently does not support paste expiration, you can follow #191 for status updates.\n\nTo use an alternative storage option, please refer to the README",
    name: "hastebin",
    category: "Other",
    health: null,
    code: "jQiMgn",
    languages: ["JavaScript", "CSS", "HTML", "Dockerfile", "Shell", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c7f6668f-4bfa-4cfc-a833-4dac548636a8",
    isApproved: false,
    activeProjects: 89,
    projects: 107,
    description: "Âü∫‰∫é PC NTQQ ÁöÑ QQ Bot ÂçèËÆÆÁ´ØÂÆûÁé∞",
    readme:
      "NapCatQQ (aka Áå´Áå´Ê°ÜÊû∂) ÊòØÁé∞‰ª£ÂåñÁöÑÂü∫‰∫é NTQQ ÁöÑ Bot ÂçèËÆÆÁ´ØÂÆûÁé∞„ÄÇ\n\nÁå´Áå´Ê°ÜÊû∂ÈÄöËøáÈ≠îÊ≥ïÁöÑÊâãÊÆµËé∑Âæó‰∫Ü QQ ÁöÑÂèëÈÄÅÊ∂àÊÅØ„ÄÅÊé•Êî∂Ê∂àÊÅØÁ≠âÊé•Âè£Ôºå‰∏∫‰∫ÜÊñπ‰æø‰ΩøÁî®ÔºåÁå´Áå´Ê°ÜÊû∂Â∞ÜÈÄöËøá‰∏ÄÁßçÂêç‰∏∫ OneBot ÁöÑÁ∫¶ÂÆöÂ∞Ü‰Ω†ÁöÑ HTTP / WebSocket ËØ∑Ê±ÇÊåâÁÖßËßÑËåÉËØªÂèñÔºåÂÜçÂéªË∞ÉÁî®Áå´Áå´Ê°ÜÊû∂ÊâÄËé∑ÂæóÁöÑQQÂèëÈÄÅÊé•Âè£‰πãÁ±ªÁöÑÊé•Âè£„ÄÇ\nÁå´Áå´ÊäÄËÉΩ\nÂ§öÁßçÂêØÂä®ÊñπÂºèÔºöÊîØÊåÅ‰ª•Êó†Â§¥„ÄÅLiteLoader Êèí‰ª∂„ÄÅ‰ªÖ QQ GUI ‰∏âÁßçÊñπÂºèÂêØÂä®\n‰ΩéÂç†Áî®ÔºöÊó†Â§¥Ê®°ÂºèÂç†Áî®ËµÑÊ∫êÊûÅ‰ΩéÔºåÈÄÇÂêàÂú®ÊúçÂä°Âô®‰∏äËøêË°å\nË∂ÖÂ§öÊé•Âè£ÔºöÂú®ÂÆûÁé∞Â§ßÈÉ®ÂàÜOnebotÊé•Âè£‰∏äÊâ©Â±ï‰∫Ü‰∏ÄÂ•óÁßÅÊúâAPI\nWebUIÔºöËá™Â∏¶ WebUI ÊîØÊåÅÔºåËøúÁ®ãÁÆ°ÁêÜÊõ¥Âä†‰æøÊç∑",
    name: "napcat",
    category: "Bots",
    health: 0,
    code: "aRUNRZ",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4833f0d3-722a-407f-94cf-8b9db3362f9e",
    isApproved: false,
    activeProjects: 0,
    projects: 7,
    description: "Manticore Search ‚Äì easy-to-use open-source fast database for search",
    readme:
      "Manticore Search is an open-source database that was created in 2017 as a continuation of the Sphinx Search engine. We built upon its strengths, significantly improving its functionality and fixing hundreds of bugs while keeping it open-source. This has made Manticore Search a modern, fast, lightweight, and fully-featured database with outstanding full-text search capabilities.",
    name: "manticore",
    category: "Other",
    health: null,
    code: "I3K2X0",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "429465ba-eed4-47d0-81cb-14f7441eea13",
    isApproved: false,
    activeProjects: 5,
    projects: 18,
    description: "Laravel Breeze Blade MySQL",
    readme:
      "\n\n\n\n\n\n\n\n\nDeploy on Railway\n\nAbout this template\n\nPHP\nLaravel 11 Breeze with Blade Template Engine\nMySQL\nInitial migration pre-configured, remember to remove it from nixpacks config in production\n\nAbout Laravel\n\nLaravel is a web application framework with expressive, elegant syntax. We believe development must be an enjoyable and creative experience to be truly fulfilling. Laravel takes the pain out of development by easing common tasks used in many web projects, such as:\n\nSimple, fast routing engine.\nPowerful dependency injection container.\nMultiple back-ends for session and cache storage.\nExpressive, intuitive database ORM.\nDatabase agnostic schema migrations.\nRobust background job processing.\nReal-time event broadcasting.\n\nLaravel is accessible, powerful, and provides tools required for large, robust applications.\n\nLearning Laravel\n\nLaravel has the most extensive and thorough documentation and video tutorial library of all modern web application frameworks, making it a breeze to get started with the framework.\n\nYou may also try the Laravel Bootcamp, where you will be guided through building a modern Laravel application from scratch.\n\nIf you don't feel like reading, Laracasts can help. Laracasts contains thousands of video tutorials on a range of topics including Laravel, modern PHP, unit testing, and JavaScript. Boost your skills by digging into our comprehensive video library.\n\nLaravel Sponsors\n\nWe would like to extend our thanks to the following sponsors for funding Laravel development. If you are interested in becoming a sponsor, please visit the Laravel Partners program.\n\nPremium Partners\n\nVehikl\nTighten Co.\nWebReinvent\nKirschbaum Development Group\n64 Robots\nCurotec\nCyber-Duck\nDevSquad\nJump24\nRedberry\nActive Logic\nbyte5\nOP.GG\n\nContributing\n\nThank you for considering contributing to the Laravel framework! The contribution guide can be found in the Laravel documentation.\n\nCode of Conduct\n\nIn order to ensure that the Laravel community is welcoming to all, please review and abide by the Code of Conduct.\n\nSecurity Vulnerabilities\n\nIf you discover a security vulnerability within Laravel, please send an e-mail to Taylor Otwell via taylor@laravel.com. All security vulnerabilities will be promptly addressed.\n\nLicense\n\nThe Laravel framework is open-sourced software licensed under the MIT license.\n",
    name: "Laravel Breeze Blade MySQL",
    category: "Starters",
    health: 0,
    code: "baR0T4",
    languages: ["PHP", "Blade", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7310966f-a75b-4db8-8e7f-0fc779726a36",
    isApproved: false,
    activeProjects: 34,
    projects: 65,
    description: "üî• The most advanced open-source online code execution system in the world.",
    readme:
      'Judge0 (pronounced like "judge zero") is a robust, scalable, and open-source online code execution system. You can use it to build a wide range of applications that need online code execution features. Some examples include competitive programming platforms, e-learning platforms, candidate assessment and recruitment platforms, online code editors, online IDEs, and many more.\n\nIn our research paper Robust and Scalable Online Code Execution System, we present Judge0\'s modern modular architecture that can be easily deployed and scaled. We study its design, comment on the various challenges in building such systems, and compare it with other available online code execution systems and online judge systems.\n\nTo see Judge0 in action, try Judge0 IDE - our free and open-source online code editor.',
    name: "judge0",
    category: "Other",
    health: 100,
    code: "h9hIWO",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "04094126-35f1-44c0-8143-cb1149c89213",
    isApproved: false,
    activeProjects: 42,
    projects: 228,
    description: "firecrawl api server + worker without auth, works with dify",
    readme:
      "üî• Firecrawl\n\nCrawl and convert any website into LLM-ready markdown or structured data. Built by Mendable.ai and the Firecrawl community. Includes powerful scraping, crawling and data extraction capabilities.\n\nThis repository is in its early development stages. We are still merging custom modules in the mono repo. It's not completely yet ready for full self-host deployment, but you can already run it locally.\n\nWhat is Firecrawl?\n\nFirecrawl is an API service that takes a URL, crawls it, and converts it into clean markdown or structured data. We crawl all accessible subpages and give you clean data for each. No sitemap required.",
    name: "firecrawl",
    category: "AI/ML",
    health: 96,
    code: "AIaBEM",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "016ce639-594c-4c2a-8b28-41ff698d538c",
    isApproved: false,
    activeProjects: 1,
    projects: 1,
    description: "Deploy OpenUI: AI-powered UI generation with GitHub OAuth and OpenAI API.",
    readme:
      "OpenUI on Railway\n\nThis template deploys a production-ready instance of OpenUI on Railway.\n\nEnvironment Variables\n\nTo run this project, you need to set the following environment variables:\n\n| Variable | Description |\n|----------|-------------|\n| GITHUB_CLIENT_ID | Your GitHub OAuth App Client ID |\n| GITHUB_CLIENT_SECRET | Your GitHub OAuth App Client Secret |\n| OPENAI_API_KEY | Your OpenAI API Key |\n| OPENUI_CORS_ORIGINS | Allowed CORS origins (comma-separated) |\n| OPENUI_ENVIRONMENT | Environment setting (e.g., 'production') |\n| OPENUI_HOST | Host URL for your OpenUI instance |\n\nFeatures\n\nSeamless deployment of OpenUI on Railway\nGitHub OAuth integration for user authentication\nOpenAI API integration for AI-powered UI generation\nCustomizable CORS settings and environment configuration\n\nGetting Started\n\nClick the \"Deploy on Railway\" button\nSet up the required environment variables\nDeploy your OpenUI instance\n\nFor more information on configuring and using OpenUI, please refer to the official documentation.",
    name: "openui",
    category: "AI/ML",
    health: null,
    code: "NzJO6n",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "becef46f-6d5c-459f-97b0-e5b7842a9fc3",
    isApproved: false,
    activeProjects: 10,
    projects: 28,
    description: "This is a Laravel blade starter app connected to a Railway MySQL database.",
    readme:
      "Laravel Starter Example\n\nThis is a Laravel blade starter app that is connected to a Railway MySQL database.\n\nDeploy on Railway\n\n‚ú® Features\n\nPHP\nLaravel\nPostgres\n\nüìù Notes\n\nEnv: Envs are standard except DB URL that is configured in Railway not in env file.\nWeb server port: App runs in port 8080.\nLogging: Logs are being sent to stdout and can be accessed via railway logs.\nMigrations: Migrations are run on deploy, remember to remove on production.\n\nAbout Laravel\n\nLaravel is a web application framework with expressive, elegant syntax. We believe development must be an enjoyable and creative experience to be truly fulfilling. Laravel takes the pain out of development by easing common tasks used in many web projects, such as:\n\nSimple, fast routing engine.\nPowerful dependency injection container.\nMultiple back-ends for session and cache storage.\nExpressive, intuitive database ORM.\nDatabase agnostic schema migrations.\nRobust background job processing.\nReal-time event broadcasting.\n\nLaravel is accessible, powerful, and provides tools required for large, robust applications.\n\nLearning Laravel\n\nLaravel has the most extensive and thorough documentation and video tutorial library of all modern web application frameworks, making it a breeze to get started with the framework.\n\nYou may also try the Laravel Bootcamp, where you will be guided through building a modern Laravel application from scratch.\n\nIf you don't feel like reading, Laracasts can help. Laracasts contains thousands of video tutorials on a range of topics including Laravel, modern PHP, unit testing, and JavaScript. Boost your skills by digging into our comprehensive video library.\n\nLaravel Sponsors\n\nWe would like to extend our thanks to the following sponsors for funding Laravel development. If you are interested in becoming a sponsor, please visit the Laravel Partners program.\n\nPremium Partners\n\nVehikl\nTighten Co.\nWebReinvent\nKirschbaum Development Group\n64 Robots\nCurotec\nCyber-Duck\nDevSquad\nJump24\nRedberry\nActive Logic\nbyte5\nOP.GG\n\nContributing\n\nThank you for considering contributing to the Laravel framework! The contribution guide can be found in the Laravel documentation.\n\nCode of Conduct\n\nIn order to ensure that the Laravel community is welcoming to all, please review and abide by the Code of Conduct.\n\nSecurity Vulnerabilities\n\nIf you discover a security vulnerability within Laravel, please send an e-mail to Taylor Otwell via taylor@laravel.com. All security vulnerabilities will be promptly addressed.\n\nLicense\n\nThe Laravel framework is open-sourced software licensed under the MIT license.\n",
    name: "Laravel Blade MySQL",
    category: "Starters",
    health: 38,
    code: "JL9ADu",
    languages: ["PHP", "Blade", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4f6ddb79-fc2a-4160-acf8-614e4dfca814",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "It's like Redis but a bit rusty...",
    readme:
      "crabdis\n\nIt's like Redis but a bit rusty...\n\nWhat?\n\nThis is a simple in-memory key-value store written in Rust. It's somewhat compatible with Redis via the RESP protocol, but it's not a drop-in replacement. A lot of commands are missing and stuff might not work as expected.\n\nPlease don't use this in production. Or do, I'm not your mom. But don't blame me if it eats your data.\n\nWhy?\n\nI wanted to write Redis but multi-threaded and in Rust. This is the result.\nWorks? Kinda. Is it good? Maybe. Is it fast? Yes.\n\nInstallation\n\nYou can find binaries on the releases page. Or you can build it yourself with cargo build --release.\n\nIf you want to install it with cargo, you can do so with cargo install crabdis.\n\nThere is also a Docker image available on Docker Hub.\n\nUsage\n\ncrabdis\n\nTODO / Missing Features\n\nx] Basic RESP protocol implementation\n[x] GET, SET, DEL, EXISTS, KEYS, FLUSHDB\n[ ] COMMAND / COMMAND DOCS (so ioredis works)\n[ ] SET arguments (EX, PX, NX, XX) + SETEX, PSETEX\n[ ] Persistence\n[ ] Hash Command family\n\nThis will start the server on 127.0.0.1:6379. You can change the address and port with the --address and --port flags.\n\nLicense\n\nThis project is licensed under the [MIT License.",
    name: "crabdis",
    category: "Storage",
    health: null,
    code: "CxB19j",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "80289bf8-67fe-4174-b9b4-65d746f4aded",
    isApproved: false,
    activeProjects: 11,
    projects: 61,
    description: "To power websites, blogs, or portfolios from small to enterprise.",
    readme:
      "Payload 3 Website Template\n\n\n  \n    \n    Live Demo \n  \n\n\nPayload 3 transforms Next.js into a complete full-stack framework. By integrating a headless CMS natively into the Next.js environment, it creates a cohesive development experience, much like WordPress did for PHP, but with cutting-edge technology.\n\n&gt; ‚ö†Ô∏è Warning: This template is regularly updated to align with the official releases from the Payload team. Consequently, new updates may introduce breaking changes that could impact the database schema. Users of this template may need to reset their database and execute the new migrations to update the schema accordingly.\n\nThis template is ideal if you are working on:\n\nA personal or enterprise-grade website, blog, or portfolio\nA content publishing platform with a fully-featured publication workflow\nA lead generation website with premium content gated behind authentication\n\nPayload 3 Dashboard\n\nThis template, configured to be hosted on Railway includes a beautifully designed, production-ready front end built with Next.js App Router, served alongside your Payload app in a single instance. This setup allows you to deploy both your backend and website where you need them. In order to make this stack whole, we are using PostgreSQL as the database and MinIO S3 for media storage.\n\nCore features:\n\nNext.js 15 (App Router)\nReact 19 &amp; React Compiler\nPostgreSQL database\nMinIO S3 for media storage\nTypeScript\nReact Hook Form\nPayload Admin Bar\nTailwindCSS styling\nshadcn/ui components\nAuthentication\nFully-featured blog\nPublication workflow\nUser accounts\nDark mode\nPre-made layout building blocks\nSEO\nRedirects\nLive preview\n\nGetting Started\n\nTo get started with using your newly deployed Payload 3 stack, you will need to set up your S3 bucket and configure it's associated environment variables. The variables you will need are S3_BUCKET, S3_ACCESS_KEY, and S3_SECRET_KEY.\n\n\n\nIn order to get these values, you will need to log into your S3 console. The username and password for the S3 console are automatically generated during deployment. You can find these values among your console's environment variables.\n\nOnce logged in, you will need to create a new bucket and generate a new access and secret key. Once you have these values, head back to your project's environment, open up your Payload instance, and replace your obtained values with the existing ones.\n\nüéâ Congradulations! You are now ready to start using your Payload 3 stack. Open up your project's URL, create your admin account, and click the \"Seed\" button to populate your database with some example data.\n\n\n\nYou can find the source code here.\nLeave a ‚≠ê if you like this project.\n",
    name: "Payload 3 Stack (PSQL & S3)",
    category: "CMS",
    health: 33,
    code: "7fbyq-",
    languages: ["Dockerfile", "TypeScript", "JavaScript", "CSS", "SCSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "27c8624f-a50b-4369-a6a1-eb94f6453aa6",
    isApproved: false,
    activeProjects: 22,
    projects: 52,
    description: "Run a Tailscale Subnet Router on Railway",
    readme:
      "\n    \n        \n    \n\n\nTailscale makes secure networking easy\n\nAchieve point-to-point network connectivity that enforces least privilege\n\nFull Guide Here\n\nAbout this Tutorial\n\nThis tutorial will help you connect to your database via the private network without you having to use public endpoints.\n\n1. Getting an Auth Key\n\nThe Auth key will authenticate the Tailscale machine that we'll deploy into our Railway project in a later step.\n\nHead over to the Keys page located within the settings menu on the Tailscale dashboard.\n\nClick Generate auth key.\n\n    Put in a description and leave all other settings as the default.\n\nClick Generate key.\n\n    Tailscale will now show you the newly generated auth key, be sure to copy it down.\n\nClick Done.\n\n2. Configure Split DNS\n\nProperly configuring our nameserver in Tailscale is essential for enabling local DNS lookups for our private domains.\n\nOpen the DNS page.\n\nUnder the Nameservers Header, click Add Nameserver ‚Üí Click Custom.\n\n    This is where we'll tell Tailscale how to route the DNS lookups for our railway.internal domains.\n\nEnter fd12::10 as the Nameserver.\n\n    This DNS nameserver is used across all private networks in every environment and will handle our DNS queries for private domains.\n\nEnable the Restrict to domain option, AKA Split DNS.\n\nEnter in railway.internal as our domain.\n\n    This makes sure only DNS lookups for our private domain are forwarded to the private DNS resolver.\n\nClick Save.\n\n3. Deploy the Tailscale Subnet Router\n\nThis will be the gateway into our environment's private network.\n\nOpen the project that contains the services you want to access privately.\n\n    For this tutorial, we will deploy the Subnet Router into a project with a Postgres database service.\n\nIn the top right of the project canvas, click Create ‚Üí Choose Template.\n\nSearch for the Tailscale Subnet Router template.\n\n    Choose the result that is published by Railway Templates.\n\nA ghost service will appear, Paste in your Auth Key from earlier.\n\nClick Deploy Template\n\nThis template will start to deploy and once deployed it will register itself as a machine in your tailnet with the name automatically derived from the project's name and environment name.\n\n4. Approve the Subnet\n\nOur subnet router will advertise the private network's CIDR range but we will need to manually approve it.\n\nHead back over to our Machines dashboard.\n\nYou will see your newly deployed machine with its name that was previously derived from the project and environment.\n\nClick on the machine's 3-dot menu ‚Üí Edit route settings.\n\nClick the radio button on the fd12::/16 to accept it.\n\n    This route covers the entire private networking range allowing us to access all services within the project.\n\nClick Save.\n\nThat is it for all the configurations needed, you can now call any service via its private domain and port just as if you were another service within the private network!",
    name: "Tailscale Subnet Router",
    category: "Other",
    health: 100,
    code: "tailscale",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d4f3a250-8d1f-431d-8701-36eb6adc4481",
    isApproved: false,
    activeProjects: 7,
    projects: 8,
    description: "A load balancer for internal networking",
    readme:
      "Internal Load Balancer\n\nIf you're using an internal railway service with multiple replicas, then you might have noticed that internal incoming traffic isn't always spread out across all replicas.\n\nThis load-balancer solves that issue by routing all traffic to this load balancer instead of the target service, and it will spread the requests to all replicas (Using Round-robin).\n\nThe only thing you need to configure is the TARGET environment variable to the internal hostname of the target service, so for example if your target's hostname is process-ocr then specify TARGET=process-ocr. And of course don't forget to route the original traffic to this load balancer instead of the original target host.",
    name: "internal-load-balancer",
    category: "Other",
    health: 0,
    code: "j79q_M",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "49f7430b-4f8b-42ad-8c76-c9e3c1808f0c",
    isApproved: false,
    activeProjects: 2,
    projects: 10,
    description: "Build a better way to look at what is happening in discord",
    readme:
      "This is a react app gives an alternative dashboard to actively look into discord channels of your choosing.\n\nIt allows for thread replies and replying back and forth within each thread. And quick search for messages or people within each channel.\n\nDev Tools üõ†\nVite\nhypercorn\n\nData Requests üìÄ\ntanstack/query\nreact-router\n\nStyling üé®\nTailwindcss\nShadcn \n\nAPI üí®\nfastapi\nGraphQL\npydiscord\n\n\nCheck out more things I built here",
    name: "Discord React Dashboard",
    category: "Bots",
    health: null,
    code: "qI6MGp",
    languages: ["TypeScript", "JavaScript", "HTML", "CSS", "Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "46a0fe78-8dea-465b-bdea-475c87a79785",
    isApproved: false,
    activeProjects: 37,
    projects: 113,
    description: "Secure & Modern All-in-One Mail Server (IMAP, JMAP, POP3, SMTP)",
    readme:
      "\n  Secure &amp; Modern All-in-One Mail Server (IMAP, JMAP, POP3, SMTP) üõ°Ô∏è\n\nFeatures\n\nStalwart Mail Server is an open-source mail server solution with JMAP, IMAP4, POP3, and SMTP support and a wide range of modern features. It is written in Rust and designed to be secure, fast, robust and scalable.\n\nKey features:\n\nJMAP server:\n  JMAP Core and JMAP Mail full compliance.\n  JMAP for Sieve Scripts extension for managing Sieve scripts.\n  JMAP for WebSocket, JMAP Blob Management and JMAP for Quotas extensions.\nIMAP4, POP3 and ManageSieve server:\n  IMAP4rev2 and IMAP4rev1 server with support for numerous extensions.\n  POP3 server with extensions, STLS and SASL support.\n  ManageSieve server for managing Sieve scripts.\nSMTP server:\n  Built-in DMARC, DKIM, SPF and ARC support for message authentication.\n  Strong transport security through DANE, MTA-STS and SMTP TLS reporting.\n  Inbound throttling and filtering with granular configuration rules, sieve scripting, MTA hooks and milter integration.\n  Distributed virtual queues with delayed delivery, priority delivery, quotas, routing rules and throttling support.\n  Envelope rewriting and message modification.\nSpam Phishing filter:\n  Comprehensive set of filtering rules on par with popular solutions.\n  Statistical spam classifier with automatic training capabilities.\n  DNS Blocklists (DNSBLs) checking of IP addresses, domains, and hashes.\n  Collaborative digest-based spam filtering with Pyzor.\n  Phishing protection against homographic URL attacks, sender spoofing and other techniques.\n  Trusted reply tracking to recognize and prioritize genuine e-mail replies.\n  Sender reputation monitoring by IP address, ASN, domain and email address.\n  Greylisting to temporarily defer unknown senders.\n  Spam traps to set up decoy email addresses that catch and analyze spam.\nFlexible and scalable:\n  Pluggable storage backends with RocksDB, FoundationDB, PostgreSQL, mySQL, SQLite, S3-Compatible, Redis and ElasticSearch support.\n  Clustering support with node autodiscovery and partition-tolerant failure detection.\n  Built-in, LDAP or SQL authentication backend support.\n  Full-text search available in 17 languages.\n  Sieve scripting language with support for all registered extensions.\n  Email aliases, mailing lists, subaddressing and catch-all addresses support.\n  Automatic account configuration and discovery with autoconfig and autodiscover. \n  Metrics, tracing, logging and alerts with OpenTelemetry and Prometheus integration.\n  Webhooks for event-driven automation.\n  Disk quotas.\nWeb-based administration:\n  Account, domain, group and mailing list management.\n  SMTP queue management for messages and outbound DMARC and TLS reports.\n  Report visualization interface for received DMARC, TLS-RPT and Failure (ARF) reports.\n  Configuration of every aspect of the mail server.\n  Log viewer with search and filtering capabilities.\n  Self-service portal for password reset and encryption-at-rest key management.\nSecure and robust:\n  Encryption at rest with S/MIME or OpenPGP.\n  Automatic TLS certificate provisioning with ACME using TLS-ALPN-01, DNS-01 or HTTP-01 challenges.\n  OAuth 2.0 authorization code and device authorization flows.\n  Two-factor authentication with Time-based One-Time Passwords (2FA-TOTP) \n  Application passwords (App Passwords).\n  Automated blocking of hosts that cause multiple authentication errors (aka fail2ban).\n  Access Control Lists (ACLs).\n  Rate limiting.\n  Security audited (read the report).\n  Memory safe (thanks to Rust).\n",
    name: "stalwart",
    category: "Other",
    health: 100,
    code: "V1KsKz",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9f72d32b-863e-4bb1-98e5-964a95a9fb82",
    isApproved: false,
    activeProjects: 4,
    projects: 8,
    description: "Open-source antivirus engine.",
    readme:
      "ClamAV is an open-source antivirus engine for detecting trojans, viruses,\nmalware, and other malicious threats. Visit https://docs.clamav.net/\nfor more information.\n\nThis template deploys ClamAV to Railway. It uses the\nofficial ClamAV Docker image, and\nmodifies it to support configuration via environment variables.\n\nTo configure ClamAV via environment variables, set\nCLAMD_CONF_${CONFIGURATION_KEY}=${VALUE} where CONFIGURATION_KEY is the\nname of the configuration specified in clamd.conf\nand VALUE is the value you want to set.\n\nfreshclam.conf can also be\nconfigured this way using FRESHCLAM_CONF_${CONFIGURATION_KEY}=${VALUE}.\n\nExample(s):\n\nTo set StreamMaxLength=100M in clamd.conf, set CLAMD_CONF_StreamMaxLength=100M in the environment\nTo set ConnectTimeout=30 in freshclam.conf, set FRESHCLAM_CONF_ConnectTimeout=30 in the environment\n",
    name: "clamav",
    category: "Other",
    health: 100,
    code: "MAnG6f",
    languages: ["Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "657f8188-37dc-4c2b-8745-48bbcb5212bf",
    isApproved: false,
    activeProjects: 10,
    projects: 26,
    description: "The OS for your personal finances.",
    readme:
      'Maybe Finance\n\nYour open-source personal finance management application.\n\nMaybe dashboard_mockup\n(Note: The image above is a mockup of what we\'re working towards. We\'re rapidly approaching the functionality shown, but not all of the parts are ready just yet.)\n\nWebsite: https://maybe.co\n\nRepository: https://github.com/maybe-finance/maybe\n\nDisclaimer\n\nMaybe is distributed under an AGPLv3 license. " Maybe" is a trademark of Maybe Finance, Inc.\n\n"Yashu Mittal" is not affiliated with Maybe Finance, Inc. in any way or form.',
    name: "Maybe Finance",
    category: "Observability",
    health: 100,
    code: "er6blq",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "23d92869-9bd9-40f3-9890-5e19cac2f3a8",
    isApproved: false,
    activeProjects: 1,
    projects: 3,
    description: "A simple starter project for a Meteor full-stack Javascript Framework",
    readme:
      "\nMeteor Starter Project\n\nWelcome to the Meteor.js Starter Project! This repository provides a boilerplate for a Meteor.js application, fully configured for deployment on Railway.\n\nFeatures\n\nMeteor.js: A full-stack JavaScript platform for building modern web and mobile applications.\nDockerized Setup: Pre-configured Docker support for local development.\nRailway Deployment: Ready to be deployed on Railway with minimal configuration.\nEnvironment Configuration: Easy management of environment variables for production readiness.\n\nPrerequisites\n\nNode.js: Ensure you have Node.js and npm installed.\nDocker: Ensure you have Docker installed on your machine for local development.\nRailway CLI: Install the Railway CLI for deploying your project to Railway.\n\nGetting Started\n\n1. Clone the Repository\n\ngit clone https://github.com/francis-Paul-code/meteor-starter\ncd meteor-starter\n\n2. Install Dependencies\n\nUse npm to install the project dependencies:\n\nmeteor npm install\n\n3. Run the Project Locally\n\nYou can start the Meteor.js application locally with:\n\nmeteor\n\nYour Meteor.js application should now be running on http://localhost:3000.\n\n4. Set Up Environment Variables\n\nIf your application relies on environment variables, create a .env file in the root of your project or copy the existing .env.example:\n\ncp .env.example .env\n\n5. Build the Project for Production\n\nIf you want to build the project for production:\n\nmeteor build ../output --directory\n\nThis command will generate the production-ready files in the output directory.\n\n6. Build and Run with Docker\n\nUse Docker to build and run the project locally:\n\ndocker-compose up --build\n\n7. Deploy to Railway\n\nTo deploy the project to Railway, follow these steps:\n\nInitialize a new Railway project:\n\nrailway init\n\nDeploy your project:\n\nrailway up\n\nRailway will automatically detect your environment variables and configuration. Your application will be deployed and accessible at a generated Railway URL.\n\nContributing\n\nFeel free to contribute to this project by submitting issues or pull requests. We welcome all improvements!\n\nLicense\n\nThis project is licensed under the MIT License.\n",
    name: "Meteor",
    category: "Starters",
    health: null,
    code: "NGEqSA",
    languages: ["JavaScript", "HTML", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "cd5bc883-2a9b-4982-a7f6-0d829479ff71",
    isApproved: false,
    activeProjects: 18,
    projects: 135,
    description: "AFFiNE - Self-host version  ",
    readme:
      "!!!READ BEFORE DEPLOY!!!\n\nRemove the start command after first deployment succeeded.\n\nOwn Your Knowledge: Self-Host AFFiNE on Railway\n\nThis template simplifies the process of deploying your own AFFiNE instance on Railway. Enjoy full control over your data, enhanced privacy, and the ability to customize AFFiNE to your exact needs.\n\nKeywords: AFFiNE, self-host, Railway, knowledge management, data control\n\nDeploy Now!",
    name: "AFFiNE",
    category: "Starters",
    health: 96,
    code: "V4HyAi",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "12bc0ddc-a2eb-44f9-97b8-1a8d673cd897",
    isApproved: true,
    activeProjects: 62,
    projects: 133,
    description: "Elastic is a scalable search and analytics engine for fast data queries",
    readme:
      "Elasticsearch is a distributed, RESTful search and analytics engine designed for horizontal scalability and near real-time search capabilities. It allows you to store, search, and analyze large volumes of data quickly. Built on top of Apache Lucene, Elasticsearch is commonly used for log and event data analysis, full-text search, and handling complex queries in a wide variety of use cases, including web search engines, enterprise search, and data analytics platforms. Its powerful features include support for structured and unstructured data, high availability, and full-text search with sophisticated filtering and ranking capabilities.",
    name: "Elasticsearch",
    category: "Other",
    health: 56,
    code: "elasticsearch",
    languages: ["Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "640873a2-5cd5-4113-8551-3918684f4420",
    isApproved: false,
    activeProjects: 18,
    projects: 30,
    description: "Deploy marimo - a next-generation reactive notebook for Python and SQL",
    readme:
      "marimo \n\nA reactive Python notebook that's reproducible, git-friendly, and deployable as scripts or apps.\n\nmarimo is a reactive Python notebook: run a cell or interact with a UI\nelement, and marimo automatically runs dependent cells (or marks them as stale), keeping code and outputs\nconsistent. marimo notebooks are stored as pure Python, executable as scripts,\nand deployable as apps.\n\nHighlights.\n\nreactive: run a cell, and marimo automatically runs all dependent cells\ninteractive: bind sliders, tables, plots, and more to Python ‚Äî no callbacks required\nreproducible: no hidden state, deterministic execution\nexecutable: execute as a Python script, parametrized by CLI args\nshareable: deploy as an interactive web app, or run in the browser via WASM\ndata-centric: built-in SQL support and data sources panel\ngit-friendly: stored as .py files\n",
    name: "marimo",
    category: "Analytics",
    health: 80,
    code: "iX6puU",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0afcd55e-d459-4d51-a727-23f0cbaf4e89",
    isApproved: false,
    activeProjects: 3,
    projects: 10,
    description: "Open Source Asset Management Infrastructure for everyone.",
    readme:
      '\n‚ú® Open Source Asset Management Infrastructure for everyone. ‚ú®\n\n\nShelf üè∑Ô∏è Asset Management infrastructure for absolutely everyone (open source). \nShelf is a simple and visual asset management and location tracking system that allows people to track their physical assets with ease.\n\nCore Features and Benefits üí´\n\nWith Shelf, you can take a picture of any item you own and store it in your own database. From there, you can generate a printable code (QR) that you can tag onto the item, making it easy to identify and locate in the future. Shelf has a handy code printing area where you can add as many QR codes as you can on an A4 sticker paper sheet. You can also add detailed information about the item, including its purchase date, purchase price, warranty information, and more.\n\n\n    Website ‚Ä¢\n    Documentation ‚Ä¢\n    Get started ‚Ä¢\n    Twitter\n\n\nDeployment\n\nThis app relays on Supabase integration. You need to setup Supabase project and connect your app to Supabase instance and database.\n\nAuthentication\n\nFor authentication to work in your Project, you need so setup some settings related to One Time Passwords in Supabase.\n\nIn order for OTP to work you need to make your OTP emails. Go to your Supabase dashboard, select your project and navigate to Authentication &gt; Email Templates. Replace the {{ .ConfirmationURL }} with {{ .Token }}. This will make sure that Supabase sends your Users a one time password instead of a magic link. You need to do this both for "Confirm signup" and "Magic link".\n\n',
    name: "Shelf",
    category: "Other",
    health: null,
    code: "iSO3Cc",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f4cf77f1-b859-411f-bda3-3b7042274035",
    isApproved: false,
    activeProjects: 13,
    projects: 16,
    description: "Node/Express server to generate a Video SDK JWT for Zoom Video SDK",
    readme:
      'Zoom Video SDK Auth Endpoint sample\n\nUse of this sample app is subject to our Terms of Use.\n\nThis is a Node.js / Express server that generates a Video SDK JWT via an HTTP request for authorized use of the Zoom Video SDK.\n\nInstallation\n\nIn terminal, run the following command to clone the repository:\n\n$ git clone https://github.com/zoom/videosdk-auth-endpoint-sample.git\n\nSetup\n\nIn terminal, cd into the cloned repository:\n\n   $ cd videosdk-auth-endpoint-sample\n\nThen install the dependencies:\n\n   $ npm install\n\nRename .env.example to .env, edit the file contents to include your Zoom Video SDK key and secret, save the file contents, and close the file:\n\nStart the server:\n\n   $ npm run start\n\nUsage\n\nMake a POST request to http://localhost:4000 (or your deployed url) with the following request body:\n\n| Property                 | Type     | Required? | Validation Rule(s)                                                    |\n| ------------------------ | -------- | --------- | --------------------------------------------------------------------- |\n| sessionName            | string | Yes   | - Required  - Value length be fewer than 200 characters           |\n| role                   | number | Yes   | - Required  - Must equal 0 or 1                               |\n| expirationSeconds      | number | No        | - Must be between 1800 (30 minutes) and 172800 (48 hours) seconds |\n| userIdentity           | string | No        | - Must be fewer than 35 characters                                    |\n| sessionKey             | string | No        | - Must be fewer than 36 characters                                    |\n| geoRegions             | string | No        | - Must be a comma-separated string with valid Zoom geo regions        |\n| cloudRecordingOption   | number | No        | - Must equal 0 or 1                                               |\n| cloudRecordingElection | number | No        | - Must equal 0 or 1                                               |\n| telemetryTrackingId    | string | No        | N/A                                                                   |\n\nExample Request\n\nPOST http://localhost:4000\n\nRequest Body:\n\n{\n  "sessionName": "Cool Cars",\n  "role": 1,\n  "sessionKey": "session123",\n  "userIdentity": "user123"\n}\n\nIf successful, the response body will be a JSON representation of your signature:\n\n{\n  "signature": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhcHBfa2V5IjoiVklERU9fU0RLX0tFWSIsImlhdCI6MTY0NjI0ODc5NiwiZXhwIjoxNjQ2MjU1OTk2LCJ0cGMiOiJDb29sIENhcnMiLCJ1c2VyX2lkZW50aXR5IjoidXNlcjEyMyIsInNlc3Npb25fa2V5Ijoic2Vzc2lvbjEyMyIsInJvbGVfdHlwZSI6MH0.Y6C65mZUxTZFeGiOI6oW5q2UkIXe3nLTK0MVNkfiJ9c"\n}\n\nIn the Video SDK, pass in the signature to the join() function:\n\n// Make http request to your auth endpoint to get the Video SDK JWT\n\n// Video SDK - web - example:\n\nclient.join(\n   signature: signature,\n   topic: sessionName,\n   userName: userName,\n   password: sessionPasscode\n)\n\nDeployment\n\nHeroku (button)\n\nAfter clicking the "Deploy to Heroku" button, enter a name for your app (or leave it blank to have a name generated for you), and insert your Zoom Video SDK credentials:\n\n   ZOOM_VIDEO_SDK_KEY (Your Zoom Video SDK Key, found on your Zoom Video SDK App\'s Credentials page)\n   ZOOM_VIDEO_SDK_SECRET (Your Zoom Video SDK Secret, found on your Zoom Video SDK App\'s Credentials page)\n\nThen click "Deploy App".\n\nUse your Heroku URL as your Video SDK Auth Endpoint.\n\n   Example: https://abc123.herokuapp.com/\n\nHeroku (CLI)\n\nIf you cloned this repository, you may use the Heroku CLI to deploy your server. Remember to set your config vars (envoirnment variables).\n\nUse your Heroku URL as your Video SDK Auth Endpoint.\n\n   Example: https://abc123.herokuapp.com/\nOther Server Hosting\n\nFor Other Server Hosting information, see this tutorial.\n\nUse your deployed URL as your Video SDK Auth Endpoint.\n\n   Example: https://abc123.compute-1.amazonaws.com/\n\nNow you can generate your Video SDK JWT.\n\nNeed help?\n\nIf you\'re looking for help, try Developer Support   or our Developer Forum. Priority support is also available with Premier Developer Support plans.\nsource: https://github.com/zoom/videosdk-auth-endpoint-sample',
    name: "Zoom VideoSDK Auth Sample",
    category: "Other",
    health: null,
    code: "dO2hTU",
    languages: ["JavaScript", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e586abf2-865e-4ba4-90df-82b4f5baf6f7",
    isApproved: false,
    activeProjects: 8,
    projects: 78,
    description: "A lightweight service that joins the RSS3 Network as a node.",
    readme:
      'Prerequisites\nBefore deploying, you need to create a node on the explorer: RSS3 Explorer.\n\nAdditionally, ensure that your Railway account is upgraded to at least the Pro Plan ($20/month). This plan is necessary to support the node\'s storage requirements, which will be around 10GB.\n\nDeployment\nYou only need to fill in two fields in the RSS3-Node-Core service:\n\nNODE_DISCOVERY_MAINTAINER_EVM_ADDRESS: Your wallet address (which is also your node address).\nNODE_DISCOVERY_MAINTAINER_SIGNATURE: The challenge signature obtained here: https://explorer.rss3.io/nodes/YOUR_WALLET_ADDRESS. (Click the "Signature" button to complete the challenge and copy your signature to paste here.)\n\nAfter the service starts, it will join the RSS3 Network as a lightweight RSS3 Node.\n\nContact\nIf you have any questions, feel free to contact me: brucexc@rss3.io.\n\nJoin the RSS3 Discord: RSS3 Discord\n',
    name: "RSS3 Node 1.0",
    category: "Other",
    health: 73,
    code: "tAkUiN",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c01b5ba6-37de-4160-a319-da2e1822f345",
    isApproved: false,
    activeProjects: 5,
    projects: 38,
    description: "Open source background jobs with no timeouts",
    readme:
      "Trigger.dev (v3)\n\nTrigger.dev\n\nAll the required environment variables are pre-configured.\n\nTo know more about all the environment variables.\nhttps://github.com/triggerdotdev/docker/blob/main/.env.example\n\nWebsite: https://trigger.dev\nDocs: https://trigger.dev/docs",
    name: "Trigger.dev",
    category: "Automation",
    health: 67,
    code: "qcn55C",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b6f6f4e8-2325-4e38-8a8f-339939a001fc",
    isApproved: false,
    activeProjects: 2,
    projects: 3,
    description: "An Ember.js starter in Javascript, comes already configured with railway",
    readme:
      "\nEmber.js Starter Project\n\nWelcome to the Ember.js Starter Project! This repository provides a boilerplate for an Ember.js application, fully configured for deployment on Railway.\n\nFeatures\n\nEmber.js: A productive and battle-tested JavaScript framework for building modern web applications.\nDockerized Setup: Pre-configured Docker support for local development.\nRailway Deployment: Ready to be deployed on Railway with minimal configuration.\nEnvironment Configuration: Easy management of environment variables for production readiness.\n\nPrerequisites\n\nNode.js: Ensure you have Node.js and npm (or yarn) installed.\nDocker: Ensure you have Docker installed on your machine for local development.\nRailway CLI: Install the Railway CLI for deploying your project to Railway.\n\nGetting Started\n\n1. Clone the Repository\n\ngit clone https://github.com/francis-Paul-code/ember-railway-starter\ncd ember-starter\n\n2. Install Dependencies\n\nUse npm or yarn to install the project dependencies:\n\nnpm install\nor\nyarn install\n\n3. Build the Project\n\nBuild the Ember.js project for production:\n\nember build --environment production\n\nThis command will generate the dist directory containing the production-ready static files.\n\n4. Set Up Environment Variables\n\nIf your application relies on environment variables, create a .env file in the root of your project or copy the existing .env.example:\n\ncp .env.example .env\n\n5. Build and Run Locally with Docker\n\nUse Docker to build and run the project locally:\n\ndocker-compose up --build\n\nYour Ember.js application should now be running on http://localhost:4200.\n\n6. Deploy to Railway\n\nTo deploy the project to Railway, follow these steps:\n\nInitialize a new Railway project:\n\nrailway init\n\nDeploy your project:\n\nrailway up\n\nRailway will automatically detect your environment variables and configuration. Your application will be deployed and accessible at a generated Railway URL.\n\nContributing\n\nFeel free to contribute to this project by submitting issues or pull requests. We welcome all improvements!\n\nLicense\n\nThis project is licensed under the MIT License.\n",
    name: "Ember.js",
    category: "Starters",
    health: null,
    code: "xlTY0P",
    languages: ["JavaScript", "HTML", "Handlebars", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f5715dfe-7a6b-4f73-ae7e-725d8355bdf1",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "Create a Help Center for your product easily.",
    readme:
      "Voidfull Help Center (Next.js) Template\n\nThis template is created by Voidfull\n\nRepo: https://github.com/voidfull-templates/nextjs-helpcenter\n\nSetup\n\nTo run this template, you need the following environment variables.\n\nNEXT_PUBLIC_VOIDFULL_SITE_ID\nNEXT_PUBLIC_VOIDFULL_CONTENT_TOKEN\n\nNOTE: Voidfull content token will always start with voidfull_pat_\n\nYou can find both these variables value by logging into your Voidfull account.\n\nWebsite: voidfull.com\nGithub: https://github.com/voidfullspace\n\n",
    name: "Voidfull Help Center (Next.js)",
    category: "Starters",
    health: null,
    code: "7NcJhi",
    languages: ["TypeScript", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "70500344-2b53-491f-8b70-e3f755277589",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "Vitess is a database clustering system for horizontal scaling of MySQL.",
    readme:
      "Vitess\n\nYou can find all the information for the environment variables in the docs.\n\nLink: https://vitess.io/docs/19.0/get-started/vttestserver-docker-image",
    name: "Vitess",
    category: "Storage",
    health: null,
    code: "fsuTFg",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "65eac4b4-fa84-4d46-8a49-b64b18d41a46",
    isApproved: false,
    activeProjects: 11,
    projects: 23,
    description: "Simple starter for a Symfony application, fully configured for deployment ",
    readme:
      "\n\nSymfony Starter Project\n\nWelcome to the Symfony Starter Project! This repository provides a boilerplate for a Symfony application, fully configured for deployment on Railway.\n\nFeatures\n\nSymfony 6.x: The latest version of the Symfony framework.\nDockerized Setup: Pre-configured Docker support for local development.\nRailway Deployment: Ready to be deployed on Railway with minimal configuration.\nEnvironment Configuration: Seamless integration with environment variables for production readiness.\n\nPrerequisites\n\nDocker: Ensure you have Docker installed on your machine for local development.\nRailway CLI: Install the Railway CLI for deploying your project to Railway.\n\nGetting Started\n\n1. Clone the Repository\n\ngit clone https://github.com/francis-Paul-code/railway-symfony-webapp-starter.git\ncd railway-symfony-webapp-starter\n\n2. Set Up Environment Variables\n\nCreate a .env file in the root of your project or copy the existing .env.example:\n\ncp .env.example .env\n\nUpdate the .env file with your database credentials and other necessary configurations.\n\n3. Build and Run the Project\n\nUse Docker to build and run the project locally:\n\ndocker-compose up --build\n\nYour Symfony application should now be running on http://localhost:8000.\n\n4. Deploy to Railway\n\nTo deploy the project to Railway, follow these steps:\n\nInitialize a new Railway project:\n\nrailway init\n\nDeploy your project:\n\nrailway up\n\nRailway will automatically detect your environment variables and configuration. Your application will be deployed and accessible at a generated Railway URL.\n\nContributing\n\nFeel free to contribute to this project by submitting issues or pull requests. We welcome all improvements!\n\nLicense\n\nThis project is licensed under the MIT License.\n",
    name: "Symfony ",
    category: "Starters",
    health: 0,
    code: "E-LDHU",
    languages: ["PHP", "JavaScript", "Twig", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e6762faf-be8b-4f0d-954d-689604f844d4",
    isApproved: false,
    activeProjects: 1,
    projects: 4,
    description: "Queue song requests in Spotify with Twitch channel points.",
    readme:
      "Creates a Postgres database (which is optional), and a Go HTTP server. The purpose of the HTTP server is to host traffic to a website, and to route requests to/from Twitch's and Spotify's APIs. This project requires developers to onboard for API access to Twitch and Spotify, and users of the service are required to be Affiliate or Partner on Twitch, and must have a Spotify Premium account. See https://github.com/SaxyPandaBear/TwitchSongRequests for more details. ",
    name: "Twitch Song Requests",
    category: "Other",
    health: null,
    code: "DoTt23",
    languages: ["Go", "HTML", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3429e687-031a-494d-97bf-61e98700a7d7",
    isApproved: false,
    activeProjects: 7,
    projects: 15,
    description: "High performance nats server",
    readme:
      "NATS Server Template\n\nNATS Logo\n\nWelcome to the NATS Server Template ‚Äì your go-to solution for lightweight, high-performance messaging systems! This template is designed to accelerate your development by providing a robust, scalable, and easy-to-configure NATS server setup.\n\nHarness the power of NATS for real-time communications and microservices orchestration. With this template, you can effortlessly integrate NATS into your project, ensuring low latency, high throughput, and seamless message distribution across your systems.\n\nPerfect for developers looking to implement pub/sub, request/reply, and distributed queue messaging patterns. Get started quickly and take your system's performance to the next level with our streamlined NATS Server Template!",
    name: "nats-server",
    category: "Queues",
    health: 0,
    code: "AEaP8G",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1d8379dd-1fa4-493b-9b63-a7cdcf4d0322",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "This is  NasDesign Ecpom template. This is a template with NextJS.",
    readme:
      "This is a template that I created with the intend to use and share with other users finding difficulties to start an E-commerce platform. I will improve it overtime and add more services to it.This is a template that I created with the intend to use and share with other users finding difficulties to start an E-commerce platform. I will improve it overtime and add more services to it.",
    name: "successful-ecom",
    category: "Other",
    health: null,
    code: "dsnbHF",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f4acce3e-6294-4a51-b9b6-4ac1468de34f",
    isApproved: false,
    activeProjects: 11,
    projects: 36,
    description: "Quickfire Minecraft Server. Simple and fast.",
    readme:
      "Quickfire Minecraft Server\n\nA project by Vessyl. Spins up an minecraft server in no time. Everything is ready. Ofc you can change everything from MaxPlayers, Mode, Version etc.\n\nView all available variables here: https://github.com/vessylapp/quickfire-test-mc/tree/master?tab=readme-ov-file#environment-variables\n\nHow to connect?\n\nGo to > Settings > Networking  > Public Networking >\nAnd there should be an address that looks something like this: monorail.proxy.rlwy.net:111111",
    name: "quickfire",
    category: "Other",
    health: null,
    code: "U9ifEK",
    languages: ["Go", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7e1d8108-dac5-4266-bff5-d255829f1149",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "Simple, no frills place to paste text. ",
    readme:
      "Croissant Paste it: The No-Annoyance Text Sharing App\n\nOverview\n\nCroissant Paste it is a lightweight, no-nonsense web application for sharing text. Whether you're collaborating on code, jotting down notes, or simply need a quick place to store and share text, Paste it offers a clean and simple solution. Built with Node.js, Express, and React.js, it prioritizes user experience by eliminating ads, distractions, trackers, and unnecessary features, allowing you to focus on what matters: your experience.\n\nFeatures\n\nNo Ads, No Distractions: A clean and minimalist interface free of ads and pop-ups, ensuring a seamless user experience.\nSimplicity at Its Core: Designed for ease of use, with an intuitive interface that requires no learning curve.\nQuick Text Sharing: Instantly generate shareable URLs for your text, making collaboration and sharing effortless.\nCustom URLs: Create custom URLs by navigating to /custom and pasting your text, making it even easier to share content with personalized links.\nFast and Lightweight: Optimized for speed and performance, providing a smooth experience even on slow networks.\nPrivacy-Focused: No user tracking or data collection. Your text is only accessible to those with whom you share it.\nResponsive Design: Access and use Croissant Paste it on any device‚Äîdesktop, tablet, or mobile.\n\nTechnology Stack\n\nNode.js: Ensures efficient and scalable server-side logic.\nExpress.js: Handles backend routing and middleware with robustness and flexibility.\nReact.js: Powers the dynamic, responsive user interface, enabling real-time interactions.\n\n\nContributions to Croissant Paste it are welcome! Feel free to fork the repository, make improvements, and submit pull requests.\n\nhttps://github.com/arhammusheer/paste.croissant.one\n\nYou're also welcome to demo or just use the prod deploy at https://paste.croissant.one",
    name: "paste.croissant.one",
    category: "Other",
    health: null,
    code: "NVtpxG",
    languages: ["TypeScript", "JavaScript", "HTML", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9651b66a-2ecc-4871-a36c-8ee01ed3b968",
    isApproved: false,
    activeProjects: 1,
    projects: 2,
    description: "Demo for Zebra Reader Tag Data Post",
    readme:
      "This template is a demo for Zebra Reader to publish Tag Data as HTTP Post method.\n\nThis is made on NodeJs with minimal configuration for testing purpose only.\n\nNote that, basic authentication is added. Please change where needed for username and password.",
    name: "tag-publisher-post-node",
    category: "Observability",
    health: null,
    code: "naLkNn",
    languages: ["HTML", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "99aa6bb6-0ce5-49d2-bd30-3e7b867e8adf",
    isApproved: false,
    activeProjects: 7,
    projects: 11,
    description: "A simple Slack bot programmed in Python",
    readme:
      "Slack Bot Template for Production Railway üöÉü§ñ\n\n1) Create your app\n\nSign up or login and create your app. \n\\\nhttps://api.slack.com/apps\n\n2) Select OAuth and Permission -&gt; Bot Token Scopes. Then add the following Bot Token scopes shown below.\n\napp_mentions:read\nchannels:history\nchannels:read\nchat:write\ncommands\nim:history\nmpim:history\n\n  \n  \nThen Install the app to the Workspace.\n\n3) Go to Railway and deploy my template\n\nDeploy on Railway\n\nAdd the following secret variables for deployment.\nSLACK_BOT_TOKEN (located in OAuth &amp; Permission)\nSLACK_SIGNING_SECRET (located in Basic Information)\nSLACK_BOT_USER_ID (located in Basic Information)\n\nOnce your variable are added deply the template\n\n4) Once your the slack template is deployed. Go to setting and generate your domain\n\nSettings ‚Üí Networking ‚Üí Gen\nerate Domain  \n\n5) Once your domain is set up then go back to slack API and go to your Event Subscription\n\nturn on Enable Events. Then in your request url paste your domain in this specific format.     \n\nhttps://{your-domain}/slack/events\n\nAdd the following scope in the Event Subscriptions below. Then Save changes.\n\n6) Turn on Interactivity &amp; Shortcuts and paste in your request url and save changes\n\n7) Go to Slash Commands ‚Üí Create new Command\n\nHere are the requiremnets for your slack comand\n\nCommand Name (has to be the states the same in the code)\nRequest Url ( [http://{your-domain}/slack/events )\nShort Description\n\n\nhere are the Command Names in the template.\n/command_example\n/modal_example\n/button_example\n\nOnce your done invite your slack bot to a channel and try out the template Example\n\n\n\n\n\n\n  ",
    name: "Slack Bot Template in Python",
    category: "Bots",
    health: null,
    code: "iSYwFQ",
    languages: ["Python", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "511ce783-ac79-4175-8dd1-20a580366a59",
    isApproved: false,
    activeProjects: 7,
    projects: 42,
    description: "Open source time-tracking solution for business or freelance.",
    readme:
      "Kimai Logo\nKimai\nFree and easy to use time tracking for freelancers, agencies and companies. Kimai is open source software available for self-hosting and as SaaS. \n\nSupports your business\nKimai has all the business core features you need to setup your time-tracking workflows and integrate it with your existing infrastructure.\n\nInstructions\nAdd your admin email & password.\nRemove the admin email & password environment variables after build (they're no longer needed).\n\nGo to the link below for more up-to-date instructions & troubleshooting help.\nhttps://github.com/hellocory/railway-kimai",
    name: "Kimai - Time Tracker",
    category: "Analytics",
    health: 100,
    code: "E3MdZb",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "cc2885a2-4372-45a8-9f57-509be99b7909",
    isApproved: false,
    activeProjects: 2,
    projects: 3,
    description: "An Ionic Vue Starter in Typescript, comes already configured with railway",
    readme:
      "Ionic Vue Starter with TypeScript\n\nThis is a starter project for building mobile and web applications using Ionic Vue with TypeScript. It is configured to be deployed on Railway.\n\nTable of Contents\nGetting Started\nProject Structure\nDeploying to Railway\nLicense\n\nGetting Started\n\nPrerequisites\n\nNode.js (&gt;= 12.x)\nnpm (or Yarn)\nIonic CLI (npm install -g @ionic/cli)\nRailway CLI\n\nInstallation\n\nClone the repository:\n\n    https://github.com/francis-Paul-code/ionic-vue-starter.git\n    cd ionic-vue-starter\n\nInstall dependencies:\n\n    npm install\n\nRunning the App\n\nTo start the development server:\n\nionic serve\nProject Structure\nionic-vue-starter/\n‚îú‚îÄ‚îÄ public/                     # Static files\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îú‚îÄ‚îÄ components/             # Reusable components\n‚îÇ   ‚îú‚îÄ‚îÄ pages/                  # Application pages\n‚îÇ   ‚îú‚îÄ‚îÄ App.vue                 # Root component\n‚îÇ   ‚îú‚îÄ‚îÄ main.ts                 # Entry point\n‚îÇ   ‚îú‚îÄ‚îÄ router/                 # Vue Router configuration\n‚îÇ   ‚îî‚îÄ‚îÄ store/                  # Vuex store configuration\n‚îú‚îÄ‚îÄ ionic.config.json           # Ionic configuration\n‚îú‚îÄ‚îÄ package.json                # NPM dependencies and scripts\n‚îî‚îÄ‚îÄ README.md                   # Project documentation\nDeploying to Railway\nLogin to Railway CLI:\n   railway login\nInitialize a new Railway project:\n   railway init\nDeploy the project:\n   railway up\n   For more detailed instructions, refer to the Railway documentation.\nLicense\n  This project is licensed under the MIT License. See the LICENSE file for more details.\n",
    name: "Ionic Vue Starter",
    category: "Starters",
    health: 100,
    code: "mKJHrx",
    languages: ["TypeScript", "Vue", "HTML", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f713429b-7571-4e91-ad91-e0bf4937ca38",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "An Ionic Angular Starter in Typescript with NgModules",
    readme:
      "Ionic Angular Starter\n\nThis is a starter project for building mobile and web applications using Ionic Angular with NgModules. It is configured to be deployed on Railway.\n\nTable of Contents\nGetting Started\nProject Structure\nDeploying to Railway\nLicense\n\nGetting Started\n\nPrerequisites\n\nNode.js (&gt;= 12.x)\nnpm (or Yarn)\nIonic CLI (npm install -g @ionic/cli)\nRailway CLI\n\nInstallation\n\nClone the repository:\n\n    git clone https://github.com/francis-Paul-code/ionic-angular-ngmodules-starter.git\n    cd ionic-angular-starter\n\nInstall dependencies:\n\n    npm install\n\nRunning the App\n\nTo start the development server:\n\nionic serve\nProject Structure\nionic-angular-starter/\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îú‚îÄ‚îÄ app/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/         # Reusable standalone components\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/              # Application pages as standalone components\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.component.ts    # Root component\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.module.ts       # Root module\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.ts             # Main entry point\n‚îÇ   ‚îú‚îÄ‚îÄ assets/                 # Static assets\n‚îÇ   ‚îú‚îÄ‚îÄ theme/                  # Application theme\n‚îÇ   ‚îú‚îÄ‚îÄ index.html              # HTML entry point\n‚îÇ   ‚îú‚îÄ‚îÄ styles.css              # Global styles\n‚îú‚îÄ‚îÄ ionic.config.json           # Ionic configuration\n‚îú‚îÄ‚îÄ package.json                # NPM dependencies and scripts\n‚îî‚îÄ‚îÄ README.md                   # Project documentation\nDeploying to Railway\nLogin to Railway CLI:\n   railway login\nInitialize a new Railway project:\n   railway init\nDeploy the project:\n   railway up\n   For more detailed instructions, refer to the Railway documentation.\nLicense\n  This project is licensed under the MIT License. See the LICENSE file for more details.\n",
    name: "Ionic Angular with NgModules",
    category: "Starters",
    health: null,
    code: "ZogcrR",
    languages: ["TypeScript", "SCSS", "JavaScript", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "77d7b3b1-1c32-421d-9aed-1f5aa5760d39",
    isApproved: false,
    activeProjects: 2,
    projects: 17,
    description: "NATS JetStream cluster with 3 servers",
    readme:
      "One click deployment for a NATS JetStream cluster with 3 servers.\n\nNATS is a simple, secure and performant communications system for digital systems, services and devices. NATS is part of the Cloud Native Computing Foundation (CNCF). NATS has over 40 client language implementations, and its server can run on-premise, in the cloud, at the edge, and even on a Raspberry Pi. NATS can secure and simplify design and operation of modern distributed systems.\n\nFor more information, check out https://nats.io.",
    name: "NATS JetStream HA",
    category: "Queues",
    health: 100,
    code: "Iy1rFN",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2d580150-e23a-489a-9f2f-89377c7cc817",
    isApproved: false,
    activeProjects: 7,
    projects: 13,
    description: "FastAPI Template For Engineers Building Complex Systems",
    readme:
      "Behemoth FastAPI\n(still working on the template overview but its simple enough)\n\nCreate a .env file\ncopy the contents of the .env_sample into the .env file\nreplace the values of POSTGRES_DATABASE_URL with your postgres username, password, host and port\nrun fastapi dev\nyou are good to go",
    name: "Behemoth FastAPI",
    category: "Starters",
    health: 57,
    code: "CtmI_O",
    languages: ["Python", "Mako", "Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e796ca67-90b8-4755-8561-9255f99c29a5",
    isApproved: false,
    activeProjects: 1,
    projects: 1,
    description: "Lightweight, easy-to-use, distributed relational database built on SQLite",
    readme:
      "Rqlite\n\nrqlite is a distributed relational database that combines the simplicity of SQLite with the robustness of a fault-tolerant, highly available cluster. It's developer-friendly, its operation is straightforward, and its design ensures reliability with minimal complexity.\n\nRead the docs to learn more about it (itz awesome) https://rqlite.io\n\nEverything is ready! No need to change env variables",
    name: "Rqlite",
    category: "Other",
    health: null,
    code: "lzxm7S",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a2e2d27d-a30f-4e8a-a3d0-64bf67ae51db",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "Geolocate IP/IP location api in one click",
    readme:
      "repo: https://github.com/TZGyn/geoip\n\nGet your maxmind account id and license key here \nhttps://www.maxmind.com/en/accounts/current/license-key\n\nGenerate a domain and locate the geolocation of an ip using\nhttps://{your_domain}/{ip}\n\nor https://{your_domain}/me to get your public ip location",
    name: "Geo IP api",
    category: "Other",
    health: null,
    code: "LiUOsa",
    languages: ["Go", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b98fe6bc-a03c-4ddf-8ef1-a8b8ece31656",
    isApproved: false,
    activeProjects: 72,
    projects: 96,
    description: "A Spring Boot starter for Java 20.",
    readme:
      "This is a simple PostgreSQL-backed todos app as a Spring Boot starter for Java 20. It includes a controller, Thymeleaf templating, a PostgreSQL database, and a static file for styles.\n\nTo read more about Spring Boot, visit the (Spring Boot Learn page)[https://spring.io/projects/spring-boot#learn].",
    name: "Spring Boot (Java 20)",
    category: "Starters",
    health: 50,
    code: "Lhg09r",
    languages: ["Java", "CSS", "HTML", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "443fa775-175b-44fe-91dc-a05780ac4bf6",
    isApproved: false,
    activeProjects: 1,
    projects: 4,
    description: "An Ionic Angular Starter in Typescript with Standalone Components",
    readme:
      "Ionic Angular Starter\n\nThis is a starter project for building mobile and web applications using Ionic Angular with standalone components. It is configured to be deployed on Railway.\n\nTable of Contents\nGetting Started\nProject Structure\nDeploying to Railway\nLicense\n\nGetting Started\n\nPrerequisites\n\nNode.js (&gt;= 12.x)\nnpm (or Yarn)\nIonic CLI (npm install -g @ionic/cli)\nRailway CLI\n\nInstallation\n\nClone the repository:\n\n    git clone https://github.com/francis-Paul-code/ionic-angular-standalone-starter.git\n    cd ionic-angular-starter\n\nInstall dependencies:\n\n    npm install\n\nRunning the App\n\nTo start the development server:\n\nionic serve\nProject Structure\nionic-angular-starter/\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îú‚îÄ‚îÄ app/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/         # Reusable standalone components\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/              # Application pages as standalone components\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.component.ts    # Root component\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.module.ts       # Root module\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.ts             # Main entry point\n‚îÇ   ‚îú‚îÄ‚îÄ assets/                 # Static assets\n‚îÇ   ‚îú‚îÄ‚îÄ theme/                  # Application theme\n‚îÇ   ‚îú‚îÄ‚îÄ index.html              # HTML entry point\n‚îÇ   ‚îú‚îÄ‚îÄ styles.css              # Global styles\n‚îú‚îÄ‚îÄ ionic.config.json           # Ionic configuration\n‚îú‚îÄ‚îÄ package.json                # NPM dependencies and scripts\n‚îî‚îÄ‚îÄ README.md                   # Project documentation\nDeploying to Railway\nLogin to Railway CLI:\n   railway login\nInitialize a new Railway project:\n   railway init\nDeploy the project:\n   railway up\n   For more detailed instructions, refer to the Railway documentation.\nLicense\n  This project is licensed under the MIT License. See the LICENSE file for more details.",
    name: "Ionic Angular with Standalone",
    category: "Starters",
    health: null,
    code: "V7xS0V",
    languages: ["TypeScript", "SCSS", "JavaScript", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "32442c88-999b-4252-b01f-bc1e944279ab",
    isApproved: false,
    activeProjects: 19,
    projects: 26,
    description: "UI library for building apps with world-class design.",
    readme:
      "Once UI is a lightweight, versatile design system intended to cover 80% of the needs of all applications. Start building your Next.js app in minutes with: \nA robust token and style system that simplifies customization and ensures consistency. \nA copy-and-paste component library that integrates seamlessly into your project.\nInteractive documentation to apply your branding and set component properties.\n\nDocumentation\nThe documentation is available at once-ui.com/docs.\n\nGet involved\nJoin the Once UI Discord server to connect with designers, developers and share your projects.\n\nLicense\n\nDistributed under the MIT License.\n\nFigma library\n\nOnce UI is also available for Figma.  \nDesign and prototype entire products from scratch in hours. Use the same tokens and components as the Next.js design system.\n\nGrab a copy from the Figma Community.",
    name: "once-ui-nextjs-starter",
    category: "Starters",
    health: 0,
    code: "76DR9Q",
    languages: ["SCSS", "TypeScript", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "29b98387-eda3-4606-a446-52a7cfc12afa",
    isApproved: false,
    activeProjects: 2,
    projects: 4,
    description: "Easily resize images on the fly.",
    readme:
      "imgproxy is a fast and secure standalone server for resizing, processing, and converting images. The guiding principles behind imgproxy are security, speed, and simplicity.\n\nimgproxy is able to quickly and easily resize images on the fly, and it's well-equipped to handle a large amount of image resizing. imgproxy is a fast, secure replacement for all the image resizing code inside your web application (such as resizing libraries, or code that calls ImageMagick or GraphicsMagic). It's also an indispensable tool for processing images from a remote source. With imgproxy, you don‚Äôt need to repeatedly prepare images to fit your design every time it changes.\n\nLearn about how to use imageproxy to prcess images or get images info.\n\nhttps://docs.imgproxy.net/category/usage",
    name: "ImgProxy",
    category: "Automation",
    health: 100,
    code: "JA6b6b",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "fd064fd5-a0f7-4bb9-9be3-a33706f3fc32",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "Powerfull image handling and manipulation.",
    readme:
      "Source code of wsrv.nl (formerly images.weserv.nl), to be used on your own server(s). weserv/images leverages powerful libraries like libvips (for image handling and manipulation) and nginx (used as web server, forward proxy and HTTP cache).\n\nAPI docs: https://wsrv.nl/",
    name: "Image manipulation",
    category: "Automation",
    health: null,
    code: "B8vVFQ",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b5995842-d70f-4080-962b-499c8ed1d05f",
    isApproved: false,
    activeProjects: 0,
    projects: 5,
    description: "An Ionic React Starter in Typescript, comes already configured with railway",
    readme:
      "Ionic React Starter\n\nThis is a starter project for building mobile and web applications using Ionic React. It is configured to be deployed on Railway.\n\nTable of Contents\nGetting Started\nProject Structure\nDeploying to Railway\nLicense\n\nGetting Started\n\nPrerequisites\n\nNode.js (&gt;= 12.x)\nnpm (or Yarn)\nIonic CLI (npm install -g @ionic/cli)\nRailway CLI\n\nInstallation\n\nClone the repository:\n\n    https://github.com/francis-Paul-code/ionic-react-railway-starter.git\n    cd ionic-react-starter\n\nInstall dependencies:\n\n    npm install\n\nRunning the App\n\nTo start the development server:\n\nionic serve\nProject Structure\nionic-react-starter/\n‚îú‚îÄ‚îÄ public/                     # Static files\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îú‚îÄ‚îÄ components/             # Reusable components\n‚îÇ   ‚îú‚îÄ‚îÄ pages/                  # Application pages\n‚îÇ   ‚îú‚îÄ‚îÄ App.tsx                 # Root component\n‚îÇ   ‚îú‚îÄ‚îÄ index.tsx               # Entry point\n‚îÇ   ‚îî‚îÄ‚îÄ theme/                  # Application theme\n‚îú‚îÄ‚îÄ ionic.config.json           # Ionic configuration\n‚îú‚îÄ‚îÄ package.json                # NPM dependencies and scripts\n‚îî‚îÄ‚îÄ README.md                   # Project documentation\nDeploying to Railway\nLogin to Railway CLI:\n   railway login\nInitialize a new Railway project:\n   railway init\nDeploy the project:\n   railway up\n   For more detailed instructions, refer to the Railway documentation.\nLicense\n  This project is licensed under the MIT License. See the LICENSE file for more details.",
    name: "Ionic React Typescript",
    category: "Starters",
    health: null,
    code: "Bh2W7c",
    languages: ["TypeScript", "HTML", "CSS", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "26d4ec44-5c35-455e-9233-5dec5a0086ed",
    isApproved: false,
    activeProjects: 2,
    projects: 7,
    description: "NoSQL cloud database that delivers versatility, performance & scalability.",
    readme:
      "Couchbase\n\nIf you are a first-time user, you can get a quick introduction to using Couchbase Server just by reading this section. In a few brief steps, you‚Äôll get direct experience with installing, running, and performing interactive queries on the server.\n\nSteps for First-Time Users\nThe following steps will guide you through some of the key aspects of Couchbase Server. At the conclusion of the Getting Started sequence, you‚Äôll have reached an excellent starting point for further, more detail-driven activities.\n\n| Step   | Topic                                      |\n|--------|--------------------------------------------|\n| Step 1 | Do a Quick Install                    |\n| Step 2 | Explore the Server Configuration      |\n| Step 3 | Run Your First SQL++ Query            |\n| Step 4 | Choose Your Next Steps                |\n",
    name: "Couchbase",
    category: "Storage",
    health: 100,
    code: "5H1xtf",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "68766678-d149-45f0-8723-294fc17e8945",
    isApproved: false,
    activeProjects: 4,
    projects: 7,
    description: "A  simple starter video player in Typescript React",
    readme:
      "This is the standard Create React App starter, with Typescript and an in-web Video Player, a Caddy is added to serve the build folder. Caddy is used in place of the default start command because the default start command does not start the app in production mode.\n\nSee the template's readme.md for more information on why Caddy is used, and why the default start command is undesirable.",
    name: "React Typescript  Video Player",
    category: "Starters",
    health: null,
    code: "Sqs3VO",
    languages: ["TypeScript", "CSS", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "340e2055-83c0-4eae-96e0-aae63a504f73",
    isApproved: false,
    activeProjects: 2,
    projects: 4,
    description: 'One-click deploy Medplum\'s popular "Foomedical" healthcare starter app',
    readme:
      "What is Foo Medical?\n\nFoo Medical is a ready to use medical practice sample app that's open source. It's built on the popular, open-source healthcare platform, Medplum. This app is meant for developers to clone, customize and run.\n\nFeatures\nCompletely free and open-source\nSecure and compliant Medplum backend, which is also \nopen source\nPatient registration and authentication\nHealth records\nLab results\nMedications\nVaccines\nVitals\nPatient-provider messaging\nCare plans\nPatient scheduling\nAll data represented in FHIR\n\nFoo Medical is designed to be forked and customized for your business' needs. Register on https://foomedical.com to see it in action.",
    name: "Medplum Healthcare: Foomedical Template",
    category: "Starters",
    health: null,
    code: "XaHdPv",
    languages: ["TypeScript", "CSS", "HTML", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "bdfab05e-6a6a-4e5d-a21d-9de76d3a25c0",
    isApproved: false,
    activeProjects: 75,
    projects: 114,
    description: "Starter ASP.NET Core API baked with env variables.",
    readme:
      "\n  ASP.NET Core API (.NET6)\n\nDescription\n\nStarter ASP.NET Core API baked with env variables.\n\nDeploy on Railway\n\nTech Stack\n\nASP.NET Core Web API\n.NET 6\n\nGetting Started\n\nInstallation\n\nClone the repo\n   git clone https://github.com/ayush-lal/dotnet6-api\nNavigate to project directory and clone .env.example\n   cd src/ExampleAPI\n   Windows:\n     copy .env.example .env\n   Linux/MacOS:\n     cp .env.example .env\nRun the API\n   dotnet run\n\nContributing\n\nContributions are what make the open source community such an amazing place to learn, inspire, and create. Any contributions you make are greatly appreciated!\n\nIf you have a suggestion that would make this project better, please fork the repo and create a pull request. You can also simply open an issue with the tag \"enhancement\".\nDon't forget to give the project a star!\n\nClone the Project\nCreate your Feature Branch (git checkout -b feature/AmazingFeature)\nCommit your Changes (git commit -m 'Add some AmazingFeature')\nPush to the Branch (git push origin feature/AmazingFeature)\nOpen a Pull Request\n",
    name: ".NET6 API",
    category: "Starters",
    health: 67,
    code: "fKgMtM",
    languages: ["C#"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ba6602a8-404a-400a-8ed4-02a315a0c8c1",
    isApproved: false,
    activeProjects: 24,
    projects: 82,
    description: "No-code/low-code platform for building apps. Alternative to Retool",
    readme:
      "Post-Installation Instructions\n\nThe initial admin account and password are admin@nocobase.com and admin123.\n\nBe sure to change the account and password after installation!\n\nDistinctive features\n\n1. Data model-driven\n\nMost form-, table-, or process-driven no-code products create data structures directly in the user interface, such as Airtable, where adding a new column to a table is adding a new field. This has the advantage of simplicity of use, but the disadvantage of limited functionality and flexibility to meet the needs of more complex scenarios.\n\nNocoBase adopts the design idea of separating the data structure from the user interface, allowing you to create any number of blocks (data views) for the data collections, with different type, styles, content, and actions in each block. This balances the simplicity of no-code operation with the flexibility of native development.\n\nmodel\n\n2. What you see is what you get\n\nNocoBase enables the development of complex and distinctive business systems, but this does not mean that complex and specialized operations are required. With a single click, configuration options are displayed on the usage interface, and administrators with system configuration privileges can directly configure the user interface in a WYSIWYG manner.\n\nwysiwyg\n\n3. Everything is implemented as plugins\n\nNocoBase adopts plugin architecture, all new functions can be realized by developing and installing plugins, and expanding the functions is as easy as installing an APP on your phone.\n\nplugins",
    name: "nocobase",
    category: "Other",
    health: 100,
    code: "j5tXQu",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "72e39019-e3a6-4bf2-974b-f6203b63c6f4",
    isApproved: false,
    activeProjects: 650,
    projects: 993,
    description: "Simple n8n deploy. It just works.",
    readme:
      "n8n\n\nn8n is a flexible and powerful workflow automation tool that connects apps, services, and APIs. It allows you to:\n\nBuild complex automated workflows with a visual, node-based editor\nIntegrate hundreds of services and tools without writing code\nCustomize your workflows with JavaScript when needed\nSelf-host for complete data control and privacy\n\nWhether you're automating business processes, building internal tools, or connecting disparate systems, n8n provides the flexibility to tackle nearly any automation challenge. Its open-source nature and active community ensure continuous improvements and integrations.\n\nLearn more\n\nn8n docs",
    name: "n8n (w/ postgres)",
    category: "Automation",
    health: 100,
    code: "MRazvG",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3c9116f4-2839-4c2a-b2e3-9d8da20c0081",
    isApproved: false,
    activeProjects: 3,
    projects: 3,
    description: "It's like proxyparty.hackclub.com, but in Caddy!",
    readme:
      "Build your own proxyparty.hackclub.com backend, but with Caddy on Docker, for use in your projects to keep links from being broken. After using this template, you should go into your fork and edit docker/Caddyfile to configure redirect and proxying setups.",
    name: "proxyparty",
    category: "Other",
    health: null,
    code: "PqHfEF",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6b38455d-81d3-42ca-9ce2-99106153d825",
    isApproved: false,
    activeProjects: 3,
    projects: 6,
    description: "A simple home inventory management software",
    readme:
      "Homebox is the inventory and organization system built for the Home User! With a focus on simplicity and ease of use, Homebox is the perfect solution for your home inventory, organization, and management needs.\n\nWebsite\nDocumentation\nGitHub\n\nNote: The development of Homebox was taken over by SysAdmins Media following the original maintainer archiving the project.\n\nTips\n\nBy default, the template has HBOX_OPTIONS_ALLOW_REGISTRATION=true to allow for initial setup. Once you have created your account, consider setting this variable to false to disable open registration.\nSince Volumes on Railway are still a new feature, there is no option to access or backup the persistent data. While Homebox has the option to import/export an inventory, it currently does not offer a comprehensive backup/restore of an installation. This means attachments, such as images, will not be recoverable if the volume is deleted.\nA complete list of supported environment variables can be found here. These can be added to the Homebox service to enable support for features such as email.\n\nNote: This is a community-made template and therefore not supported by the Homebox team. Please direct help requests to the Railway thread for the template.",
    name: "Homebox",
    category: "CMS",
    health: 100,
    code: "unXB5b",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "84f0ea44-ff9a-4023-b462-b5835af7a0b1",
    isApproved: false,
    activeProjects: 62,
    projects: 110,
    description: "A FastHTML starter project using Poetry as the package manager.",
    readme:
      "FastHTML - Hello World!\n\nThis is a super simple FastHTML template to get you going without the necessary set up.\n\nIt deploys via Docker using Poetry as the package manager. You can change this if you want to.\n\nYou can expand this as much as you want to as well. Read the FastHTML docs for more information and to get going!",
    name: "FastHTML",
    category: "Starters",
    health: 13,
    code: "HBHYEX",
    languages: ["Dockerfile", "Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "862b1f94-8688-447b-8911-6468a767df1a",
    isApproved: false,
    activeProjects: 5,
    projects: 15,
    description: "A powerful Hono Backend with Drizzle and Postgres for Node.js/Bun",
    readme:
      "REST API with DB\n\nA powerful Hono Backend with Drizzle and Postgres for Node.js/Bun\n\nDeploy on Railway\n\nOverview\n\nThis project demonstrates a robust REST API built with Hono, using Drizzle ORM for database operations with PostgreSQL. It's designed to run on Bun, providing a fast and efficient backend solution. The project structure allows for easy deployment on Railway, making it ideal for rapid development and scaling.\n\nKey Features\n\nFast REST API using Hono framework\nDatabase integration with Drizzle ORM and PostgreSQL\nRuns on Bun for improved performance\nEasy deployment to Railway\nHealth check endpoint for monitoring\nUser management API endpoint\nDockerized for consistent environments\n\nSetup\n\nTo install dependencies:\n\nbun install\n\nSet up your .env file with your database URL:\n\nDATABASE_URL=your_postgres_url_here\n\nDB\n\nTo generate database migrations, use the following command:\n\nbun run db:generate\n\nTo apply the generated migrations to the database, run:\n\nbun run db:push\n\nTo seed the database with sample data, execute:\n\nbun run db:seed\n\nDevelop\n\nTo run the application locally, execute the following command in your terminal:\n\nbun run dev\n\nDeploy\n\nInitialize your project:\n\nrailway init\n\nTo deploy the bot on Railway:\n\nrailway up\n\nRemember to set the¬†DATABASE_URL¬†environment variable in your Railway project settings.\n\nDATABASE_URL\n\nLearn More\n\nHono Documentation\nDrizzle ORM Documentation\nBun Documentation\nRailway Documentation\nRepository\n",
    name: "REST API with DB",
    category: "Starters",
    health: 100,
    code: "hIiRi5",
    languages: ["TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e5712e76-5bc4-4dfa-ad61-cf5005a09ec4",
    isApproved: false,
    activeProjects: 2,
    projects: 7,
    description: "‚ö° The lightning-fast asynchronous Python web framework",
    readme:
      "Overview\n\nSanic is a Python 3.8+ web server and web framework that‚Äôs written to go fast. It allows the usage of the async/await syntax added in Python 3.5, which makes your code non-blocking and speedy.\n\nHighlights\n\nPython\nSanic\n\nLearn More\n\nDocumenation",
    name: "sanic",
    category: "Starters",
    health: null,
    code: "BK4r9u",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "bbdb38bd-13fa-4dc8-9304-52bbe14f7b9a",
    isApproved: false,
    activeProjects: 1,
    projects: 3,
    description: "Record and share your terminal sessions",
    readme:
      "asciinema\n\nasciinema (aka asciinema CLI or asciinema recorder) is a command-line tool\nfor recording terminal sessions.\n\nUnlike typical screen recording software, which records visual output of a\nscreen into a heavyweight video files (.mp4, .mov), asciinema recorder runs\ninside a terminal, capturing terminal session output into a lightweight\nrecording files in the\nasciicast format (.cast).\n\nThe recordings can be replayed in a terminal, embedded on a web page with the\nasciinema player, or published to\nan asciinema server, such as\nasciinema.org, for further sharing.\n\n![asciinema CLI\ndemo](https://asciinema.org/a/85R4jTtjKVRIYXTcKCNq0vzYH?autoplay=1)\n\nNotable features:\n\nrecording\n  and\n  replaying\n  of sessions inside a terminal,\nlive streaming of terminal sessions, with local HTTP server mode, and a relay\n  forwarding mode,\nlight-weight recording\n  format, which is highly\n  compressible (down to 15% of the original size e.g. with zstd or gzip),\nintegration with asciinema\n  server, e.g.\n  asciinema.org, for easy recording hosting.\n\nasciinema server\n\nasciinema server is a server-side component of the asciinema ecosystem.\n\nIt implements a hosting platform for terminal session recordings. This includes\nan API endpoint for uploading recordings, which is used by the asciinema\nCLI, and offers a familiar web\ninterface for viewing, browsing, sharing and managing recordings.\n\nThe server is built with Elixir language and\nPhoenix framework, and embeds asciinema's\nvirtual terminal, avt, to perform tasks such\nas preview generation and recording analysis.\n\nasciinema.org is a public asciinema server instance\nmanaged by the asciinema team, offering free hosting for terminal recordings,\navailable to everyone. Check asciinema.org/about\nto learn more about this instance.\n\nYou can easily self-host asciinema\nserver and use the\nasciinema CLI with your own instance.\nIf you're not comfortable with uploading your terminal sessions to\nasciinema.org, if your company policy prevents you from doing so, or if you\nsimply prefer self-hosting everything, then asciinema has you covered.\n\nNotable features:\n\nhosting of terminal session recordings in\n  asciicast format,\nperfectly integrated asciinema\n  player for best viewing experience,\neasy sharing of\n  recordings via secret links,\neasy embedding of the\n  player, or linking via preview images (SVG),\nprivacy friendly - no tracking, no ads,\nvisibility control for recordings: unlisted (secret) or public,\neditable recording metadata like title or long description (Markdown),\nconfigurable terminal themes and font families,\nability to download plain text version (.txt) of a recording.\n\nRefer to asciinema server docs for\nfurther details.",
    name: "asciinema",
    category: "Other",
    health: null,
    code: "cqZ8ew",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9acc969c-98b4-43c4-ae5f-5700c1c3f297",
    isApproved: false,
    activeProjects: 851,
    projects: 946,
    description: "A simple Python Telegram bot built using the telebot",
    readme:
      "Overview\n\nThis project is a simple Telegram bot built using the telebot library. It demonstrates the basic structure of a Telegram bot and uses Poetry for dependency management. The bot responds to commands and messages, and can be easily extended with additional functionality.\n\nKey Features\n\nMinimal Telegram bot application\nResponds to '/start' and '/hello' commands\nEchoes all other messages\nUses telebot for bot functionality\nUses Poetry for dependency management\nEasy to understand and extend\n\nSetup\n\npip install poetry\npoetry install\n\nDevelop\n\nTo run the bot locally:\n\npoetry run python -B main.py\n\nMake sure to set up your .env file with your Telegram bot token:\n\nTELEGRAM_BOT_TOKEN=your_token_here\n\nDeploy\n\nInitialize your project:\n\nrailway init\n\nTo deploy the bot on Railway:\n\nrailway up\n\nRemember to set the TELEGRAM_BOT_TOKEN environment variable in your Railway project settings.TELEGRAM_BOT_TOKEN\n\nTest\n\nOpen Telegram, start a chat with your bot, and try the commands /start or /hello. The bot will also echo any other messages you send.\n\nLearn More\n\nTelebot Documentation\nPoetry Documentation\nTelegram Bot API\nRailway Documentation\nTelegram Python Bot Repository",
    name: "Telegram Bot Python",
    category: "Bots",
    health: 0,
    code: "a0ln90",
    languages: ["Python", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "319b7088-b685-4041-a118-d127c8a4f808",
    isApproved: false,
    activeProjects: 16,
    projects: 40,
    description: "Send push notifications to your phone or desktop using PUT/POST",
    readme:
      "Overview\nntfy lets you send push notifications to your phone or desktop via scripts from any computer, using simple HTTP PUT or POST requests.\n\nSetup\nAdd a Custom Domain or Railway-Provided domain on port 80\n\nConfiguration\nCustomize your deployment with command line arguments or environment variables.\n\nDocumentation\n",
    name: "ntfy",
    category: "Observability",
    health: 88,
    code: "5HQY7M",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e0e7dbeb-8325-46ab-b01a-f44b094527a7",
    isApproved: false,
    activeProjects: 249,
    projects: 299,
    description: "A simple Python Discord bot built using the discord.py",
    readme:
      "Overview\n\nThis project is a simple Discord bot built using the discord.py library. It demonstrates the basic structure of a Discord bot and uses Poetry for dependency management. The bot responds to commands and can be easily extended with additional functionality.\n\nKey Features\n\nMinimal Discord bot application\nResponds to '!ping' and '!hello' commands\nUses discord.py for bot functionality\nUses Poetry for dependency management\nEasy to understand and extend\n\nSetup\n\npip install poetry\n\nDevelop\n\nTo run the bot locally:\n\npoetry run python bot.py\n\nMake sure to set up your¬†.env¬†file with your Discord bot token:\n\nDISCORD_TOKEN=your_token_here\n\nDeploy\n\nTo deploy the bot on Railway:\n\nrailway up\n\nRemember to set the¬†DISCORD_TOKEN¬†environment variable in your Railway project settings.\n\nDISCORD_TOKEN\n\nTest\n\nOpen Discord, Add Discord to the channel and Try with !hello or !ping.\n\nLearn More\n\nDiscord.py Documentation\nPoetry Documentation\nDiscord Developer Portal\nRailway Documentation\nRepository",
    name: "Discord Python",
    category: "Bots",
    health: 0,
    code: "x6I4zS",
    languages: ["Python", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c7f03dc6-449e-465b-a3ab-b4267d7199b4",
    isApproved: false,
    activeProjects: 10,
    projects: 20,
    description: "Open Source backend for your next SaaS and Mobile app in 1 file",
    readme:
      "Overview: This Docker template sets up PocketBase, a backend-as-a-service platform, using Alpine Linux for a lightweight and efficient environment. It supports specifying the PocketBase version via the PB_VERSION environment variable (default is 0.22.18). \n\nThe setup includes installing necessary packages, downloading the specified PocketBase version, and running the server on port 8080. \n\nDeployment Instructions: \nNothing required\n\nSteps to Get Started:\nCustomize the PB_VERSION environment variable if a \ndifferent version is required.\n\nFor external access, configure the PUBLIC_URL environment variable with your domain or public URL; this is necessary for accessing the service from the internet. It is available from the service on Railway.\n\nIf accessing within Railway, no additional configuration is needed.\n\nOnce the setup is complete, access PocketBase at http://localhost:8080 or your public URL for further configuration and use.",
    name: "pocketbase",
    category: "Other",
    health: 50,
    code: "Oasf2M",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b5cc9649-f2b6-4f99-8db0-95b8a13d98e5",
    isApproved: false,
    activeProjects: 16,
    projects: 26,
    description: "A minimal Flask application with Poetry",
    readme:
      'Overview\n\nThis project is a minimal Flask web application that serves a simple "Hello World" response. It demonstrates the basic structure of a Flask app and uses Poetry for dependency management.\n\nKey Features\n\nMinimal Flask application\nReturns "Hello World" on the root route\nUses Poetry for dependency management\nEasy to understand and extend\n\nLearn More\n\nFlask Documentation\nPoetry Documentation\nRepository of this Template',
    name: "Flask Poetry",
    category: "Starters",
    health: 50,
    code: "Die4Zz",
    languages: ["Python", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "486240b2-184d-4682-a59c-6ee35b170e4b",
    isApproved: false,
    activeProjects: 8,
    projects: 19,
    description: "Quickly host the database viewer Prisma Studio with only a database url",
    readme:
      "Prisma studio template\nThis is a Railway template used to quickly host Prisma Studio with only a database url. It is made to be quick to set up and have minimal configuration required.\n\nPrisma Studio is a database viewer using Prisma where you can easily view data and relations in a database.\nPrisma Studio screenshot\n\nOptions\nDatabase url\nRequired, This is the database url prisma uses to connect to the database.\n\nProvider\nOptional, This is the database provider prisma uses. Possible values: \ncockroachdb\nmongodb\nmysql\npostgresql\nsqlite\nsqlserver\n\nIf unset, the provider will be guessed from the database url.\n\nSchema source\nIf set, the schema will be loaded from this source instead of from the database.\n\nWhile this template still works without a prisma schema, it's a better experience to have one, as things like relations that are only stored in the schema and not in the database, will not show up in prisma studio without a prisma schema.\n\nThis is either a direct link to the text contents of the schema, or a public github repo containing the schema.\nSupported formats:\nDirect link to the text contents of the schema, starting with http where the origin is not https://github.com.\nowner/repo\nowner/repo/branch\nowner/repo/tree/branch\nowner/repo/blob/branch\nowner/repo/blob/branch/path...\nowner/repo/tree/branch/path...\n\nExamples of valid schema sources would be:\nhttps://github.com/prisma/prisma-examples/blob/latest/accelerate/svelte-starter/prisma/schema.prisma\nhttps://raw.githubusercontent.com/prisma/prisma-examples/latest/accelerate/svelte-starter/prisma/schema.prisma\ntrpc/examples-next-prisma-starter\ntrpc/examples-next-prisma-starter/main\nhttps://github.com/trpc/examples-next-prisma-starter",
    name: "Prisma studio",
    category: "Other",
    health: 94,
    code: "NpN5Jl",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ba686e2c-af64-44e4-a0ce-dee802485498",
    isApproved: false,
    activeProjects: 10,
    projects: 18,
    description: "A minimal Typescript webserver.",
    readme:
      'Typescript webserver\nThis is a minimal Typescript webserver. It will respond to "GET /" requests with the text "Hello World!". This is made using express.\nIt will use the default port provided by Railway, or 3000 if it isn\'t set.\nOnce the template is used to create a project, it will automatically start without extra configuration required.',
    name: "Typescript",
    category: "Starters",
    health: 50,
    code: "hIFwIW",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "49549949-9895-45fd-9fc6-882b4b836f4b",
    isApproved: false,
    activeProjects: 10,
    projects: 16,
    description: "A simple Hello world webserver written in node.",
    readme:
      'Node hello world\nThis is a simple Hello world webserver written in node. It will respond to "GET /" requests with the text "Hello World!". This is made using express.\nIt will use the default port provided by Railway, or 3000 if it isn\'t set.\nOnce the template is used to create a project, it will automatically start without extra configuration required.',
    name: "Hello world",
    category: "Starters",
    health: 100,
    code: "CYqWyQ",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7ad92d00-8909-4a97-be55-231e236eaffd",
    isApproved: false,
    activeProjects: 2,
    projects: 7,
    description: "Postgres for Search and Analytics",
    readme:
      "\n  Postgres for Search and Analytics \n\n\n\n  Website \n  Docs \n  Community \n  Blog \n  Changelog\n\n\nPublish ParadeDB Artifact Hub Docker Pulls License\nSlack URL\nX URL\n\nParadeDB is an Elasticsearch alternative built on Postgres. We're modernizing the features of Elasticsearch's product suite, starting with real-time search and analytics.\n\nStatus\n\nParadeDB is currently in Public Beta. Star and watch this repository to get notified of updates.\n\nRoadmap\n\nx] Search\n  [x] Full-text search with BM25 with [pg_search\n  x] Dense and sparse vector search with [pgvector\n  x] Hybrid search\n[ ] Analytics\n  [x] An analytical query engine over data in Postgres or in any object store or table format with [pg_analytics\n   ] Column-oriented table access method for fast analytics inside Postgres\n  [ ] High-volume data/Kafka ingest\n[x] Self-Hosted ParadeDB\n  [x] Docker image based on [Postgres (see deployment instructions)\n  x] Kubernetes Helm chart based on [CloudNativePG (see deployment instructions)\nx] Specialized Workloads\n  [ ] Support for geospatial data with [PostGIS\n  x] Support for cron jobs with [pg_cron\n  x] Support for basic incremental view maintenance (IVM) via [pg_ivm\n\nGet Started\n\nTo get started, please visit our documentation.\n\nDeploying ParadeDB\n\nParadeDB and its extensions are available as commercial software for installation on self-hosted Postgres deployment and via Docker and Kubernetes as standalone images. For more information, including enterprise features and support, please contact us by email.\n\nExtensions\n\nYou can find prebuilt binaries for all ParadeDB extensions on Debian 12, Ubuntu 22.04 and 24.04, and Red Hat Enterprise Linux 8 and 9 for Postgres 14, 15 and 16 in the GitHub Releases. We officially support Postgres 12 and above, and you can compile the extensions for other versions of Postgres by following the instructions in the respective extension's README.\n\nDocker Image\n\nTo quickly get a ParadeDB instance up and running, simply pull and run the latest Docker image:\n\ndocker run --name paradedb -e POSTGRES_PASSWORD=password paradedb/paradedb\n\nThis will start a ParadeDB instance with default user postgres and password password. You can then connect to the database using psql:\n\ndocker exec -it paradedb psql -U postgres\n\nTo install ParadeDB locally or on-premise, we recommend using our docker-compose.yml file. Alternatively, you can pass the appropriate environment variables to the docker run command, replacing the &lt;&gt; with your desired values:\n\ndocker run \\\n  --name paradedb \\\n  -e POSTGRES_USER= \\\n  -e POSTGRES_PASSWORD= \\\n  -e POSTGRES_DB= \\\n  -v paradedb_data:/var/lib/postgresql/ \\\n  -p 5432:5432 \\\n  -d \\\n  paradedb/paradedb:latest\n\nThis will start a ParadeDB instance with non-root user ` and password . The -v flag enables your ParadeDB data to persist across restarts in a Docker volume named paradedb_data`.\n\nYou can then connect to the database using psql:\n\ndocker exec -it paradedb psql -U  -d  -p 5432 -W\n\nParadeDB collects anonymous telemetry to help us understand how many people are using the project. You can opt out of telemetry using configuration variables within Postgres:\n\nALTER SYSTEM SET paradedb.pg_search_telemetry TO 'off';\nALTER SYSTEM SET paradedb.pg_analytics_telemetry TO 'off';\n\nHelm Chart\n\nParadeDB is also available for Kubernetes via our Helm chart. You can find our Helm chart in the ParadeDB Helm Chart GitHub repository or download it directly from Artifact Hub.\n\nParadeDB Cloud\n\nAt the moment, ParadeDB is not available as a managed cloud service. If you are interested in a ParadeDB Cloud service, please let us know by joining our waitlist.\n\nSupport\n\nIf you're missing a feature or have found a bug, please open a\nGitHub Issue.\n\nTo get community support, you can:\n\nPost a question in the ParadeDB Slack Community\nAsk for help on our GitHub Discussions\n\nIf you need commercial support, please contact the ParadeDB team.\n\nContributing\n\nWe welcome community contributions, big or small, and are here to guide you along\nthe way. To get started contributing, check our first timer issues\nor message us in the ParadeDB Community Slack. Once you contribute, ping us in Slack and we'll send you some ParadeDB swag!\n\nFor more information on how to contribute, please see our\nContributing Guide.\n\nThis project is released with a Contributor Code of Conduct.\nBy participating in this project, you agree to follow its terms.\n\nThank you for helping us make ParadeDB better for everyone :heart:.\n\nLicense\n\nParadeDB is licensed under the GNU Affero General Public License v3.0 and as commercial software. For commercial licensing, please contact us at sales@paradedb.com.\n",
    name: "paradedb",
    category: "Storage",
    health: 100,
    code: "GXXRuO",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8ee63008-77f5-40ca-a7bc-2195e9e4821f",
    isApproved: false,
    activeProjects: 1,
    projects: 1,
    description: "Railway Postgres 16 + Hashids",
    readme:
      "Based on the default Postgres 16 database image, with hashids.\n\n-- Install the hashids extension\nCREATE EXTENSION IF NOT EXISTS hashids;\n\n-- Example table using hashids\nCREATE TABLE users (\n    id BIGSERIAL PRIMARY KEY,\n    username TEXT NOT NULL,\n    hash_id TEXT GENERATED ALWAYS AS (encode_id(id)) STORED\n);",
    name: "Postgres16 + Hashids",
    category: "Other",
    health: 100,
    code: "daaDbI",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8583d207-e6ca-4ec1-bdaa-81488d86bbbe",
    isApproved: false,
    activeProjects: 1,
    projects: 3,
    description: "A NextJS app to handle QStash queue messages (and publish them too!)",
    readme:
      "QStash NextJS publisher and handler\n\nThis template shows you how to build a QStash queue handler, and provides a simple type-safe wrapper to build and publish messages to queues.\n\nThe way Upstash's QStash works is that it lets you publish to a queue, then QStash will handle sending that payload to a specified URL of your choosing. This is then part of the request payload. We use Next.js as the backend here to process the messages, as well as provide an example of how to publish a message to a queue. Everything is serialized/deserialized with SuperJSON, and validated with zod.\n\nThe result is that you only have to build out a handler that lets you process a message, and you get the rest for free. You specify the payload you're expecting, and you'll get a type-safe async function to do your work in processing the message.\n\nThis project was initialized with  T3 Stack bootstrapped with create-t3-app. Please read more about their documentation and generally about Next.js if you're curious.\n\nQuick Start\n\nCreate a project on Upstash and associate all of the correct variables.\nCreate a Queue in the QStash tab with the name of the queue(s) in src/app/_services/QStash/types.ts. If you want to see messages immediately, create a queue named process-post so you can test it out.\nOpen the home page of the deployed Next.js app and click the button. You should see that the message shows up in QStash, then you should see logs in your deployment logs for processing the message.\n\nYou can now extend this to handle all of your background work super simply. No more setup required!\n",
    name: "QStash + NextJS",
    category: "Queues",
    health: 100,
    code: "kCPk-X",
    languages: ["TypeScript", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "64cc2709-b6ff-41ba-b56a-7c10b32e3e3e",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "Concise, consistent, and legible badges",
    readme:
      "Shields.io is a service for concise, consistent, and legible badges, which can easily be included in GitHub readmes or any other web page. The service supports dozens of continuous integration services, package registries, distributions, app stores, social networks, code coverage services, and code analysis services. It is used by some of the world's most popular open-source projects.\n\nhttps://shields.io/docs",
    name: "Shields.io",
    category: "Other",
    health: null,
    code: "ghZo4m",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3a4cafbb-7077-4722-a07c-749c008f5570",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "Document base alternative to Notion",
    readme:
      "Docmost is a open source alternative to Notion. Code is all open source and users can host their own instance. Railway is the one of the best places to self hosted Docmost instance. This template contains everything necessary for Docmost. A PostgreSQL server, a Redis cache, and Docmost server is included in this template.",
    name: "docmost",
    category: "Other",
    health: null,
    code: "pC7ctE",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a999c02c-a2bd-4b92-ae3f-0ac3f69a0437",
    isApproved: false,
    activeProjects: 2,
    projects: 6,
    description: "A simple setup for running Bun crons or scripts.",
    readme:
      "This is a dead-simple way to start adding a cron to your application using Bun. You can use Railway's Cron scheduling to run any TypeScript file super easily now with Bun.sh ‚Äî just make your start command be\n\nbun run your-file.ts\n\nset your cron schedule in the service settings, and you're off to the races.",
    name: "Bun Crons + Scripts",
    category: "Starters",
    health: 100,
    code: "mS2kAe",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6c0982fd-5dc2-426b-bd97-d52fc0ce3426",
    isApproved: false,
    activeProjects: 9,
    projects: 13,
    description: "A simple Python GraphQL server. Introspection + production-ready servers.",
    readme:
      "This template is un-opinionated, but gets you out the door ASAP with a functional GraphQL server.\n\nIt creates two services; one is an introspection server using Strawberry's built-in server. The other is a production-ready Flask server, where you can increase the number of replicas easily and scale horizontally.\n\nRead more about Strawberry at their website",
    name: "Strawberry GraphQL",
    category: "Starters",
    health: 100,
    code: "gPbU5Z",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c69d6202-f011-4c6f-9ee0-7d864ffcc634",
    isApproved: false,
    activeProjects: 37,
    projects: 144,
    description: "Collaborative wiki and documentation. Alternative to Notion & Confluence. ",
    readme:
      "Docmost\n\nDocmost is an open-source collaborative wiki and documentation software. It is an open-source alternative to Confluence and Notion. \n\nAfter deploying, register your first user as the admin.\n\nFeatures\nReal-time collaboration\nSpaces\nPermissions management\nGroups\nComments\nPage history\nSearch\nFile attachment\n\nKnown Issues\n\nThe Docmost container connects to the Redis instance through the public URL. Connecting through the private URL results in errors. I am working on a fix.",
    name: "Docmost",
    category: "Other",
    health: 100,
    code: "W4t6Ei",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d28e1300-f6de-4989-a2bf-dac423090357",
    isApproved: false,
    activeProjects: 10,
    projects: 47,
    description: "The Open-Source Email Platform for AWS",
    readme:
      "Setting up AWS\nPlunk is built on top of AWS SES and requires configuration on AWS.\n\nThe exact steps can be found in the Plunk Documentation.\n\nDeploying Template\nWith your AWS setup and keys in hand, you are ready to deploy the template.\n\nAttaching a domain\nAttach a domain to port 3000 of the driaug/plunk resource\nRedeploy the driaug/plunk resource\n\nYour environment variables will be automatically configured once the resource is redeployed.",
    name: "Plunk",
    category: "Other",
    health: 93,
    code: "T2xefJ",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7adee127-3404-4aa0-9265-6616363f7c9b",
    isApproved: false,
    activeProjects: 1,
    projects: 2,
    description: "Simple request logger for debugging webhooks that require public urls.",
    readme:
      "I made this as a simple request logger to debug webhooks. Just throw up a deployment in railway.app and watch the logs. Written in nodejs + express.\n\nSteps:\nDeploy template to railway\nPoint webhooks to railway provider URL\nOpen deployment logs\nTrigger Webhook",
    name: "simple-request-logger",
    category: "Other",
    health: null,
    code: "Is-oSM",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "05dd5c62-89de-40a7-8de7-fea5a4259bb0",
    isApproved: false,
    activeProjects: 2,
    projects: 6,
    description: "A drop-in replacement for AWS SQS",
    readme:
      "SmoothMQ is an open-source message queue that is compatible with the SQS API. This means all existing code and libraries work with it out of the box.\n\nIt also improves upon the API. With SmoothMQ, you can:\n\nSchedule messages for the future\nView and search messages via a dashboard\nExport Prometheus metrics\n\nIt is written in Go, deploys as a single binary, and stores data on local disk.\n\n",
    name: "smoothmq",
    category: "Queues",
    health: 100,
    code: "AJv-64",
    languages: ["Go", "HTML", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4754eebb-2814-4f23-82f1-860216cec789",
    isApproved: false,
    activeProjects: 4,
    projects: 10,
    description: "A no-code blazing fast EVM indexer tool built in rust.",
    readme:
      "This template deploys the demo at https://github.com/o-az/rindexer-railway/tree/main/rindexer to railway.\n\nTo deploy against your own contract configuration, fork https://github.com/o-az/rindexer-railway, update https://github.com/o-az/rindexer-railway/tree/main/rindexer and deploy.",
    name: "rindexer",
    category: "Other",
    health: 100,
    code: "Rqrlcf",
    languages: ["Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b4263dda-376c-4426-98a9-6f4f8464fa87",
    isApproved: false,
    activeProjects: 0,
    projects: 6,
    description: "Bare bones Grafana provisioned with VictoriaLogs",
    readme:
      'Overview\n\nBare bones template to set up a Grafana instance provisioned with a VictoriaLogs data source. \n\nA basic starter for sending logs to VictoriaLogs (replace VICTORIALOGS_INSTANCE] and [BASE_64_AUTH] with your actual instance url and base-64 encoded username:password):\n\ncurl --request POST \\\n  --url \'https://[VICTORIALOGS_INSTANCE]/insert/jsonline?_stream_fields=stream&amp;_time_field=date&amp;_msg_field=log.message\' \\\n  --header \'Authorization: Basic [BASE_64_AUTH]\' \\\n  --header \'Content-Type: application/stream+json\' \\\n  --data \'{ "log": { "level": "info", "message": "hello world" }, "date": "0", "stream": "stream1" }\n{ "log": { "level": "error", "message": "oh no!" }, "date": "0", "stream": "stream1" }\n{ "log": { "level": "info", "message": "hello world" }, "date": "0", "stream": "stream2" }\'\n\nRead more about VictoriaLogs data ingestion options [here.\n\nDocumentation\n\nThe full list of CLI flags for VictoriaLogs can be found here.\n\nThe provisioned Grafana configuration can be found here.',
    name: "VictoriaLogs-Grafana",
    category: "Observability",
    health: null,
    code: "AB1r4X",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "86028090-0936-4958-901c-25844d222277",
    isApproved: false,
    activeProjects: 9,
    projects: 16,
    description: "A simple ready-to-deploy api gateway",
    readme:
      "Api-Gateway\n\ntitle: Api-Gateway\n\ndescription: A basic ready-to-deploy api gateway \n\ntags:\n  api-gateway\n  spring boot\n  java\n\nFor the full docs go to: GitHub Repo\n\nNOTE: This template consists of a service that acts as a gateway and a Postgres database to store the configurations. This service and the database are connected through private networking, so the project must have private networking enabled in order for it to work correctly. Otherwise, the PGHOST variable is initialized empty and both components must be manually restarted to obtain the correct value.\n\nThis is after all a project designed for deploy in railway as a template... so: \n\nDeploy on Railway\n",
    name: "api-gateway",
    category: "Other",
    health: 100,
    code: "IR4lVv",
    languages: ["Java", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0830e39a-acba-41cb-9738-a49aaeb60a37",
    isApproved: false,
    activeProjects: 10,
    projects: 15,
    description: "Pre-scouting app for FRC.",
    readme:
      "Pre-scouting app is a way to pre-scout for FRC (FIRST Robotics Competition) events. It uses pre compiled data from APIs like The Blue Alliance and Statbotics, and you and your team's your own, team-specific, data, all in one app.\n\nGitHub Repo\nInstallation Guide\nGeneral Guide\n",
    name: "pre-scouting-app",
    category: "Other",
    health: 67,
    code: "EphMDM",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "97739eae-8983-448b-be58-5802475fd82b",
    isApproved: false,
    activeProjects: 47,
    projects: 77,
    description: "A Discord LLM Bot in Python.",
    readme:
      "Overview\n\nThe ultimate Railway template for seamlessly integrating an LLM into your Discord bot. Designed to help you deploy and customize your AI assistant with ease.\n\nHighlights\n\nüåü LLM Model: Leverage the latest advancements with our chatbot, powered by OpenAI‚Äôs new GPT-4o mini, for the most accurate and helpful responses.\n\nüåü Group Sessions: Collaborate effortlessly with your team in a single Discord thread, with the AI chatbot providing real-time assistance.\n\nüåü Search Previous Messages: Quickly find and revisit past conversations with our easy-to-use search feature.\n\nüåü Resume Previous Threads: Pick up right where you left off by resuming previous discussions with the AI assistant.\n\nüåü Zero Downtime: Enjoy seamless service with smart rate limit management that prevents interruptions, and handle multiple messages at once for smooth interactions.\n\nUser Manual\nüåü Starting a New Independent Session\nCommand: @start_session\n\nWhen to Use: When you want to start a new independent conversation with the bot.\n\nHow to Use: Simply type @start_session followed by your first question in any channel.\n\nExample: @start_session What is the weather today?\n\nüåü Sending a Message in an Existing Independent Session\nCommand: @bot\n\nWhen to Use: When you want to continue an existing conversation with the bot.\n\nHow to Use: Type @bot followed by your message directly in the channel.\n\nExample: @bot Can you help me with my homework?\n\n3.üåü Starting a New Group Session\nCommand: @start_group_session\n\nWhen to Use: When you want to initiate a group discussion involving the bot and other users.\n\nHow to Use: Type @start_group_session followed by your first question or topic in the channel where the group discussion will take place.\n\nExample: @start_group_session What are the latest trends in AI?\n\nüåü Sending a Message in an Existing Group Session\nCommand: @bot_group\n\nWhen to Use: When you want to contribute to an ongoing group discussion involving the bot.\n\nHow to Use: Type @bot_group followed by your message directly in the channel where the group session is active.\n\nExample: @bot_group Does anyone know the answer to this question? \n\n\nüåü Searching for Information in an Individual Session\nCommand: @search_session\n\nWhen to Use: When you want the bot to search through individual session conversations.\n\nHow to Use: Type @search_session followed by your query in the channel.\n\nExample: @search_session What is the capital of France?\n\nüåü Searching for Information in a Group Session\nCommand: @search_group_session\n\nWhen to Use: When you want the bot to search through group session conversations.\n\nHow to Use: Type @search_group_session followed by your query in the channel where the group session is active.\n\nExample: @search_group_session What are the latest trends in AI?\n\nüåü Resuming a Previous Individual Session\nCommand: @resume_session:\n\nWhen to Use: When you want to resume a previous conversation with the bot in an individual session.\n\nHow to Use: Type @resume_session: followed by the session ID in the channel.\n\nExample: @resume_session: 123456\n\nüåüResuming a Previous Group Session\nCommand: @resume_group_session:\n\nWhen to Use: When you want to resume a previous group conversation with the bot.\n\nHow to Use: Type @resume_group_session: followed by the session ID in the channel.\n\nExample: @resume_group_session: 789012\n\nLearn More\ndiscord.py",
    name: "Discord LLM Bot",
    category: "Bots",
    health: 86,
    code: "PVL8qm",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1edc5407-21b7-4618-af05-e3bcbe89ccb3",
    isApproved: false,
    activeProjects: 472,
    projects: 1786,
    description: "Full ecommerce solution, manage products, inventory, orders, etc.",
    readme:
      'This boilerplate is a all in one medusajs 2.0 e-commerce webshop solution, it comes preconfigured with both backend + admin dashbord and connected to the "storefront" (webshop frontend).\n\nUpdated to v2.6.1 ü§© 3rd Apr. 2025\n\nVideo instructions\nalt text\n\nAdditional information and instructions\nInstructions: https://funkyton.com/medusajs-2-0-is-finally-here/\n\nGitHub: https://github.com/rpuls/medusajs-2.0-for-railway-boilerplate\n\n\n',
    name: "Medusajs 2.0 + Storefront",
    category: "Other",
    health: 100,
    code: "gkU-27",
    languages: ["TypeScript", "JavaScript", "CSS", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2c40c036-83c6-4dff-99df-783c631339bb",
    isApproved: false,
    activeProjects: 0,
    projects: 5,
    description: "The easiest and most secure way to access and protect infrastructure.",
    readme:
      "\nTeleport\nThis template requires you to create your own password separately! Read the instructions under the Bootstrap service and remember to delete it once you register an account.\n\nTeleport provides connectivity, authentication, access controls and audit for infrastructure.\n\nHere is why you might use Teleport:\nSet up SSO for all of your cloud infrastructure [1].\nProtect access to cloud and on-prem services using mTLS endpoints and short-lived certificates.\nEstablish tunnels to access services behind NATs and firewalls.\nProvide an audit log with session recording and replay for various protocols.\nUnify Role-Based Access Control (RBAC) and enforce the principle of least privilege with access requests.\n\n[1] The open source version supports only GitHub SSO.\n\nTeleport works with SSH, Kubernetes, databases, RDP, and web services.\n\nArchitecture: https://goteleport.com/docs/architecture/\nGetting Started: https://goteleport.com/docs/getting-started/\n\nSourced from Teleport's README.\n\nHighlights\n\nTeleport (one click deploy)\nPostgreSQL Backed Storage\nAutomatic Administrator User Creation\n\nUsage\n\nDeploy this template, acknowledge how to register for your Teleport cluster, and manage your new instance in your browser. Delete the Bootstrap service once you have access to Teleport. You can recreate it if you need to reset your administrator password.\n\nLicense\n\nTeleport is distributed in multiple forms with different licensing implications.\n\nThe Teleport API module (all code in the repository under /api) is available under the Apache 2.0 license.\n\nThe remainder of the source code in this repository is available under the GNU Affero General Public License. Users compiling Teleport from source must comply with the terms of this license.\n\nTeleport Community Edition builds distributed on http://goteleport.com/download are available under a modified Apache 2.0 license.\n\nHelpful Resources\n\nhttps://github.com/6ixfalls/railway-teleport\nhttps://github.com/gravitational/teleport\n https://goteleport.com/docs/reference/config/#reference-configurations",
    name: "Teleport",
    category: "Authentication",
    health: null,
    code: "RkdXAK",
    languages: ["Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2910ca1a-789d-46ce-a531-4267693fbb8d",
    isApproved: false,
    activeProjects: 8,
    projects: 29,
    description: "Playground for running open-source generative AI models on Fireworks AI.",
    readme:
      "Overview\nThis template deploys a simple Streamlit app for running the following open-source text and image generation models on Fireworks AI:\nText: Meta Llama 3 70B\nText: Google Gemma 2 9B Instruct\nText: Mixtral MoE 8x7B Instruct\nText: Yi Large\nImage: Stable Diffusion XL\n\nPre-requisites\nFireworks API key - get it here.\n\nRead more\nRunning Open-Source Generative AI Models on Fireworks AI\nGitHub repo",
    name: "Fireworks AI Playground",
    category: "AI/ML",
    health: 100,
    code: "dYYPjx",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "bebb42c1-e82a-4fae-a9fd-381ce9dd1d71",
    isApproved: false,
    activeProjects: 0,
    projects: 21,
    description: "Bedrock | Modern WordPress Boilerplate",
    readme:
      "The most popular choice for managing Wordpress with composer is now available on Railway. \n\nBedrock is a modern template boilerplate for managing version controlled Wordpress instances. \n\nThis repo follows the best practices for developing apps on Wordpress.\n\nThis template is for you if:\n\nYou are familiar with bedrock and composer\nYou want to manage your plugins and code changes with git.\nYou want to let Wordpress manage your content and uploads.\n\nCreate your own bedrock Wordpress site using the following steps:\n\nFork the repo: https://github.com/enterprise-wp/bedrock-singleapp\nDeploy this template - use roots.io/salts.html for generating tokens.\nVisit settings, disconnect my provided repo and point it to your forked repo. \n\nALERT\n`\nThis template is undergoing active development and currently awaiting a Volumes from Railway. Updates to come soon.\n`",
    name: "Bedrock | Modern WordPress Boilerplate",
    category: "CMS",
    health: null,
    code: "wJtnwV",
    languages: ["PHP"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "61c081f1-fb86-4834-b9c0-123d4907295f",
    isApproved: false,
    activeProjects: 4,
    projects: 21,
    description: "PB with access to Hooks and CMS",
    readme:
      "This setup provides access to the hooks folder for custom server-side logic and integrates PocketCMS for content management. To access Hooks eject the service from the template so it copies a repo into your Github. Pocket CMS is available ‚îú‚îÄ CMS Admin UI: /cms/",
    name: "Pocketbase with PB Hooks and PocketCMS",
    category: "Starters",
    health: 100,
    code: "6ckIwL",
    languages: ["Dockerfile", "Shell", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "fb8fedea-1ddc-4030-9fb2-4d5b9b6c0a81",
    isApproved: false,
    activeProjects: 2,
    projects: 9,
    description: "Open source durable execution platform (seperate services + scaling)",
    readme:
      "\nTemporal\n\nThis version of Temporal allows you to scale individual parts of Temporal up and down as needed. Recommended deployment for production.\n\nLooking to manage the dynamic configuration of Temporal? Check out the Starter Package to see how to configure it.\n\nTemporal is a microservice orchestration platform which enables developers to build scalable applications without sacrificing productivity or reliability. Temporal server executes units of application logic, Workflows, in a resilient manner that automatically handles intermittent failures, and retries failed operations.\n\nTemporal is a mature technology, a fork of Uber's Cadence. Temporal is being developed by Temporal Technologies, a startup by the creators of Cadence.\n\nLearn more about Temporal at https://docs.temporal.io/.\n\nSourced from Temporal's README.\n\nHighlights\n\nTemporal (one click deploy)\nHello World Activity/Workflow Template\nPostgreSQL Backed Storage\n\nUsage\n\nDeploy this template, the relevant environment variables (such as authentication, which should be used in production) and manage your new instance in your browser.\n\nLicense\n\nTemporal is licensed under the MIT License.\n\nHelpful Resources\n\nhttps://github.com/railwayapp-templates/temporal\nhttps://github.com/temporalio/temporal\nhttps://github.com/temporalio/samples-typescript\nhttps://docs.temporal.io/",
    name: "Temporal Replicated",
    category: "Queues",
    health: 86,
    code: "w3_rdm",
    languages: ["Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "dfd7af56-c706-4ccc-b8f5-c0414e103d24",
    isApproved: false,
    activeProjects: 7,
    projects: 21,
    description: "Deploys repository-configured Temporal with two example apps.",
    readme:
      "\nTemporal\nTemporal is a microservice orchestration platform which enables developers to build scalable applications without sacrificing productivity or reliability. Temporal server executes units of application logic, Workflows, in a resilient manner that automatically handles intermittent failures, and retries failed operations.\n\nTemporal is a mature technology, a fork of Uber's Cadence. Temporal is being developed by Temporal Technologies, a startup by the creators of Cadence.\n\nLearn more about Temporal at https://docs.temporal.io/.\n\nSourced from Temporal's README.\n\nHighlights\n\nTemporal (one click deploy)\nHello World Activity/Workflow Template\nPostgreSQL Backed Storage\nDynamic Temporal Configuration\n\nUsage\n\nDeploy this template, configure dynamic.yaml, the relevant environment variables (such as authentication, which should be used in production) and manage your new instance in your browser.\n\nLicense\n\nTemporal is licensed under the MIT License.\n\nHelpful Resources\n\nhttps://github.com/railwayapp-templates/temporal\nhttps://github.com/temporalio/temporal\nhttps://github.com/temporalio/samples-typescript\nhttps://docs.temporal.io/",
    name: "Temporal Starter Package",
    category: "Queues",
    health: 100,
    code: "9qwii0",
    languages: ["TypeScript", "JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8a654f0b-7868-487c-a705-dd841562bc67",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "A simple NodeJS app to back up your MongoDB database to S3 via a cron.",
    readme:
      "Overview\nThe template uses node-cron or Railway cron, written in TypeScript to dump your MongoDB data to a file and then upload the file to S3.\n\nHighlights\nConfigurable backup schedule: By default, the cron runs at 00 AM every day but is configurable via the BACKUP_CRON_SCHEDULE environment variable.\n\nSupport for custom buckets: The script also supports using a AWS_S3_ENDPOINT environment variable to use any S3 compliant storage bucket.\n\nConfiguration\nAWS_ACCESS_KEY_ID\nAWS_SECRET_ACCESS_KEY\nAWS_S3_BUCKET\nAWS_S3_REGION\nBACKUP_MONGO_URI\nBACKUP_CRON_SCHEDULE\nAWS_S3_ENDPOINT\n",
    name: "mongo-s3-backup",
    category: "Other",
    health: null,
    code: "VkrypE",
    languages: ["TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8c6c94ba-a4a3-40a3-b67a-347b36f5f066",
    isApproved: false,
    activeProjects: 17,
    projects: 37,
    description: "ChatGPT on open-webui -minimal and easy",
    readme:
      "ChatGPT on OpenWebUI offers a seamless experience through the OpenAI API. Its minimal and intuitive design ensures easy navigation, making it lightweight and user-friendly. One significant advantage is that it does not require Ollama, simplifying the setup process. Users can effortlessly engage with advanced AI, benefiting from its straightforward interface and efficient performance, enhancing productivity and interaction.",
    name: "ChatGPT-webui",
    category: "Other",
    health: null,
    code: "U-DJZB",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "73a85b19-b615-4cd4-93ca-a980992d0f7d",
    isApproved: false,
    activeProjects: 27,
    projects: 70,
    description: "Simplify, secure, and manage your PDF effortlessly.",
    readme:
      "Features\nDark mode support.\nCustom download options\nParallel file processing and downloads\nAPI for integration with external scripts\nOptional Login and Authentication support (see here for documentation)\nDatabase Backup and Import (see here for documentation)\nPDF Features\nPage Operations\nView and modify PDFs - View multi page PDFs with custom viewing sorting and searching. Plus on page edit features like annotate, draw and adding text and images. (Using PDF.js with Joxit and Liberation.Liberation fonts)\nFull interactive GUI for merging/splitting/rotating/moving PDFs and their pages.\nMerge multiple PDFs together into a single resultant file.\nSplit PDFs into multiple files at specified page numbers or extract all pages as individual files.\nReorganize PDF pages into different orders.\nRotate PDFs in 90-degree increments.\nRemove pages.\nMulti-page layout (Format PDFs into a multi-paged page).\nScale page contents size by set %.\nAdjust Contrast.\nCrop PDF.\nAuto Split PDF (With physically scanned page dividers).\nExtract page(s).\nConvert PDF to a single page.\nConversion Operations\nConvert PDFs to and from images.\nConvert any common file to PDF (using LibreOffice).\nConvert PDF to Word/Powerpoint/Others (using LibreOffice).\nConvert HTML to PDF.\nURL to PDF.\nMarkdown to PDF.\nSecurity & Permissions\nAdd and remove passwords.\nChange/set PDF Permissions.\nAdd watermark(s).\nCertify/sign PDFs.\nSanitize PDFs.\nAuto-redact text.\nOther Operations\nAdd/Generate/Write signatures.\nRepair PDFs.\nDetect and remove blank pages.\nCompare 2 PDFs and show differences in text.\nAdd images to PDFs.\nCompress PDFs to decrease their filesize (Using OCRMyPDF).\nExtract images from PDF.\nExtract images from Scans.\nAdd page numbers.\nAuto rename file by detecting PDF header text.\nOCR on PDF (Using OCRMyPDF).\nPDF/A conversion (Using OCRMyPDF).\nEdit metadata.\nFlatten PDFs.\nGet all information on a PDF to view or export as JSON",
    name: "Stirling-PDF",
    category: "Other",
    health: 95,
    code: "ZelMkZ",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "95ee8a69-785f-4ba4-bde5-4501db2e8de8",
    isApproved: false,
    activeProjects: 1,
    projects: 8,
    description: "imgproxy with S3 source for fast image delivery",
    readme:
      "This template for Railway sets up imgproxy with an S3 source, enabling efficient and fast image delivery. By utilizing imgproxy, images are dynamically resized and optimized on-the-fly, ensuring quick loading times and reduced bandwidth usage. The integration with S3 provides a scalable and reliable storage solution, perfect for handling large volumes of images. Ideal for developers seeking a streamlined and performant image processing pipeline.",
    name: "imgproxy with S3 source",
    category: "Other",
    health: 80,
    code: "6HKVuw",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2cb8f9bd-e472-4647-b86d-c8da77fb368c",
    isApproved: false,
    activeProjects: 18,
    projects: 51,
    description: "Redis HTTP Server (Upstash compatibility) ",
    readme:
      "Redis HTTP Server with Upstash compatibility\n\nThis template is an HTTP server that interacts with the Redis database via HTTP requests. It supports compatibility with Upstash, a cloud service that provides Redis.\n\nTechnologies used:\nHono: A lightweight framework for building high-performance HTTP servers in TypeScript. In this template, Hono is used to handle HTTP requests.\nNx: A project management tool that helps organize code and dependencies. It is used to structure the application and run tasks such as build, testing, and deployment.\n\nWhy use this template:\nSimple setup and high performance thanks to Hono.\nNx helps manage the project and dependencies, making development more convenient.",
    name: "Serverless Redis",
    category: "Storage",
    health: 100,
    code: "hBFwO4",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c9d75c6a-9405-437e-b7c1-e47523f78dfd",
    isApproved: false,
    activeProjects: 10,
    projects: 19,
    description: "A service that can convert ChatGPT on the web to OpenAI API format.",
    readme:
      'CHAT2API\n\nü§ñ ‰∏Ä‰∏™ÁÆÄÂçïÁöÑ ChatGPT TO API ‰ª£ÁêÜ\n\nüåü Êó†ÈúÄË¥¶Âè∑Âç≥ÂèØ‰ΩøÁî®ÂÖçË¥π„ÄÅÊó†ÈôêÁöÑ GPT-3.5\n\nüí• ÊîØÊåÅ AccessToken ‰ΩøÁî®Ë¥¶Âè∑ÔºåÊîØÊåÅ GPT-4„ÄÅGPT-4o„ÄÅ GPTs\n\nüîç ÂõûÂ§çÊ†ºÂºè‰∏éÁúüÂÆû API ÂÆåÂÖ®‰∏ÄËá¥ÔºåÈÄÇÈÖçÂá†‰πéÊâÄÊúâÂÆ¢Êà∑Á´Ø\n\n‰∫§ÊµÅÁæ§\n\nhttps://t.me/chat2api\n\nË¶ÅÊèêÈóÆËØ∑ÂÖàÈòÖËØªÂÆå‰ªìÂ∫ìÊñáÊ°£ÔºåÂ∞§ÂÖ∂ÊòØÂ∏∏ËßÅÈóÆÈ¢òÈÉ®ÂàÜ„ÄÇ\n\nÊèêÈóÆÊó∂ËØ∑Êèê‰æõÔºö\n\nÂêØÂä®Êó•ÂøóÊà™ÂõæÔºàÊïèÊÑü‰ø°ÊÅØÊâìÁ†ÅÔºåÂåÖÊã¨ÁéØÂ¢ÉÂèòÈáèÂíåÁâàÊú¨Âè∑Ôºâ\nÊä•ÈîôÁöÑÊó•Âøó‰ø°ÊÅØÔºàÊïèÊÑü‰ø°ÊÅØÊâìÁ†ÅÔºâ\nÊé•Âè£ËøîÂõûÁöÑÁä∂ÊÄÅÁ†ÅÂíåÂìçÂ∫î‰Ωì\n\nÂäüËÉΩ\n\nÊúÄÊñ∞Áâà v1.3.6\n\n&gt; Â∑≤ÂÆåÊàê\n&gt; - x] ÊµÅÂºè„ÄÅÈùûÊµÅÂºè‰º†Ëæì\n&gt; - [x] ÂÖçÁôªÂΩï GPT-3.5 ÂØπËØù\n&gt; - [x] GPT-3.5 ÂØπËØùÔºà‰º†ÂÖ•Ê®°ÂûãÂêç‰∏çÂåÖÂê´ gpt-4ÔºåÂàôÈªòËÆ§‰ΩøÁî® gpt-3.5Ôºå‰πüÂ∞±ÊòØ text-davinci-002-render-shaÔºâ\n&gt; - [x] GPT-4 ÂØπËØùÔºà‰º†ÂÖ•Ê®°ÂûãÂêçÂåÖÂê´: gpt-4Ôºågpt-4oÔºågpt-4-moblie Âç≥ÂèØ‰ΩøÁî®ÂØπÂ∫îÊ®°ÂûãÔºåÈúÄ‰º†ÂÖ• AccessTokenÔºâ\n&gt; - [x] GPT-4 ÁîªÂõæ„ÄÅ‰ª£Á†Å„ÄÅËÅîÁΩë\n&gt; - [x] ÊîØÊåÅ GPTsÔºà‰º†ÂÖ•Ê®°ÂûãÂêçÔºögpt-4-gizmo-g-*Ôºâ\n&gt; - [x] ÊîØÊåÅ Team Plus Ë¥¶Âè∑ÔºàÈúÄ‰º†ÂÖ• team account idÔºâ\n&gt; - [x] ‰∏ä‰º†ÂõæÁâá„ÄÅÊñá‰ª∂ÔºàÊ†ºÂºè‰∏∫ API ÂØπÂ∫îÊ†ºÂºèÔºåÊîØÊåÅ URL Âíå base64Ôºâ\n&gt; - [x] WebUIÔºà[http://127.0.0.1:5005Ôºå‰∏çÊîØÊåÅÁôªÂΩï‰ΩøÁî®, ÁΩëÂÖ≥ÂâØ‰∫ßÂìÅÔºåÂõ†Ê≠§‰∏çÂÅöÁª¥Êä§Ôºâ\n&gt; - x] ÂèØ‰Ωú‰∏∫ÁΩëÂÖ≥‰ΩøÁî®ÔºåÂèØÂ§öÊú∫ÂàÜÂ∏ÉÈÉ®ÁΩ≤\n&gt; - [x] Â§öË¥¶Âè∑ËΩÆËØ¢ÔºåÂêåÊó∂ÊîØÊåÅ AccessToken Âíå RefreshToken\n&gt; - [x] ËØ∑Ê±ÇÂ§±Ë¥•ÈáçËØïÔºåËá™Âä®ËΩÆËØ¢‰∏ã‰∏Ä‰∏™ Token\n&gt; - [x] Tokens ÁÆ°ÁêÜÔºåÊîØÊåÅ‰∏ä‰º†„ÄÅÊ∏ÖÈô§\n&gt; - [x] ÂÆöÊó∂‰ΩøÁî® RefreshToken Âà∑Êñ∞ AccessToken / ÊØèÊ¨°ÂêØÂä®Â∞Ü‰ºöÂÖ®ÈÉ®ÈùûÂº∫Âà∂Âà∑Êñ∞‰∏ÄÊ¨°ÔºåÊØè4Â§©Êôö‰∏ä3ÁÇπÂÖ®ÈÉ®Âº∫Âà∂Âà∑Êñ∞‰∏ÄÊ¨°„ÄÇ\n&gt; - [x] ÊîØÊåÅÊñá‰ª∂‰∏ãËΩΩÔºåÈúÄË¶ÅÂºÄÂêØÂéÜÂè≤ËÆ∞ÂΩï\n\n&gt; TODO\n&gt; - [ ] ÊöÇÊó†ÔºåÊ¨¢ËøéÊèê issue\n\nTokens ÁÆ°ÁêÜ\n\nÈ¶ñÂÖàÈÖçÁΩÆÁéØÂ¢ÉÂèòÈáè AUTHORIZATIONÔºåÁÑ∂ÂêéËøêË°åÁ®ãÂ∫è„ÄÇ\n\nËÆøÈóÆ /tokens ÊàñËÄÖ /api_prefix/tokens ÂèØ‰ª•Êü•ÁúãÁé∞Êúâ Tokens Êï∞ÈáèÔºå‰πüÂèØ‰ª•‰∏ä‰º†Êñ∞ÁöÑ Tokens ÔºåÊàñËÄÖÊ∏ÖÁ©∫ Tokens„ÄÇ\n\nËØ∑Ê±ÇÊó∂‰º†ÂÖ• AUTHORIZATION ‰∏≠‰Ω†ÈÖçÁΩÆÁöÑÂÄºÂç≥ÂèØÂ§öË¥¶Âè∑ËΩÆËØ¢Ôºå AUTHORIZATION ÂèØ‰ª•ÈÖçÁΩÆÂ§ö‰∏™ÂÄºÔºåÁî®Ëã±ÊñáÈÄóÂè∑ÂàÜÈöî„ÄÇ\n\ntokens.png\n\nÁéØÂ¢ÉÂèòÈáè\n\nÊØè‰∏™ÁéØÂ¢ÉÂèòÈáèÈÉΩÊúâÈªòËÆ§ÂÄºÔºåÂ¶ÇÊûú‰∏çÊáÇÁéØÂ¢ÉÂèòÈáèÁöÑÂê´‰πâÔºåËØ∑‰∏çË¶ÅËÆæÁΩÆÔºåÊõ¥‰∏çË¶Å‰º†Á©∫ÂÄºÔºåÂ≠óÁ¨¶‰∏≤Êó†ÈúÄÂºïÂè∑„ÄÇ\n\n| ÂàÜÁ±ª   | ÂèòÈáèÂêç               | Á§∫‰æãÂÄº                                                         | ÈªòËÆ§ÂÄº                   | ÊèèËø∞                                                           |\n|------|-------------------|-------------------------------------------------------------|-----------------------|--------------------------------------------------------------|\n| ÂÆâÂÖ®Áõ∏ÂÖ≥ | API_PREFIX        | your_prefix                                               | None                | API ÂâçÁºÄÂØÜÁ†ÅÔºå‰∏çËÆæÁΩÆÂÆπÊòìË¢´‰∫∫ËÆøÈóÆÔºåËÆæÁΩÆÂêéÈúÄËØ∑Ê±Ç /your_prefix/v1/chat/completions |\n|      | AUTHORIZATION     | your_first_authorization,your_second_authorization | []                  | ‰Ω†Ëá™Â∑±‰∏∫‰ΩøÁî®Â§öË¥¶Âè∑ËΩÆËØ¢ Tokens ËÆæÁΩÆÁöÑÊéàÊùÉÔºåËã±ÊñáÈÄóÂè∑ÂàÜÈöî                              |\n|      | AUTH_KEY          | your_auth_key                                             | None                | ÁßÅ‰∫∫ÁΩëÂÖ≥ÈúÄË¶ÅÂä†auth_keyËØ∑Ê±ÇÂ§¥ÊâçËÆæÁΩÆËØ•È°π                                    |\n| ËØ∑Ê±ÇÁõ∏ÂÖ≥ | CHATGPT_BASE_URL  | https://chatgpt.com                                       | https://chatgpt.com | ChatGPT ÁΩëÂÖ≥Âú∞ÂùÄÔºåËÆæÁΩÆÂêé‰ºöÊîπÂèòËØ∑Ê±ÇÁöÑÁΩëÁ´ôÔºåÂ§ö‰∏™ÁΩëÂÖ≥Áî®ÈÄóÂè∑ÂàÜÈöî                           |\n|      | PROXY_URL         | http://ip:port,http://username:password@ip:port    | []                  | ÂÖ®Â±Ä‰ª£ÁêÜ URLÔºåÂá∫ 403 Êó∂ÂêØÁî®ÔºåÂ§ö‰∏™‰ª£ÁêÜÁî®ÈÄóÂè∑ÂàÜÈöî                                 |\n|      | EXPORT_PROXY_URL  | http://ip:portÊàñhttp://username:password@ip:port    | None                | Âá∫Âè£‰ª£ÁêÜ URLÔºåÈò≤Ê≠¢ËØ∑Ê±ÇÂõæÁâáÂíåÊñá‰ª∂Êó∂Ê≥ÑÊºèÊ∫êÁ´ô ip                                   |\n|      | ARKOSE_TOKEN_URL  | https://example.com/token                                 | []                  | Ëé∑Âèñ Arkose token ÁöÑÂú∞ÂùÄ                                          |\n| ÂäüËÉΩÁõ∏ÂÖ≥ | HISTORY_DISABLED  | true                                                      | true                | ÊòØÂê¶‰∏ç‰øùÂ≠òËÅäÂ§©ËÆ∞ÂΩïÂπ∂ËøîÂõû conversation_id                                 |\n|      | POW_DIFFICULTY    | 00003a                                                    | 00003a              | Ë¶ÅËß£ÂÜ≥ÁöÑÂ∑•‰ΩúÈáèËØÅÊòéÈöæÂ∫¶Ôºå‰∏çÊáÇÂà´ËÆæÁΩÆ                                            |\n|      | RETRY_TIMES       | 3                                                         | 3                   | Âá∫ÈîôÈáçËØïÊ¨°Êï∞Ôºå‰ΩøÁî® AUTHORIZATION ‰ºöËá™Âä®ËΩÆËØ¢‰∏ã‰∏Ä‰∏™Ë¥¶Âè∑                           |\n|      | ENABLE_GATEWAY    | true                                                      | true                | ÊòØÂê¶ÂêØÁî®ÁΩëÂÖ≥Ê®°ÂºèÔºàWEBUIÔºâ                                              |\n|      | CONVERSATION_ONLY | false                                                     | false               | ÊòØÂê¶Áõ¥Êé•‰ΩøÁî®ÂØπËØùÊé•Âè£ÔºåÂ¶ÇÊûú‰Ω†Áî®ÁöÑÁΩëÂÖ≥ÊîØÊåÅËá™Âä®Ëß£ÂÜ≥powÂíåarkoseÊâçÂêØÁî®                        |\n|      | ENABLE_LIMIT      | true                                                      | true                | ÂºÄÂêØÂêé‰∏çÂ∞ùËØïÁ™ÅÁ†¥ÂÆòÊñπÊ¨°Êï∞ÈôêÂà∂ÔºåÂ∞ΩÂèØËÉΩÈò≤Ê≠¢Â∞ÅÂè∑                                       |\n|      | UPLOAD_BY_URL     | false                                                     | false               | ÂºÄÂêØÂêéÊåâÁÖß URL+Á©∫Ê†º+Ê≠£Êñá ËøõË°åÂØπËØùÔºåËá™Âä®Ëß£Êûê URL ÂÜÖÂÆπÂπ∂‰∏ä‰º†ÔºåÂ§ö‰∏™ URL Áî®Á©∫Ê†ºÂàÜÈöî           |\n|      | CHECK_MODEL       | false                                                     | false               | Ê£ÄÊü•Ë¥¶Âè∑ÊòØÂê¶ÊîØÊåÅ‰º†ÂÖ•Ê®°ÂûãÔºåÂºÄÂêØÂêéÂèØ‰ª•Á®çÂæÆÈÅøÂÖç4oËøîÂõû3.5ÂÜÖÂÆπÔºå‰ΩÜÊòØ‰ºöÂ¢ûÂä†ËØ∑Ê±ÇÊó∂Âª∂Ôºå‰∏îÂπ∂‰∏çËÉΩËß£ÂÜ≥ÈôçÊô∫ÈóÆÈ¢ò         |\n|      | SCHEDULED_REFRESH | false                                                     | false               | ÊòØÂê¶ÂÆöÊó∂Âà∑Êñ∞ AccessToken ÔºåÂºÄÂêØÂêéÊØèÊ¨°ÂêØÂä®Á®ãÂ∫èÂ∞Ü‰ºöÂÖ®ÈÉ®ÈùûÂº∫Âà∂Âà∑Êñ∞‰∏ÄÊ¨°ÔºåÊØè4Â§©Êôö‰∏ä3ÁÇπÂÖ®ÈÉ®Âº∫Âà∂Âà∑Êñ∞‰∏ÄÊ¨°„ÄÇ    |\n\nÈÉ®ÁΩ≤\n\nRailway ÈÉ®ÁΩ≤\n\n[Deploy on Railway\n\nZeabur ÈÉ®ÁΩ≤\n\nDeploy on Zeabur\n\nÁõ¥Êé•ÈÉ®ÁΩ≤\n\ngit clone https://github.com/LanQian528/chat2api\ncd chat2api\npip install -r requirements.txt\npython app.py\n\nDocker ÈÉ®ÁΩ≤\n\nÊÇ®ÈúÄË¶ÅÂÆâË£Ö Docker Âíå Docker Compose„ÄÇ\n\ndocker run -d \\\n  --name chat2api \\\n  -p 5005:5005 \\\n  lanqian528/chat2api:latest\n\n(Êé®ËçêÔºåÂèØÁî® PLUS Ë¥¶Âè∑) Docker Compose ÈÉ®ÁΩ≤\n\nÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑÁõÆÂΩïÔºå‰æãÂ¶Ç chat2apiÔºåÂπ∂ËøõÂÖ•ËØ•ÁõÆÂΩïÔºö\n\nmkdir chat2api\ncd chat2api\n\nÂú®Ê≠§ÁõÆÂΩï‰∏≠‰∏ãËΩΩÂ∫ì‰∏≠ÁöÑ docker-compose.yml Êñá‰ª∂Ôºö\n\nwget https://raw.githubusercontent.com/LanQian528/chat2api/main/docker-compose.yml\n\n‰øÆÊîπ docker-compose.yml Êñá‰ª∂‰∏≠ÁöÑÁéØÂ¢ÉÂèòÈáèÔºå‰øùÂ≠òÂêéÔºö\n\ndocker-compose up -d\n\n‰ΩøÁî®\n\nÂú®ÁΩëÈ°µ‰ΩøÁî®ÔºåÁõ¥Êé•ËÆøÈóÆ‰ª•‰∏ãÂú∞ÂùÄÔºå‰ªÖÊîØÊåÅ‰ΩøÁî®ÂÖçÁôª GPT-3.5Ôºö\n\nhttp://127.0.0.1:5005\n\n‰ΩøÁî® API ÔºåÊîØÊåÅ‰º†ÂÖ• AccessToken Êàñ RefreshTokenÔºåÂèØÁî® GPT-4, GPT-4o, GPTsÔºö\n\ncurl --location \'http://127.0.0.1:5005/v1/chat/completions\' \\\n--header \'Content-Type: application/json\' \\\n--header \'Authorization: Bearer {{OpenAI APIKEY}}\' \\\n--data \'{\n     "model": "gpt-3.5-turbo",\n     "messages": {"role": "user", "content": "Say this is a test!"}],\n     "stream": true\n   }\'\n\nÂ∞Ü‰Ω†Ë¥¶Âè∑ÁöÑ AccessToken Êàñ RefreshToken ÂΩì‰Ωú OpenAI APIKEY ‰º†ÂÖ•„ÄÇ\n\nÂ¶ÇÊûúÊúâteamË¥¶Âè∑ÔºåÂèØ‰ª•‰º†ÂÖ• ChatGPT-Account-IDÔºå‰ΩøÁî® Team Â∑•‰ΩúÂå∫Ôºö\n\n‰º†ÂÖ•ÊñπÂºè‰∏ÄÔºö\nheaders ‰∏≠‰º†ÂÖ• ChatGPT-Account-IDÂÄº\n\n‰º†ÂÖ•ÊñπÂºè‰∫åÔºö\nAuthorization: Bearer ,\n\nÂ¶ÇÊûúËÆæÁΩÆ‰∫Ü AUTHORIZATION ÁéØÂ¢ÉÂèòÈáèÔºåÂèØ‰ª•Â∞ÜËÆæÁΩÆÁöÑÂÄºÂΩì‰Ωú OpenAI APIKEY ‰º†ÂÖ•ËøõË°åÂ§ö Tokens ËΩÆËØ¢„ÄÇ\n\n&gt; - AccessToken Ëé∑Âèñ: chatgptÂÆòÁΩëÁôªÂΩïÂêéÔºåÂÜçÊâìÂºÄ [https://chatgpt.com/api/auth/session Ëé∑Âèñ accessToken Ëøô‰∏™ÂÄº„ÄÇ\n&gt; - RefreshToken Ëé∑Âèñ: Ê≠§Â§Ñ‰∏çÊèê‰æõËé∑ÂèñÊñπÊ≥ï„ÄÇ\n&gt; - ÂÖçÁôªÂΩï gpt-3.5 Êó†ÈúÄ‰º†ÂÖ• Token„ÄÇ\n\nArkoseToken\n\n&gt; #### ÁõÆÂâçÊîØÊåÅÂ§ñÈÉ®ÊúçÂä°Êèê‰æõ ArkoseToken\n&gt;\n&gt; #### Êé®Ëçê‰ΩøÁî® docker-compose ÊñπÂºèÈÉ®ÁΩ≤ÔºåÂ∑≤ÂÜÖÁΩÆ Arkose ÊúçÂä°\n\nËÆæÁΩÆÁéØÂ¢ÉÂèòÈáè ARKOSE_TOKEN_URL\n\nÂú®ÈúÄË¶Å ArkoseToken ÁöÑÊó∂ÂÄôÔºåchat2api ‰ºöÂêë ARKOSE_TOKEN_URL ÂèëÈÄÅ POST ËØ∑Ê±Ç\n\nËØ∑ÊåâÁÖß‰ª•‰∏ãÊ†ºÂºèÊèê‰æõÂ§ñÈÉ®ÊúçÂä°Ôºö\n\nËØ∑Ê±Ç‰ΩìÔºö\n\n{"blob": "rFYaxQNEApDlx/Db.KyrE79pAAFBs70CYtbM4pMNUsc7jIkLGdiDs7vziHRGe78bqWXDo0AYyq2A10qIlcTt89lBYXJqCbONC/nD8C199pEZ/c9ocVKKtM27jZQ7fyOpWd9p5qjKeXT4xEGBFpoE3Re1DwdQeijYp7VMJQyw7RYN+IDB1QEx3aKSO6aTI+ivnhw9ztfn/p1SkvAyyOhur/ArF08WQ+rXQpxpttaSQlzMsIwlYbuUUuYE2f9JrQaYG7qip1DKvju111P6wTNy4QVlMXG32VrzaOWh4nmQ0lOcZ1DmN6u2aeJZotffHV2zOOQAqqnParidTbN+qFre2t77ZwBuGKGqLyT8LeOp02GdFwcyw0kkeX+L7vwYAzBpjA5ky0r0X+i8HpzWt8QCyWzEW9kHn9LLCTwg2MOumzjb66Ad4WDe+C1bAcOKuEyXiYh+a1cWZAOdzEuxEg90yCfI7DZR94BsoDR85gEC/Og88i098u5HV7hZZEOQ6J8fmi68FSyPkN7oLCmBsZCMAZqzapNP/MkeIMExrdw7Jf/PtMrZN4bwM56mWfyIJf5h/zXu8PUajVwE9Pj/M5VtB0spZg49JNeHExosVCAB0C0JW+T8vEIwoqiY4pRQ0lbMHTQZFpU2xURTgcgh+m6g1SEYR1FY3de1XnzfiTQq1RTNJPydj5xpt6r6okr8yIJdRhmVXlQI+pS7vi3+Lls2hnpr7L+l1mcUIMPZNBCs3AUFJNpp6SwQjZkPvKggg1p+uS6PdvKRizM9O9+FKc103AhuSia8KTrvU8tWhBhCzIHCD4LNfnkjuBWSdbDttva4AEXUoPuKkQCWaBzq4lQPUIHFOM9HmNe738vVkNdAuOYffxDNegcpIxLVgZGfbgLQ="}\n\nÂìçÂ∫î‰ΩìÔºö\n\n{"token": "45017c7bb17115f36.7290869304|r=ap-southeast-1|meta=3|metabgclr=transparent|metaiconclr=%23757575|guitextcolor=%23000000|pk=0A1D34FC-659D-4E23-B17B-694DCFCF6A6C|at=40|sup=1|rid=3|ag=101|cdn_url=https%3A%2F%2Ftcr9i.openai.com%2Fcdn%2Ffc|lurl=https%3A%2F%2Faudio-ap-southeast-1.arkoselabs.com|surl=https%3A%2F%2Ftcr9i.openai.com|smurl=https%3A%2F%2Ftcr9i.openai.com%2Fcdn%2Ffc%2Fassets%2Fstyle-manager"}\n\nÂ∏∏ËßÅÈóÆÈ¢ò\n\n&gt; - ÈîôËØØ‰ª£Á†ÅÔºö\n&gt;   - 401ÔºöÂΩìÂâç IP ‰∏çÊîØÊåÅÂÖçÁôªÂΩïÔºåËØ∑Â∞ùËØïÊõ¥Êç¢ IP Âú∞ÂùÄÔºåÊàñËÄÖÂú®ÁéØÂ¢ÉÂèòÈáè PROXY_URL ‰∏≠ËÆæÁΩÆ‰ª£ÁêÜÔºåÊàñËÄÖ‰Ω†ÁöÑË∫´‰ªΩÈ™åËØÅÂ§±Ë¥•„ÄÇ\n&gt;   - 403ÔºöËØ∑Âú®Êó•Âøó‰∏≠Êü•ÁúãÂÖ∑‰ΩìÊä•Èîô‰ø°ÊÅØ„ÄÇ\n&gt;   - 429ÔºöÂΩìÂâç IP ËØ∑Ê±Ç1Â∞èÊó∂ÂÜÖËØ∑Ê±ÇË∂ÖËøáÈôêÂà∂ÔºåËØ∑Á®çÂêéÂÜçËØïÔºåÊàñÊõ¥Êç¢ IP„ÄÇ\n&gt;   - 500ÔºöÊúçÂä°Âô®ÂÜÖÈÉ®ÈîôËØØÔºåËØ∑Ê±ÇÂ§±Ë¥•„ÄÇ\n&gt;   - 502ÔºöÊúçÂä°Âô®ÁΩëÂÖ≥ÈîôËØØÔºåÊàñÁΩëÁªú‰∏çÂèØÁî®ÔºåËØ∑Â∞ùËØïÊõ¥Êç¢ÁΩëÁªúÁéØÂ¢É„ÄÇ\n\n&gt; - Â∑≤Áü•ÊÉÖÂÜµÔºö\n&gt;   - Êó•Êú¨ IP ÂæàÂ§ö‰∏çÊîØÊåÅÂÖçÁôªÔºåÂÖçÁôª GPT-3.5 Âª∫ËÆÆ‰ΩøÁî®ÁæéÂõΩ IP„ÄÇ\n&gt;   - 99%ÁöÑË¥¶Âè∑ÈÉΩÊîØÊåÅÂÖçË¥π GPT-4o Ôºå‰ΩÜÊ†πÊçÆ IP Âú∞Âå∫ÂºÄÂêØÔºåÁõÆÂâçÊó•Êú¨ÂíåÊñ∞Âä†Âù° IP Â∑≤Áü•ÂºÄÂêØÊ¶ÇÁéáËæÉÂ§ß„ÄÇ\n\n&gt; - ÁéØÂ¢ÉÂèòÈáè AUTHORIZATION ÊòØ‰ªÄ‰πàÔºü\n&gt;   - ÊòØ‰∏Ä‰∏™Ëá™Â∑±Áªô chat2api ËÆæÁΩÆÁöÑ‰∏Ä‰∏™Ë∫´‰ªΩÈ™åËØÅÔºåËÆæÁΩÆÂêéÊâçÂèØ‰ΩøÁî®Â∑≤‰øùÂ≠òÁöÑ Tokens ËΩÆËØ¢ÔºåËØ∑Ê±ÇÊó∂ÂΩì‰Ωú APIKEY ‰º†ÂÖ•„ÄÇ\n&gt; - AccessToken Â¶Ç‰ΩïËé∑ÂèñÔºü\n&gt;   - chatgptÂÆòÁΩëÁôªÂΩïÂêéÔºåÂÜçÊâìÂºÄ https://chatgpt.com/api/auth/session Ëé∑Âèñ accessToken Ëøô‰∏™ÂÄº„ÄÇ\n&gt; - PLUS Ë¥¶Âè∑Êä•Èîô 403Ôºü\n&gt;   - PLUS Ë¥¶Âè∑ÈúÄË¶ÅÈÖçÁΩÆ ArkoseTokenÔºåËØ∑Ê†πÊçÆ‰∏äÊñáËøõË°åÈÖçÁΩÆ„ÄÇ\n&gt; - ArkoseToken ÊòØ‰ªÄ‰πàÔºåÊÄé‰πàËé∑ÂèñÔºü\n&gt;   - ËØ∑ÂèÇËÄÉ‰∏äÊñáÁöÑËØ¥ÊòéÔºåÊõ¥Â§öËØ∑ÂèÇËÄÉ https://www.arkoselabs.com/\n\nËµûÂä©ÂïÜ\n\nCapsolver\n\nLicense\n\nMIT License',
    name: "chat2api",
    category: "AI/ML",
    health: null,
    code: "Q9R9Rg",
    languages: ["Python", "HTML", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "701db69c-9aaa-4551-a4a6-9a54e552bc1d",
    isApproved: false,
    activeProjects: 41,
    projects: 99,
    description: "The most scalable open-source MQTT broker for IoT",
    readme:
      "Description\n\nThis Railway template sets up an EMQX MQTT broker with a Caddy reverse proxy. The EMQX broker is configured to handle MQTT connections over TCP on port 1883. The Caddy reverse proxy manages access to the EMQX admin dashboard and handles MQTT connections over WebSocket.\n\n!NOTE]\nAdmin password is randomly generated by default. See varialbe EMQX_DASHBOARD__DEFAULT_PASSWORD\n\nThis template deploys an open-source community edition of the EMQX broker.\n\nEMQX\n\nEMQX is a highly scalable, open-source MQTT broker designed to support large-scale IoT applications. It enables the exchange of messages between devices with minimal overhead, ensuring efficient and reliable communication.\n\nDefault Ports\n\nRailway doesn't allow to expose multiple ports, thus there is a Caddy reverse proxy to handle HTTP and WebSocket connections.\n\nEMQX listens the following ports by default\n\nTCP Port: 1883 (MQTT)\nWebSocket Port: 8083 (MQTT over WebSocket)\nSSL Port: 8883 (MQTT over TLS)\nSecure WebSocket Port: 8084 (MQTT over secure WebSocket)\nAdmin Dashboard Port: 18083 (EMQX admin UI)\n\nThis template exposes 1883 TCP port directly from emqx service.\n\n‚ú® Features\n\nRandom admin password generation.\nMQTT 5.0 Support: EMQX supports the MQTT 5.0 specification, offering features like shared subscriptions, enhanced security, message properties, and more.\nHigh Performance: EMQX is designed for high performance and low latency, suitable for applications that require real-time communication.\nScalability: EMQX can be easily scaled horizontally to handle a large number of concurrent connections and messages.\nReliability: Ensures message delivery even in unreliable network conditions. Persistent sessions and durable message storage mechanisms prevent message loss.\nSecurity: Comprehensive security features, including TLS/SSL encryption, client authentication, access control, and integration with external authentication mechanisms.\nWebSockets: Supports MQTT over WebSockets, allowing devices and applications to communicate over HTTP/HTTPS ports.\nAdvanced Clustering: Enables setting up multiple instances that work together to provide high availability and fault tolerance.\nSession Management: Provides flexible session management options, including session expiration, resumption, and storage.\nRetained Messages: Stores the last known state of a topic, ensuring that new subscribers immediately receive the latest data.\nQoS (Quality of Service): Supports MQTT's QoS levels, ensuring that messages are delivered as required by the application's quality-of-service requirements.\n\nüíÅ‚Äç‚ôÄÔ∏è Services\n\nEMQX\nCaddy Reverse Proxy\n\nüõ†  How to use\n\nClick the Railway button üëÜ\nAdd the required environment variables\nDeploy\nOpen the deployment URL in a browser. Check EMQX_DASHBOARD__DEFAULT_PASSWORD variable for the password for admin user, if you didn't set it manually.\nTry [MQTTX web client to connect to deployed server\n\nEnvironment Variables for EMQX Service\n\nWS_PORT=8083: MQTT over WebSocket port.\nSSL_PORT=8883: MQTT over TLS port.\nTCP_PORT=1883: MQTT TCP port.\nWSS_PORT=8084: MQTT over secure WebSocket port.\nADMIN_PORT=18083: Dashboard port.\nEMQX_NODE__COOKIE=${{ secret(64) }}: Cookie secret for node communication.\nEMQX_DASHBOARD__DEFAULT_PASSWORD=${{ secret(18) }}: Admin password for the EMQX dashboard.\n\nEnvironment Variables for Caddy Service\n\nMQTT_SERVICE=${{emqx.RAILWAY_PRIVATE_DOMAIN}}: Name of the service/container with EMQX.\nMQTT_WS_PORT=${{emqx.WS_PORT}}: Port of the MQTT over WebSocket listener.\nMQTT_ADMIN_PORT=${{emqx.ADMIN_PORT}}: Port of the EMQX admin UI listener.\n\nüìù Notes\n\nEMQX repo: https://github.com/emqx/emqx-docker\nDocs: https://docs.emqx.com/en/\nCaddy image: https://github.com/maximofftech/railway-emqx",
    name: "EMQX",
    category: "Queues",
    health: 100,
    code: "KOG0Z4",
    languages: ["Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "37de5dbb-e44a-4816-b382-65623b3c7835",
    isApproved: false,
    activeProjects: 43,
    projects: 51,
    description: "A Whatsapp Multi Device Bot",
    readme:
      "TurboMods has developed an innovative WhatsApp Multi-Device Bot designed to enhance your WhatsApp experience. This bot boasts over 100 features, making it incredibly versatile and useful for a variety of tasks. \n\nOne of the standout features is its ability to streamline and simplify your WhatsApp usage, ensuring a smoother and more efficient experience. Whether you are managing multiple groups or engaging in fun activities, this bot has got you covered. It offers comprehensive group management tools, allowing you to seamlessly handle group chats, add or remove members, and maintain order with ease. \n\nFor those looking for entertainment, the bot includes numerous fun features that can keep you and your contacts engaged. From interactive games to interesting quizzes, there's always something to enjoy. Additionally, it offers powerful downloading capabilities, enabling you to easily download videos, images, and other media directly from your chats or links. \n\nThe conversion tools are another highlight, providing quick and easy ways to convert various types of files. Whether you need to convert audio formats, document types, or even images, this bot can handle it all effortlessly. \n\nOverall, the WhatsApp Multi-Device Bot by TurboMods is a comprehensive tool that significantly enhances the functionality of WhatsApp. Its multitude of features ensures that users can enjoy a more organized, fun, and efficient messaging experience. Whether you are looking to manage groups, have fun with friends, or download and convert files, this bot is the perfect solution.",
    name: "Toxic-Alexa",
    category: "Bots",
    health: 100,
    code: "T2aOGe",
    languages: ["JavaScript", "HTML", "Nix", "Dockerfile", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "248cfa2e-a788-4853-a16f-7263cf559b8f",
    isApproved: false,
    activeProjects: 43,
    projects: 51,
    description: "CORS Anywhere is a NodeJS reverse proxy.",
    readme:
      "Build Status\nCoverage Status\n\nCORS Anywhere is a NodeJS proxy which adds CORS headers to the proxied request.\n\nThe url to proxy is literally taken from the path, validated and proxied. The protocol\npart of the proxied URI is optional, and defaults to \"http\". If port 443 is specified,\nthe protocol defaults to \"https\".\n\nThis package does not put any restrictions on the http methods or headers, except for\ncookies. Requesting user credentials is disallowed.\nThe app can be configured to require a header for proxying a request, for example to avoid\na direct visit from the browser.\n\nExample\n\n// Listen on a specific host via the HOST environment variable\nvar host = process.env.HOST || '0.0.0.0';\n// Listen on a specific port via the PORT environment variable\nvar port = process.env.PORT || 8080;\n\nvar cors_proxy = require('cors-anywhere');\ncors_proxy.createServer({\n    originWhitelist: ], // Allow all origins\n    requireHeader: ['origin', 'x-requested-with'],\n    removeHeaders: ['cookie', 'cookie2']\n}).listen(port, host, function() {\n    console.log('Running CORS Anywhere on ' + host + ':' + port);\n});\nRequest examples:\n\nhttp://localhost:8080/http://google.com/ - Google.com with CORS headers\nhttp://localhost:8080/google.com - Same as previous.\nhttp://localhost:8080/google.com:443 - Proxies https://google.com/\nhttp://localhost:8080/ - Shows usage text, as defined in lib/help.txt\nhttp://localhost:8080/favicon.ico - Replies 404 Not found\n\nLive examples:\n\nhttps://cors-anywhere.herokuapp.com/\nhttps://robwu.nl/cors-anywhere.html - This demo shows how to use the API.\n\nDocumentation\n\nClient\n\nTo use the API, just prefix the URL with the API URL. Take a look at [demo.html for an example.\nA concise summary of the documentation is provided at lib/help.txt.\n\nNote: as of February 2021, access to the demo server requires an opt-in,\nsee: https://github.com/Rob--W/cors-anywhere/issues/301\n\nIf you want to automatically enable cross-domain requests when needed, use the following snippet:\n\n(function() {\n    var cors_api_host = 'cors-anywhere.herokuapp.com';\n    var cors_api_url = 'https://' + cors_api_host + '/';\n    var slice = ].slice;\n    var origin = window.location.protocol + '//' + window.location.host;\n    var open = XMLHttpRequest.prototype.open;\n    XMLHttpRequest.prototype.open = function() {\n        var args = slice.call(arguments);\n        var targetOrigin = /^https?:\\/\\/(+)/i.exec(args[1]);\n        if (targetOrigin &amp;&amp; targetOrigin[0].toLowerCase() !== origin &amp;&amp;\n            targetOrigin[1] !== cors_api_host) {\n            args[1] = cors_api_url + args[1];\n        }\n        return open.apply(this, args);\n    };\n})();\n\nIf you're using jQuery, you can also use the following code instead of the previous one:\n\njQuery.ajaxPrefilter(function(options) {\n    if (options.crossDomain &amp;&amp; jQuery.support.cors) {\n        options.url = 'https://cors-anywhere.herokuapp.com/' + options.url;\n    }\n});\n\nServer\n\nThe module exports createServer(options), which creates a server that handles\nproxy requests. The following options are supported:\n\nfunction getProxyForUrl - If set, specifies which intermediate proxy to use for a given URL.\n  If the return value is void, a direct request is sent. The default implementation is\n  [proxy-from-env, which respects the standard proxy\n  environment variables (e.g. https_proxy, no_proxy, etc.).  \narray of strings originBlacklist - If set, requests whose origin is listed are blocked.  \n  Example: 'https://bad.example.com', 'http://bad.example.com']\narray of strings originWhitelist - If set, requests whose origin is not listed are blocked.  \n  If this list is empty, all origins are allowed.\n  Example: ['https://good.example.com', 'http://good.example.com']\nfunction handleInitialRequest - If set, it is called with the request, response and a parsed\n  URL of the requested destination (null if unavailable). If the function returns true, the request\n  will not be handled further. Then the function is responsible for handling the request.\n  This feature can be used to passively monitor requests, for example for logging (return false).\nfunction checkRateLimit - If set, it is called with the origin (string) of the request. If this\n  function returns a non-empty string, the request is rejected and the string is send to the client.\nboolean redirectSameOrigin - If true, requests to URLs from the same origin will not be proxied but redirected.\n  The primary purpose for this option is to save server resources by delegating the request to the client\n  (since same-origin requests should always succeed, even without proxying).\narray of strings requireHeader - If set, the request must include this header or the API will refuse to proxy.  \n  Recommended if you want to prevent users from using the proxy for normal browsing.  \n  Example: ['Origin', 'X-Requested-With'].\narray of lowercase strings removeHeaders - Exclude certain headers from being included in the request.  \n  Example: [\"cookie\"]\ndictionary of lowercase strings setHeaders - Set headers for the request (overwrites existing ones).  \n  Example: {\"x-powered-by\": \"CORS Anywhere\"}\nnumber corsMaxAge - If set, an Access-Control-Max-Age request header with this value (in seconds) will be added.  \n  Example: 600 - Allow CORS preflight request to be cached by the browser for 10 minutes.\nstring helpFile - Set the help file (shown at the homepage).  \n  Example: \"myCustomHelpText.txt\"\n\nFor advanced users, the following options are also provided.\n\nhttpProxyOptions - Under the hood, [http-proxy\n  is used to proxy requests. Use this option if you really need to pass options\n  to http-proxy. The documentation for these options can be found here.\nhttpsOptions - If set, a https.Server will be created. The given options are passed to the\n  https.createServer method.\n\nFor even more advanced usage (building upon CORS Anywhere),\nsee the sample code in test/test-examples.js.\n\nDemo server\n\nA public demo of CORS Anywhere is available at https://cors-anywhere.herokuapp.com. This server is\nonly provided so that you can easily and quickly try out CORS Anywhere. To ensure that the service\nstays available to everyone, the number of requests per period is limited, except for requests from\nsome explicitly whitelisted origins.\n\nNote: as of February 2021, access to the demo server requires an opt-in,\nsee: https://github.com/Rob--W/cors-anywhere/issues/301\n\nIf you expect lots of traffic, please host your own instance of CORS Anywhere, and make sure that\nthe CORS Anywhere server only whitelists your site to prevent others from using your instance of\nCORS Anywhere as an open proxy.\n\nFor instance, to run a CORS Anywhere server that accepts any request from some example.com sites on\nport 8080, use:\nexport PORT=8080\nexport CORSANYWHERE_WHITELIST=https://example.com,http://example.com,http://example.com:8080\nnode server.js\n\nThis application can immediately be run on Heroku, see https://devcenter.heroku.com/articles/nodejs\nfor instructions. Note that their Acceptable Use Policy forbids\nthe use of Heroku for operating an open proxy, so make sure that you either enforce a whitelist as\nshown above, or severly rate-limit the number of requests.\n\nFor example, to blacklist abuse.example.com and rate-limit everything to 50 requests per 3 minutes,\nexcept for my.example.com and my2.example.com (which may be unlimited), use:\n\nexport PORT=8080\nexport CORSANYWHERE_BLACKLIST=https://abuse.example.com,http://abuse.example.com\nexport CORSANYWHERE_RATELIMIT='50 3 my.example.com my2.example.com'\nnode server.js\n\nLicense\n\nCopyright (C) 2013 - 2021 Rob Wu \n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \"Software\"), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\nof the Software, and to permit persons to whom the Software is furnished to do\nso, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.",
    name: "cors-anywhere",
    category: "Other",
    health: 100,
    code: "7Q2KsC",
    languages: ["JavaScript", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7ca04102-12af-465b-874f-31e3c9522766",
    isApproved: false,
    activeProjects: 2,
    projects: 6,
    description: "Open Source Image CDN that provides image transformation API",
    readme:
      "TransformImgs\n\nSource Github repository: https://github.com/Pixboost/transformimgs\n\nGo Reference\nGo Report Card\nBuild Status\ncodecov\nDocker Pulls\nDocker Automated build\n\nOpen Source Image CDN that provides image transformation API and supports \nthe latest image formats, such as WebP, AVIF, Jpeg XL, and network client hints. \n\nTable of Contents\n\n\nWhy?\nFeatures\nQuickstart\nAPI\nRunning\n  Docker\n  Options\n  Running Locally From Source Code\n  Using from Go Web Application\nSaaS\nPerformance tests\nOpened tickets for images related features\nContribute\nLicense\nTodo\n\nWhy?\n\nWe wrote a big blog on this, and here is TLDR:\n\nTransformimgs is an image CDN for Web, so API must cover typical use cases, like\nthumbnails, zoom in product images, etc. Any new API endpoints must \nsolve the above problems.\n\nThe goal is to have zero-config API that makes decisions based on the input, so you don't need to provide additional parameters like quality, output format, type of compression, etc.\n\nTherefore, this allows you to configure the integration once. New features, like new image formats, will work\nwith your front end automatically without any changes.\n\nTo achieve that goal we should keep API to bare minimum and hide the smartness in the implementation. \n\nFeatures\n\nResize/optimises/crops raster (PNG and JPEG) images.\nJpegXL / AVIF / WebP support based on \"Accept\" header.\nVary header support - ready to deploy behind any CDN.\nResponsive images support including high DPI (retina) displays \nSave-Data support\n\nQuickstart\n\nThere is an example of running API behind reverse proxy with integration example in quickstart/ folder.\n\nTo run:\n\ncd quickstart\ndocker-compose up\nopen https://localhost\n\nAPI\n\nThe API has 4 HTTP endpoints:\n\n/img/{IMG_URL}/optimise - optimises image\n/img/{IMG_URL}/resize - resizes image\n/img/{IMG_URL}/fit - resize image to the exact size by resizing and cropping it\n/img/{IMG_URL}/asis - returns original image\n\nDocs:\nSwagger-UI - use API key MjUyMTM3OTQyNw__ which allows to transform any image from unsplash.com\nOpenAPI spec\n\nRunning Locally\n\nDocker\n\nThe latest docker image published on Docker hub\n\nStarting the server:\n\n$ docker run -p 8080:8080 pixboost/transformimgs OPTIONS]\n\nTo verify:\n\nHealth check: curl http://localhost:8080/health\nTransformation: open http://localhost:8080/img/https://images.unsplash.com/photo-1591769225440-811ad7d6eab3/resize?size=600\n\nOptions\n\nEverything below is optional and have sensible defaults.\n\n| Option | Description | Default |\n|--------|-------------| ------- |\n| cache  | Number of seconds to cache image(0 to disable cache). Used in max-age HTTP response. | 2592000 (30 days) |\n| proc   | Number of images processors to run. | Number of CPUs (cores) |\n| disableSaveData | If set to true then will disable Save-Data client hint. Should be disabled on CDNs that don't support Save-Data header in Vary. | false |\n\nRunning from source code\n\nPrerequisites:\n\nGo 1.18+ with [modules support\nInstalled imagemagick v7.0.25+ with AVIF support in /usr/local/bin\n\n$ git clone git@github.com:Pixboost/transformimgs.git\n$ cd transformimgs\n$ ./run.sh\n\nUsing from Go Web Application\n\nYou could also easily plugin HTTP route into your existing web application \nusing service.GetRouter method. Here is a quick example of how to do that. \n\nSaaS\n\nWe run SaaS version at pixboost.com with generous free tier.\n\nPerks of SaaS version:\nCDN with HTTP/3 support included\nDashboard with usage monitor\nAPI Key support with domains allow list\nAWS S3 integration\nAPI workflows for cache busting and warmup\nVersion upgrades\n\nGo modules have been introduced in v6.\n\nPerformance tests\n\nThere is a JMeter performance test you can run against a service. To run tests:\n\nStart a performance test environment:\n$ docker-compose -f docker-compose-perf.yml up\nRun JMeter tests:\n$ jmeter -n -t perf-test.jmx -l ./results.jmx -e -o ./results\n\nRun JMeter WebP test:\n$ jmeter -n -t perf-test-webp.jmx -l ./results-webp.jmx -e -o ./results-webp\n\nRun JMeter AVIF test:\n$ jmeter -n -t perf-test-avif.jmx -l ./results-avif.jmx -e -o ./results-avif\n\nRun JMeter JPEG XL test:\n$ jmeter -n -t perf-test-jxl.jmx -l ./results-jxl.jmx -e -o ./results-jxl\n\nOpened tickets for images related features\n\nSafari to support Save-Data\nAuto sizes for lazy loaded img in Firefox\nAuto sizes for lazy loaded img in Safari\n\nContribute\n\nShout out with any ideas. PRs are more than welcome.\n\nLicense\n\nYou can check out the MIT here\n\n",
    name: "transformimgs",
    category: "Automation",
    health: 100,
    code: "a_Rgxz",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "09f768a1-c2ab-45e0-b02e-5c87a8f88473",
    isApproved: false,
    activeProjects: 2,
    projects: 3,
    description: "Infinitely transfer between devices over pure HTTP with pipes or browsers",
    readme:
      "Piping Server\n\nInfinitely transfer between every device over HTTP/HTTPS\n\nExample usage can be found here.\n\nPiping Server transfers data to POST /hello or PUT /hello into GET /hello. The path /hello can be anything such as /mypath or /mypath/123/. A sender and receivers who specify the same path can transfer. Both the sender and the recipient can start the transfer first. The first one waits for the other. \n\nStream\nThe most important thing is that the data are streamed. This means that you can transfer any data infinitely. \n\nIdeas\nPiping Server is designed based on the ideas as follows.\n\nInfinite transfer: You can transfer any kind of data infinitely on a stream. Streams are very efficient in terms of both time and space.\nZero installation: All you need is to have either a Web browser or curl, which are widely pre-installed. You do not need to install any extra software.\nSimpleness: Making simple makes it more secure.\nStorageless: The server makes transfer more secure since the server never stores your data.\nPurity: The server streams over pure HTTP, which makes integration easier with other softwares.\nEngineer friendly: Also designed for Unix/Linux users, who use pipes, not only for Web browser users.",
    name: "Piping server",
    category: "Other",
    health: 100,
    code: "zLz276",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1d649cc8-3278-4338-a2b0-db010bbcde66",
    isApproved: false,
    activeProjects: 11,
    projects: 50,
    description: "Setup for Kong Gateway with PostgreSQL and Konga UI management.",
    readme:
      "Overview\n\nThis setup provides a full environment for running Kong Gateway, a powerful and flexible API management solution, alongside PostgreSQL for database storage and Konga UI for a user-friendly web interface to manage Kong.\n\nServices Description\n\n1. kong-database\nImage: postgres:latest\nDescription: This service runs a PostgreSQL database that stores Kong Gateway's configuration and runtime data.\nEnvironment Variables: \n  POSTGRES_USER: User for PostgreSQL (default: kong)\n  POSTGRES_DB: Database name for PostgreSQL (default: kong)\n  POSTGRES_PASSWORD: Password for PostgreSQL (default: kong)\nPorts: Exposes port 5432\nVolumes: Uses a named volume kong-data to persist data\nHealth Check: Ensures PostgreSQL is ready before other services start\n\n2. kong-migration\nImage: kong:latest\nDescription: A temporary service that initializes the database by running Kong migrations.\nEnvironment Variables: \n  KONG_DATABASE: Database type (postgres)\n  KONG_PG_HOST: Host of PostgreSQL service (kong-database)\n  KONG_PG_USER: User for PostgreSQL (same as POSTGRES_USER)\n  KONG_PG_PASSWORD: Password for PostgreSQL (same as POSTGRES_PASSWORD)\nCommand: Runs kong migrations bootstrap to set up the database schema\nDepends On: Waits for kong-database to be healthy before starting\n\n3. kong\nImage: kong:latest\nDescription: The main Kong Gateway service that manages and routes APIs.\nEnvironment Variables: \n  Various configurations for logging, admin API listening, and database connection\n  KONG_DATABASE: Database type (postgres)\n  KONG_PG_HOST: Host of PostgreSQL service (kong-database)\n  KONG_PG_USER: User for PostgreSQL (same as POSTGRES_USER)\n  KONG_PG_PASSWORD: Password for PostgreSQL (same as POSTGRES_PASSWORD)\nPorts: Exposes ports 8000, 8443, 8001, and 8444 for proxy and admin API\nHealth Check: Ensures the Kong service is operational\n\n4. konga\nImage: pantsel/konga:latest\nDescription: Konga provides a web interface to manage Kong Gateway.\nEnvironment Variables: \n  Configuration for connecting to the PostgreSQL database\n  DB_ADAPTER: Database adapter (postgres)\n  DB_HOST: Host of PostgreSQL service (kong-database)\n  DB_USER: User for PostgreSQL (same as POSTGRES_USER)\n  DB_PASSWORD: Password for PostgreSQL (same as POSTGRES_PASSWORD)\n  DB_DATABASE: Database name (same as POSTGRES_DB)\n  NODE_ENV: Environment mode (production)\nPorts: Exposes port 1337 for accessing the Konga UI\nHealth Check: Ensures the Konga service is operational\n\nGetting Started\n\nClone the Repository: Download the project to your local machine.\nCreate a .env File: Add the following environment variables in a .env file:\n   POSTGRES_USER=kong\n   POSTGRES_DB=kong\n   POSTGRES_PASSWORD=kong\nStart the Services: Use the command docker-compose up -d to start all services.\n\nAccess Points\n\nKong Admin API: Available at http://localhost:8001 and https://localhost:8444\nKonga UI: Available at http://localhost:1337\n\nVolumes\n\nkong-data: This named volume persists PostgreSQL data to ensure it survives container restarts.\n\nHealth Checks\n\nEach service is equipped with health checks to verify their operational status and facilitate automatic recovery.\n\nThis setup ensures a robust and easy-to-manage environment for API management using Kong, with PostgreSQL for data storage and Konga UI for streamlined administration.",
    name: "Kong API Gateway",
    category: "Other",
    health: 70,
    code: "Addl8t",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d3b2ee5c-0580-4db3-bba7-2e2117e32bd6",
    isApproved: false,
    activeProjects: 1,
    projects: 5,
    description: "A Jenkins automation agent.",
    readme:
      "Jenkins\n\nBuild great things at any scale\n\nThe leading open source automation server, Jenkins provides hundreds of plugins to support building, deploying and automating any project.\n\nAgent Setup\n\nJenkins Node Setup\n\nFollow these steps to create a node in your Jenkins instance.\n\nSetup the agent on Jenkins\nGo to your Jenkins dashboard\nGo to Manage Jenkins option in main menu\nGo to Nodes item in System Configuration\nGo to New Node option in side menu\nFill the Node(agent) name and select the type; (e.g. Name: agent1, Type: Permanent Agent)\nNow fill the fields like remote root directory, labels, # of executors, etc.\n    root directory should be set to /home/jenkins/agent\n    Launch method should be set to Launch agent by connecting it to the controller\nPress the Save button and the agent1 will be registered, but offline for the time being. Click on it.\nYou should now see the secret used for the configuration of the template.\n\nTemplate configuration\nSet the JENKINS_AGENT_NAME environment variable to the agent name you selected above.\nSet the JENKINS_SECRET  environment variable to the secret generated above.\nSet the JENKINS_URL environment variable to the url of your Jenkins instance. If using the Jenkins Template, it should be set to http://${{Jenkins.JENKINS_PRIVATE_URL}}:${{Jenkins.JENKINS_PRIVATE_PORT}}\n\nYour agent should now be setup.\n",
    name: "Jenkins Agent",
    category: "Automation",
    health: 100,
    code: "id4SxN",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a8b9f8a3-43cb-43c4-9f39-8eeb44c8deef",
    isApproved: false,
    activeProjects: 20,
    projects: 44,
    description: "The leading open source automation server.",
    readme:
      "Jenkins\n\nBuild great things at any scale\n\nThe leading open source automation server, Jenkins provides hundreds of plugins to support building, deploying and automating any project.\n\nSetup\n\nDeploy this template and wait for it to become healthy.\nFollow the post-install instructions defined here or\n    Copy the admin password printed in the container logs\n    Goto the Jenkins site by clicking the HTTP URL defined in the settings.\n    Paste admin password and create your account\n\nAdding more agents\n\nTo add more agents, use the Jenkins Agent template and follow the instructions defined there.",
    name: "Jenkins",
    category: "Automation",
    health: 50,
    code: "NwM5O-",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "79da45d5-10e5-49b8-8bcb-2566b147e0c4",
    isApproved: false,
    activeProjects: 15,
    projects: 40,
    description: "Open Source email platform. Sendgrid, Resend alternative",
    readme:
      'Prerequisites\n\nA Github account\nAn AWS account\n\nIf you have any questions join #self-host on discord.\n\nStep 1: Environment variables\n\nUnsend depends on AWS ses to send emails and SNS to receive email status. Along with that it also depends on Postgres as a database and Redis for queue. Copy the .env.selfhost.example file to .env and fill in the values.\n\nAWS credentials\n  tl;dr: Login to your AWS console and create a new user with programmatic access. Attach the AmazonSNSFullAccess and AmazonSESFullAccess policies to the user. Then create a new access key for the user.\n\nAdd the following environment variables.\n\n    AWS_ACCESS_KEY_ID=\n    AWS_SECRET_ACCESS_KEY=\n\n  Follow this for detailed steps: Create AWS\n  credentials\n\nGithub app credentials for login\n  Usend uses github authentication for login.\n\nUse this link to create an github app\n\nCallback URL : https:///api/auth/callback/github\n\n\nAdd the following environment variables.\n\nGITHUB_ID=""\nGITHUB_SECRET=""\n\nNext auth url and secret\n  Url is the app url you\'re going to use/\n\nAdd the following environment variables.\n\nNEXTAUTH_SECRET=""\n\nStep 3: Setting up a region\n\nIn order to send emails, you need to select an region in aws. Use a region where your users are located / where unsend is hosted. If you\'re confused just use us-east-1.\n\nYou can check available regions here\n\nOnce you logged in to unsend, it will prompt you add ses configuration\n',
    name: "unsend",
    category: "Other",
    health: 100,
    code: "QbMnwX",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9fe82382-ce5c-4510-b4a4-778c6eacc648",
    isApproved: false,
    activeProjects: 12,
    projects: 33,
    description: "Open source continuous file synchronization",
    readme:
      "Security\n\nBy default, Syncthing is set up to allow connections to its interface from anywhere using a public address (0.0.0.0:8384). This means anyone could potentially access it unless you protect it. To keep your Syncthing instance secure, you should set up a username and password for the web interface. To do this, open Syncthing, go to Actions ‚Üí Settings ‚Üí GUI, and set a username and password under Authentication User and Authentication Password.",
    name: "Syncthing",
    category: "Storage",
    health: 100,
    code: "HfZZpH",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7b16718e-16ca-4dfb-8f57-043440c89eb1",
    isApproved: false,
    activeProjects: 8,
    projects: 24,
    description: "Effortlessly deploy a status page and start monitoring endpoints in minutes",
    readme:
      "Logo\n\nEffortlessly deploy a status page and start monitoring endpoints in minutes\n\nhttps://statusnook.com\n\nhttps://github.com/goksan/statusnook\n\n\nStatus page\n\nMonitors\n\nNotifications",
    name: "Statusnook",
    category: "Observability",
    health: 100,
    code: "VkhOWC",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2f41cb4f-12f4-4896-bfb0-5842ec0947ba",
    isApproved: false,
    activeProjects: 1,
    projects: 3,
    description: "Postgres for search and analytics",
    readme:
      "ParadeDB is an Elasticsearch alternative built on Postgres. We‚Äôre modernizing the features of Elasticsearch, starting with real-time search and analytics.\n\nParadeDB is not a fork of Postgres, but regular Postgres with custom extensions installed. ParadeDB itself ships with Postgres 16.",
    name: "paradedb",
    category: "Other",
    health: null,
    code: "FFIUl4",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d340f34c-084f-4136-ac5a-2917b4490a9a",
    isApproved: false,
    activeProjects: 0,
    projects: 5,
    description: "rust gRPC + Postgres + backups",
    readme:
      "rust-grpc-quickstart-template\n\nCLIs\n\nBuf\n\nhttps://buf.build/docs/installation\n\ncargo install protoc-gen-prost-crate\n\nGeneration\n\nmake protos\nor\nbuf generate",
    name: "rust-ms-template",
    category: "Other",
    health: null,
    code: "7fGUFg",
    languages: ["Rust", "Dockerfile", "PLpgSQL", "Makefile", "Python", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5593a0c0-5ae0-4534-aff6-743fa80c726d",
    isApproved: false,
    activeProjects: 6,
    projects: 24,
    description: "A sensible modern set of defaults for a Next.js app with Supabase (+ auth!)",
    readme:
      "Next.js + tRPC + Prisma + Supabase = Profit!\n\nThis is a project template that sets you up with all of the basics required to build an interesting full stack app. It combines these frameworks into a setup that should empower you to build with sensible defaults.\n\nIt is based on the T3 Stack, bootstrapped with create-t3-app, and then hand-tuned by Bob Ambrose.\n\nThings that this template comes with\n\nNext.js App Router\nPostgres database\nAuth\nType-safe API\nUI library in ShadCN/UI\n\nThis is everything you need to start building an advanced app.\n\nTo be very clear ‚Äî you get a login page automatically with this template!!\n\nQuick Start\n\nIf you're familiar with these systems, here's your guide to getting going. The short of it is that you need an account with Supabase, and the rest will take care of itself. See .env.example to know what to add; you'll add this to your .env file. See the Supabase Docs for what specifically to do\n\nOnce you do this, you can start the development server with npm run dev and visit localhost:3000 to get started.\n\nOverview\n\nI can't possibly explain the systems better than they explain themselves, but if you're new to any of this tech, I'll do my best to explain the overall picture. But first, some links to each of the projects involved here.\n\nNext.js\nSupabase\nPrisma\ntRPC with TanStack Query\nTailwind CSS with ShadCN UI\n\nGenerally speaking, here's how things click together:\n\nNext.js at its core. This is the web server framework that will return a React app.\ntRPC as the server API. It provides type safety end-to-end at its core. We use this as the main way to talk to the database to make sure we get authorized queries.\n  Note: this template does not take full advantage of Supabase's RLS (row-level security) as an auth strategy. It instead creates\nSupabase as the auth, database, and storage provider.\n\nThis template doesn't enforce an opinion on data fetching strategies, but you do have basically two options\n\nUse the TanStack query hooks from the trpc component to fetch data in the React Lifecycle. This is the pre- React Server Components way to fetch data.\nUse the trpc client to fetch data in React Server Components. You can take full advantage of Suspense and have the first response from the server return interesting HTML.\n\nThere is lengthy debate on what the right approach will be for each use case. I encourage you to think critically about what one is best for you. If you're not sure, try starting with the TanStack query option and try pre-fetching queries in the server component for the page.\n\nYou can see examples in prefetch/page.tsx, server-only-fetch/page.tsx, and client-only-fetch/page.tsx. It's also worth noting that you can pre-fetch data in the initial SSR render of client components too, but I digress.\n",
    name: "Next.js + Supabase (Prisma + tRPC)",
    category: "Starters",
    health: 25,
    code: "wj1mcU",
    languages: ["TypeScript", "JavaScript", "CSS", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e1ab3d10-f10d-453d-b17b-f3970e72643e",
    isApproved: false,
    activeProjects: 12,
    projects: 13,
    description: "Discord.js. 24/7. Connect BuildShip / Fastgen / serverless backend.",
    readme:
      'Watch YouTube Walkthrough\n\n")\n\nDrag and drop 24/7 Discord bots (Discord.js) integrated with low-code / no-code backend tools like Buildship, FastGen, Xano or 3rd party serverless endpoints.\n\nHosted on Railway a 24/7 low-code / no-code instant deployment platform.\n\nUsing BuildShip.com you can generate custom code as nodes then drag and drop the custom functionality.\n\nCustomize the Discord bot gateway intents as Railway variables.\n\nMore detailed instructions: https://github.com/matthewlal/discord.js-bot-nocode/',
    name: "Discord Bot - No code / Low code",
    category: "Bots",
    health: 0,
    code: "xyquaG",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d071d59e-2574-4113-9a57-a0589a681860",
    isApproved: false,
    activeProjects: 24,
    projects: 78,
    description: "Data Visualization and Data Exploration | Looker, Tableau alternative",
    readme:
      "Why Superset?\n\nSuperset is a modern data exploration and data visualization platform. Superset can replace or augment proprietary business intelligence tools for many teams. Superset integrates well with a variety of data sources.\n\nSuperset provides:\n\nA no-code interface for building charts quickly\nA powerful, web-based SQL Editor for advanced querying\nA lightweight semantic layer for quickly defining custom dimensions and metrics\nOut of the box support for nearly any SQL database or data engine\nA wide array of beautiful visualizations to showcase your data, ranging from simple bar charts to geospatial visualizations\nLightweight, configurable caching layer to help ease database load\nHighly extensible security roles and authentication options\nAn API for programmatic customization\nA cloud-native architecture designed from the ground up for scale\n\nDeployment Instructions\n\nCreate a new project using the template\nPopulate the environment variables. For SECRET_KEY, use openssl rand -base64 42 to generate a secure SECRET_KEY\nWait for deployment to complete and voila!",
    name: "Apache Superset",
    category: "Analytics",
    health: 92,
    code: "S7TBaH",
    languages: ["Dockerfile", "Shell", "Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6066013c-6181-43f4-b975-aea4981139c2",
    isApproved: false,
    activeProjects: 3,
    projects: 8,
    description: "3.13.3-management - RabbitMQ - UI",
    readme:
      "Family Circle API - Social Networking Application\n\nDescription\n\nThis is a Java project using Spring Boot and Maven. It's a social networking application that includes features such as register users, create post, comment, react, share, follow, evaluate physical condition for mommy and baby, and so on. The application also includes security configurations and logging.\n\nGetting Started\n\nPrerequisites\n\nJava 11 or higher\nMaven\nMySQL\nRabbitMQ\nAmazon S3 bucket\n\nInstallation\n\nClone the repository\nNavigate to the project directory - cd source/social-networking\nSet up the environment variables essentially for the database connection, RabbitMQ connection, Email SMTP connection, JWT secret key, Amazon S3 bucket, and AWS credentials.\nRun mvn clean install to build the project\n\nUsage\n\nRun the project using the command mvn spring-boot:run. The application will start and you can interact with it through the exposed endpoints.\n\nLogging\n\nThe application uses Log4j2 for logging. The configuration is located in log4j2.xml. Logs are written to the console and also to a file in the logs directory.\n\nContributing\n\nPull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.\n\nContact\n\nNguy·ªÖn Hu·ª≥nh Thanh To√†n - Email: toannguyenit239@gmail.com\n\nProject Link: https://github.com/zakushi2002/social-networking-api\n\nFront-end Project Link: https://github.com/KhanhTran297/FamilyCircle\n\nLink to app interface design: https://www.figma.com/design/iXu1duPqYVoDj3Ve14eyI5/FamilyCircle?node-id=12-1668&t=f2zV18x7n4BPW3Lp-1\n\nPlease replace the placeholders with the actual values.\n",
    name: "RabbitMQ-Family-Circle",
    category: "Other",
    health: null,
    code: "ska4rn",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "eaebef5e-0968-4edd-ac41-609168f1cf27",
    isApproved: false,
    activeProjects: 2,
    projects: 2,
    description: "Spring Boot 2.3.0.RELEASE + MySQL",
    readme:
      "Family Circle API - Social Networking Application\n\nDescription\n\nThis is a Java project using Spring Boot and Maven. It's a social networking application that includes features such as register users, create post, comment, react, share, follow, evaluate physical condition for mommy and baby, and so on. The application also includes security configurations and logging.\n\nGetting Started\n\nPrerequisites\n\nJava 11 or higher\nMaven\nMySQL\nRabbitMQ\nAmazon S3 bucket\n\nInstallation\n\nClone the repository\nNavigate to the project directory - cd source/social-networking\nSet up the environment variables essentially for the database connection, RabbitMQ connection, Email SMTP connection, JWT secret key, Amazon S3 bucket, and AWS credentials.\nRun mvn clean install to build the project\n\nUsage\n\nRun the project using the command mvn spring-boot:run. The application will start and you can interact with it through the exposed endpoints.\n\nLogging\n\nThe application uses Log4j2 for logging. The configuration is located in log4j2.xml. Logs are written to the console and also to a file in the logs directory.\n\nContributing\n\nPull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.\n\nContact\n\nNguy·ªÖn Hu·ª≥nh Thanh To√†n - Email: toannguyenit239@gmail.com\n\nProject Link: https://github.com/zakushi2002/social-networking-api\n\nFront-end Project Link: https://github.com/KhanhTran297/FamilyCircle\n\nLink to app interface design: https://www.figma.com/design/iXu1duPqYVoDj3Ve14eyI5/FamilyCircle?node-id=12-1668&t=f2zV18x7n4BPW3Lp-1\n\nPlease replace the placeholders with the actual values.\n",
    name: "Family Circle",
    category: "Other",
    health: null,
    code: "VPihOQ",
    languages: ["Java", "HTML", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "81db442e-fced-4098-8dae-5d65bfc95bcd",
    isApproved: false,
    activeProjects: 3,
    projects: 19,
    description: "United! Free and open membership software for collective organizations",
    readme:
      "United is free and open membership software for collective organizations, allowing robust tracking of membership, expirations, email broadcast tools, providing single-sign-on for your members, and more.\n\nThe source code is licensed under the AGPL (v3.0 or later) and can be found at https://codeberg.org/reesericci/united.\n\nMore info can be found at https://united.obl.ong",
    name: "United!",
    category: "Other",
    health: 100,
    code: "eqEBYm",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3e12c4ae-8b02-43cb-82e7-0cbc725cac19",
    isApproved: false,
    activeProjects: 1,
    projects: 4,
    description: "Pocketbase with Litestream Streaming Replication",
    readme:
      "Pocketbase\n\nOpen Source backend for your next SaaS and Mobile app in 1 file.\n\nAfter deploying, go to https://your_railway_app/_/ to register your admin account and access the admin interface.\n\nStreaming SQLite replication\n\nThis version comes with streaming SQLite replication and restoration to a S3 bucket.\n\nIf you are using Railway's MINIO template, set the region to the default of us-east-1. Your endpoint will be the URL to your MINIO bucket and will look something like this: https://bucket-production-XXXX.up.railway.app\n\nRealtime Database\n\nEmbedded performant database with schema builder, data validations, realtime subscriptions and easy to use REST api.\n\nAuthentication\n\nManage your app users and handle email/password and OAuth2 sign ups (Google, Facebook, GitHub, GitLab) without the hassle.\n\nFile Storage\n\nSanely store files locally or in a S3 storage. Easily attach media to your database records and generate thumbs on the fly.\n\nExtendable\n\nUse as a standalone app or as Go framework, that you can extend via hooks to create your own custom portable backend. Provides official client SDKs for painless integration.",
    name: "Pocketbase + Litestream",
    category: "Other",
    health: null,
    code: "s9RV_t",
    languages: ["Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a6435d67-633a-4b76-85b2-f3882bef7ec1",
    isApproved: false,
    activeProjects: 3,
    projects: 11,
    description: "The most popular open source, multi-protocol, Java-based message broker.",
    readme:
      "Apache ActiveMQ¬Æ is the most popular open source, multi-protocol, Java-based message broker. It supports industry standard protocols so users get the benefits of client choices across a broad range of languages and platforms. Connect from clients written in JavaScript, C, C++, Python, .Net, and more. Integrate your multi-platform applications using the ubiquitous AMQP protocol. Exchange messages between your web applications using STOMP over websockets. Manage your IoT devices using MQTT. Support your existing JMS infrastructure and beyond. ActiveMQ offers the power and flexibility to support any messaging use-case.",
    name: "ActiveMQ",
    category: "Queues",
    health: 100,
    code: "JwaQug",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "181fb14c-38d7-4e81-9313-ca2d59a371a5",
    isApproved: false,
    activeProjects: 2,
    projects: 10,
    description: "A markdown email micro service for the people! - Free alternative to Resend",
    readme:
      "00 is a self hostable SES dashboard for sending and monitoring emails with AWS.\n\nKey features\nRun SST to configure AWS for you.\nThe ability to send emails by sending a POST request to /api/emails.\nMonitor email status (with multi-recipient tracking).\nSearch emails and messages (a message is created for every recipient).\nView email body.\nLog tracking for requests and queue.\n\nSES is an incredibly affordable way to build an email heavy application.\n\nHowever monitoring the emails is a bit of a nightmare, and often requires custom infrastructure. Even setting up the SES -> SNS -> SQS pipeline is a headache for developers unfamiliar with AWS. And when that is done your still left with hooking in or building custom some dashboard for viewing bounces and all the vital information you care about.\n\n00 provides an SST configuration step to set up the SES -> SNS -> SQS pipeline,\nso you can just run a command and let SST do the rest.\n\nThen 00 provides you that dashboard for viewing the information you care about.\n\nGetting started\n\nThe quickest way to get started is to clone this repo and run sst deploy in it. Make sure to set the EMAIL_IDENTITY env variable first, this will be the email or domain you wish to send from.\n\nUsing SST is easy, and you can find the steps to do so here and learn how to configure your credentials here\n\nIf you would like to avoid using SST you must manually configure AWS.\nYou need to set up a configuration set to write to an SQS queue via SNS. You can configure it however you want, but the more events you send to the queue the more 00 will be able to track (obviously).\n\nMore details: https://github.com/technomancy-dev/00/",
    name: "(00) Double Zero - Email Service (Resend alternative)",
    category: "Automation",
    health: 0,
    code: "_WfU9l",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "73f1694b-d7a1-4b04-8bf0-9d2119e17542",
    isApproved: false,
    activeProjects: 26,
    projects: 105,
    description: "A comprehensive FastAPI and PostgreSQL template.",
    readme:
      "Overview\n\nFastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.\n\nHighlights\n\nPostgreSQL integration: Seamlessly integrate with PostgreSQL databases using powerful ORMs like SQLAlchemy, enabling efficient data management and complex query handling.\n\nOpenAPI document authentication: Automatically generate interactive API documentation with integrated authentication mechanisms, making it easy to secure your endpoints and provide clear, concise documentation for developers.\n\nAsynchronous SQLAlchemy:  Leverage SQLAlchemy 2.0 to support asynchronous programming, allowing for non-blocking database operations and improved performance,\n\nLearn More\n\nGithub",
    name: "FastAPI - PostgreSQL",
    category: "Starters",
    health: 90,
    code: "IhHgYS",
    languages: ["Python", "CSS", "HTML", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0dd6e785-f8b4-4dbf-ac2e-f796eede5792",
    isApproved: false,
    activeProjects: 2,
    projects: 14,
    description: "A FastAPI App for benchmarking LLM models from various vendors.",
    readme:
      "Overview\n\nFastAPIChat is a modern, high-performance application for benchmarking LLM models from different vendors. Built with FastAPI and Python 3.9+, it leverages the power of FastAPI's asynchronous capabilities and provides an extensive system for collecting user feedback.\n\nHighlights\n\nMulti-LLM Benchmarking: Easily compare and evaluate the performance of LLM models from various vendors with different system prompts and temperature settings.\nFeedback Collection: Implement a robust feedback system to rate LLM outputs, enabling data collection for future fine-tuning and improvements.\nStreaming Responses: Integrated with FastAPI for real-time, non-blocking streaming responses, enhancing the user experience with immediate feedback.\n\nLearn More\nGithub",
    name: "FastAPIChat",
    category: "AI/ML",
    health: null,
    code: "_-qAbG",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "83e2b87d-af74-40f7-b8ea-82a3faf2e813",
    isApproved: false,
    activeProjects: 15,
    projects: 30,
    description: "High-Performance server for NATS.io, cloud and edge native messaging system",
    readme:
      "One click deployment for Nats server.\n\nNATS is a simple, secure and performant communications system for digital systems, services and devices. NATS is part of the Cloud Native Computing Foundation (CNCF). NATS has over 40 client language implementations, and its server can run on-premise, in the cloud, at the edge, and even on a Raspberry Pi. NATS can secure and simplify design and operation of modern distributed systems.\n\nhttps://github.com/nats-io/nats-server ",
    name: "Nats",
    category: "Queues",
    health: 96,
    code: "08FNhp",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f2f01c40-fd52-415a-9559-51fa794fcebd",
    isApproved: false,
    activeProjects: 45,
    projects: 72,
    description: "Deploy ChatGPT Telegram Bot with optional Pinecone on Railway.",
    readme:
      "Railway Deployment Template for ChatGPT Telegram Bot via Telegraf\n\nThis template sets up the chatgpt-telegram-bot-telegraf on Railway with the following features:\n\nNode.js Environment: Automatically installs dependencies and starts the Telegram bot.\nPostgreSQL Database: Configures a PostgreSQL database for storing user data and messages.\nPinecone Integration: Optional long-term memory support using Pinecone.\n\nEnjoy seamless deployment and scaling with Railway's infrastructure!",
    name: "chatgpt-telegram-bot-telegraf",
    category: "Bots",
    health: 80,
    code: "6T8UU3",
    languages: ["TypeScript", "Jupyter Notebook", "Dockerfile", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "fd75ccec-9409-4558-9de7-a6430402a5dd",
    isApproved: false,
    activeProjects: 2,
    projects: 4,
    description: "Una implementaci√≥n de Prueba",
    readme:
      "Esta es una implementaci√≥n de prueba, a partir de un repositorio clonado de Github, espec√≠ficamente ¬´Medusa¬ª. Aun se encuentra en una fase muy embrionaria, espero mejorarlo en los proximos dias Tened Paciencia! Apenas estoy dando mis primeros pininos con estas tecnolog√≠as\nEsta es una implementaci√≥n de prueba, a partir de un repositorio clonado de Github, espec√≠ficamente ¬´Medusa¬ª. Aun se encuentra en una fase muy embrionaria, espero mejorarlo en los proximos dias Tened Paciencia! Apenas estoy dando mis primeros pininos con estas tecnolog√≠as",
    name: "daring-courage",
    category: "CMS",
    health: null,
    code: "QqePmq",
    languages: ["TypeScript", "JavaScript", "Shell", "Handlebars", "CSS", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "98fc3632-5470-4624-976b-18729a72979b",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "Account Abstraction ERC-4337 Bundler: Skandha by Etherspot",
    readme:
      "SKANDHA on Railway with Arbitrum\n\nThis project is a fork of the original etherspot/skandha repository. We would like to acknowledge and thank the original creators for their work and contribution. This fork has been modified to enable hosting on Railway with default settings configured for Arbitrum.\n\nIntroduction\nIn ERC-4337, a Bundler is the core infrastructure component that allows account abstraction to work on any EVM network. On the highest level, its purpose is to work with a mempool of User Operations to get the transaction to be included on-chain.\n\nThis project allows you to deploy the SKANDHA bundler application on Railway with support for Arbitrum. SKANDHA is a platform designed to provide decentralized orchestration for blockchain-based tasks, specifically functioning as a Bundler for ERC-4337.\n\nGetting Started\nFollow these steps to get the project up and running:\n\nFork the Repository: Fork this repository to your own GitHub account.\nClone the Repository: Clone the forked repository to your local machine.\n    git clone https://github.com/voidfab/skandha.git\nDeploy to Railway: Follow the Railway Documentation to deploy the project. Or 1-click deploy:\n\nDeploy on Railway\n\nConfiguration\nBy default, this project is configured to work with Arbitrum. To modify the configuration, edit the necessary environment variables and settings in the railway.toml or config.json (or environment variables directly on Railway Preferred Method).\n\nSkandha Help\nBelow are all the ENV Variables you can set (details can be found in etherspots docs)\nSKANDHA_ENTRYPOINTS=0x5FF137D4b0FDCD49DcA30c7CF57E578a026d2789,0x0000000071727De22E5E9d8BAf0edAc6f37da032\nRELAYERS=0xac0974bec39a17e36ba4a6b4d238ff944bacb478cbed5efcae784d7bf4f2ff80,0x59c6995e998f97a5a0044966f0945389dc9e86dae88c7a8412f4603b6b78690d\nSKANDHA_BENEFICIARY_ADDRESS=0xf39Fd6e51aad88F6F4ce6aB8827279cffFb92266\nSKANDHA_RPC=\nSKANDHA_RPC_SUBMIT=\nSKANDHA_GAS_PRICE_MARKUP=0\nSKANDHA_ENFORCE_GAS_PRICE=false\nSKANDHA_ENFORCE_GAS_PRICE_THRESHOLD=1000\nSKANDHA_ETHERSCAN_API_KEY=\nSKANDHA_RECEIPT_LOOKUP_RANGE=\nSKANDHA_CONDITIONAL_TRANSACTIONS=\nSKANDHA_EIP2930=\nSKANDHA_MIN_STAKE=\nSKANDHA_MIN_UNSTAKE_DELAY=\nSKANDHA_BUNDLE_GAS_LIMIT_MARKUP=\nSKANDHA_RELAYING_MODE=\nSKANDHA_BUNDLE_INTERVAL=\nSKANDHA_BUNDLE_SIZE=\nSKANDHA_PVG_MARKUP=\nSKANDHA_CANONICAL_MEMPOOL=\nSKANDHA_CANONICAL_ENTRY_POINT=\nSKANDHA_CGL_MARKUP=\nSKANDHA_VGL_MARKUP=\nSKANDHA_GAS_FEE_IN_SIMULATION=\nSKANDHA_THROTTLING_SLACK=\nSKANDHA_BAN_SLACK=\nSKANDHA_MIN_INCLUSION_DENOMINATOR=\nSKANDHA_MERKLE_API_URL=\nSKANDHA_SKIP_BUNDLE_VALIDATION=\nSKANDHA_BUNDLE_GAS_LIMIT=\nSKANDHA_USEROP_GAS_LIMIT=\nSKANDHA_KOLIBRI_AUTH_KEY=\nSKANDHA_ENTRYPOINT_FORWARDER=\nSKANDHA_FASTLANE_VALIDATOR=\nSKANDHA_ESTIMATION_GAS_LIMIT=\nSKANDHA_PVG_MARKUP_PERCENT=\nSKANDHA_CGL_MARKUP_PERCENT=\nSKANDHA_VGL_MARKUP_PERCENT=\nSKANDHA_WL_PAYMASTER=\nSKANDHA_WL_ACCOUNT=\nSKANDHA_WL_FACTORY=\nPORT=14337\n\nSecurity Considerations\nWhen reading the EIP specs, you'll notice that there are many rules a bundler must follow. Although the list of rules may seem long and complex, each one has been extensively debated and discussed by security researchers and builders within the Ethereum ecosystem.\n\nOne of the bundler's main jobs is to comply with these rules to prevent all possible DoS attack vectors. These include everything from basic sanity checks that make sure a User Operation is structurally sound to more in-depth tracing for banned opcodes and storage access to make sure bundles cannot be censored once submitted to the network.\n\nSimilar to Ethereum clients, all bundler implementations are expected to pass a test suite to ensure compliance and that it won't fragment the mempool.\n\nSpec Tests: https://github.com/eth-infinitism/bundler-spec-tests\n\nAcknowledgements\nSpecial thanks to the original creators of the pimlico/skandha project. This fork wouldn't be possible without their foundational work.\n\nThe ERC-4337 Team and the Ethereum community for their continued support and guidance in the development of the EIP-4337 specification.\n\nLicense\nThis project is licensed under the GNU GENERAL PUBLIC LICENSE. See the LICENSE file for details.\n\n",
    name: "Skandha 4337 Bundler",
    category: "Other",
    health: null,
    code: "uOkE4n",
    languages: ["TypeScript", "JavaScript", "Solidity", "Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "35f1b277-f759-483b-b628-319de58bbcaa",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "ordering system for small business management",
    readme:
      "ordering system for small business management\n\nWith a database table to generate quick access in the form of an API and automate simple tasks, to integrate with desktop and mobile applications.\n\nThe idea is to be a project with a small scope and easy to manage, to then test the possibility of scaling the entire infrastructure and creating documentation.\n",
    name: "Ordering_system",
    category: "Automation",
    health: null,
    code: "bGmGYQ",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ba78849f-ab10-4646-a6d5-e06dcc85c476",
    isApproved: false,
    activeProjects: 2,
    projects: 2,
    description: "JustLogs template for twitch logging",
    readme:
      "Justlog is a twitch irc bot. It focuses on logging and providing an api for the logs.\n\nThis template sets up a Justlog instance and uses it to power the Justlog Docker image.\n\nRepo for Justlogs\n\nSeveral variables need to be set and will be populated in the configuration file.",
    name: "Twitch Chat Logger (justlogs)",
    category: "Bots",
    health: null,
    code: "vtHoV_",
    languages: ["Python", "Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a966547e-ab6f-4b11-9388-e4612adb5e48",
    isApproved: false,
    activeProjects: 4,
    projects: 16,
    description: "Joomla is an open-source CMS for building websites",
    readme:
      "Deploy Joomla on the cloud with a MySQL database in just one click. Enjoy seamless setup and configuration, allowing you to focus on building and managing your website effortlessly. Experience the power and flexibility of Joomla combined with the convenience of cloud deployment, all at your fingertips.",
    name: "Joomla",
    category: "CMS",
    health: null,
    code: "_I6lj_",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "77816d34-0ee9-4b90-b6c6-be5f74de4d80",
    isApproved: false,
    activeProjects: 0,
    projects: 3,
    description: "Lightweight, encrypted, and selfhosted Firefox Send alternative. ",
    readme:
      "Gokapi is a lightweight server to share files, which expire after a set amount of downloads or days. It is similar to the discontinued Firefox Send, with the difference that only the admin is allowed to upload files.\n\nThis enables companies or individuals to share their files very easily and having them removed afterwards, therefore saving disk space and having control over who downloads the file from the server.\n\nIdentical files will be deduplicated. An API is available to interact with Gokapi. AWS S3 and Backblaze B2 can be used instead of local storage. Customization is very easy with HTML/CSS knowledge. Encryption including end-to-end encryption is available.",
    name: "Gokapi",
    category: "Other",
    health: null,
    code: "c7QMpx",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f5f22b26-96cf-496b-9d19-4e116303b820",
    isApproved: false,
    activeProjects: 9,
    projects: 56,
    description: "Open source google photos alternative",
    readme:
      "Deploy the Immich server and with the machine learning server.\n\nIt uses a postgres installation with the Vectors extension installed and a Redis instance for cache. Images are stored on the Immich server volume, make sure to expand it.\n\nHigh performance self-hosted photo and video management solution\n",
    name: "immich",
    category: "Storage",
    health: 83,
    code: "k-RfAP",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b1bb1fdc-7648-4dca-9310-c2d61e554892",
    isApproved: false,
    activeProjects: 6,
    projects: 9,
    description: "Vitesse for Nuxt 3 üèîüíö‚ö°Ô∏è",
    readme:
      "Features\n\nüíö Nuxt 3 - SSR, ESR, File-based routing, components auto importing, modules, etc.\n\n‚ö°Ô∏è Vite - Instant HMR.\n\nüé® UnoCSS - The instant on-demand atomic CSS engine.\n\nüòÉ Use icons from any icon sets in Pure CSS, powered by UnoCSS.\n\nüî• The script setup syntax.\n\nüçç State Management via Pinia, see ./composables/user.ts.\n\nüìë Layout system.\n\nüì• APIs auto importing - for Composition API, VueUse and custom composables.\n\nüèé Zero-config cloud functions and deploy.\n\nü¶æ TypeScript, of course.\n\nüì≤ PWA with offline support and auto-update behavior.\n\nPlugins\n\nNuxt Modules\n\nVueUse - collection of useful composition APIs.\nColorMode - dark and Light mode with auto detection made easy with Nuxt.\nUnoCSS - the instant on-demand atomic CSS engine.\nPinia - intuitive, type safe, light and flexible Store for Vue.\nVitePWA - zero-config PWA Plugin for Nuxt 3.\nDevTools - unleash Nuxt Developer Experience.",
    name: "Vitesse Nuxt 3",
    category: "Starters",
    health: 100,
    code: "wWYXbc",
    languages: ["TypeScript", "Vue", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1505903d-e1f4-4a46-affd-fded72f92c18",
    isApproved: false,
    activeProjects: 174,
    projects: 468,
    description: "Zero Config | One click | WordPress | Docker | MySQL",
    readme:
      "One Click WordPress + MySQL\n\n‚ú® Features\nZero Configuration: No config setup needed, simply deploy and start using in 1 Click!\nWordPress & MySQL Integration: Seamless integration of WordPress and MySQL.\n\nüíÅ‚Äç‚ôÄÔ∏è How to use\n\nDeploy this template\n\nDeploy on Railway\n\nFollow the prompts to set up your project. All environment variables are pre-configured.\n\nAfter deployment\nAccess your WordPress site through the provided Railway URL.\nFinish WordPress Setup.\nYour WordPress site is ready!\nManage your MySQL database through the Railway dashboard.",
    name: "WordPress + MySQL",
    category: "Blogs",
    health: 100,
    code: "yG1Jw8",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e9adb166-9fc5-4048-b253-dbcef54eff9b",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "Account Abstraction ERC-4337 Bundler: Alto by Pimlico",
    readme:
      'NOTE: If it is failing on healthcheck, flip the runtime from V2 to Legacy and redeploy.\n\n‚õ∞Ô∏è Alto ‚õ∞Ô∏è\n\nALTO on Railway with Arbitrum\n\nThis project is a fork of the original pimlico/alto repository. We would like to acknowledge and thank the original creators for their work and contribution. This fork has been modified to enable hosting on Railway with default settings configured for Arbitrum.\n\nTable of Contents\nIntroduction\nGetting Started\nFeatures\nConfiguration\nAlto Help\nSecurity Considerations\nUserOperation Mempool\nAcknowledgements\nLicense\n\nIntroduction\nIn ERC-4337, a Bundler is the core infrastructure component that allows account abstraction to work on any EVM network. On the highest level, its purpose is to work with a mempool of User Operations to get the transaction to be included on-chain.\n\nThis project allows you to deploy the ALTO bundler application on Railway with support for Arbitrum. ALTO is a platform designed to provide decentralized orchestration for blockchain-based tasks, specifically functioning as a Bundler for ERC-4337.\n\nGetting Started\nFollow these steps to get the project up and running:\n\nFork the Repository: Fork this repository to your own GitHub account.\nClone the Repository: Clone the forked repository to your local machine.\n    git clone https://github.com/syphrpunk/alto.git\nInstall Dependencies: Navigate to the project directory and install the required dependencies.\n    cd alto\n    pnpm install\nDeploy to Railway: Follow the Railway Documentation to deploy the project. Or 1-click deploy\n\nDeploy on Railway\n\nOnce the service is up and running - it can be called at \nhttps://{domain}.up.railway.app/rpc\n\nsample post\n{\n    "jsonrpc": "2.0",\n    "method": "eth_supportedEntryPoints",\n    "params": [],\n    "id": 1\n}\n\n\nsample response\n{\n    "jsonrpc": "2.0",\n    "id": 1,\n    "result": [\n        "0x5FF137D4b0FDCD49DcA30c7CF57E578a026d2789",\n        "0x0000000071727De22E5E9d8BAf0edAc6f37da032"\n    ]\n}\nLearn more at the repo directly https://github.com/syphrpunk/alto?tab=readme-ov-file#alto-on-railway-with-arbitrum',
    name: "Alto 4337 Bundler",
    category: "Other",
    health: null,
    code: "Uii9K8",
    languages: ["TypeScript", "Solidity", "Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "67f3ab56-b641-4a35-88ec-0a1f7e5e1d5f",
    isApproved: false,
    activeProjects: 3,
    projects: 18,
    description: "Allows you to send events to PostHog Cloud using your own domain.",
    readme:
      "PostHog Reverse Proxy\n\nhttps://posthog.com/docs/advanced/proxy\n\nA reverse proxy allows you to send events to PostHog Cloud using your own domain.\n\nThis means that events are less likely to be intercepted by tracking blockers. You'll be able to capture more usage data without having to self-host PostHog.\n\nSetting up a reverse proxy means setting up a service to redirect requests from a subdomain you choose (like e.yourdomain.com) to PostHog. It is best practice to use a subdomain that does not include posthog, analytics, tracking, or other similar words. \n\nYou then use this subdomain as your api_host in the initialization of PostHog instead of us.i.posthog.com or eu.i.posthog.com.\n\nposthog.init('phc_YOUR_TOKEN', {\n  api_host: 'https://e.yourdomain.com'\n})\n\nCustom domain\n\nIt's recommend that you associate this service to a custom domain. If your frontend service is yourdomain.com, make this service e.yourdomain.com.\n\nEnvironment Variables\n\nThis template requires two environment variables, SERVER_NAME and PORT. Both are set by default by the template and don't need to be changed.\n\nSERVER_NAME is set to ${{RAILWAY_PUBLIC_DOMAIN}}\n\nPORT is the port through which Railway will contact this service, by default it's 80 but it pretty much doesn't matter.",
    name: "posthog-proxy",
    category: "Analytics",
    health: 100,
    code: "qHvw-4",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "36130f7f-dc20-4096-9565-1541508ba309",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "‚õ∫Ô∏è Lightweight version of Vitesse Vue",
    readme:
      "Features\n\n‚ö°Ô∏è Vue 3, Vite, pnpm, ESBuild - born with fastness\n\nüóÇ File based routing\n\nüì¶ Components auto importing\n\nüé® UnoCSS - The instant on-demand atomic CSS engine.\n\nüòÉ Use icons from any icon sets in Pure CSS\n\nüî• Use the new script setup style\n\n‚úÖ Use Vitest for unit and components testing\n\nü¶æ TypeScript, of course\n\nSee Vitesse for full featureset.\n\nDropped Features from Vitesse\n\ni18n\nLayouts\nSSG\nPWA\nMarkdown\n\nPre-packed\n\nUI Frameworks\n\nUnoCSS - The instant on-demand atomic CSS engine.\n\nIcons\n\nIconify - use icons from any icon sets üîçIc√¥nes\nPure CSS Icons via UnoCSS\n\nPlugins\n\nVue Router\n  unplugin-vue-router - file system based routing\nunplugin-auto-import - Directly use Vue Composition API and others without importing\nunplugin-vue-components - components auto import\nunplugin-vue-macros - Explore and extend more macros and syntax sugar to Vue.\nVueUse - collection of useful composition APIs\n",
    name: "Vue Vitesse Lite",
    category: "Starters",
    health: null,
    code: "-Ukdc9",
    languages: ["TypeScript", "Vue", "HTML", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d3ce7337-7ee6-41b1-9187-e3a01fcbe379",
    isApproved: false,
    activeProjects: 2,
    projects: 3,
    description: "üèï Opinionated Vite + Vue Starter Template",
    readme:
      "Features\n\n‚ö°Ô∏è Vue 3, Vite, pnpm, esbuild - born with fastness\n\nüóÇ File based routing\n\nüì¶ Components auto importing\n\nüçç State Management via Pinia\n\nüìë Layout system\n\nüì≤ PWA\n\nüé® UnoCSS - the instant on-demand atomic CSS engine\n\nüòÉ Use icons from any icon sets with classes\n\nüåç I18n ready\n\nüîé Component Preview\n\nüóí Markdown Support\n\nüî• Use the new script setup syntax\n\nüì• APIs auto importing - use Composition API and others directly\n\nüñ® Static-site generation (SSG) via vite-ssg\n\nü¶î Critical CSS via critters\n\nüî§ Webfont self-hosting\n\nü¶æ TypeScript, of course\n\n‚öôÔ∏è Unit Testing with Vitest, E2E Testing with Cypress on GitHub Actions\n\n‚òÅÔ∏è Deploy on Netlify, zero-config\n\nPre-packed\n\nUI Frameworks\n\nUnoCSS - The instant on-demand atomic CSS engine.\n\nIcons\n\nIconify - use icons from any icon sets üîçIc√¥nes\nPure CSS Icons via UnoCSS\n\nPlugins\n\nVue Router\n  unplugin-vue-router - file system based routing\n  vite-plugin-vue-layouts - layouts for pages\nPinia - Intuitive, type safe, light and flexible Store for Vue using the composition api\nunplugin-vue-components - components auto import\nunplugin-auto-import - Directly use Vue Composition API and others without importing\nunplugin-vue-macros - Explore and extend more macros and syntax sugar to Vue.\nvite-plugin-pwa - PWA\nunplugin-vue-markdown - Markdown as components / components in Markdown\n  @shikijs/markdown-it - Shiki for syntax highlighting\nVue I18n - Internationalization\n  unplugin-vue-i18n - unplugin for Vue I18n\nVueUse - collection of useful composition APIs\nvite-ssg-sitemap - Sitemap generator\n@vueuse/head - manipulate document head reactively\nvite-plugin-webfont-dl - Zero-config webfont (Google Fonts) downloader and injector to improve website's performance.\nvite-plugin-vue-devtools - Designed to enhance the Vue developer experience.\n\nCoding Style\n\nUse Composition API with script setup SFC syntax\nESLint with @antfu/eslint-config, single quotes, no semi.\n\nDev tools\n\nTypeScript\nVitest - Unit testing powered by Vite\nCypress - E2E testing\npnpm - fast, disk space efficient package manager\nvite-ssg - Static-site generation\n  critters - Critical CSS\nNetlify - zero-config deployment\nVS Code Extensions\n  Vite - Fire up Vite server automatically\n  Volar - Vue 3 script setup IDE support\n  Iconify IntelliSense - Icon inline display and autocomplete\n  i18n Ally - All in one i18n support\n  ESLint\n\nVariations\n\nAs this template is strongly opinionated, the following provides a curated list for community-maintained variations with different preferences and feature sets. Check them out as well. PR to add yours is also welcome!\n\nOfficial\n\nvitesse-lite - Lightweight version of Vitesse\nvitesse-nuxt3 - Vitesse for Nuxt 3\nvitesse-nuxt-bridge - Vitesse for Nuxt 2 with Bridge\nvitesse-webext - WebExtension Vite starter template\n\nCommunity\n\nvitesse-ssr-template by @frandiox - Vitesse with SSR\nvitailse by @zynth17 - Like Vitesse but with TailwindCSS\nvitesse-modernized-chrome-ext by @xiaoluoboding - ‚ö°Ô∏è Modernized Chrome Extension Manifest V3 Vite Starter Template\nvitesse-stackter-clean-architect by @shamscorner - A modular clean architecture pattern in vitesse template\nvitesse-enterprise by @FranciscoKloganB - Consistent coding styles regardless of team-size.\nvitecamp by @nekobc1998923 - Like Vitesse but without SSG/SSR/File based routing, includes Element Plus\nvitesse-h5 by @YunYouJun - Vitesse for Mobile\nbat by @olgam4 - Vitesse for SolidJS\nvitesse-solid by @xbmlz - Vitesse for SolidJS, build with SolidStart, includes UnoCSS and HopeUI.",
    name: "Vue Vitesse",
    category: "Starters",
    health: 100,
    code: "Van86l",
    languages: ["TypeScript", "Vue", "HTML", "CSS", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3187a47f-1edd-41ae-b9d8-1c9b1912bc7b",
    isApproved: false,
    activeProjects: 10,
    projects: 31,
    description: "A self-hosted recipe manager and meal planner for the whole family",
    readme:
      "Mealie is a self hosted recipe manager and meal planner with a RestAPI backend and a reactive frontend application built in Vue for a pleasant user experience for the whole family. Easily add recipes into your database by providing the url and Mealie will automatically import the relevant data or add a family recipe with the UI editor. Mealie also provides an API for interactions from 3rd party applications.\n\nWebsite\nDocumentation\nGitHub\n\nTips\n\nThe deployment will create a default administrator account with the username changeme@example.com and the password MyPassword . You should login and follow the setup flow to change the username and password.\nCommunication with Postgres is done exclusively over the private network and the database is not exposed externally by default. If you want to enable external access, go to the database settings and enable TCP proxying on port 5432. This can be disabled at any time.\nChanging the Railway-provided domain or adding a custom domain may require redeploying the Mealie service.\nSince Volumes on Railway are still a new feature, there is no option to access or backup the persistent data. However, Mealie natively supports backing up and restoring data via the user interface. These backups can easily be restored on fresh deployments after logging in.\nA complete list of supported environment variables can be found here. These can be added to the Mealie service to enable support for email, LDAP, and/or OpenID Connect (OIDC).\n\nNote: This is a community-made template and therefore not supported by the Mealie team. Please direct help requests to the Railway thread for the template.",
    name: "Mealie",
    category: "CMS",
    health: 100,
    code: "aEkcNZ",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6e792033-31c2-4b22-981a-b0fa870915bf",
    isApproved: false,
    activeProjects: 2,
    projects: 2,
    description: "Multipart Upload Manager for uploads to AWS S3",
    readme:
      "This project is a starting point for managing multipart uploads to AWS S3 buckets without the need for the file to pass through the server which will save time, effort, and money by leveraging a client to do the upload directly to S3 via pre-signed URLs.\n\nThis nodeJS server is designed to act as a backend that will be able to securely generate the pre-signed URLs and to provide a client with the necessary information to manage multipart uploads with the ability to resume the upload if a connection is lost.\n\nSteps to prepare for use:\nCreate an account with AWS.\nCreate a new S3 bucket\nCreate an IAM user with permissions on that same bucket\nGenerate credentials for that IAM user (access_key, access_secret)\n\nSet ENV Variables for deployment:\nThere are 5 required variables needed for this starter to work for you, visit the repo in gitHub to see the example env file.\n\n\nThis starter is meant to work in conjunction with a client application or script which will need to make the API calls to the NodeJS server once deployed in order to retrieve the data and generate the pre-signed URLs to be used when uploading large files to S3.\n",
    name: "NodeJS-multipart-uploader",
    category: "Starters",
    health: null,
    code: "ZvGKWx",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "178149ec-f488-4468-858e-9e05a48f0254",
    isApproved: false,
    activeProjects: 1168,
    projects: 1667,
    description: "n8n ai automation template",
    readme:
      "This one-click deploy template combines the power of Flowise for multi-agent flows and n8n for a wide array of tools. \n\nFlowise enables seamless management of multi-agent flows, while n8n provides a comprehensive set of tools for various purposes. \n\nBy utilizing this template, users can effortlessly set up both Flowise and n8n with just a single click, saving time and effort in the deployment process. Furthermore, n8n's extensive library of over 500 integrations for agent tools ensures that you have access to a wide range of connectors and functionalities to streamline and optimize your workflows.\n\nWhether you need to streamline communication between agents, automate tasks, or manage data flows, this template offers a convenient and robust solution that combines the strengths of Flowise and n8n, empowering you to create sophisticated and efficient workflows with ease.",
    name: "flowise-with-n8n-ai-automation",
    category: "AI/ML",
    health: 100,
    code: "Xx4_lu",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e17dc9ef-3758-4e98-8a78-06fa8aabd27a",
    isApproved: false,
    activeProjects: 18,
    projects: 46,
    description: "A minimal Hono web application.",
    readme:
      'Overview\n\nHono is a web application framework focussed on speed with support for any runtime.\n\nTemplate\n\nThis template deploys a minimal Hono web app, one that simply returns "Hello Hono".\n\nContribute\n\nIf you have any suggestions, don\'t hesitate to open an issue in the template repo.',
    name: "Hono",
    category: "Starters",
    health: 100,
    code: "q63Oi1",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3cbbbc68-ed98-45fc-a8c1-07aad42a3241",
    isApproved: false,
    activeProjects: 5,
    projects: 13,
    description: "The popular T3 App ready to go on Railway with Postgres.",
    readme:
      "Overview\n\nThis starter was scaffolded with the T3 App CLI using: \nTailwind\nPrisma\ntRPC\nNextAuth\nYou will need to add your own NextAuth providers in src/server/auth.ts, there's none configured by default.\n\nDatabase migrations are configured to run as part of the start command. If you plan on using multiple replicas I would suggest to move the migrations into the build command.\n\nLearn more\n\nFor more information about create-t3-app please head over to https://create.t3.gg/en/introduction or join the discord https://t3.gg/discord\n\nContribute\n\nIf you have any suggestions, don't hesitate to open an issue in the template repo.",
    name: "T3 Postgres",
    category: "Starters",
    health: 100,
    code: "Qi2Q_U",
    languages: ["TypeScript", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "447f9604-254a-4d3b-96d7-e84db9df8077",
    isApproved: false,
    activeProjects: 0,
    projects: 6,
    description: "A basic Blitz starter using Postgres.",
    readme:
      'Overview\n\nBlitz.js is titled as "The Missing Fullstack Toolkit for Next.js".\n\nYou get authentication, data fetching and Prisma all working nicely together in a type-safe way.\nThis template makes it easy to deploy Blitz.js with Postgres to Railway.\n\nLearn more\n\nTo learn more about Blitz.js you can head to https://blitzjs.com/ and go through the docs.\n\nContribute\n\nIf you have any suggestions, don\'t hesitate to open an issue in the template repo.',
    name: "Blitz Postgres",
    category: "Starters",
    health: null,
    code: "u6vADm",
    languages: ["TypeScript", "CSS", "JavaScript", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b18b461c-eb19-4ef8-938b-a3c5ec79aca3",
    isApproved: false,
    activeProjects: 5,
    projects: 18,
    description: "Ingestion and analysis of structured logs and traces",
    readme:
      "Contains a single service using the official datalust/seq Docker image with an attached volume for log storage. Featuring:\n\nUI and log ingestion on port 443 using the service's public domain\nLog ingestion on port 5341 within the private network\n\nGetting Started\n\nSet a temporary password in the SEQ_FIRSTRUN_ADMINPASSWORD variable and deploy the template\nVisit the public address of the service (e.g. https://your-seq-service.up.railway.app) and log in using admin and the temporary password\nEnter a new, permanent password for the admin user\n\nYou can now send logs to your Seq instance from the private network on http://your-seq-service.railway.internal:5341 or from outside on https://your-seq-service.up.railway.app.\n\nSee the Seq docs for more information on logging. In particular, you might want to add an API key to restrict who can send logs to Seq. There are also many advanced options available through environment variables.",
    name: "Datalust Seq",
    category: "Observability",
    health: 83,
    code: "TgfPHD",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ae23d90d-28ea-47d6-9a27-8b7338b6aa44",
    isApproved: false,
    activeProjects: 8,
    projects: 19,
    description: "Starter Remix JS app using create-remix@latest",
    readme:
      "This is a basic Remix app that can be deployed with one click and built upon.\n\nThe nixpacks file has been updated here to explicitly omit dev-dependencies on the server using --omit=dev rather than relying on an environment variable that specifies production mode. No warnings or errors show up at build/deploy stage.\n\nMake sure you have a url setup so you can access your new Remix app!",
    name: "Remix",
    category: "Starters",
    health: 100,
    code: "4nlQ1-",
    languages: ["TypeScript", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "507c210a-9757-4d2d-85b7-29dc6a8d5fd8",
    isApproved: false,
    activeProjects: 23,
    projects: 40,
    description: "SSL-enabled MongoDB service",
    readme:
      'The official Mongo image in Docker hub does not come with SSL baked in.\n\nSince this could pose a problem for applications or services attempting to connect to Mongo services, this service has SSL enabled right out of the box.\n\nHow does it work?\n\nSelf-signed server certificates are created using a generated root CA. The server\'s CN is set to the MONGOHOST\nvariable. During startup the script will print the root CA private key and certificate so that they can be used to\nverify the server certificate and generate client certificates, as explained below.\n\nAccessing the service\n\nMongo is launched with the preferTLS mode. This means that connections are not required to use TLS and you can\ncontinue to connect to Mongo using the MONGO_URL or MONGO_PRIVATE_URL variables.\n\nIf you would like to use TLS then there are three options:\n\n1. Connect without client certificates\n\nSet the tls and tlsAllowInvalidCertificates (required because of the self-signed server certificate) options when\nconnecting:\n\nmongosh --tls --tlsAllowInvalidCertificates "$MONGO_URL"\nor\nmongosh "$MONGO_URL/?tls=true&tlsAllowInvalidCertificates=true"\n\n2. Connect without client certificates but with root CA certificate\n\nWhen starting up the wrapper script will print the generated root CA key and certificate files. You can use them to\nverify the server\'s certificate and/or generate your own.\n\nScroll up in the service logs and copy the text starting with -----BEGIN CERTIFICATE----- and ending\nwith -----END CERTIFICATE----- to a file named root.crt.\n\nYou can now verify the server\'s certificate with the tlsCAFile option:\n\nmongosh --tls --tlsCAFile root.crt "$MONGO_URL"\nor\nmongosh "$MONGO_URL/?tls=true&tlsCAFile=root.crt"\n\n3. Connect with client certificates\n\nCreate the root.crt file as explained above. From the service logs copy the text starting\nwith -----BEGIN PRIVATE KEY----- and ending\nwith -----END PRIVATE KEY----- to a file named root.key.\n\nGenerate the client certificates (set the SSL_CERT_DAYS environment variable if you want to change the default\ncertificate expiry of 820 days):\n\nopenssl req -new -nodes -text -out "client.csr" -keyout "client.key" -subj "/CN=localhost"\nopenssl x509 -req -in "client.csr" -text -out "client.crt" -CA "root.crt" -CAkey "root.key" -CAcreateserial -days "${SSL_CERT_DAYS:-820}"\ncat "client.key" "client.crt" > "client.pem"\n\nUse the new client.pem file with the tlsCertificateKeyFile option when connecting:\n\nmongosh --tls --tlsCAFile root.crt --tlsCertificateKeyFile client.pem "$MONGO_URL"\nor\nmongosh "$MONGO_URL/?tls=true&tlsCAFile=root.crt&tlsCertificateKeyFile=client.pem"\n\nCustom start command\n\nExtend the current start command if you need to add other arguments to mongo:\n\nwrapper.sh mongod --config=/etc/mongo/mongod.conf --ipv6 --bind_ip=::,0.0.0.0\n\nIf you need a custom config then be sure to copy the current tls parameters found in mongod.conf.\n\nCert expiry\n\nBy default, the cert expiry is set to 820 days. You can control this by configuring the SSL_CERT_DAYS environment\nvariable as needed.\n\nGitHub\n\nDockerfiles can be found at https://github.com/kovalromank/mongo-ssl.\n\nReferences the official Railway postgres-ssl service at https://github.com/railwayapp-templates/postgres-ssl.',
    name: "MongoDB SSL",
    category: "Storage",
    health: 100,
    code: "V-1Lmx",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4d9bfdab-1fea-4c7d-9921-498df869bc21",
    isApproved: false,
    activeProjects: 2,
    projects: 12,
    description: "Camunda BPM Platform: Workflow and process automation with BPMN and DMN.",
    readme:
      "Camunda BPM Platform is a powerful tool for workflow and process automation, supporting BPMN for process modeling and DMN for decision modeling. It provides a flexible, open-source solution for managing business processes.\n\nURLs for Access:\n\nWelcome Page: https://public-domain.up.railway.app/camunda-welcome/index.html\n\nAdmin Console: https://public-domain.up.railway.app/camunda\n  Default Admin User: demo\n  Default Admin Password: demo\n\nSwagger UI: https://public-domain.up.railway.app/swaggerui\n\n\nFor detailed documentation and further information, visit the Camunda Documentation.\n\nThis setup allows you to quickly start using Camunda and leverage its features for business process management and automation.\n",
    name: "Camunda BPMN Platform",
    category: "Automation",
    health: null,
    code: "3WDvSx",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4659890e-e159-4f34-a392-3d1120712dfc",
    isApproved: false,
    activeProjects: 55,
    projects: 77,
    description: "The official template for self-hosting the Triplit Server",
    readme:
      "The Official Triplit Server\n\nInstructions\n\nCreate an account on Triplit\nCreate a new project\nProvide your project ID to the environmental variables of your deployment\nUpdate your project to point to your Railway deployment\n",
    name: "Triplit Server",
    category: "Storage",
    health: 100,
    code: "UnVh5f",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f383273f-67ec-42c3-9f48-6f3da0f3dfb2",
    isApproved: false,
    activeProjects: 21,
    projects: 46,
    description: "OpenSearch is a scalable, open-source search and analytics suite.",
    readme:
      "OpenSearch is a powerful, open-source search and analytics suite derived from Elasticsearch. It provides a highly scalable and flexible solution for full-text search, log and event data analysis, and real-time application monitoring. With built-in security features, alerting, and machine learning capabilities, OpenSearch empowers developers and organizations to manage large datasets efficiently and gain actionable insights. Its compatibility with Elasticsearch APIs and numerous plugins ensures seamless integration and extended functionality, making it an ideal choice for various use cases ranging from enterprise search to operational analytics. For more information, visit the OpenSearch documentation.\n",
    name: "Opensearch",
    category: "Observability",
    health: 94,
    code: "1xgwst",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f0d5c1fb-7677-4062-9278-0c479b862418",
    isApproved: false,
    activeProjects: 0,
    projects: 13,
    description: "Shorten URLs, manage your links and view the click rate statistics.",
    readme:
      "\n\nKutt\nKutt your links shorter.\n\nKey Features\n\nCreate, protect and delete your links and monitor them with detailed statistics.\nUse custom domains for your links. Add or remove them for free.\nUse the provided API to create, delete, and get URLs from anywhere.\n\n\n\n\n\n\n.h {\n    color: #B89BD8;\n}\n",
    name: "Kutt",
    category: "Other",
    health: null,
    code: "OX3Lgk",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0a29350b-951d-408a-a336-008552a78507",
    isApproved: false,
    activeProjects: 19,
    projects: 78,
    description: "Elasticsearch is a search engine based on the Lucene library.",
    readme:
      "Elasticsearch is a distributed, RESTful search and analytics engine capable of addressing a growing number of use cases. As the heart of the Elastic Stack, it centrally stores your data for lightning fast search, fine‚Äëtuned relevancy, and powerful analytics that scale with ease.",
    name: "Elasticsearch-Kibana",
    category: "Observability",
    health: 80,
    code: "S0SXRv",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7e5cc7e9-6aad-4b7d-aa53-ae28bb04f310",
    isApproved: false,
    activeProjects: 18,
    projects: 69,
    description: "PrestaShop an open-source e-commerce platform, alternative to WooCommerce.",
    readme:
      "One-click deployment of PrestaShop on a cloud platform allows you to launch the e-commerce platform with a single button press. This uses pre-configured settings and automated scripts to provision necessary resources like servers, databases, and storage, while also configuring network and security, making the deployment process fast and straightforward with minimal human intervention.",
    name: "Prestashop",
    category: "CMS",
    health: 100,
    code: "IMvWvj",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3c8ea1b2-3557-4f36-8e5f-6ba0bf11b6dd",
    isApproved: false,
    activeProjects: 3,
    projects: 25,
    description: "A production-ready blog built with Next.js 14 and Strapi CMS",
    readme:
      "Blog: Next.js + Strapi \n\nA production-ready blog built with Nextjs 14 (App Router, RSC) and Strapi CMS configured to host files in a S3 Bucket\n\nImportant:\n\nIt's optional to add the AWS S3 variables, the deployment will complete, but the files will be saved in the deployment file system, therefore, if you update or redeploy the Strapi Admin, the files will be lost.\n\nTo make Strapi host the files in a S3 Bucket, follow the instructions of this post. You can jump to the Set up AWS since the project is already configured. You only need to create a bucket, an user and give it the permissions to manage the bucket.",
    name: "Blog (Next.js + Strapi)",
    category: "Blogs",
    health: null,
    code: "0wEVIJ",
    languages: ["TypeScript", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "424e613f-14a3-4e7a-b43f-35f17314c93a",
    isApproved: false,
    activeProjects: 22,
    projects: 51,
    description: "Automatic code review tool that helps you deliver Clean Code.",
    readme:
      "SonarQube is a self-managed, automatic code review tool that systematically helps you deliver Clean Code. SonarQube integrates into your existing workflow and detects issues in your code to help you perform continuous code inspections of your projects. SonarQube analyses 30+ different programming languages and integrates into your Continuous Integration (CI) pipeline of DevOps platforms to ensure that your code meets high-quality standards.\n\nDefault login:\nuser: admin\npassword: admin",
    name: "SonarQube",
    category: "Automation",
    health: 100,
    code: "68DDoI",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8f6d11f5-4acd-4ed7-9e75-21bf4f9891e5",
    isApproved: false,
    activeProjects: 73,
    projects: 79,
    description: "A Telegram Bot that automatically reacts to posts in Telegram All messages.",
    readme:
      '\n  \n\n‚ù§Ô∏è Auto Reaction Bot ‚ú®\n\n\n\n\n\n \n\n\n‚ú® Automate Your Telegram Chats with this Auto Reaction Bot! React to Messages Effortlessly! üöÄ\n\n  Serverless deployment on Cloudflare - Free\n  \n  \n  Telegram API\n  ¬∑\n  Supported Reactions\n  .\n  Report a Bug\n\n\nAuto Reaction Preview\n\n‚ú® Features\nAutomatic Reactions ‚úì\nSupports Multiple Chats ‚úì\nCustomizable Reactions ‚úì\nEfficient Real-Time Processing ‚úì\nServerless Architecture ‚úì\nSupports for Groups &amp; Channels ‚úì\nCompliance with Telegram API Updates ‚úì\nLightweight Code - Easy Setup ‚úì\nMore Comming Soon...\n\n‚úÖ Demo: Experience the Auto Reaction Bot in demo: Auto Reaction Bot ‚ú®.\n\nüõ† Configuring Environments\n\nTo ensure that your Telegram Auto-Reaction Bot operates correctly, you will need to configure several environment variables in your Cloudflare Worker settings:\n\nBOT_TOKEN: This is your bot\'s token, which you can generate from BotFather. This token allows your bot to authenticate and interact with the Telegram API.\nBOT_USERNAME: The username you have set for your bot. This is used within the script to identify messages intended for your bot.\nEMOJI_LIST: A string of emojis that the bot will use to react to messages. You can customize this list to include any emojis you prefer, such as üëç‚ù§üî•ü•∞üëèüòÅüéâü§©üôèüëåüïäüòçüê≥‚ù§‚Äçüî•üíØ‚ö°üèÜ.\nRESTRICTED_CHATS: A list of chat IDs where the bot should not react to messages (Optional). Split each chat ID by " , ". Example : -1001233434,3434234\n\nüß© Configure the Webhook\nOpen your web browser and enter the following URL (replace  with your actual bot token and https://your.cloudflare.worker.url/ with your Cloudflare Worker URL):\n    \n    \nhttps://api.telegram.org/bot/setWebhook?url=https://your.cloudflare.worker.url/\n\nVerify the Webhook Configuration:\nTo check if the webhook is set up correctly, navigate to:\n    \n\nhttps://api.telegram.org/bot/getWebhookInfo\n\nüéØ Credits and Other\nBased on Telegram BOT API\nüßë‚Äçüíª Built with üíñ by Single Developers  \n\n‚öñÔ∏è License\nAnd of course:\n\nMIT: http://opensource.org/licenses/MIT\n',
    name: "Auto-Reaction-Bot",
    category: "Bots",
    health: null,
    code: "xAf8hY",
    languages: ["JavaScript", "Dockerfile", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9e36a0b5-63eb-48f3-a03b-ee49d6eff53e",
    isApproved: false,
    activeProjects: 0,
    projects: 3,
    description: "Simple HTTP uptime monitor with email and webhook alerts",
    readme:
      "CIAO is an open-source HTTP monitoring tool that helps you track the status of websites and APIs. It alerts you via email or webhooks when an endpoint becomes unavailable or changes its status. Ideal for monitoring production, staging, or internal services.\n\nüîó GitHub: brotandgames/ciao\n",
    name: "CIAO - check in and out",
    category: "Observability",
    health: null,
    code: "Y_0mDB",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "af44be2b-f1c4-4d29-9751-e8bf1aafad38",
    isApproved: false,
    activeProjects: 4,
    projects: 32,
    description: "No-Code Form Builder Tailored to Your Brand",
    readme:
      "\n\n  \n    No-Code Form Builder Tailored to Your Brand\n    Effortlessly create simple and engaging forms with Input. Our customization options empower you to\n      showcase your forms in your brand's colors, ensuring a cohesive and professional appearance.\n  \n  \n\t\n    \n  \n\n\n\n\nWith Email Support\n\n\nSetting up an SMTP email service is mandatory for some features, as team invitations or email notifications. You can add the required SMTP variables when deploying the service.\n\n\n\n\nAdditional Resources\n\n\nWebsite:  https://getinput.co\n\nGithub:  https://github.com/deck9/input\n\n\n\n\n\ta.link {\n    text-decoration: none;\n    color: #3498db;\n    font-weight: 600;\n    transition: color 0.3s ease, border-bottom 0.3s ease;\n    position: relative;\n}\n\na.link:hover {\n    color: #2ecc71;\n\tcursor: pointer;\n}\n\na.link::after {\n    content: '';\n    display: block;\n    width: 0;\n    height: 2px;\n    background: #2ecc71;\n    transition: width 0.3s;\n    position: absolute;\n    bottom: -2px;\n    left: 0;\n}\n\na.link:hover::after {\n    width: 100%;\n}\n\n\t.st {\n    \tfont-family: Arial, sans-serif;\n\t}\n\n  .container {\n    display: flex;\n    flex-direction: row;\n    max-width: 800px;\n    padding: 20px;\n\n    margin: auto;\n    padding: 0;\n    display: flex;\n    justify-content: center;\n    align-items: center;\n    height: fit-content;\n\n    color: #000;\n  }\n\n  .text-section {\n    flex: 1;\n    padding-right: 20px;\n  }\n\n  .text-section h2 {\n    font-size: 30px;\n    margin-bottom: 10px;\n\tmax-width: 20ch;\n  }\n\n  .text-section p {\n    font-size: 16px;\n    color: #EBEBEB;\n    max-width: 50ch;\n  }\n  \n  .image-section {\n  \twidth: 50vw;\n    max-width: 350px;\n    height: 350px;\n    max-height: 350px;\n  }\n\n  .image-section img {\n  \t\tposition: absolute;\n    \tmargin-left: 25px;\n        margin-top: 25px;\n        width: calc(45vw - 50px);\n        max-width: 350px;\n        height: auto;\n        border-radius: 5px;\n\t\tbackground-color: #4169E1;\n  }\n  \n\t.image-section svg {\n    \tposition: absolute;\n\t\twidth: 20vw;\n        max-width: 200px;\n        height: auto;\nfilter: invert(100%);\n\n    }\n\n\t.h {\n    \tcolor: #4169E1\n    }\n\n@media screen and (max-width: 600px) {\n  .container {\n  flex-direction: column;\nheight: 250px;\n  }\n\n\t.image-section img {\n\t\tdisplay: none;\n\t}\n\n\t.image-section svg {\n    \tdisplay: none;\n    }\n}\n",
    name: "Input",
    category: "Other",
    health: 100,
    code: "tVI695",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f10763b7-023a-41e7-9243-9ab3a2afdf28",
    isApproved: false,
    activeProjects: 11,
    projects: 31,
    description: "A Blazing Fast AI Gateway. Route to 100+ LLMs with 1 fast & friendly API.",
    readme:
      "One click Railway template for Portkey AI Gateway\n\nFeatures: https://portkey.ai/features/ai-gateway\nRepo: https://github.com/Portkey-AI/gateway\nDocker: https://hub.docker.com/r/portkeyai/gateway\n\nWhat is Gateway?\n\nGateway streamlines requests to 100+ open & closed source models with a unified API. It is also production-ready with support for caching, fallbacks, retries, timeouts, loadbalancing, and can be edge-deployed for minimum latency.\n\n‚úÖ  Blazing fast (9.9x faster) with a tiny footprint (~45kb installed)\n\n‚úÖ  Load balance across multiple models, providers, and keys\n\n‚úÖ  Fallbacks make sure your app stays resilient\n\n‚úÖ  Automatic Retries with exponential fallbacks come by default\n\n‚úÖ  Configurable Request Timeouts to easily handle unresponsive LLM requests\n\n‚úÖ  Multimodal to support routing between Vision, TTS, STT, Image Gen, and more models\n\n‚úÖ  Plug-in middleware as needed\n\n‚úÖ  Battle tested over 300B tokens\n\n‚úÖ  Enterprise-ready for enhanced security, scale, and custom deployments\n",
    name: "Portkey AI - Gateway",
    category: "AI/ML",
    health: 100,
    code: "jOsex-",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2070e3f1-2b30-4bf2-a901-4b8cb8556a82",
    isApproved: false,
    activeProjects: 33,
    projects: 79,
    description: "Hollo's official Railway template",
    readme:
      "Hollo is a federated single-user microblogging software powered by Fedify. Although it is for single-user, it is designed to be federated through ActivityPub, which means that you can follow and be followed by other users from other instances, even from other software that supports ActivityPub like Mastodon, Misskey, and so on.\n\nThe Railway is the simplest way to deploy Hollo.  With this template, you can get started with your own Hollo in just a few clicks.\n\nTo deploy Hollo, you need S3 or S3-compatible object storage for storing media such as images. There are many S3-compatible object storage services, including AWS S3, Cloudflare R2, MinIO, DigitalOcean Spaces, and Linode Object Storage. Once you have your object storage ready, you'll need to configure the environment variables below appropriately (see how to use the S3 client API for each service):\n\nS3_BUCKET: The bucket name of the S3-compatible object storage.\nS3_URL_BASE: The public URL base of the S3-compatible object storage.\nS3_ENDPOINT_URL: The endpoint URL for S3-compatible object storage. \nAWS_ACCESS_KEY_ID: The access key for S3-compatible object storage.\nAWS_SECRET_ACCESS_KEY: The secret key for S3-compatible object storage.\n\nOnce you've set up your environment variables and Hollo is deployed on Railway, go to https://yourdomain/setup to set up your login credentials and add your profile.\n\nIt's important to note that you need to decide on a domain name before you start setting up Hollo for the first time. This is because you can't change your domain name once Hollo is set up.\n\nOnce you've created your profile, you're ready to start enjoying Hollo. It's worth noting that Hollo doesn't have much of a web interface of its own, so you'll need to use a client app like Phanpy for now.",
    name: "Hollo",
    category: "Blogs",
    health: 88,
    code: "eopPyH",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8488b43b-f729-40d7-bdd3-86dcde1df607",
    isApproved: false,
    activeProjects: 5,
    projects: 8,
    description: "Open-source CMS platform for building websites and internal tools.",
    readme:
      "Overview\nCombining the utility of a Headless CMS with the power of a Backend-as-a-Service, Directus handles APIs, Auth, Admin, and more so you can focus on building amazing apps and websites.\n\nFeatures\nInstant GraphQL + REST APIs out of the box\nGranular RBAC to protect data\nVisualize data with custom dashboards\nAutomate flows that trigger on actions\nEnable anyone to author content, manage media, and visualize data\nBuild admin panels, manage digital experiences content, power SaaS platforms, and more\n\nLearn More\nDirectus\nDocumentation\nGitHub\n",
    name: "Directus + Cloudinary",
    category: "CMS",
    health: 100,
    code: "9-6XyM",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f531acb3-a278-4966-8b5d-def7286487b1",
    isApproved: false,
    activeProjects: 6,
    projects: 18,
    description: "Authenticated langflow sessions only.",
    readme:
      "By default, this variable is set to True. When enabled (True), Langflow operates as it did in versions prior to 0.5‚Äîautomatic login without requiring explicit user authentication.\n\nThis template turns authentication ON by default. Make sure to set the .envs below:\n\nLANGFLOW_AUTO_LOGIN=False\nLANGFLOW_SUPERUSER=username\nLANGFLOW_SUPERUSER_PASSWORD=hunter2\nLANGFLOW_SECRET_KEY=randomly_generated_secure_key",
    name: "langflow 1.0-alpha w/ user auth",
    category: "AI/ML",
    health: null,
    code: "Z1CH2j",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "898f65b4-7cb0-4eb5-b0d5-cefd2ca3f9c5",
    isApproved: false,
    activeProjects: 34,
    projects: 60,
    description: "The Lightweight Minecraft Proxy",
    readme:
      "Gate\n\nThe Lightweight Minecraft Proxy\n\nReplacing Bungee Cord/Velocity ‚Ä¢ Optimized for efficiency, low memory usage 10MB ‚Ä¢ Developed in Go ‚Ä¢ Embrace the cloud native era!\n\nIt replaces legacy proxies but also runs alongside them. Gate is entirely written in Go and heavily inspired by the Velocity project. \n\nWhy do we need a Minecraft proxy?\nUse-cases\n\n    You want to keep players connected to the proxy to move them between your different game servers like they would change the world.\n    You want to enable cross game server plugins that e.g. handle player chat events or register proxy-wide commands broadcast messages and more.\n    You want to intercept and log packets on the network traffic between players and servers\n\nHow does a Minecraft proxy work?\n\nGate presents itself as a normal Minecraft server in the player's server list, but once the player connects Gate forwards the connection to one of the actual game servers (e.g. Minecraft vanilla, paper, spigot, sponge, etc.) to play the game.\n\nThe player can be moved around the network of Minecraft servers without fully disconnecting, since we want the player to stay connected (and not want them to re-login via the server-list every time).",
    name: "Gate",
    category: "Other",
    health: 100,
    code: "fsdULq",
    languages: ["Go", "TypeScript", "Vue", "CSS", "Makefile", "Dockerfile", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0c189df8-2ba9-40ae-9612-c3d05d3ac2cd",
    isApproved: false,
    activeProjects: 6,
    projects: 21,
    description: "An open-source alternative to Crowdin, Phrase or Lokalise",
    readme:
      "Why to use Tolgee?\n\nBeacause it saves a lot of time you would spend on localization tasks without it. Because it enables you to provide perfectly translated software. \n\nFrame 47\n\nIn context translating & One click screenshots\n\nAdd translations in the code, and translate them directly in the app with the Tolgee i18n tool. Clicking an element while holding the ALT/option key opens a dialog where you can simply modify your strings. No need to edit large .json/.po/.whatever file. In-context translating works great also in the production environment.\n\nOnce. That's how many times you have to click to take a screenshot from your application with highlighted phrases to translate. Just ALT + click a string and hit the camera button. Boom! Screenshot generated.\n\nSep-06-2022 16-38-49\n\nTranslating on production\n\nIn-context translating also works in the production environment of your deployed app. Using the Tolgee Tools Chrome plugin, you can simply provide your API key and start translating. This enables anybody without developer knowledge to translate your app.\n\nTrue integrations\n\nTolgee is not just another localization platform offering integrations that just sync your local data with the backend. Tolgee is truly integrated into your app via SDKs.\n\nMachine translation\n\nWe support DeepL, Google Translate, and AWS Translate. Select which services you want to use in the settings section. The machine translation features make the whole localization process significantly faster. Translators can just use translation suggestions provided by third-party machine translation services.\n\nTranslation memory\n\nTolgee automatically makes suggestions from translations you already used in the project so you can translate similar phrases in a similar way.\n\nTranslation memory suggestions also show the similarity percentage, the key, and the original text of the translated string.\n\nAuto translation\n\nWhen enabled, Tolgee automatically translates new keys using translation memory or machine translation services. Your strings are translated immediately, right after creation. Select if you would like to use translation memory and/or which machine translation service you would like to use to automatically translate new keys.\n\nActivity log\n\nSee who modified, reviewed or commented on the phrases in your project. Clearly.\n\nComment on translations\n\nSomething look off? Tell others what you would change. You can comment every translation on Tolgee platform.\n\nTranslation history\n\nSee the changes to specific translations of a specific key in a specific language. Something is wrong? You know where to point the finger!\n\nFor more detailed documentation about Tolgee, visit tolgee.io.",
    name: "tolgee",
    category: "Other",
    health: 86,
    code: "IsMFRe",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3420264f-646a-417f-a424-9ea0b266f9ef",
    isApproved: false,
    activeProjects: 40,
    projects: 98,
    description: "Deploy a Spring microservice ecosystem with Eureka and Cloud Gateway",
    readme:
      "Spring Cloud Netflix Eureka\n\nüë®‚Äçüë©‚Äçüëß‚Äçüë¶ Target Audience\n\nThis template is intended for everyone interested in deploying Spring Cloud and Spring Boot based microservices architectures.\n\n‚ú® Features\n\nWith this template you will deploy a fully-fledged Spring Cloud Microservice Ecosystem with the following features:\n\nNetflix Eureka server prepared to register microservices in your architecture.\n HTTP resolution is enabled for testing purposes. We recommend to disable it for a production deployment.\n\nSpring Cloud Gateway instance prepared to fetch data from Netflix Eureka to build the route table for redirections.\n HTTP resolution is enabled.\n If you want to use a complex Spring Cloud Gateway implementation with filters and request translation, use this template.\n\nTwo microservices (empty implementation) ready to be used with Eureka and Cloud Gateway. They expose a dummy endpoint for testing purposes.\n HTTP resolution is disabled so these parts of the architecture are not reachable directly from the Internet.\n\nAfter deployment, you can test the entire ecosystem with the following GET request:\n\ncurl --location 'gateway_public_domain/microservice-one/'\n\nWhere gateway_public_domain is the public domain provided by Railway (something like spring-cloud-gateway-production-XXXX.up.railway.app)\n\nüëÄ See also\n\nCheck out another templates with each part of this one but separately:\nEureka Server Standalone\nCloud Gateway Straightforward Standalone\nCloud Gateway ACL Standalone\nMicroservice Archetype Standalone\n\n###‚ùì What is Spring Cloud Netflix Eureka?\n\nSpring Cloud Netflix Eureka is a key tool in the microservices world, offering a robust solution for service discovery. Part of the Spring Cloud ecosystem, it is based on Netflix Eureka. Its main function is to allow services to register in its registry and discover other services through simple queries. This approach facilitates scalability and service management in microservices architectures, where services can vary and change dynamically.\n\nEureka helps developers focus on business logic while the system automatically handles service discovery. This includes load balancing, fault handling, and providing an easy interface for service management. Eureka seamlessly integrates with other Spring Cloud components like Config Server and Circuit Breaker, offering a cohesive ecosystem for microservices development.\n\nIn summary, Spring Cloud Netflix Eureka is an essential tool for building scalable, resilient, and efficient modern microservices-based applications.\n\n###‚ùì What is Spring Cloud Gateway?\n\nSpring Cloud Gateway is a powerful library within the Spring ecosystem, designed for building API gateways in a microservices architecture. It acts as an intermediary for handling requests, routing them to various microservices. This gateway simplifies the complexity of managing multiple services by providing a single entry point for all incoming requests.\n\nKey features of Spring Cloud Gateway include dynamic routing, security, and monitoring. It supports routing based on various criteria like URL paths or headers and can dynamically route requests to different backends. This flexibility is crucial for modern applications with evolving needs.\n\nFurthermore, Spring Cloud Gateway integrates seamlessly with other Spring Cloud components, enhancing its functionality with service discovery, load balancing, and circuit breakers. This integration ensures that applications are not only efficiently routed but also resilient and secure.\n\nIn essence, Spring Cloud Gateway is an indispensable tool for developers looking to streamline their microservices architecture, offering easy management, dynamic routing, and integration with the broader Spring Cloud ecosystem.\n",
    name: "Spring Microservice Ecosystem",
    category: "Starters",
    health: 0,
    code: "f6CKpT",
    languages: ["Java", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "126bc83f-ecec-44fd-b3a2-47384f3ae660",
    isApproved: false,
    activeProjects: 74,
    projects: 100,
    description: "Wechat2RSS Êèê‰æõÈïøÊúüÁ®≥ÂÆöÂèØÁî®ÁöÑÂæÆ‰ø°ÂÖ¨‰ºóÂè∑RSSÊúçÂä°",
    readme:
      "Wechat2RSS Êèê‰æõÈïøÊúüÁ®≥ÂÆöÂèØÁî®ÁöÑÂæÆ‰ø°ÂÖ¨‰ºóÂè∑RSSÊúçÂä°\n\nÂÖ®ÂäüËÉΩÊú¨Âú∞ÂÆûÁé∞Ôºå‰øùÊä§ÈöêÁßÅ\n‰∏çÈôêÊï∞ÈáèËÆ¢ÈòÖ\nÂπ≥Âùá6Â∞èÊó∂Ôºå‰ΩéÊó∂Âª∂ËÆ¢ÈòÖÊõ¥Êñ∞\nÈÄÇÈÖçÂ§öÁßçÊñáÁ´†Ê†ºÂºèÁöÑÂÖ®ÊñáËæìÂá∫\nÊîØÊåÅÂõæÁâá„ÄÅÈü≥È¢ë„ÄÅËßÜÈ¢ë‰ª£ÁêÜ\nÂÖ¨‰ºóÂè∑ËøÅÁßªËá™Âä®Ë∑üÈöè\nÊúçÂä°ÂºÇÂ∏∏ÈÄöÁü•\n\nÂèÇËÄÉÊñáÊ°£ https://wechat2rss.xlab.app/deploy/\n\nhttps://wechat2rss.xlab.app/deploy/\nhttps://wechat2rss.xlab.app/deploy/\nhttps://wechat2rss.xlab.app/deploy/",
    name: "Wechat2RSS",
    category: "Other",
    health: 50,
    code: "KIQWgJ",
    languages: ["JavaScript", "TypeScript", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ff165412-40e5-40c1-86e3-6dd0277f2b21",
    isApproved: false,
    activeProjects: 360,
    projects: 502,
    description: "OpenAI Proxy (100+ LLMs) - OpenAI, Azure, Bedrock, Anthropic, HuggingFace",
    readme:
      'A fast, and lightweight OpenAI-compatible server to call 100+ LLM APIs.\n\nCall all LLM APIs using the OpenAI format. Use Azure, OpenAI, Cohere, Anthropic, Ollama, VLLM, Sagemaker, HuggingFace, Replicate (100+ LLMs)\n\nTest your deployed proxy: \n\nimport openai\nclient = openai.OpenAI(\n    api_key="your-master-key",\n    base_url="your-proxy-url"\n)\n\nrequest sent to model set on litellm proxy, litellm --model\nresponse = client.chat.completions.create(\n    model="gpt-3.5-turbo",\n    messages = [\n        {\n            "role": "user",\n            "content": "this is a test request, write a short poem"\n        }\n    ]\n)\n\nprint(response)',
    name: "OpenAI-Proxy",
    category: "AI/ML",
    health: 100,
    code: "HLP0Ub",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "009617f4-7783-48d1-bfbe-785b53be9736",
    isApproved: false,
    activeProjects: 11,
    projects: 27,
    description: "Docker-compose port for peppermint.sh",
    readme:
      "Introducing Peppermint, a fully open-source helpdesk solution designed to enhance the user experience for teams currently utilizing costly software alternatives. Our goal is to develop intuitive software that encompasses all the feature-rich components in premium solutions yet remains user-friendly.\n\nWelcome to the documentation for Peppermint.sh, an open-source ticket management platform that empowers you to manage your data effectively and deliver top-tier client support. Explore this documentation to understand how to leverage Peppermint.sh efficiently and develop extensions for its functionality.\n\nThis comprehensive guide covers initial setup, practical usage, and advanced development techniques, equipping you to maximize Peppermint's potential.",
    name: "peppermint",
    category: "Other",
    health: 67,
    code: "ZIVdC1",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a0201f80-7f50-4102-bcf9-41544a5174cd",
    isApproved: false,
    activeProjects: 2,
    projects: 4,
    description: "Elevating HTTP Testing to Effortless Debugging.",
    readme:
      "ServeBin is a cutting-edge HTTP testing and debugging tool, built with the latest technologies in Go. This documentation provides comprehensive details about the endpoints, parameters, and responses offered by ServeBin, empowering developers to streamline their testing workflows and ensure the reliability of their applications. Explore the various features and capabilities of ServeBin to optimize your development process and elevate your HTTP testing experience.\n\nLive Demo: https://servebin.dev",
    name: "ServeBin",
    category: "Other",
    health: null,
    code: "GkiYuO",
    languages: ["Go", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5e6d85b8-6cdc-4532-bd92-4e4a8fb0345e",
    isApproved: false,
    activeProjects: 72,
    projects: 113,
    description: "Ghost allows you to build a website, publish content, newsletters & more.",
    readme:
      "Description\n\nThis template deploys Ghost with a MySQL database integrated.\n\nInstallation\n\nJust click on the Railway button and deploy it.\nNo special config is required, you can leave default parameters.\nThe app will be available after a minute on the generated Railway URL.\n\nIf you found this helpful, or have any question, follow me on X/Twitter : @LeBugArtisan\n\nUseful links\n\nGhost config docs: https://ghost.org/docs/config/\nDocker image: https://hub.docker.com/\\_/ghost",
    name: "Deploy Ghost on Railway",
    category: "Blogs",
    health: 100,
    code: "_tnMWG",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6e84ccf9-1da6-481a-8cab-1b9cdf38d068",
    isApproved: false,
    activeProjects: 16,
    projects: 100,
    description: "Librechat.ai with RAG enabled",
    readme:
      "LibreChat is a versatile, open-source AI communications platform that integrates multiple AI models and offers extensive customization options. With the integration of Retrieval-Augmented Generation (RAG) functionality, LibreChat enhances its capabilities by combining large language models (LLMs) with external knowledge bases to provide more accurate and contextually relevant responses. This integration allows the platform to retrieve real-time data and incorporate it into the generation process, ensuring that the chatbot's responses are up-to-date and domain-specific.\n\n###Key Features of LibreChat with RAG:\n\n####Multiple Language Models\nUsers can choose from various advanced AI models, including OpenAI, Bing, and Azure, ensuring access to the latest technologies.\nCustomizable Internal Settings: Fine-tune model responses by adjusting parameters such as temperature and tone, and set prompt prefixes for specific roles.\n\n####Search and Filter Functionality\nEfficiently reference previous AI conversations with built-in search and filter options.\n\n####Plugin System\nExtend chatbot capabilities by interacting with external data sources and environment through a robust plugin system.\n\n####Conversation Branching\nExplore different conversational paths by editing and resubmitting messages, enhancing contextual understanding.\nFunction Agents: Utilize predefined functions to complete specific tasks, adding a new dimension to chatbot capabilities.\n\n####User Authentication\nSecure and scalable user authentication system supporting email and social logins.\n\n####Extensive Documentation\nComprehensive guides and documentation facilitate community involvement and plugin contributions.\n\n###Benefits of RAG Integration\n\n####Enhanced Accuracy\nBy grounding responses in external, up-to-date information, RAG reduces the likelihood of generating inaccurate or outdated answers.\n\n####Cost-Effective\nAvoid the high costs of retraining models by using RAG to provide relevant data as part of the prompt.\n\n####Improved User Trust\nResponses can include citations or references to sources, increasing transparency and reliability.\n\n####Versatility\nApplicable to various natural language processing tasks, including dialogue systems, content generation, and information retrieval.",
    name: "Librechat with RAG",
    category: "AI/ML",
    health: 80,
    code: "cnhjS_",
    languages: ["Python", "Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "69703966-b2a6-451f-a131-b493bf091ed4",
    isApproved: true,
    activeProjects: 364,
    projects: 1501,
    description: "An open-source LLM app development platform",
    readme:
      "‚ö†Ô∏è After deploying for the first time, you'll need the auto-generated INIT_PASSWORD variable in the Api service to setup the admin account. Expect possible loading delays as a result of cache on fresh deployments.\n\ncover-v5-optimized\n\nDify is an open-source LLM app development platform. Its intuitive interface combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production. Here's a list of the core features:\n\n1. Workflow: \n  Build and test powerful AI workflows on a visual canvas, leveraging all the following features and beyond.\n\nhttps://github.com/langgenius/dify/assets/13230914/356df23e-1604-483d-80a6-9517ece318aa\n\n2. Comprehensive model support: \n  Seamless integration with hundreds of proprietary / open-source LLMs from dozens of inference providers and self-hosted solutions, covering GPT, Mistral, Llama3, and any OpenAI API-compatible models. A full list of supported model providers can be found here.\n\nproviders-v5\n\n\n3. Prompt IDE: \n  Intuitive interface for crafting prompts, comparing model performance, and adding additional features such as text-to-speech to a chat-based app. \n\n4. RAG Pipeline: \n  Extensive RAG capabilities that cover everything from document ingestion to retrieval, with out-of-box support for text extraction from PDFs, PPTs, and other common document formats.\n\n5. Agent capabilities: \n  You can define agents based on LLM Function Calling or ReAct, and add pre-built or custom tools for the agent. Dify provides 50+ built-in tools for AI agents, such as Google Search, DELL¬∑E, Stable Diffusion and WolframAlpha.\n\n6. LLMOps: \n  Monitor and analyze application logs and performance over time. You could continuously improve prompts, datasets, and models based on production data and annotations.\n\n7. Backend-as-a-Service: \n  All of Dify's offerings come with corresponding APIs, so you could effortlessly integrate Dify into your own business logic.\n\nFeature comparison\n\n  \n    Feature\n    Dify.AI\n    LangChain\n    Flowise\n    OpenAI Assistants API\n  \n  \n    Programming Approach\n    API + App-oriented\n    Python Code\n    App-oriented\n    API-oriented\n  \n  \n    Supported LLMs\n    Rich Variety\n    Rich Variety\n    Rich Variety\n    OpenAI-only\n  \n  \n    RAG Engine\n    ‚úÖ\n    ‚úÖ\n    ‚úÖ\n    ‚úÖ\n  \n  \n    Agent\n    ‚úÖ\n    ‚úÖ\n    ‚ùå\n    ‚úÖ\n  \n  \n    Workflow\n    ‚úÖ\n    ‚ùå\n    ‚úÖ\n    ‚ùå\n  \n  \n    Observability\n    ‚úÖ\n    ‚úÖ\n    ‚ùå\n    ‚ùå\n  \n  \n    Enterprise Features (SSO/Access control)\n    ‚úÖ\n    ‚ùå\n    ‚ùå\n    ‚ùå\n  \n  \n    Local Deployment\n    ‚úÖ\n    ‚úÖ\n    ‚úÖ\n    ‚ùå\nNext steps\n\nIf you need to customize the configuration, please refer to the comments in our docker-compose.yml file and manually set the environment configuration. You can see the full list of environment variables here.\n\nCommunity &amp; contact\n\nGithub Discussion. Best for: sharing feedback and asking questions.\nGitHub Issues. Best for: bugs you encounter using Dify.AI, and feature proposals. See our Contribution Guide.\nEmailQuestions%20About%20Dify). Best for: questions you have about using Dify.AI.\nDiscord. Best for: sharing your applications and hanging out with the community.\nTwitter. Best for: sharing your applications and hanging out with the community.\n\nLicense\n\nThis repository is available under the Dify Open Source License, which is essentially Apache 2.0 with a few additional restrictions.",
    name: "Dify",
    category: "AI/ML",
    health: 56,
    code: "V1xiql",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "11e2c052-6fed-401a-b5b4-9ec7efc12b37",
    isApproved: false,
    activeProjects: 193,
    projects: 368,
    description: "Simple Langflow 1.0 Preview deployment using PostgreSQL as the database.",
    readme:
      "Langflow is a visual framework for building multi-agent and RAG applications\n\nThis template is a simple setup that provides a persistent database with the use of PostgreSQL.\n\nEnvironment variables:\nLANGFLOW_LOG_LEVEL: this is used to set the Langflow's logging level to improve debugging experience and to better control the logs.\nLANGFLOW_PORT: sets Langflow port. Defaults to Railway's exposed port.\nLANGFLOW_SECRET_KEY: Secret Key. Set it to a Secret value as this is used for authentication.\nLANGFLOW_DATABASE_URL: Set this to the DATABASE_URL. This is set to the URL of the Postgres instance that we set up in this template.\n\nOther environment variables can be found in the Langflow repo. All Langflow variables should start with LANGFLOW_.\n\n\n\n",
    name: "Langflow Pre-releases",
    category: "AI/ML",
    health: null,
    code: "UsJ1uB",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "20754be4-8c99-4eaf-b2ff-096fdf6b8c8c",
    isApproved: false,
    activeProjects: 19,
    projects: 37,
    description: "A worflow automation for Digital Team Academy",
    readme:
      "DTA - N8N\n\nThis template will be usefull for students at Digital Team Academy.\n\nThe infrastrcture :\n\nPostgresql Database for storing user creds, workflow configurations, worflow logs etc...\nN8N, for the UI and Backend\n\nN8N is an open-source workflow automation tool that allows users to connect various applications and automate tasks between them. It provides a powerful and flexible way to create workflows using a visual editor, enabling users to design and manage complex processes without the need for extensive coding knowledge. \n\nKey Features\n\nVisual Workflow Designer: N8N offers an intuitive drag-and-drop interface to design workflows, making it accessible for users of all technical levels.\nExtensive Integrations: It supports integration with numerous applications and services, including databases, APIs, and various SaaS products.\nCustom Nodes: Users can create custom nodes to extend the functionality and connect with proprietary or less common services.\nSelf-Hosted: Being open-source, N8N can be self-hosted, providing users with full control over their data and workflows.\nScalable: It can handle simple tasks as well as complex automation processes, making it suitable for both small businesses and large enterprises.\n\nUse Cases\n\nData Synchronization: Automatically sync data between different systems, ensuring consistency and accuracy across platforms.\nNotifications and Alerts: Set up automated notifications for specific events or conditions, improving responsiveness and communication.\nETL Processes: Extract, transform, and load data across various databases and data warehouses.\nAPI Integration: Easily connect and interact with different APIs, enabling seamless data exchange between systems.\nAutomation of Repetitive Tasks: Streamline repetitive tasks to save time and reduce manual effort.\n\nGetting Started\n\nTo start using N8N, you can either use the hosted version provided by the N8N team or set up your own instance by following the installation instructions available on their official documentation.\n\nConclusion\n\nN8N is a versatile and powerful tool for automating workflows and integrating applications. Its open-source nature and extensive feature set make it a valuable resource for developers and businesses looking to improve efficiency and streamline operations.",
    name: "n8n-DTA",
    category: "Automation",
    health: 100,
    code: "71sXeU",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "361c7393-3fc1-4d4a-9483-b2e1741afc88",
    isApproved: false,
    activeProjects: 56,
    projects: 162,
    description: "An open source alternative to Slack and Microsoft Teams.",
    readme:
      "Everything is pre-configured to work out of the box. The majority of settings are handled within the app's CMS.\n\nWhen visiting the app you will be prompted to create an admin user.\n\nIf you add a different domain, you just need to re-deploy the app for the changes to the environment to take effect.",
    name: "Mattermost",
    category: "Other",
    health: 92,
    code: "arWblT",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f2ff1acd-2559-4d37-8321-67b8b7a65e55",
    isApproved: false,
    activeProjects: 4,
    projects: 11,
    description: "A Railway starter template based on Remix, PostgreSQL (Prisma) and Radix UI",
    readme:
      "A Remix PostgreSQL Railway template\n\nA Railway template based on Remix, PostgreSQL (via Prisma) and Radix UI.\n\nThis starter comes with some batteries included:\n\nDatabase migrations are automatically applied when deployed\nPassword-based authentication (incl. user registration and session management)\nAn example for a protected route\nDark mode and theme switcher\nA notification service",
    name: "remix-postgresql",
    category: "Starters",
    health: 67,
    code: "VeLWVf",
    languages: ["TypeScript", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "79959043-b76c-4987-9a50-92a5730e0b96",
    isApproved: false,
    activeProjects: 17,
    projects: 129,
    description: "The OS for your personal finances",
    readme:
      "Maybe is an OS for your personal finances by a small team alongside an incredible community.\n\nDeploying\n\nThis template should give you a minimal Maybe install. After creating your account, you should consider setting REQUIRE_INVITE_CODE to true to prevent others from signing up.",
    name: "Maybe",
    category: "Observability",
    health: 100,
    code: "_mFlP4",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a5d55c74-1b36-4b01-8981-f27caefad55e",
    isApproved: false,
    activeProjects: 34,
    projects: 42,
    description: "REST API for Suno AI for interacting with Suno AI's music generator.",
    readme:
      '‚ú® Suno AI API üéµ\n\n‚ú® Python API Library for Suno AI ‚Äî Create Music with Generative AI ! üöÄ\n\n  Available as Both Python Library and REST API\n  \n\nüìö SunoAI API Library is an unofficial Python client for interacting with Suno AI\'s music generator. This library facilitates generating music using Suno\'s Chirp v3 model and includes main functions of Suno AI with a built-in music downloader. It can be deployed as a REST API using FastAPI, Local, Docker, on a PaaS provider like Heroku.\n\n‚ú® Features\nPython Client üêç: Easily interact with Suno AI.\nSong Generation üé∂: Utilize the Chirp v3 model for generating music.\nRetrieve Song Info by ID üéµ: Access detailed information about any song on Suno AI.\nMusic Downloader üì•: Built-in functionality to download any music on Suno AI directly.\nREST API Deployment üåê: Deployable as a REST API on PasS Platform , VPS or Local.\nComprehensive Documentation üìö: Includes detailed examples and usage guides.\nDocker Support üê≥: Enables containerized deployment with Docker for flexibility.\nPaaS Deployment ‚òÅÔ∏è: Facilitates deployment on platforms like Heroku for convenient accessibility.\n\nüìã Before deploy REST API, you must sign up on the suno.ai website and obtain your cookie as shown in repo README.md file. Set the cookie in SUNO_COOKIE at Environmental variables section.\n\nüí° You can find cookie from the Web Browser\'s Developer Tools -&gt; Network Tab\n\nüåê REST API Usage\n\n1. Generate Music\n\nPOST /generate\n\n  Request Body:\n    {\n      "prompt": "A serene melody about the ocean",\n      "is_custom": false,\n      "tags": "relaxing, instrumental",\n      "title": "Ocean Waves",\n      "make_instrumental": true,\n      "wait_audio": true\n    }\n\n  Response:\n\n    \n    Click to view\n    \n    \n        {\n            "id": "124b735f-7fb0-42b9-8b35-761aed65a7f6",\n            "video_url": "",\n            "audio_url": "https://audiopipe.suno.ai/item_id=124b735f-7fb0-42b9-8b35-761aed65a7f6",\n            "image_url": "https://cdn1.suno.aiimage_124b735f-7fb0-42b9-8b35-761aed65a7f6.png",\n            "image_large_url": "https://cdn1.suno.aiimage_large_124b735f-7fb0-42b9-8b35-761aed65a7f.png",\n            "is_video_pending": False,\n            "major_model_version": "v3",\n            "model_name": "chirp-v3",\n            "metadata": {\n                "tags": "English men voice",\n                "prompt": "I found a love, for me\\nDarling,just dive right in and follow mylead\\nWell, I found a girl, beautiful andsweet\\nOh, I never knew you were thesomeone waiting for me\\n\\n‚Ä≤Cause we werejust kids when we fell in love\\nNot knowingwhat it was\\nI will not give you up thistime\\nBut darling, just kiss me slow\\nYourheart is all I own\\nAnd in your eyes,you\'re holding mine\\n\\nBaby, I‚Ä≤m dancing inthe dark\\nWith you between myarms\\nBarefoot on the grass\\nListening toour favourite song\\nWhen you said youlooked a mess\\nI whispered underneath mybreath\\nBut you heard it\\nDarling, you lookperfect tonight",\n                "gpt_description_prompt": None,\n                "audio_prompt_id": None,\n                "history": None,\n                "concat_history": None,\n                "type": "gen",\n                "duration": None,\n                "refund_credits": None,\n                "stream": True,\n                "error_type": None,\n                "error_message": None\n            },\n            "is_liked": False,\n            "user_id":"2340653f-32cb-4343-artb-09203ty749e9",\n            "display_name": "Snonymous",\n            "handle": "anonymous",\n            "is_handle_updated": False,\n            "is_trashed": False,\n            "reaction": None,\n            "created_at": "2024-05-05T11:54:09.356Z",\n            "status": "streaming",\n            "title": "Perfect by Malith-Rukshan/Suno-API",\n            "play_count": 0,\n            "upvote_count": 0,\n            "is_public": False\n        }\n    ]\n    \n\n2. Retrieve Songs\n\nPOST /songs\n\n  Request Body:\n    {\n      "song_ids": "uuid-format-1234,4567-abcd"\n    }\n  Response:\n    Array of Clips - Same to /generate Response\n\n3. Get a Specific Song\n\nPOST /get_song\n\n  Request Body:\n    {\n      "song_id": "uuid-song-id"\n    }\n  Response:\n    Just Clip Response - Same to /generate Response but Only Clip\n\n4. Retrieve Credit Information\n\nGET /credits\n\n  Response:\n    {\n      "credits_left": 50,\n      "period": "2024-05",\n      "monthly_limit": 100,\n      "monthly_usage": 25\n    }\n\n&gt; According to [Suno.ai Each song generation consumes 5 credits, thus a total of 10 credits is necessary for each successful call.\n\n‚öñÔ∏è License\nThis project is distributed under the MIT License. This license allows everyone to use, modify, and redistribute the code. However, it comes with no warranties regarding its functionality. For more details, see the LICENSE file in the repository.\n\nüåü Support and Community\nIf you found this project helpful, don\'t forget to give it a ‚≠ê on GitHub. This helps others find and use the project too! ü´∂\n\nJoin our Telegram channels, \n\n@SingleDevelopers, for more amazing projects and updates ‚úì\n@SunoAPI, for this project updates ‚úì\n\nüì¨ Contact\nIf you have any questions, feedback, or just want to say hi, you can reach out to me:\n\nDeveloper : @MalithRukshan\nSupport Group : @Suno_API\n\nüßë‚Äçüíª Built with üíñ by Single Developers  \n\n',
    name: "Suno-API",
    category: "AI/ML",
    health: 50,
    code: "IdlBP8",
    languages: ["Python", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "625aab2e-4650-45bb-9682-6a012ba6926d",
    isApproved: false,
    activeProjects: 6,
    projects: 19,
    description: "Optimal images at incredible speeds",
    readme:
      'Serving optimized and correctly sized images is the fastest way to a quicker, more profitable site or app. 60% of website bytes are from images.\n\nImageflow edits and optimizes images so quickly you can do it on-demand. No need to manually generate every size/format combination of every image.\n\nIf you‚Äôre using ImageMagick, switch to imageflow_tool and get higher-quality images with smaller file sizes ‚Äî up to 17x faster.\n\nMost people prefer on-demand image processing, as it greatly simplifies web development.\n\nDeploying\n\nImageflow can be accessed at /u/. Images must be signed to avoid processing for non-customers. Images can be signed using the following procedure:\n\nURLSafe base64 encode the image url (remove trailing =s)\nUsing a HMAC encoder with SHA-256, encode the result of your base64 encoder using the following procedure:\n\npublic static string SignString(string data, string key, int signatureLengthInBytes) {\n      if (signatureLengthInBytes &lt; 1 || signatureLengthInBytes &gt; 32) throw new ArgumentOutOfRangeException(nameof(signatureLengthInBytes));\n     HMACSHA256 hmac = new HMACSHA256(Encoding.UTF8.GetBytes(key));\n     byte] hash = hmac.ComputeHash(Encoding.UTF8.GetBytes(data));\n     byte[] shorterHash = new byte[signatureLengthInBytes];\n     Array.Copy(hash, shorterHash, signatureLengthInBytes);\n     return EncodingUtils.ToBase64U(shorterHash);\n}\n\nget the file extension of the original url\ncombine them: base64url.signature.extension\n\nSee available transforms and filtering [here \n\nhere is a complete implementation in c#:\n\nusing Imazen.Common.Helpers;\nusing System;\nusing System.Collections.Generic;\nusing System.IO;\n\npublic class Program\n{\n\tpublic static void Main()\n\t{\n\t\tConsole.Write(String.Join(".",EncodeAndSignUrl("image url", "key").ToArray()));\n\t}\n\tprivate static string SanitizeImageExtension(string extension)\n\t{\n\t\textension = extension.ToLowerInvariant().TrimStart(\'.\');\n\t\tswitch (extension)\n\t\t{\n\t\t\tcase "png":\n\t\t\t\treturn "png";\n\t\t\tcase "gif":\n\t\t\t\treturn "gif";\n\t\t\tcase "webp":\n\t\t\t\treturn "webp";\n\t\t\tcase "jpeg":\n\t\t\tcase "jfif":\n\t\t\tcase "jif":\n\t\t\tcase "jfi":\n\t\t\tcase "jpe":\n\t\t\t\treturn "jpg";\n\t\t\tdefault:\n\t\t\t\treturn null;\n\t\t}\n\t}\n\n\tpublic static List EncodeAndSignUrl(string url, string key)\n\t{\n\t\tvar uri = new Uri(url);\n\t\tvar path = uri.AbsolutePath;\n\t\tvar extension = Path.GetExtension(path);\n\t\tvar sanitizedExtension = SanitizeImageExtension(extension) ?? "jpg";\n\t\tvar data = EncodingUtils.ToBase64U(url);\n\t\tvar sig = Signatures.SignString(data, key, 8);\n\t\tvar e = new List()\n\t\t{\n\t\t\tdata,\n\t\t\tsig,\n\t\t\tsanitizedExtension\n\t\t};\n\t\treturn e;\n\t}\n}',
    name: "Imageflow",
    category: "Storage",
    health: null,
    code: "5f0FWi",
    languages: ["C#"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5ad7f9a1-ff68-4534-a5ad-f8a108078e28",
    isApproved: false,
    activeProjects: 19,
    projects: 36,
    description: "Create a fake API using ChatGPT's website",
    readme:
      "For more info, please visit https://github.com/slippersheepig/ChatGPT-to-API-Railway\nBy default, no account is logged in. If you need local deployment, please visit https://github.com/slippersheepig/ChatGPT-to-API\nSource code https://github.com/xqdoo00o/ChatGPT-to-API\nAPI endpoint is https://the-name-you-defined-production.up.railway.app/v1/chat/completions\nAPI KEY is sk-mjj\nCopyright belongs to xqdoo00o. For more information, please see the author's project\nIf you want to deploy it yourself from github, please refer to the following steps\n1. Log in to your github, create a new private blank repository, and copy the Dockerfile and api_keys.txt of this project to your project\n The content in api_keys.txt can be edited and used for API authentication\n If you want to log in to your account, you need to complete the following two steps (ignore this step if you do not log in to your account)\n Create a new harPool folder in the repository, upload the chatgpt.com.har file into the folder, and add COPY harPool/ /cta/harPool/ in the second to last line of the Dockerfile.\n Create a new accounts.txt file in the repository, enter and save the account information in the following format, and add COPY accounts.txt. in the second to last line of the Dockerfile.\n email:password\n You can also fork this repository directly (not recommended, because non-paid GitHub users cannot make it private after forking, and your project has the risk of privacy leakage and abuse, especially if you add your account information, it is equivalent to being completely public)\n2. Open Railway, click login in the upper right corner and select github to log in. Continue to click New Project in the upper right corner and follow the instructions below.\n Click Deploy from Github repo and select the warehouse you created in the first step\n Click Add variables, fill in SERVER_HOST for VARIABLE_NAME, fill in 0.0.0.0 for VALUE, and click Add on the right\n Continue to click New Variable on the upper right, fill in PORT for VARIABLE_NAME, fill in 8080 for VALUE, and click Add on the right\n You will find Apply 2 changes in the upper left corner of the webpage, click Deploy on the right side of it\n Wait a few minutes and click Deployments below the project name. If the status has changed to Active, click View Logs on the right. If the last line shows that it is listening to 0.0.0.0:8080, the deployment is successful.\n Click Settings under the project name, scroll down to the Networking option, click Generate Domain under Public Networking, and the XXX-production.up.railway.app that comes out is the API access address.",
    name: "ChatGPT-to-API",
    category: "AI/ML",
    health: 0,
    code: "Yxd_qk",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f2504f5b-2870-4a62-a888-6b892c1b7e2e",
    isApproved: false,
    activeProjects: 79,
    projects: 187,
    description: "Web browser automation built for everyone, and loved by developers",
    readme:
      "\n    \n        \n    \n\n\nBrowserless\n\nBrowserless allows remote clients to connect and execute headless work, all inside of docker\n\nOverview\n\nBrowserless supports the standard, Puppeteer, Selenium and Playwright libraries.\n\nIt takes care of common issues such as missing system-fonts, missing external libraries, and performance improvements, along with edge-cases like downloading files and managing sessions. For details, check out the documentation.\n\nIf you've been struggling to deploy headless browsers without running into issues or bloated resource requirements, then Browserless was built for you.\n\nExamples\n\nVarious minimal code examples for using Browserless on Railway with some common libraries -\n\nhttps://github.com/brody192/puppeteer-example (Node)\n\nhttps://github.com/brody192/playwright-example (Node)\n\nhttps://github.com/brody192/playwright-example-python\n\nHighlights\n\nWorks seamlessly with Puppeteer, Playwright, and Selenium.\nNo need to install extra packages, dependencies, or system libraries.\nRAM, CPU and GPU are fully managed to stop browsers devouring resources.\nScaling and load balancing is handled for you to absorb any traffic surges.\nChrome's zombie processes are cleared away to stop servers from clogging up.\n\nFeatures\n\nParallelism and queueing are built-in and configurable.\nFonts and emoji's working out-of-the-box.\nWorks with most headless libraries.\nConfigurable session timers to keep things running smoothly.\nError tolerant: if Chrome dies it won't.\n\nLearn More\n\nBrowserless\n",
    name: "Browserless v2",
    category: "Automation",
    health: 100,
    code: "0jqemX",
    languages: ["Dockerfile", "Shell"],
    tags: ["browser", "chrome", "automation", "testing"],
  },
  {
    __typename: "Template",
    id: "296579e6-6a7e-4545-9a72-e409c651179d",
    isApproved: false,
    activeProjects: 14,
    projects: 43,
    description: "Monitor, evaluate & improve your LLM apps!",
    readme:
      "Overview\n\nLangtrace‚Ää is an open-source observability tool built on OpenTelemetry principles, designed to gather and analyze traces for enhancing LLM applications.\n\nLangtrace optimizes for the following 3 pillars of observability for your LLM apps:\n\nUsage - Tokens and Cost\nAccuracy\nPerformance - Latency and Success Rate\n\nTo learn more about Langtrace, check out our docs.",
    name: "Langtrace",
    category: "AI/ML",
    health: 67,
    code: "8dNq1c",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "15cfc3d2-4274-403c-a1a3-2bee9bb92a75",
    isApproved: true,
    activeProjects: 58,
    projects: 132,
    description: "The AI-native embedding database",
    readme:
      '\n\n  \n\n The AI-native embedding database \nCurrent Version: 0.6.3\n\nQuickstart\nDo you hate reading? This is for you! Here\'s a super quick rundown of how to use this template.\n\nAssuming we have this template deployed and we have another NodeJS service next to it that we want to use to connect to ChromaDB. You can easily connect by doing the following:\n\nSetting Service Variables\n\nIn your service, create the following service variables:\nCHROMA_TOKEN="${{Chroma.CHROMA_SERVER_AUTHN_CREDENTIALS}}"\nCHROMA_URL="${{Chroma.CHROMA_PUBLIC_URL}}"\n&gt; Note: This assumes that the chroma  service\'s name wasn\'t changed.\n\nCreating Client\nIn your application, add the following code:\nimport { ChromaClient } from  "chromadb";\n\nconst chroma = new ChromaClient({\n  path:  process.env.CHROMA_URL,\n  auth: {\n    provider: "token",\n    credentials: process.env.CHROMA_TOKEN,\n    tokenHeaderType: "AUTHORIZATION"\n  }\n});\n&gt; Note: This assumes that you have all necessary dependencies installed, like chromadb.\n\nAnd now you\'re ready to use Chroma! Of course this is just a quick example and your actual setup may vary. This quickstart did not cover how to connect over the private network, please see below.\n\nConnecting to ChromaDB\n\nThis template is exposed publicly by default. Meaning to connect to it you can use the CHROMA_PUBLIC_URL service variable. \n\nHowever, it\'s recommended you use the Private Network in production. To use this template with the private network, set CHROMA_HOST_ADDR to :: on the Chroma service then connect through the CHROMA_PRIVATE_URL service variable.\n\nAuthentication\n\nThis Chroma DB template uses token authentication by default as specified in the CHROMA_SERVER_AUTHN_PROVIDER service variable. A secure token is automatically created in the CHROMA_SERVER_AUTHN_CREDENTIALS service variable.\n\nYou can change the authentication to basic or any other authentication, to do that please refer to ChromaDB\'s documentation (see below).\n\nDocumentation\n\nAll the documentation is covered here!',
    name: "ChromaDB",
    category: "Storage",
    health: 100,
    code: "kbvIRV",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "375968e5-b6fd-4b4b-b430-b2f3f06eecf6",
    isApproved: false,
    activeProjects: 17,
    projects: 30,
    description: "A powerful solution to collect, save, and view websites offline.",
    readme:
      'Without active preservation effort, everything on the internet eventually dissapears or degrades. Archive.org does a great job as a centralized service, but saved URLs have to be public, and they can‚Äôt save every type of content.\n\nArchiveBox is an open source tool that lets organizations & individuals archive both public & private web content while retaining control over their data. It can be used to save copies of bookmarks, preserve evidence for legal cases, backup photos from FB/Insta/Flickr or media from YT/Soundcloud/etc., save research papers, and more.\n\nRailway\n\nIf you set a username, you must also set a password. You should remove both of these values after the first deploy completes.\n\nIt may take a few minutes for ArchiveBox to boot up for the first time. Do not be alarmed if you see messages like "Nothing here... yet" or "Application failed to respond" within the first 5 minutes.\n\nArchiveBox is lightweight. It should use ~80mb of RAM idle.',
    name: "ArchiveBox",
    category: "Storage",
    health: 0,
    code: "2Vvhmy",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7c42d873-53b9-4a88-8e29-ed58f818f2c1",
    isApproved: false,
    activeProjects: 231,
    projects: 506,
    description: "User-friendly ChatGPT UI alternative designed to operate offline. ",
    readme:
      "Overview\nThis template deploys Open WebUI (formerly Ollama WebUI), an extensible, feature-rich, and user-friendly self-hosted web interface designed to operate entirely offline. It supports various LLM runners, including Ollama and OpenAI-compatible APIs.\n\nLearn More\nOpen-Source ChatGPT UI Alternative with Open WebUI\nOpen WebUI site\nOpen WebUI GitHub repo",
    name: "Open WebUI",
    category: "AI/ML",
    health: 72,
    code: "2yb5lj",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "007b6afb-6a6e-44f3-89b0-52d12d332014",
    isApproved: false,
    activeProjects: 2,
    projects: 20,
    description: "Explore + Share beautiful photos and videos on the Fediverse",
    readme:
      "A fresh take on photo sharing. Get inspired with beautiful photos captured by people around the world.\n\nAd-free and privacy friendly\nOpen source and decentralized\nChronological\n\nWhat do you get here?\n\nThis configuration is pretty opinionated. Its supposed to be good to get you started, but you'll certainly want to change it ‚Äî you can see the variables here. \n\nSpecifically, you may want to:\n\ndisable ActivityPub if you want a local only community\nor turn off signups by setting OPEN_REGISTRATION to false.\nchange FILESYSTEM_DRIVER to be S3 (see further configuration) to avoid filling up your railway disk too fast",
    name: "Pixelfed",
    category: "Blogs",
    health: null,
    code: "OZSdEw",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "35b5c7cd-377f-4165-9027-72f61801fb73",
    isApproved: false,
    activeProjects: 0,
    projects: 6,
    description: "Minimal Streamlit app for AI/ML, Analytics, and more",
    readme:
      "A minimal Streamlit app template for Python to build AI/ML applications, Analytics and Data Science tools with ease. One click deployment and development. Rapidly build, deploy, and share beautiful ML and data science web apps. \n\nNo HTML. No writing API endpoints. Just Python.\n\n",
    name: "streamlit",
    category: "Starters",
    health: null,
    code: "FcYr3g",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2f04b67f-dde6-44df-a33c-110139614b65",
    isApproved: false,
    activeProjects: 63,
    projects: 227,
    description: "Backend, Admin dashboard and Webshop in one package",
    readme:
      "This template creates a vendure backend service, connects to a postgres database and creates a react (remix) storefront. The template connects all the pieces so you don't have to do anything.\n\nYouTube demonstration and tutorial\nalt text\n\nVisit: https://funkyton.com/vendure-tutorial/ for more details on how this template works.",
    name: "Vendure backend, react storefront, postgres",
    category: "Other",
    health: 100,
    code: "6DeBLr",
    languages: ["TypeScript", "CSS", "Handlebars", "JavaScript", "Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2969326b-0cbe-475d-9cc4-0f733974c0fd",
    isApproved: false,
    activeProjects: 2,
    projects: 13,
    description: "A fast, fun, and small ActivityPub server for the Fediverse",
    readme:
      "GoToSocial is an ActivityPub social network server, written in Golang. GoToSocial provides a lightweight, customizable, and safety-focused entryway into the Fediverse. With GoToSocial, you can keep in touch with your friends, post, read, and share images and articles. All without being tracked or advertised to!\n\nIMPORTANT DEPLOYMENT STEPS\n\nAfter the first deployment succeeds, you will need to create your first user. This must be done from the command line. Open the GoToSocial container's settings, and add a start command that says /gotosocial/gotosocial admin account create --username some_username --email someone@example.org --password 'some_very_good_password'\nRedeploy, and wait a little bit to be confident the command has completed\nDelete the start command to revert it to default\nBefore seriously using the fediverse, configure a custom domain ‚Äî it will be hard to switch off the railway provided one later\n\nFeatures\n\nYou can follow people and have followers, you make posts which people can favourite and reply to and share, and you scroll through posts from people you follow using a timeline.\n\nYou can write long posts or short posts, or just post images, it's up to you.\n\nYou can also, of course, block people or otherwise limit interactions that you don't want by posting just to your friends.\n\nGoToSocial is not designed for 'must-follow' influencers with tens of thousands of followers, and it's not designed to be addictive.\n\nYour timeline and your experience are shaped by who you follow and how you interact with people, not by metrics of engagement!",
    name: "GoToSocial",
    category: "Blogs",
    health: null,
    code: "apM9fC",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "879152bb-c94d-4c6c-a832-fbfd86870753",
    isApproved: false,
    activeProjects: 2,
    projects: 26,
    description: "A working template to spin up authentik with minimal resources.",
    readme:
      "Bootstrap password\n\nWhen deploying, you must provide an admin username and password. This is done in plain text in the environment variables. You must change your admin password as soon as you login the first time.\n\nPatience\n\nIt takes up to 5 minutes to deploy this template.\n\nConfiguration\n\nAuthentik is very configurable through environment variables, see the documentation.\n\nCustom styling\n\nThis Docker image injects a custom css file. You can configure the brand and secondary colours through the server's environment variables OVERRIDE_ACCENT_COLOUR and OVERRIDE_LINK_COLOUR.",
    name: "authentik",
    category: "Authentication",
    health: 100,
    code: "Vx-b8p",
    languages: ["Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "66bc8958-99ec-4c07-9d09-55191a4357b0",
    isApproved: false,
    activeProjects: 6,
    projects: 24,
    description: "An open-source, web-based, self-hosted, collaborative markdown editor.",
    readme:
      "Ideas grow better together.\n\nHedgeDoc (formerly known as CodiMD) is an open-source, web-based, self-hosted, collaborative markdown editor.\n\nYou can use it to easily collaborate on notes, graphs and even presentations in real-time. All you need to do is to share your note-link to your co-workers and they‚Äôre ready to go.\n\nDeployment\n\nThis template is a one-click deploy on railway. Once the deployment completes and you are allocated a URL, Hedgedoc will begin working.\n\nConfiguration\n\nPlease use the environment variables in the configuration docs.\n\nNotes\n\nThis template uses an older version of Postgres, because Hedgedoc uses an older version of Postgres.",
    name: "HedgeDoc",
    category: "CMS",
    health: 100,
    code: "9CXSkd",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "64617302-a740-4660-84b9-89df0f3db1cb",
    isApproved: false,
    activeProjects: 1,
    projects: 11,
    description: "A platform for searching, monitoring, and analyzing machine-generated data",
    readme:
      "What is Splunk?\n\nSplunk is a powerful software platform designed for searching, monitoring, and analyzing machine-generated data via a web-style interface. Its core functionality revolves around indexing large volumes of data and making that data searchable, providing real-time insights and operational intelligence.\n\nSplunk's capabilities extend across various domains, including IT operations, security, business analytics, and more, making it an essential tool for enterprises looking to leverage their machine data for better decision-making and problem-solving.\n\nKey Features of Splunk\n\nData Indexing and Search: Splunk can ingest a vast range of data sources, indexing them to enable fast and efficient search capabilities.\nVisualization: Create dashboards, graphs, and visual reports to represent data insights visually.\nAlerts and Reports: Set up automated alerts and scheduled reports to stay informed about critical changes or issues.\nMachine Learning: Integrate machine learning to predict and prevent issues before they occur.\nSecurity and Compliance: Use Splunk for security monitoring, threat detection, and ensuring compliance with industry standards.\n\nHow Splunk Can Be Useful\n\nIT Operations\n\nSplunk helps in monitoring and troubleshooting IT systems by aggregating logs from different sources. It can quickly identify the root causes of issues and reduce downtime, leading to improved system performance and reliability.\n\nSecurity and Threat Management\n\nBy collecting and analyzing security data, Splunk can detect anomalies and potential threats. It aids in incident response and compliance reporting, making it a valuable tool for cybersecurity teams.\n\nBusiness Analytics\n\nSplunk enables businesses to analyze customer behavior, transaction data, and other business metrics. This analysis can drive strategic decisions, optimize operations, and enhance customer experiences.\n\nApplication Development\n\nDevelopers can use Splunk to monitor application logs and performance metrics, facilitating continuous integration and delivery (CI/CD) processes. This ensures that applications run smoothly and meet user expectations.\n\nOfficial Resources\n\nSplunk Official Documentation\nSplunk User Guide\n\nThese resources provide comprehensive information on getting started with Splunk, advanced configurations, and best practices.\n\n",
    name: "Splunk",
    category: "Other",
    health: 100,
    code: "CrRewK",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "660d3202-08a3-44ef-8c02-f3a8c161224c",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "Figma Alternative, Design and code beautiful products. Together.",
    readme:
      "Penpot (Figma self hosted alternative) is the web-based open-source design tool that bridges \nthe gap between designers and developers.\n\nPenpot expresses designs as code. The final product reflects \nthe designers' initial vision. No extra work required. \n\nhttps://penpot.app",
    name: "penpot",
    category: "Starters",
    health: null,
    code: "pfvsxg",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "bb1f43b8-55a1-46d7-8f93-65c9fc809345",
    isApproved: false,
    activeProjects: 3,
    projects: 8,
    description: "A self-hosted Spotify tracking dashboard",
    readme:
      "Your Spotify\n\nYour Spotify tracks what you listen to on Spotify and lets you explore those statistics through a pretty-looking web interface.\n\nGetting Started\n\nYou'll need to create an application in Spotify's developer portal before deploying this template. To do so:\n\nOpen the Spotify developer dashboard.\nClick Create app and fill in whatever you like for the App name, App description, and Website fields.\nIn the Redirect URI field, enter https://example.com/oauth/spotify/callback. You'll change example.com to your backend's actual domain later, but enter example.com for now.\nClick Settings. Note your Client ID.\nClick View client secret. Note your Client secret.\n\nWhen you deploy this template, provide your client ID and secret when asked. Once the backend has been deployed, edit your Spotify app's redirect URI to replace example.com with the backend's public domain (e.g., your-spotify.up.railway.app).\n\nImporting Data\n\nBy default, Your Spotify can only access your streaming history from as far back as 24 hours before you first authorized Your Spotify to access your Spotify account. If you want Your Spotify to have access to earlier streaming history (and you probably do), you'll need to manually request that data from Spotify and provide it to Your Spotify. You can request said data here (scroll down to Download your data).\n\nThere are two kinds of data requests you can make.\n\nAccount data\n\nYour account data contains the last year of your streaming history. It will take Spotify up to five days to prepare this data once you request it.\n\nWhen you receive your data package, open Your Spotify, go to Settings > Account, scroll down to Import data, and select Account data from the dropdown menu. Click SELECT YOUR STREAMINGHISTORYX.JSON FILES and upload all files in your data package whose names begin with StreamingHistory.\n\nExtended streaming history\n\nYour extended streaming history contains the streaming history for the lifetime of your account. It will take Spotify up to 30 days to prepare this data once you request it.\n\nWhen you receive your data package, open Your Spotify, go to Settings > Account, scroll down to Import data, and select Extended streaming history from the dropdown menu. Click SELECT YOUR STREAMING_HISTORY_AUDIO.JSON FILES and upload all files in your data package whose names begin with Streaming_History_Audio.\n\nCustom Domains\n\nIf you add a custom domain to the frontend, you must redeploy the server for it to take effect.\n\nIf you add a custom domain to the backend, you must redeploy both the frontend and the backend for it to take effect. You must also add a redirect URI for your custom domain to your Spotify application.\n\nAll of this also applies if you change the name of the default up.railway.app domain.\n\nAdding Users\n\nIf you want people aside from yourself to be able to use your Your Spotify instance, you'll need to authorize them by hand in the User Management tab of your app's page on the Spotify developer dashboard. You can only add up to 25 users. \n\nYou don't need to authorize yourself unless you're using Your Spotify with a different Spotify account then the one that owns your Spotify application.\n\nUsers who aren't authorized can still log into your Your Spotify instance, but Your Spotify won't be able to request data for them.\n\nIf you don't like having to authorize users by hand or can't live with the 25-user cap, you can try your hand at requesting a quota extension from Spotify. If your request is granted, both of these limitations will be lifted.\n\nTime Zones\n\nThis template configures Your Spotify to display statistics in UTC by default. While you can change this default via the backend's TIMEZONE environment variable, it's better if you just leave that alone and change your account's time zone in the Your Spotify UI by going to Settings > Statistics > Timezone. \n\nAcknowledgements\n\nYour Spotify is developed by Timothee Boussus. I maintain this template, but have no affiliation with the upstream project.\n\n\"Spotify\" and the Spotify logo are registered trademarks of Spotify AB. This project is not affiliated with or endorsed by Spotify AB.\n\nMore Information\n\nFor more information, visit the upstream repository.",
    name: "Your Spotify",
    category: "Other",
    health: 100,
    code: "UfZbjv",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "857f0eb2-32d9-422b-841e-62d3c74d8c2f",
    isApproved: false,
    activeProjects: 4,
    projects: 12,
    description: "Pocketbase + Stripe | FastPocket Freebie",
    readme:
      "Fill your environment variables from Stripe\nUpdate the endpoints with your own callbacks\nClick Load from JSON file and grab the schema file from pb_bootstrap/pb_schema.json\nStart creating products\n\nGo to the Github for a lot more detail:\n https://github.com/mrwyndham/pocketbase-stripe\n\nUse a prebuilt next.js frontend if it takes your fancy by purchasing https://fastpocket.dev",
    name: "pocketbase-stripe",
    category: "Starters",
    health: null,
    code: "izeSvS",
    languages: ["Go", "Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1afbc7f4-d44e-4b5b-a12e-eb52a101fea1",
    isApproved: false,
    activeProjects: 5,
    projects: 18,
    description: "Change, Query, Secure, Govern all databases in a single place",
    readme:
      "\n    \n        \n    \n\n\n\n   Different  database development tasks\n\n\n\n   Multiple  database systems\n\n\n\n   Unified  process\n\n\n\n   Single  tool\n\n\nThe GitLab/GitHub for database DevOps. World's most advanced database DevOps and CI/CD for Developer, DBA and Platform Engineering teams.\n\nOverview\n\nBytebase is a database schema change and version control management tool for teams. It consists of a web console and a backend. The backend has a migration core to manage database schema changes. It also integrates with VCS to enable version controlled schema management.\n\nBytebase is the middleware sitting between you and your database. It's the GitLab/GitHub for Database DevOps, built for developers, DBAs and platform engineers. As GitLab/GitHub provides a GUI and collaboration workspace for teams to manage code, Bytebase does the similar job for managing databases.\n\nKey Features\n\nSQL Review\n\nBytebase analyzes SQL changes to enforce rules in compliance with your organization's policy. The enforcement includes naming conventions, anti-SQL pattern detection and etc. Prod and non-prod environments can also enforce different rules respectively.\n\nDatabase CI/CD and Change Automation\n\nLike code review, Bytebase streamlines the database change process. Within a single workflow, a database change can be reviewed and deployed from the dev environment all the way to the production environment.\n\nGitOps (Database-as-Code)\n\nBytebase keeps the complete schema change history. It also integrates with VCS systems. Teams can manage the SQL migration scripts in the VCS and trigger schema deployment on code commit.\n\nBatch Change and Query\n\nBytebase allows you to change a collection of databases in a single workflow. It also allows you to issue\na single query against multiple databases.\n\nSQL Editor\n\nA web-based SQL Editor to query and export data. DBAs no longer need to give away sensitive database credentials when developers need to access the data.\n\nDynamic Data Masking\n\nBytebase provides multi-level masking policy with workflow to grant unmasked data access.\n\nData Access Control\n\nBytebase provides a suite of features to enable organizations to enforce data security policies, avoid data leaks and conform compliance.\n\nData Rollback\n\nStatement-level rollback\n\nDatabase-level manual and periodical backup and restore\n\nPoint-in-time recovery (PITR)",
    name: "Bytebase",
    category: "Other",
    health: 75,
    code: "_ce3VS",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9956a08c-4b6e-4ec3-88a7-d51eae526596",
    isApproved: false,
    activeProjects: 2926,
    projects: 4438,
    description: "Deploy n8n on Railway with one click for easy workflow automation.",
    readme:
      " This Railway template enables you to deploy n8n, a powerful open-source workflow automation tool, with just one click. Designed for simplicity and efficiency, the template comes pre-configured to integrate seamlessly with external services via webhooks. It uses PostgreSQL for reliable data persistence, ensuring that your workflows remain intact across restarts and redeployments. ",
    name: "n8n",
    category: "Automation",
    health: 96,
    code: "0vH6fh",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "de1ea7af-89eb-431a-b1ae-3f1d6245e29e",
    isApproved: false,
    activeProjects: 1,
    projects: 15,
    description: " More than a Grammar Checker",
    readme:
      "LanguageTool\nLanguageTool is an Open Source proofreading software for English, French, German, Polish, Russian, and more than 20 other languages. It finds many errors that a simple spell checker cannot detect.\n\nNotes\nUse the following URL in your extension or desktop app:\n\n/v2",
    name: "LanguageTool",
    category: "AI/ML",
    health: 100,
    code: "KdtxnQ",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2fa460d7-bbeb-4d62-9098-3f857479a2f7",
    isApproved: false,
    activeProjects: 19,
    projects: 36,
    description: "A cloud IDE built from C9 SDK",
    readme:
      "Intro\n\ndemo\n\nThis is a self-hosted IDE / Code editor, built from C9 SDK. With C9 IDE you can set up development environments in the cloud. It comes with nvm, pm2 and nginx that can help you publish your application pulically accessible to the world.\n\nVariable\n\nC9SDK_PASSWORD: password for basic auth. it would be publically accessible if this env is not defined\nGIT_REPO: automatic git repo deployment\nGIT_BRANCH: target branch, if not present, default branch will be used.\nINITIAL_COMMAND: (optional) custom command that can be used for installing custom dependencies or even start your git repo your own way\nGIT_REPO, GIT_BRANCH: (optional) a sample repo running nodejs & react & postgres is added for demo purpose, to show it can run real world application.\nDOMAIN_NAME: (optional) this env will be used with deployment script in the sample application. if empty, nginx will run the application at port 8081, and you need to use TCP Proxy to get it pulicly accessible (Container settings -> Network) \n\nWhat is the best use case for this?\n\nOnline - cross device development. it is an alternative to code-server. it is lighter than code-server which will be more resouce (cost) effective.\nRun any real world application without Docker (DinD is not yet supported in Railway)\nGitlab Runner Shell executor for Gitlab CI/CD \n\nInstructions to run real world application\n\nRun your application at some local port. for example: python -m SimpleHTTPServer 9000 to start a static web server at port 9000.\nPrepare your domain and add to Service settings -> networking. make sure the DNS record is setup.\nAdd a nginx conf files to /etc/nginx/sites-enabled to reserve proxy your application. make sure to use server_name your_domain;\nRun nginx -t to test your .conf file\nRun nginx -s reload to apply changes.\nYour application should be pulically accessible now.\n\nAuto Git Repo Deployment\nThe start script checks the environment variable GIT_REPO (and GIT_BRANCH) and automatically clones and deploys the repository.\nGIT_REPO should be https url containing access token key\nThe repo will be cloned to /root/the-project.\nThe repo needs to have the following deployment structure, which is: \n    depoyments: folder\n    - deploy.sh: suppose to install project deps and start the project\n    - setup-cron.sh suppose to setup cron for automatically checking new commit and pull and re-deploy\n    - setup-nginx.sh suppose to setup nginx reserve proxy with production domain name\n\n\n\n",
    name: "C9 IDE",
    category: "Starters",
    health: 100,
    code: "EjubUu",
    languages: ["Shell", "Dockerfile", "JavaScript", "TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "16b3dec3-fe73-499b-b84c-9647aa490dff",
    isApproved: false,
    activeProjects: 3,
    projects: 4,
    description: "aitekflow is a app builder",
    readme:
      "AitekFlow App Builder is a no-code platform designed to empower users to create AI-driven applications effortlessly. It features an intuitive drag-and-drop interface, allowing even those without coding experience to integrate AI functionalities into custom apps quickly and efficiently.",
    name: "reminiscent-existence",
    category: "Automation",
    health: 0,
    code: "f53xGc",
    languages: ["JavaScript", "CSS", "Dockerfile", "HTML", "Shell", "HCL"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "245916da-29fc-416a-8138-b4b302125044",
    isApproved: false,
    activeProjects: 3,
    projects: 9,
    description: "Forgejo is a self-hosted lightweight software forge.",
    readme:
      "Forgejo is a self-hosted lightweight software forge.\n\nNotes\nDue to Railway only allowing 1 port to be forwarded to your project, you must use HTTP for checkout and push to the repositories setup in your Gitea instance.\n\nPurpose\nThe goal of this project is to make the easiest, fastest, and most painless way of setting up a self-hosted Git service.\n\nForgejo is a fork of Gitea, which is itself a fork of Gogs.\n\nSetup Instructions\nTo deploy the Gitea project on Railway, just click through, all environment variables are already configured for you. Once deployed, visit your domain, and you can start setting up your instance.",
    name: "Forgejo",
    category: "Storage",
    health: 50,
    code: "Ot34oR",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "87dffae0-ce4a-41e7-a37d-6b0c4d4ab463",
    isApproved: false,
    activeProjects: 0,
    projects: 3,
    description: "Professional grade time-tracking application, free and open-source",
    readme:
      "Kimai is a professional grade time-tracking application, free and open-source. It handles use-cases of freelancers as well as companies with dozens or hundreds of users. Kimai was build to track your project times and ships with many advanced features, including but not limited to:\n\nJSON API, invoicing, data exports, multi-timer and punch-in punch-out mode, tagging, multi-user - multi-timezones - multi-language (over 30 translations existing!), authentication via SAML/LDAP/Database, two-factor authentication (2FA) with TOTP, customizable role and team permissions, responsive design, user/customer/project specific rates, advanced search & filtering, money and time budgets, advanced reporting, support for plugins and so much more.\n\n",
    name: "Kimai",
    category: "Analytics",
    health: null,
    code: "SmKtMI",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4527f3b5-93e4-453c-8578-671480040631",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "Automated Github Backup System for Disaster Recovery",
    readme:
      "Git Backup\n\nAutomated Github Backup System for Disaster Recovery. This system takes daily snapshots of the whole organisation code and store them into S3 as a backup storage which is easily searchable based on date wise directory structure. \n\nExample of ENV File\n\nGITHUB_TOKEN=\nGITHUB_ORG=\nAWS_REGION=\nAWS_ACCESS_KEY_ID=\nAWS_SECRET_ACCESS_KEY=\nAWS_BUCKET_NAME=",
    name: "Git Backup",
    category: "Automation",
    health: null,
    code: "HgR-fs",
    languages: ["TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "688f38ee-1750-4aeb-bdc1-d38694acc29e",
    isApproved: false,
    activeProjects: 1,
    projects: 5,
    description: "Everyday AI Tools: Unburn Toys",
    readme:
      "Unburn Toys\nEmpower your daily tasks with our versatile AI toolbox, delivering essential tools for every need.\n\nSetup\nYou require gemini api key, get it from here and put it in GOOGLE_API_KEY variable.\nNo need to change MODEL_NAME, it's default value will be gemini-1.5-pro-latest\n\nContribute\nMake this project more awesome by contributing to our project -> github",
    name: "Unburn Toys",
    category: "AI/ML",
    health: null,
    code: "K1iD7P",
    languages: ["TypeScript", "CSS", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c8712a74-481b-4716-a1a9-8ebd71741031",
    isApproved: false,
    activeProjects: 4,
    projects: 8,
    description: "Run cron jobs on Railway using Node.js",
    readme:
      "A simple template for deploying and running a cron job on Railway using JavaScript.\n\nSimply select this template and add in your env variables like the corn timer, base URL, different endpoints & query params to hit at random every time.\n\nFor more details refer - https://github.com/rajdeep-ghosh/cronjob",
    name: "Cron Job",
    category: "Automation",
    health: 33,
    code: "I6jLyB",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0b1c2bc1-8154-4fb9-8c43-349495bcb217",
    isApproved: false,
    activeProjects: 104,
    projects: 131,
    description: "Use Coze on your favorite OpenAI client.",
    readme:
      "This project converts the Coze API to the OpenAI API format, giving you access to Coze's LLMs, knowledge base, plugins, and workflows within your preferred OpenAI clients.\n\nFeatures\n\nConvert Coze API into an OpenAI API\nSupport streaming and blocking\nSupport Chatbots API on Coze\n",
    name: "coze2openai",
    category: "AI/ML",
    health: 100,
    code: "yM5tQL",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "492ca6c1-2234-488f-940c-d597fae60ed0",
    isApproved: true,
    activeProjects: 9,
    projects: 23,
    description: "An open source, Redis compatible, in-memory data store",
    readme:
      "\n    \n        \n    \n\n\nAn open source, Redis compatible, in-memory data store\n\nA new project to resume development on the formerly open-source Redis project. We're calling it Valkey, since it's a twist on the key-value datastore.\n\nWhat is Valkey?\n\nValkey is a high-performance data structure server that primarily serves key/value workloads. It supports a wide range of native structures and an extensible plugin system for adding new data structures and access patterns.",
    name: "Valkey",
    category: "Other",
    health: 96,
    code: "pQYeJx",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "768a3c10-5f40-4ae5-b41e-37733a0d915a",
    isApproved: false,
    activeProjects: 5,
    projects: 8,
    description: "Unofficial API for JustWatch",
    readme:
      "This project offers an unofficial API for JustWatchm, a comprehensive streaming guide that aggregates data from multiple streaming platforms. It empowers users to effortlessly discover where to stream their beloved movies and shows online.\n\n\nThis API is unofficial and not endorsed by or affiliated with JustWatch. Use it responsibly and adhere to the terms of service of the platforms it accesses.",
    name: "justwatch-unofficial-api",
    category: "Other",
    health: null,
    code: "TCwMfF",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ec10ccb6-835d-4378-8008-1d23ed913681",
    isApproved: false,
    activeProjects: 3,
    projects: 3,
    description: "A data streaming proxy service that uses Server-Sent Events (SSE).",
    readme:
      "Setting Up Turso (Optional)\nCreate a Turso account\nUsing either the CLI or web UI, create a new Turso database, and note the URL\nUsing either the CLI or web UI, get the auth token for the database\n\nNote: A local SQLite file can be used instead of a Turso/libSQL database (set the TURSO_URL to a file - eg. 'file:data.db'). The file must be persistent between runs.\n\nRailway Deployment\nPlug in the environment variables into Railway\nDeploy!\n\nLive Site\nTest out the site by visiting the live page at your Railway domain. Try to create a new Fluxpoint by sending a POST request to /new, or by pressing the button on the homepage.",
    name: "flux",
    category: "Other",
    health: null,
    code: "_RXeq1",
    languages: ["TypeScript", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "cc9f788d-d90c-4199-90f6-03797503f5bd",
    isApproved: false,
    activeProjects: 3,
    projects: 12,
    description: "Open Source, Privacy-First Simple Analytics for Mobile, Desktop, and Web",
    readme:
      "\n    \n        \n    \n\n\nAptabase\n\nOpen Source, Privacy-First and Simple Analytics for Mobile, Desktop and Web Apps\n\nNotes:\n\nCommunication to Postgres is done exclusively over the private network and the database is not exposed externally in any way by default, if you want to enable access from outside of the private network you can go to the databases settings to enable TCP proxying and enter the internal port (5432) the TCP proxy can be again removed at any point to close off external access.\n\nCommunication to Clickhouse is done exclusively over the private network and the database is not exposed externally in any way by default, if you want to enable access from outside of the private network you can go to the databases settings to generate a domain, the domain can be again removed at any point to close off external access.\n\nOverview\n\nAptabase is an open-source alternative to Firebase/Google Analytics, specifically built for Mobile, Desktop and Web apps.\n\nExtensive list of SDK: No matter what framework or language you use, we have an SDK for you. Swift, React Native, Flutter, Electron, Kotlin, and many others.\n\nPrivacy-First: We prioritize user privacy and collect minimal usage data without using unique identifiers. Instead, we focus on monitoring sessions, complying fully with GDPR, CCPA, and PECR regulations.\n\nSimple: Built-in and user-friendly dashboard for all your essential metrics, enabling you to gain insights effortlessly and grasp the dynamics of your apps.\n\nOpen-Source: Our source code is 100% open source. There is nothing hidden. All the server code and SDKs are available for you to inspect and contribute to.\n\nSDKs\n\nAptabase provides SDKs for the most popular frameworks and languages to make it easier to integrate them into your app.\n\nSwift (Apple)\nAndroid (Kotlin)\nReact Native\nFlutter\nTauri\nNativeScript\n.NET MAUI\nElectron\nWeb Apps\nUnreal Engine\nUnity Engine",
    name: "Aptabase",
    category: "Other",
    health: 83,
    code: "6MbF4W",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5bee8dcf-f0ed-448d-b7e2-1f9a216d9b55",
    isApproved: false,
    activeProjects: 294,
    projects: 436,
    description: "A relational model database server produced by Microsoft",
    readme:
      'Overview\n\nMicrosoftSQL database service. Microsoft SQL Server is a proprietary relational database management system developed by Microsoft.\n\nA Volume is mounted to the service to persist data between deploys.\n\nTCP proxying is configured to allow accessing the database from anywhere.\n\nHow to use\n\nReference the MSSQL_URL variable from your service to connect to the database in your tool of choice (e.g. ${{MicrosoftSQL.MSSQL_URL}})\n\nConnecting\n\nConnect to the database using the proxied domain and port found in the service Variables page. The password can also be found on the Variables page.\n\nLicense\n\nLegal Notice: Container License Information\n\nBy passing the value "Y" to the environment variable "ACCEPT_EULA", you are expressing that you have a valid and existing license for the edition and version of SQL Server that you intend to use. You also agree that your use of SQL Server software running in a Docker container image will be governed by the terms of your SQL Server license.\n\nTo specify the edition, use the MSSQL_PID environment variable. Details can be found in the Environment Variables section of the configuration documentation.\n\nSQL Server Developer edition lets developers build any kind of application on top of SQL Server. It includes all the functionality of Enterprise edition, but is licensed for use as a development and test system, not as a production server. SQL Server Developer Edition cannot be used in a production environment. The SQL Server 2017 Developer Edition license terms are located here.',
    name: "Microsoft SQL Server",
    category: "Other",
    health: 44,
    code: "wcAazg",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "75e848aa-d5ce-401a-821d-bfa0deb3f4aa",
    isApproved: false,
    activeProjects: 123,
    projects: 273,
    description: "The open-source server for scalable web3 apps.",
    readme:
      "\nTemplate\n\nThis is the official community Railway template for thirdweb Engine maintained by the thirdweb community team. This template deploys thirdweb Engine, which lets you create and interact with backend developer wallets, enabling high throughput with automatic nonce and gas management. This template also deploys a PostgreSQL database to store data.\n\nRequirements\n\nPostgres (only supports v14+)\nRedis (only supports v7.2.4+)\nthirdweb API secret key. [Get it here]\nWallet address\n\nStep\n\nHow to deploy your self-hosted thirdweb Engine on the Railway\n\nOverview\n\nProduction-grade HTTP server to interact with any smart contract on any EVM. Engine is a backend HTTP server that reads, writes, and deploys contracts at production scale.\n\nCreate &amp; manage funded backend wallets to send blockchain transactions via authenticated APIs.\nBuild scalable blockchain apps with transaction retries, wallet nonce management, and gas estimation.\nOffer the best UX by deploying &amp; transacting with ERC-4337 compatible smart accounts, enabling sign-less flows and gasless transactions.\nGet a complete web3 infrastructure already set up with RPC, IPFS, and account abstraction infrastructure.\n\nAre you looking for a managed thirdweb Engine? Try Cloud-Hosted!\n\nDocumentation\n\nFor the complete documentation, please visit the thirdweb Engine documentation.\n\nGuides\n\nüìñ How to Deploy a Self-hosted thirdweb Engine On Railway In Less Than 3 Minutes\nüìñ Getting started with thirdweb Engine\nüì∫ Build scalable apps with a web3 backend\n\nFAQs\n\nHow are Engine and the thirdweb Contract SDK different?\nDoes Engine work with all thirdweb smart contracts?\nDoes Engine work with my non-thirdweb smart contract?\nWhat is the difference between cloud-hosted and self-hosted thirdweb Engine?\n\nSupport\n\nIf you need help, please submit a ticket to our support site.\n\nCommunity\n\nJoin our Discord community for thirdweb developers!",
    name: "thirdweb Engine",
    category: "Other",
    health: 96,
    code: "fcEVay",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "830a432e-d4de-4fab-958b-4d5137b30d28",
    isApproved: false,
    activeProjects: 8,
    projects: 19,
    description: "A free open source IT asset/license management system",
    readme:
      '\n    \n        \n    \n\n\nOpen Source Asset Management System\n\nThis is a FOSS project for asset management in IT Operations. Knowing who has which laptop, when it was purchased in order to depreciate it correctly, handling software licenses, etc.\n\nGeneral Features\n\nMobile-friendly for asset updates on the go\nWeb-based software so it works on any device\nSlack notification integration for checkin/checkout \nTons of security features to keep your data safe\nPre-defined "kits" for faster checkouts\nSAML login integration \nJAMF integration using Jamf2Snipe \nIncludes a robust JSON REST API \nTranslated into over 55 languages for easy localization \nPer-user language support for distributed teams\nOne-click (or cron) backups \nLDAP login/user sync \nGoogle Secure LDAP user sync \nSCIM support for automatic user provisioning\nnew! Kandji integration using Kandji2snipe\n\nAdmin Dashboard\n\nAt-a-glance access to recent activity and an overall view of what assets, accessories, consumables, and components you have.\n\nItems that have been checked in, checked out, recently updated or deleted, show up in a recent activity snapshot.\n\nAsset Management\n\nEasily see which assets are assigned, to whom, and their physical location. Check them back into inventory with one click, or click through to see the asset\'s complete history. Seeing what assets are currently deployed, pending (brand new awaiting software installs, out for repair), ready to deploy, or archived (lost/stolen, or broken) is quick and easy.\n\nEasily see which assets are assigned, to whom, and their physical location\nOne-click checkin\nAsset Models let you group common features\nRequire User Acceptance (End-User EULAs/Terms of Service) on Checkout\nEmail alerts for expiring warrantees and licenses\nIntegrates with most handheld barcode scanners and QR code reader apps\nQuick and easy asset auditing\nAdd your own custom fields for additional asset attributes\nEasily import and export assets\nGenerate QR code labels for easy mobile access and labels\nAssets marked as requestable can be requested by a user\nAssets retain full history including checkouts, checkins and maintenance\nOptional digital signatures on asset acceptance\n\nLicense Management\n\nYou get the same quick access with licenses, too. We‚Äôre working on making this even better, by letting you smartly handle multi-pack licenses with ease. Enable email alerts to get an email when your licenses are expiring.\n\nEmail Notifications\n\nSnipe-IT comes with beautiful built-in email notifications for users and administrators.\n\nSent to Users\nAsset Checkout/Checkin (with optional EULA and asset acceptance)\nCheckin Deadline Approaching\n\nSent to Admins\nAsset Checkout/Checkin\nExpected Checkin Report\nExpiring License Report\nLow Inventory Report\n\nIntegrations &amp; Robust JSON REST API\n\nEasily integrate your own proprietary systems and workflows with a powerful REST API. And while the native API is straightforward and well-documented, new open source SDKs are being developed by the community all the time to make integration even easier, including:\n\nKandji2Snipe\nUniFi to Snipe-IT\nJAMF\nGoogle App Scripts\nSAM command line interface option for using the Snipe-IT API\nSnipeSharp .NET module\nInQRy by Microsoft\nPowershell API Wrapper\n',
    name: "Snipe-IT",
    category: "Other",
    health: 92,
    code: "7Su9hO",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b788a770-1101-4e98-a608-7d158bfe6789",
    isApproved: false,
    activeProjects: 158,
    projects: 528,
    description: "All your business on one platform. Simple, efficient, yet affordable!",
    readme:
      "\n    \n        \n    \n\n\nAll your business on one platform.\nSimple, efficient, yet affordable!\n\nNotes:\n\nYour Odoo deployment will create a default administrator account with the username admin and the password admin. The first thing you will want to do is login and change your username and password from the preferences menu.\n\nCommunication to Postgres is done exclusively over the private network and the database is not exposed externally in any way by default, if you want to enable access from outside of the private network you can go to the databases settings to enable TCP proxying and enter the internal port (5432) the TCP proxy can be again removed at any point to close off external access.\n\nOverview\n\nImagine a vast collection of business apps at your disposal.\nGot something to improve? There is an app for that.\nNo complexity, no cost, just a one-click install.\n\nEach app simplifies a process and empowers more people.\nImagine the impact when everyone gets the right tool for the job, with perfect integration.\n\nWebsite Builder\n\nOdoo Website is changing how people think about website design. Thanks to its user-friendly and intuitive interface, you can create, manage, and customize your website effortlessly.\n\neCommerce\n\nSo good, it's easy to setup- yet, stunningly complete. Design appealing product pages with one of the best page builder on the market. Then, from marketing to operations, enjoy the simplicity of a unified platform.\n\nInvoicing\n\nThe simplified billing process you have been dreaming of! Create professional invoices, customize them to your liking, and get paid faster than ever.\n\nHelpdesk\n\nThe ticketing platform that supports your team, so they can support your customers. Say goodbye to complicated and embrace a new era of seamless, efficient, and customer-centric support with Odoo.\n\nInventory\n\nReduce stockouts, speed up operations, optimize routes and get real time visibility with Odoo's warehouse management app.\n\n",
    name: "Odoo",
    category: "Other",
    health: 96,
    code: "m3dQ_V",
    languages: ["Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "252947e9-2ebb-40f9-9ac8-ad110536ee4d",
    isApproved: false,
    activeProjects: 3,
    projects: 7,
    description: "The urPodder deployment template for Podcast Syncing.",
    readme:
      "This template provides a nice easy way to quickly set up a UrPodder instance which is a drop in replacement for gPodder.net (Which seems to have closed signup a while ago.)\n\nGet more info and code at the UrPodder Readme",
    name: "UrPodder",
    category: "Other",
    health: null,
    code: "y__BwA",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f607b05a-5665-418e-ae37-bca113d022ee",
    isApproved: false,
    activeProjects: 1,
    projects: 9,
    description: "Monitors ram usage and restarts when exceeded. Supports automatic restarts",
    readme:
      "This template will help you control and restart any services that continue to increase in ram usage due to a memory leak or some other reason.\n\nYou have 2 options:\n\nOption 1 allows you to monitor the ram usage of a service and restart it if it exceeds your ram usage limit. This works by setting MAX_RAM_CRON_INTERVAL_CHECK using your preferred cron configuration such as * * * * *. You must also set MAX_RAM_GB. For 1GB you just set 1, for anything less than 1GB it is 0.5 for example\n\nOption 2 allows you to restart the service at a defined cron interval regardless of the ram usage. You use the env CRON_INTERVAL_RESTART. You can define it for in the middle of the night to prevent impacting others such as 0 4 * * *\n\nYou must also set RAILWAY_API_TOKEN and TARGET_SERVICE_NAME. The target service name is the service you would like the ram monitor to monitor.\n\nThe template further uses RAILWAY_PROJECT_ID, RAILWAY_ENVIRONMENT_ID, and RAILWAY_ENVIRONMENT_NAME. These are however automatically set by railway. This means the monitor will only target the service name in the same environment it is  hosted. You could target other environments by changing these variables manually.",
    name: "Railway Ram Restart",
    category: "Automation",
    health: 100,
    code: "1FHSG9",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0085b132-cb73-4c14-abf7-1d8b2b3cf0b5",
    isApproved: false,
    activeProjects: 77,
    projects: 319,
    description: "Deploy an ecommerce backend and admin using Medusa",
    readme:
      "Note: this deploys a simple Medusa backend that's good for testing or simple use cases. For a recommended production deployment, refer to this template.\n\nDeploy a fully-fledged ecommerce backend and admin dashboard using Medusa.\n\nOnce the deployment finishes, you can access the admin dashboard at /app. Refer to this documentation to learn how to create an admin user.\n\nYou can refer to the Admin and Store API references to learn how to send requests to the Medusa backend.\n\nPlease note that this template doesn't use Redis or the production module for events and caching. Refer to the documentation to learn how to set them:\n\nSet redis_url in Medusa's configurations\nInstall and use the Redis Event Bus module\nInstall and use the Redis Cache module\n\nYou can refer to the Medusa documentation for guides related to troubleshooting, development, plugins, and more.\n\nPlease consider giving Medusa a star on GitHub.",
    name: "(v1) Simple Medusa Backend",
    category: "Other",
    health: 76,
    code: "pwNTJ1",
    languages: ["TypeScript", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0dcf93fe-986c-4f56-829d-f34fda7d5bd1",
    isApproved: false,
    activeProjects: 1,
    projects: 7,
    description: "A drop-in replacement for Redis to store data on a volume.",
    readme:
      "Overview\n\nApache Kvrocks deployed with the apache/kvrocks Docker image. A volume is mounted to the service to persist data.\n\nHow to use\n\nReference the KVROCKS_PRIVATE_URL variable from your service to connect to Kvrocks (e.g. ${{Kvrocks.KVROCKS_PRIVATE_URL}})\n\n\n\n",
    name: "Apache Kvrocks",
    category: "Storage",
    health: null,
    code: "wdpkLY",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7d251bf8-44f1-43a8-867b-e37b2846104c",
    isApproved: false,
    activeProjects: 3,
    projects: 19,
    description: "Nx Cloud Community Edition",
    readme:
      "Original Nx Cloud is a service that helps you and your team scale your Nx workspace. It provides a dashboard that gives you insights into your workspace's health, and it provides a set of CI integrations that help you and your team get the most out of Nx. We are currently working on the first version of Nx Cloud Community Edition.",
    name: "Nx Cloud CE",
    category: "Other",
    health: 80,
    code: "ORHjp6",
    languages: ["TypeScript", "JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8ed59a3f-c4f5-41cc-bf78-b0ce2343b355",
    isApproved: false,
    activeProjects: 10,
    projects: 45,
    description: "Personal CRM. Document your life.",
    readme:
      "\n    \n        \n    \n\n\nDocument your life.\nMonica is an open-source personal relationship management system, that lets you document your life and remember everything about your friends, family, and business relationships.\n\nIntroduction\nMonica is an open-source web application that enables you to document your life, organize, and log your interactions with your family and friends. We call it a PRM, or Personal Relationship Management. Imagine a CRM‚Äîa commonly used tool by sales teams in the corporate world‚Äîfor your friends and family.\n\nFeatures\n  Add and manage contacts\n  Define relationships between contacts\n  Reminders\n  Automatic reminders for birthdays\n  Ability to add notes to a contact\n  Ability to record how you met someone\n  Management of activities with a contact\n  Management of tasks\n  Management of addresses and all the different ways to contact someone\n  Management of contact field types\n  Management of a contact‚Äôs pets\n  Top of the art diary to keep track of what‚Äôs happening in your life\n  Ability to record how your day went\n  Upload documents and photos\n  Ability to define custom genders\n  Ability to define custom activity types\n  Ability to favorite contacts\n  Multiple vaults and users\n  Labels to organize contacts\n  Ability to define what section should appear on the contact sheet\n  Multiple currencies\n  Translated in 27 languages\n\nWho is it for?\nThis project is for people who want to document their lives and those who have difficulty remembering details about the lives of people they care about.\n\nWe‚Äôve also had a lot of positive reviews from people with Asperger syndrome, Alzheimer‚Äôs disease, and introverts who use our app every day.\n\nWhat Monica isn't\n  Monica is not a social network and it never will be. It‚Äôs not meant to be social. It‚Äôs designed to be the opposite: it‚Äôs for your eyes only.\n  Monica is not a smart assistant. It won‚Äôt guess what you want to do. It‚Äôs actually pretty dumb: it will only send you emails for the things you asked to be reminded of.\n  Monica does not have built-in AI with integrations like ChatGPT.\n  Monica is not a tool that will scan your data and do nasty things with it. It‚Äôs your data, your server, do whatever you want with it. You‚Äôre in control of your data.\n\nMonica Documentation",
    name: "Monica",
    category: "Other",
    health: 100,
    code: "G_bkYr",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ee143d18-d0e1-4e0a-acf3-038fb874e481",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "A Go + Go Templates + HTMX Starter",
    readme:
      "This template is meant to get you started with Go, templates, and HTMX for full stack applications. This is modeled after my personal site, and has blogging and server sent events built right in. For an example of a full site using this template, please check out my site: https://atri.dad\n\nOnce deployed, you should be good to begin modifying the code to make changes. There is nothing needed out of the box to set things up!",
    name: "GOTH Stack",
    category: "Starters",
    health: null,
    code: "Tu9vmY",
    languages: ["Go", "HTML", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0c3e8415-3be5-486c-bf7f-17b30603b882",
    isApproved: false,
    activeProjects: 15,
    projects: 68,
    description: "Self-hosted social media management",
    readme:
      "\n    \n                \n    \n\n\nEasily create, schedule, publish, and manage social media content in one place, with no limits or monthly subscription fees\n\nNotes:\n\nCommunication to MariaDB is done exclusively over the private network and the database is not exposed externally in any way by default, if you want to enable access from outside of the private network you can go to the databases settings to enable TCP proxying and enter the internal port (3306) the TCP proxy can be again removed at any point to close off external access.\n\nCommunication to KeyDB is done exclusively over the private network and the database is not exposed externally in any way by default, if you want to enable access from outside of the private network you can go to the databases settings to enable TCP proxying and enter the internal port (6379) the TCP proxy can be again removed at any point to close off external access.\n\nOverview\n\nMixpost is a robust and versatile social media management platform, designed to streamline social media operations and enhance content marketing strategies. Our platform empowers brands and businesses to effectively manage their online presence, leading them to success in the dynamic digital landscape. Mixpost's mission is to offer a comprehensive and powerful solution, enabling users to elevate their social media management and achieve tangible results.\n\nThe platform allows users to craft, organize, and schedule their content for times when their audience is most engaged and active. Mixpost's user-friendly scheduling system ensures that content publishing is seamless and efficient. It also facilitates team collaboration by allowing users to assign tasks, manage permissions, and monitor team performance, optimizing team interactions and workflow. Additionally, Mixpost automates post scheduling to ensure maximum audience reach and engagement, significantly boosting interaction and customer engagement.\n\nTrusted by a wide range of users, Mixpost stands out as a proficient and influential tool for social media management and content marketing. It is perfectly suited for enterprises, small to medium businesses, marketing agencies, solopreneurs, and e-commerce stores.\n\nSupported social platforms\n\nFacebook\nInstagram\nMastodon\nLinkedIn\nPinterest\nYouTube\nTikTok\nX (Previously Twitter)\n\nFeatures\n\nMixpost offers a multitude of features, making social media management more effective and simpler:\n\nStreamlined Social Account Management:\nBring all your social media accounts together in one place for smarter and more efficient management.\n\nAdvanced Analytics:\nGain insights into your audience's behavior and preferences. Mixpost provides detailed analytics, allowing you to choose from preset reports or create custom ones based on the data that matters most to you.\n\nPost Versions and Conditions:\nTailor your content for each social network and automate follow-up comments on high-performing posts, enhancing engagement and reach.\n\nEfficient Media Library:\nQuickly access and reuse media files like images, GIFs, and videos, and integrate with stock image sources for a diverse range of content.\n\nTeam Collaboration and Workspaces:\nFoster team collaboration with dedicated workspaces. Discuss ideas, manage tasks, and monitor performance, all from a centralized platform.\n\nQueue and Calendar Management:\nBuild a natural content posting schedule and visualize your strategy with an easy-to-use calendar.\n\nCustomizable Post Templates:\nBoost efficiency with reusable post templates, perfect for maintaining consistency across your social media channels.\n\nDynamic Variables and Hashtag Groups:\nInsert dynamic text and organize your hashtags strategically for increased post effectiveness.\nAnd many more features that make Mixpost a standout choice for managing social media and content marketing. Discover all the features in detail at Mixpost Features.\n\nIt is the ideal social media management software for bloggers, artisans, entrepreneurs, and marketing teams looking to optimize internal costs.",
    name: "Mixpost Pro",
    category: "Automation",
    health: 79,
    code: "cw5DSn",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "49a1a358-9387-4115-ab61-31d30d3ec5cf",
    isApproved: false,
    activeProjects: 2,
    projects: 9,
    description: "Self-Host spoo.me URL shortener on railway.app",
    readme:
      "spoo.me is a free, open-source service for shortening URLs. It offers URL statistics, a free API, and customization options. You can create custom slugs, add password protection, and manage link lifespans.\n\nDeploying steps:\n\nCreate a mongoDB server\nCreate 2 webhooks\nClick on the deploy now button of this template\nFill in the required environment variables\nWait for the deployment to finish",
    name: "spoo-me",
    category: "Other",
    health: 0,
    code: "_6W-dI",
    languages: ["Python", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "72afcceb-4653-49cb-957e-2543d296ae7d",
    isApproved: false,
    activeProjects: 16,
    projects: 23,
    description: "Postgres DB with Drizzle HTTP Proxy",
    readme:
      "This template deploys 2 services:\n\nPostgresql Database\nDrizzle HTTP Proxy Service\n\nThe Proxy Service is a node docker container running hono app which exposes a /query endpoint that drizzle can use to execute queries over http.\n\nGithub Repo: nmajor/drizzle-pg-proxy\nDocker Image: nmajor/drizzle-pg-proxy",
    name: "drizzle-pg-proxy",
    category: "Other",
    health: 100,
    code: "yvPIKJ",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0b6e9169-d25f-49d0-9bfb-06eec5d0ab95",
    isApproved: false,
    activeProjects: 10,
    projects: 35,
    description: "Platform to securely manage application configuration and secrets",
    readme:
      "Setup\nThis guide explains how to set up self-hosted Infisical using Docker this setup is based on the new Infisical Backend that uses Postgres. Infisical recommends using Kubernetes for high availability and large teams instead of Docker.\n\nThe default configuration are good to get you started. If you want to customize some of the functionality, you can do it now or later on.\n\nEmail services\nTo enable multi-factor authentication and other features it is required to add your own email service. Infisical has great documentation on how to set up an email service if you don‚Äôt have one, I would recommend resend.com and it is really simple to set up and free for low usage.\nIn your Railway project, in the ‚ÄúInfisical‚Äù service, add the following environment variables (if you already deployed the service make sure to redeploy for the changes to take effect):\n\nSMTP_HOST=\nSMTP_USERNAME=\nSMTP_PASSWORD=\nSMTP_PORT=\nSMTP_SECURE=\nSMTP_FROM_ADDRESS=\nSMTP_FROM_NAME=\nNote: I faced issues using port 587 from resend, and recommend using port 2465 instead.\n\n###SSO\nFollow Infisicals documentation here.\n\n###External services\nThis is why you have chosen Infisical, right? Infisical has a full list of the services that are supported and the environment variables that are required to be set. There is also great documentation on how to get the variables from the services you use.",
    name: "Infisical (with postgres)",
    category: "Other",
    health: 96,
    code: "CZTj7E",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b1783a42-1cb6-40a0-8288-9724e151d9cd",
    isApproved: false,
    activeProjects: 6,
    projects: 16,
    description: "A minimal dotenvx -environment variables- setup in a Node.js application",
    readme:
      "dotenvx in a Node.js environment\n\nWelcome to the Railway dotenvx Node.js template!\n\nThis example provides a minimal setup for managing environment variables using the dotenvx library in a Node.js environment (e.g. http or express server).\n\n‚ö†Ô∏è Disclaimer\n\nThis is a demonstration template. \nThe .env.keys file should not be commited in a real project.\n\n(cf. Development and production use)\n\n‚ú® Overview\n\ndotenvx is described as a better dotenv‚Äìfrom the creator of dotenv :\n\nrun anywhere (cross-platform)\nmulti-environment\nencrypted envs\n\nüöÄ Use as it stands\n\nClick the 'Deploy Now' button üëÜ\n\nDeploy with the pre-configured environment variables values (production):\n\nDOTENV_PRIVATE_KEY_PRODUCTION=706afc89eaa09ea9441d0f18f7c2fbbb6c77a201abf47aaa3a607e499a52c51d\n\nClick on the \"public domain\" link provided by Railway to observe the variables being loaded from the server.\n\nHello ${process.env.NAME ?? 'world'} from ${process.env.ENVIRONMENT ?? 'space'}!;\n\nThere you go! üí™\n\nPlease, note that there may be a delay of 2-3 minutes for the DNS to become aware of this new address. If this doesn't work after a few minutes, in the settings, delete the public address (Public Networking) and regenerate one.\n\n(Bonus) To use development environment variables, change the name and value of the private key:\n\nDOTENV_PRIVATE_KEY=78ef7c8b904d674d8a2e468714e4b770a3c7c76b3c09cdfa1bc80bcd862f0036\n\nüíª Development and production use\n\nInstalling dotenvx globally:\n\nnpm install @dotenvx/dotenvx -g\n\n&gt; Install globally as a cli to unlock dotenv for ANY language, framework, or platform. I am using (and recommending) this approach going forward. ‚Äì motdotla\n\nAdd (or uncomment) the .env.keys file in the .gitignore to prevent it from being tracked:\n\n.env.keys\n\nThen, at the root of the project, make sure you no longer track this file:\n\ngit rm -r --cached .\n\nIf there are, you can add and commit these changes.\n\nEncrypt your secrets and generate your own private keys file (.env.key):\n\n    3.1. Remove existing .env.keys file:\n\n    rm .env.keys\n\n    3.2 Setting up your custom .env and .env.production files:\n\n    NAME=YOUR_NAME\n    ENVIRONMENT=YOUR_ENV\n    YOUR_CUSTOM_KEY=YOUR_CUSTOM_VALUE\n\n    Make sure you don't have a DOTENV_PUBLIC_KEY variable in your environment files to generate new keys.\n\n    3.3. Encrypt created environment files:\n\n    dotenvx encrypt -f .env\n    dotenvx encrypt -f .env.production\n\nFinally, in Railway, update the variable with the value of the newly generated key: either DOTENV_PRIVATE_KEY or DOTENV_PRIVATE_KEY_PRODUCTION, depending on the variables you wish to load.\n\nAnd that's it! You've just regenerated the encrypted file and decryption keys. Each time you add, delete, or modify environment variables in your .env files, check that the values are encrypted before deploying the file on your server. It's that simple!\n\n‚öíÔ∏è Useful commands\n\nRetrieve initial value(s) from and encrypted .env file:\n\ndotenvx get {KEY} -f,--env-file]                   # Return a single value\ndotenvx get [-f,--env-file    # Return all values\n\nSet a new encrypted key/value:\n\ndotenvx set {KEY} {VALUE} -f,--env-file]\n\nDecrypt an encrypted environment file:\n\ndotenvx decrypt [-f,--env-file\n\nMore information and details about the CLI:\n\ndotenvx --help\n\nüìÑ Learn more\n\nBlog post:\ndotenvx ¬∑ Secure and Next-Generation dotenv Successor\n\ndotenvx:\nDocumentation\nRailway Express.js deployment tutorial\nGithub Repository\n\ndotenvx-node-template:\nREADME with instructions\nGithub Repository\nOpen an issue\n\nContribution\n\nContributions are welcome! If you encounter any issues or have suggestions for improvements, feel free to open an issue or submit a pull request.\n\nLicense\nThis template is licensed under the MIT License. See the LICENSE file for details.",
    name: "dotenvx (Node.js)",
    category: "Starters",
    health: 100,
    code: "zXEiVF",
    languages: ["JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b6c2d613-0e98-4d60-88b9-49a94153403e",
    isApproved: false,
    activeProjects: 13,
    projects: 61,
    description: "Basic structure of a Django app with Postgres, Celery, Redis, and Flower.",
    readme:
      "Django app with Postgres, Celery, Redis, and Flower. The deployed Celery repo should be changed to your own app repo with Celery added to your requirements file.\n\nUsing Flower for observing Celery tasks, with port 5555 open.\n\nRequires wiring up access between databases and app & Celery.",
    name: "Django with Celery",
    category: "Starters",
    health: 86,
    code: "a6vvTu",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "51bff5fa-60df-4a3f-846b-a9553db1d4ac",
    isApproved: false,
    activeProjects: 1,
    projects: 3,
    description: "Integration between Google Calendar and Todoist.",
    readme:
      "An integration between Todoist and Google Calendar retrieves events for the next 7 days from Google Calendar and creates a synchronized copy on Todoist.\n\nIt is possible to synchronize multiple Google accounts with Todoist, and for each of them, the title, description, date, duration, and meeting links of the events are synchronized. Additionally, the email associated with the Google account is added as a label on the Todoist task.\n\nContext: I primarily use Todoist to manage my daily tasks, but I'm required to use Google Calendar for work meetings. Having to use a second tool alongside Todoist isn't practical, and Todoist's default integration doesn't provide all the necessary information from Google Calendar: the meeting link and event description. That's why I created this integration.",
    name: "Todoist Sync",
    category: "Automation",
    health: 50,
    code: "AP1rpk",
    languages: ["TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "516ba0bc-ef60-45db-8e26-3ddd25650c5c",
    isApproved: false,
    activeProjects: 1,
    projects: 1,
    description: "Sync server of PenX  for cross device sync data",
    readme:
      "PenX is a structured note-taking app designed for personal use. In PenX, Privacy is first important thing. our mission is building a elegant tool to manage personal digital assets, like notes, tasks, ideas, password, documents.\n\nLocal-First - You own your data, in spite of the cloud\nPrivacy-First - Use End-To-End Encryption to sync data\nOpen Source - Trust our code, not our words\nVersion control - GitHub-Based Version control Out-of-box",
    name: "PenX sync server",
    category: "Other",
    health: null,
    code: "L-0Ee-",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "aee31030-c0b0-4150-9b98-5109943e8945",
    isApproved: false,
    activeProjects: 8,
    projects: 15,
    description: "Link your OpenAI Assistants to a database + Evaluate Assistant responses",
    readme:
      "OpenAI Assistants Link is a repo for linking local resources to the OpenAI Assistants API for leveraging and scaling assistant capabilities. This repo acts as a template for research or enterprise devs trying to scale the use of OpenAI assistants within their organization.\n\nOpenAI Assistants Link also offers a base-level approach to evaluating LLM responses from the Assistants API. These evaluations should act as a guideline for how to begin your approach to LLM evals and should be modified to best fit your needs.\n\nYou will probably find this repo useful if one or more of these points apply:\n\nYou are at a company that wants to use OpenAI and you have little experience with it.\nYou are at a company that wants to automate customer experiences with chatbots.\nYou have automated customer experiences with chatbots but have no testing/evaluation criteria.\nYou like learning!",
    name: "OpenAI Assistants LInk",
    category: "AI/ML",
    health: null,
    code: "-M8zbi",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "74435edd-94b2-4826-81bf-0b9930c04799",
    isApproved: false,
    activeProjects: 10,
    projects: 39,
    description: "A free and open-source resume builder",
    readme:
      "\n    \n                \n    \n\n\nA free and open-source resume builder that simplifies the process of creating, updating, and sharing your resume.\n\nOverview\n\nReactive Resume is a free and open-source resume builder that simplifies the process of creating, updating, and sharing your resume. With zero user tracking or advertising, your privacy is a top priority. The platform is extremely user-friendly and can be self-hosted in less than 30 seconds if you wish to own your data completely.\n\nIt's available in multiple languages and comes packed with features such as real-time editing, dozens of templates, drag-and-drop customisation, and integration with OpenAI for enhancing your writing.\n\nYou can share a personalised link of your resume to potential employers, track its views or downloads, and customise your page layout by dragging-and-dropping sections. The platform also supports various font options and provides dozens of templates to choose from. And yes, there's even a dark mode for a more comfortable viewing experience.\n\nStart creating your standout resume with Reactive Resume today!\n\nFeatures\n\nFree, forever and open-source\nNo telemetry, user tracking or advertising\nYou can self-host the application in less then 30 seconds\nAvailable in multiple languages (help add/improve your language here)\nUse your email address (or a throw-away address, no problem) to create an account\nYou can also sign in with your GitHub or Google account, and even set up two-factor authentication for extra security\nCreate as many resumes as you like under a single account, optimising each resume for every job application based on it‚Äôs description for a higher ATS score\nBring your own OpenAI API key and unlock features such as improving your writing, fixing spelling and grammar or changing the tone of your text in one-click\nTranslate your resume into any language using ChatGPT and import it back for easier editing\nCreate single page resumes or a resume that spans multiple pages easily\nCustomize the colours and layouts to add a personal touch to your resume.\nCustomise your page layout as you like just by dragging-and-dropping sections\nCreate custom sections that are specific to your industry if the existing ones don't fit\nJot down personal notes specific to your resume that's only visible to you\nLock a resume to prevent making any further edits (useful for master templates)\nDozens of templates to choose from, ranging from professional to modern\nDesign your resume using the standardised EuroPass design template\nSupports printing resumes in A4 or Letter page formats\nDesign your resume with any font that's available on Google Fonts\nShare a personalised link of your resume to companies or recruiters for them to get the latest updates\nYou can track the number of views or downloads your public resume has received\nBuilt with state-of-the-art (at the moment) and dependable technologies that's battle tested and peer reviewed by the open-source community on GitHub\nMIT License, so do what you like with the code as long as you credit the original author\nAnd yes, there‚Äôs a dark mode too üåì\n\nBuilt With\n\nReact (Vite), for the frontend\nNestJS, for the backend\nPostgres (primary database)\nPrisma ORM, which frees you to switch to any other relational database with a few minor changes in the code\nKeyDB (for caching, session storage and resume statistics)\nMinio (for object storage: to store avatars, resume PDFs and previews)\nBrowserless (for headless chrome, to print PDFs and generate previews)\nSMTP Server (to send password recovery emails)\nSentry (for error tracing and performance monitoring)\nGitHub/Google OAuth (for quickly authenticating users)\nLinguiJS and Crowdin (for translation management and localization)",
    name: "Reactive Resume",
    category: "Other",
    health: 96,
    code: "Op_-gE",
    languages: ["Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "acf2ae87-a39f-4418-8e5a-80a6586e0b8d",
    isApproved: false,
    activeProjects: 3,
    projects: 10,
    description: "The open-source web application to draw mind maps together.",
    readme:
      "\n    \n        \n    \n\n\nThe open-source web application to draw mind maps together.\nCollaborate together on mind maps\nShare mind maps with others - either by a QR code or by providing the link.\nAdd images, colors, font properties and links to nodes\nImport and export functionality\n\nColors and Images\nColors and images of mind maps exploit brain characteristics to express concepts in a more effective and lasting way\n\nRadial Tree\nHierarchical structure of mind maps exploits the radial geometry, which is divided on several levels and facilitates concept expressiveness.\n\nUses\nMind maps are particularly effective to learn or organize ideas, for example in educational or business contexts.",
    name: "TeamMapper",
    category: "Other",
    health: 100,
    code: "SXkslC",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "344738cd-fda9-41b4-bdd1-2784283bcace",
    isApproved: false,
    activeProjects: 8,
    projects: 11,
    description: "Track, Organize, and Manage your Things.",
    readme:
      "\n    \n        \n    \n\n\nTrack, Organize, and Manage your Things.\nHomebox is the inventory and organization system built for the Home User! With a focus on simplicity and ease of use, Homebox is the perfect solution for your home inventory, organization, and management needs. While developing this project, I've tried to keep the following principles in mind:\n\nSimple - Homebox is designed to be simple and easy to use. No complicated setup or configuration required. Use either a single docker container, or deploy yourself by compiling the binary for your platform of choice.\nBlazingly Fast - Homebox is written in Go, which makes it extremely fast and requires minimal resources to deploy. In general idle memory usage is less than 50MB for the whole container.\nPortable - Homebox is designed to be portable and run on anywhere. We use SQLite and an embedded Web UI to make it easy to deploy, use, and backup.\n\nProject Status\nHomebox is currently in early active development and is currently in beta stage. This means that the project may still be unstable and clunky. Overall, we are striving to not introduce any breaking changes and have checks in place to ensure migrations and upgrades are smooth. However, we do not guarantee that there will be no breaking changes. We will try to keep the documentation up to date as we make changes.\n\nFeatures\nCreate and Manage Items by providing a name and a description - That's it! Homebox requires only a few details to be provided to create an item, after that you can specify as much detail as you want, or hide away some of the things you won't ever need.\nOptional Details for Items include\n  Warranty Information\n  Sold To Information\n  Purchased From Information\n  Item Identifications (Serial, Model, etc)\n  Categorized Attachments (Images, Manuals, General)\n  Arbitrary/Custom Fields\nCSV Import/Export for quickly creating and managing items\nCustom Reporting\nBill of Materials Export\nQR Code Label Generator\nOrganize Items by creating Labels and Locations and assigning them to items.\nMulti-Tenant Support - All users are placed in a group and can only see items in their group. Invite family members to your group, or share an instance among friends!",
    name: "Homebox",
    category: "Other",
    health: 100,
    code: "A6PKuM",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "302aab96-dff6-4a3e-aab8-ce244ca61f34",
    isApproved: false,
    activeProjects: 301,
    projects: 517,
    description: "one-click deploy your private ChatGPT/Cluade/LLMs chatbot application",
    readme:
      "\n\nü§Ø Lobe Chat - An open-source, modern-design ChatGPT/LLMs UI/Framework. Supports speech-synthesis, multi-modal, and extensible plugin system.\n\nOne-click FREE deployment of your private OpenAI ChatGPT/Claude/Gemini/Groq/Ollama chat application.\n\n‚ú® Features\n\n1. Multi-Model Service Provider Support\n\nIn the continuous development of LobeChat, we deeply understand the importance of diversity in model service providers for meeting the needs of the community when providing AI conversation services. Therefore, we have expanded our support to multiple model service providers, rather than being limited to a single one, in order to offer users a more diverse and rich selection of conversations.\n\nIn this way, LobeChat can more flexibly adapt to the needs of different users, while also providing developers with a wider range of choices.\n\nSupported Model Service Providers\n\nWe have implemented support for the following model service providers:\n\nAWS Bedrock: Integrated with AWS Bedrock service, supporting models such as Claude / LLama2, providing powerful natural language processing capabilities. Learn more\nAnthropic (Claude): Accessed Anthropic's Claude series models, including Claude 3 and Claude 2, with breakthroughs in multi-modal capabilities and extended context, setting a new industry benchmark. Learn more\nGoogle AI (Gemini Pro, Gemini Vision): Access to Google's Gemini series models, including Gemini and Gemini Pro, to support advanced language understanding and generation. Learn more\nChatGLM: Added the ChatGLM series models from Zhipuai (GLM-4/GLM-4-vision/GLM-3-turbo), providing users with another efficient conversation model choice. Learn more\nMoonshot AI (Dark Side of the Moon): Integrated with the Moonshot series models, an innovative AI startup from China, aiming to provide deeper conversation understanding. Learn more\nGroq: Accessed Groq's AI models, efficiently processing message sequences and generating responses, capable of multi-turn dialogues and single-interaction tasks. Learn more\nOpenRouter: Supports routing of models including Claude 3, Gemma, Mistral, Llama2 and Cohere, with intelligent routing optimization to improve usage efficiency, open and flexible. Learn more\n01.AI (Yi Model): Integrated the 01.AI models, with series of APIs featuring fast inference speed, which not only shortened the processing time, but also maintained excellent model performance. Learn more\n\n2. Local Large Language Model (LLM) Support\n\n\n\nTo meet the specific needs of users, LobeChat also supports the use of local models based on Ollama, allowing users to flexibly use their own or third-party models.\n\n&gt; TIP\n&gt;\n&gt; Learn more about üìò Using Ollama in LobeChat by checking it out.\n\n3. Model Visual Recognition\n\n\n\nLobeChat now supports OpenAI's latest gpt-4-vision model with visual recognition capabilities,\na multimodal intelligence that can perceive visuals. Users can easily upload or drag and drop images into the dialogue box,\nand the agent will be able to recognize the content of the images and engage in intelligent conversation based on this,\ncreating smarter and more diversified chat scenarios.\n\nThis feature opens up new interactive methods, allowing communication to transcend text and include a wealth of visual elements.\nWhether it's sharing images in daily use or interpreting images within specific industries, the agent provides an outstanding conversational experience.\n\n4. TTS &amp; STT Voice Conversation\n\n\n\nLobeChat supports Text-to-Speech (TTS) and Speech-to-Text (STT) technologies, enabling our application to convert text messages into clear voice outputs,\nallowing users to interact with our conversational agent as if they were talking to a real person. Users can choose from a variety of voices to pair with the agent.\n\nMoreover, TTS offers an excellent solution for those who prefer auditory learning or desire to receive information while busy.\nIn LobeChat, we have meticulously selected a range of high-quality voice options (OpenAI Audio, Microsoft Edge Speech) to meet the needs of users from different regions and cultural backgrounds.\nUsers can choose the voice that suits their personal preferences or specific scenarios, resulting in a personalized communication experience.\n\n5. Text to Image Generation\n\n\n\nWith support for the latest text-to-image generation technology, LobeChat now allows users to invoke image creation tools directly within conversations with the agent. By leveraging the capabilities of AI tools such as DALL-E 3, MidJourney, and Pollinations, the agents are now equipped to transform your ideas into images.\n\nThis enables a more private and immersive creative process, allowing for the seamless integration of visual storytelling into your personal dialogue with the agent.\n\n6. Plugin System (Function Calling)\n\n\n\nThe plugin ecosystem of LobeChat is an important extension of its core functionality, greatly enhancing the practicality and flexibility of the LobeChat assistant.\n\nBy utilizing plugins, LobeChat assistants can obtain and process real-time information, such as searching for web information and providing users with instant and relevant news.\n\nIn addition, these plugins are not limited to news aggregation, but can also extend to other practical functions, such as quickly searching documents, generating images, obtaining data from various platforms like Bilibili, Steam, and interacting with various third-party services.\n\n7. Agent Market (GPTs)\n\n\n\nIn LobeChat Agent Marketplace, creators can discover a vibrant and innovative community that brings together a multitude of well-designed agents,\nwhich not only play an important role in work scenarios but also offer great convenience in learning processes.\nOur marketplace is not just a showcase platform but also a collaborative space. Here, everyone can contribute their wisdom and share the agents they have developed.\n\n8. Mobile Device Adaptation\n\n\n\nWe have carried out a series of optimization designs for mobile devices to enhance the user's mobile experience. Currently, we are iterating on the mobile user experience to achieve smoother and more intuitive interactions. If you have any suggestions or ideas, we welcome you to provide feedback through GitHub Issues or Pull Requests.\n\n* What's more\n\nBeside these features, LobeChat also have much better basic technique underground:\n\n[x] üí® Quick Deployment: Using the Vercel platform or docker image, you can deploy with just one click and complete the process within 1 minute without any complex configuration.\n[x] üåê Custom Domain: If users have their own domain, they can bind it to the platform for quick access to the dialogue agent from anywhere.\n[x] üîí Privacy Protection: All data is stored locally in the user's browser, ensuring user privacy.\n[x] üíé Exquisite UI Design: With a carefully designed interface, it offers an elegant appearance and smooth interaction. It supports light and dark themes and is mobile-friendly. PWA support provides a more native-like experience.\n[x] üó£Ô∏è Smooth Conversation Experience: Fluid responses ensure a smooth conversation experience. It fully supports Markdown rendering, including code highlighting, LaTex formulas, Mermaid flowcharts, and more.\n\n&gt; ‚ú® more features will be added when LobeChat evolve.\n",
    name: "Lobe Chat",
    category: "AI/ML",
    health: 68,
    code: "FB6HrV",
    languages: ["TypeScript", "JavaScript", "CSS", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3236d793-fccd-4cba-8723-c0e66078f3c2",
    isApproved: false,
    activeProjects: 7,
    projects: 19,
    description: "Automate code & data workflows with interactive notebooks",
    readme:
      'Livebook\n\nWebsite\n\nLivebook is a web application for writing interactive and collaborative code notebooks. It features:\n\n  Code notebooks with Markdown support and Code cells where Elixir code is evaluated on demand.\n\n  Rich code editor through CodeMirror: with support for autocompletion, inline documentation, code formatting, etc.\n\n  Interactive results via Kino: display Vega-Lite charts, tables, maps, and more.\n\n  Automation: use Smart cells to perform high-level tasks and write notebooks faster than ever. Query databases, plot charts, build maps, and more directly from Livebook\'s UI.\n\n  Reproducible: Livebook ensures your code runs in a predictable order, all the way down to package management. It also tracks your notebook state, annotating which parts are stale.\n\n  Collaboration: multiple users can work on the same notebook at once, no additional setup required.\n\n  Decentralized: Livebook is open-source and you can run it anywhere. The "Run in Livebook" badge makes it easy to import any Livebook into your own Livebook.\n\n  Versionable: notebooks are stored in the .livemd format, which is a subset of Markdown with support for diagrams via Mermaid and for mathematical formulas via KaTex. .livemd files can be shared and play well with version control.\n\n  Custom runtimes: when executing Elixir code, you can either start a fresh Elixir instance, connect to an existing node, or run it inside an existing Elixir project, with access to all of its modules and dependencies. This means Livebook can be a great tool to introspect and document existing projects too.\n\nGetting started\n\nDefault password can be found in the environment variables.\n\nSecurity considerations\n\nLivebook is built to document and execute code. Anyone with access to a Livebook instance\nwill be able to access any file and execute any code in the machine Livebook is running.\n\nEnvironment variables\nLIVEBOOK_PASSWORD - sets a password that must be used to access Livebook. Must be at least 12 characters. Defaults to token authentication.\nLIVEBOOK_PORT - sets the port Livebook runs on. Defaults to 8080.',
    name: "Livebook",
    category: "Analytics",
    health: 100,
    code: "4uLt1s",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6ae6bf7f-8255-4a5a-8ec4-29c8ca7c1e73",
    isApproved: false,
    activeProjects: 28,
    projects: 48,
    description: "A self-hosted GitHub Actions runner",
    readme:
      'Run GitHub Actions in Railway if, for example, you want to access your services or databases using private networking.\n\nCaution! GitHub recommends only using self-hosted runners for private repositories!!\n\nPer-repository runner\n\nGo to your repository settings, then click actions, then runners, then "New self-hosted runner". Under the "configure" section, you\'ll see a line with --url and --token. Put the value of --url in the REPO_URL env var, and the value of --token in the RUNNER_TOKEN  env var.\n\nOrganization-wide runner\n\nGo to your org\'s settings, then actions, then runners. Click "New Runner", then "Self-hosted runner". Under "Configure", copy the value after --token and paste it into the RUNNER_TOKEN env var.\n\nSet RUNNER_SCOPE to org and ORG_NAME to the name of your org.\n\nUsing it in GitHub Actions\n\nJust set runs-on to self-hosted in your workflow.\n\nMore config\n\nSee the GitHub repo for all available environment variables and tags.\n\nApp sleeping\n\nDo not use app sleeping with this template. Runners work by long-polling and will not wake themselves up when there\'s a new job to run.',
    name: "GitHub Actions Runner",
    category: "Other",
    health: 20,
    code: "cd7y1G",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "382bcc24-9b1c-4c3f-b08d-fc83f73e9566",
    isApproved: false,
    activeProjects: 29,
    projects: 245,
    description: "Open-source project management that unlocks customer value",
    readme:
      "\n\n\n\n  \n\n\n\nPlane\nOpen-source project management that unlocks customer value.\n\n\n    Website ‚Ä¢\n    Releases ‚Ä¢\n    Twitter ‚Ä¢\n    Documentation\n\n\n\n    \n      \n    \n\n\nMeet Plane. An open-source software development tool to manage issues, sprints, and product roadmaps with peace of mind. üßò‚Äç‚ôÄÔ∏è\n\n‚ö° Setup\n\nInstance admin can configure instance settings using our God-mode feature.\n\nTo configure your instance, visit your domain/god-mode and enter your email and chose a password.\n\nüöÄ Features\n\nIssues: Quickly create issues and add details using a powerful, rich text editor that supports file uploads. Add sub-properties and references to problems for better organization and tracking.\n\nCycles\n  Keep up your team's momentum with Cycles. Gain insights into your project's progress with burn-down charts and other valuable features.\n\nModules: Break down your large projects into smaller, more manageable modules. Assign modules between teams to track and plan your project's progress easily.\n\nViews: Create custom filters to display only the issues that matter to you. Save and share your filters in just a few clicks.\n\nPages: Plane pages, equipped with AI and a rich text editor, let you jot down your thoughts on the fly. Format your text, upload images, hyperlink, or sync your existing ideas into an actionable item or issue.\n\nAnalytics: Get insights into all your Plane data in real-time. Visualize issue data to spot trends, remove blockers, and progress your work.\n\nDrive (coming soon): The drive helps you share documents, images, videos, or any other files that make sense to you or your team and align on the problem/solution.\n\nüì∏ Screenshots\n\n\n    \n      \n    \n  \n\n    \n      \n    \n  \n  \n    \n      \n    \n  \n  \n    \n      \n    \n  \n   \n    \n      \n    \n  \n\n   \n    \n      \n    \n  \n\n",
    name: "Plane",
    category: "Observability",
    health: 92,
    code: "MrCqPF",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8e33e9ae-8f83-4362-8aea-1b12a646804a",
    isApproved: false,
    activeProjects: 14,
    projects: 76,
    description: "A headless open-source GraphQL commerce platform for the modern web.",
    readme:
      "Vendure is an open-source headless e-commerce platform built on Node.js with GraphQL, Nest & TypeScript, with a focus on developer productivity and ease of customization.\n\nThis template deploys an official quick start repo to get it easily deploy on Railway.\n\nSee also:\n\nDocs\nOfficial repository\nOne-click-deploy\n\n\n[1]: https://www.vendure.io/\n[2]: https://docs.vendure.io/guides/deployment/deploy-to-railway/\n[3]: https://github.com/vendure-ecommerce/vendure",
    name: "Vendure",
    category: "Starters",
    health: 100,
    code: "mFsdab",
    languages: ["TypeScript", "Handlebars", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6710ec44-a929-4d86-b5cd-fa53482e9026",
    isApproved: false,
    activeProjects: 38,
    projects: 118,
    description: "Ready to use right after launch! No setup required.",
    readme:
      "Ready to use\nThis template doesn't require any customization. You can launch it and start publishing articles right away. Add MailGun credetials to enable automated email sending. This is useful if you want to allow members to signup, and send news letters.\n\nCustomization friendly\nThis template is launched from a git repository, making it easy to customize should you want to. Simple eject, and clone your local version to make customizations - the source code is unpacked unlike all the docker versions of ghost.\n\nInstructions: https://funkyton.com/ghost-on-railway-deploy-your-blog-with-1-click/\n\nOptional config\nCloudinary URL to sotre youre media in cloudinary\nMailGun credentials for email sending.\n\nAbout ghost: Ghost is a powerful app for professional publishers to create, share, and grow a business around their content. It comes with modern tools to build a website, publish content, send newsletters & offer paid subscriptions to members.",
    name: "Ghost blog ",
    category: "Blogs",
    health: 96,
    code: "ZQcedl",
    languages: ["JavaScript", "CSS", "HTML", "Handlebars", "XSLT"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8f72b25c-9fd1-4f66-9c53-84c0146eddfe",
    isApproved: false,
    activeProjects: 366,
    projects: 402,
    description: "Python API handles user reg., login, authentication, and profile update.",
    readme:
      'üêç Python Flask User Register/Login API\n\nThis is a Python Flask application that provides various \nAPI routes for user registration, login, and profile update actions.\n\nThe application uses MongoDB for storing user data and Flask \nJWT-Extended for handling JWT-based authentication.\n\nConfiguration\n\nApplication configuration variables are declared in a .env file. Here\'s a sample .env file:\n\nFLASK_APP=app\nFLASK_ENV=development\nMONGO_URL=mongodb://localhost:27017\nMONGO_DB=test\nJWT_SECRET_KEY=secret123\n\n\nKey configuration variables include:\n\nFLASK_APP: The application startup file\nFLASK_ENV: The current application environment. This should be production in a production environment.\nMONGO_URL: Connection string for MongoDB instance\nMONGO_DB: The database for the application within MongoDB\nJWT_SECRET_KEY: Secret key to sign JWTs\n\nApplication Structure\n\nThe main application is launched from app.py at the root directory.\nThe auth_routes.py file contains the /login, /register, /logout, and /checkauth routes used for user authentication.\nThe core/init.py file is the package initializer for the core package. This is where Flask and JWT are configured, and where routes are registered to the application.\nThe User model in user.py represents a user in the system, which includes a pre-save hooks to hash passwords and update the timestamp.\n\nSetup and Usage\n\nClone the repository\n\n    git clone https://github.com/CrACK000/easy-python-backend-app.git\n\n\nInstall the requirements\n\n    pip install -r requirements.txt\n\n\nRun the application\n\n    flask run\n\n\nAccess the apis at http://localhost:5000 to register, login or perform other actions.\n\n‚úâÔ∏è API Testing with Postman\n\nThis Python Flask API provides different endpoints for managing user registration, login, and profile updates. \nThe API can be tested using different tools like Postman, cURL etc. In this documentation, we demonstrate \nhow to test the API using the Postman tool.\n\nBefore testing, ensure that you are running your application locally. Refer to the main README.md for the instructions on how to run the application.\n\nImporting Postman Collection\n\nA Postman collection called postman_collection.json is included in the root directory \nof this project\'s GitHub repository. This collection includes the requests needed to \ntest the user registration, login, profile checking and profile updates.\n\nTo use this collection:\n\nClone or download this repository to your local machine.\nOpen Postman.\nClick on the Import button on the top left corner.\nSelect the postman_collection.json file from your local directory.\n\nThe collection should be imported into Postman, and you can use it to test the different endpoints.\n\nRegister\n\nMethod : POST\nURL Path : /register\nFormdata : username password email\n\nThis endpoint is used to register a new user. The request should include username, password and email in the form data.\n\nLogin\n\nMethod : POST\nURL Path : /login\nFormdata : username password\n\nThis endpoint is used to login a user. The request should include username and password in the form data. \nOn successful login, it returns a JWT access token, remember to replace it with  for the \nfollowing requests.\n\nCheck Auth\n\nMethod : GET\nURL Path : /checkAuth\nHeaders : Authorization : Bearer \n\nThis endpoint is used to verify the user\'s JWT access token is valid or not. Replace  with \nthe token rendered after user login.\n\nEdit Profile\n\nMethod : PATCH\nURL Path : /updateProfile\nHeaders : Authorization : Bearer \nFormdata : new_username\n\nThis endpoint is used to updated the username of the user. Replace  with the token rendered \nafter user login. new_username is the username you want to update to.\n\nNote\n\nThe JWT token obtained from the /login endpoint will be used in the Authorization header for \nthe /checkAuth and /editProfile requests as Bearer . Note that this token will expire \naccording to the expiration time set in your application (default is 15 minutes), so if your \ntesting takes longer than that, you will need to login again to get a new token.\n\nIf the token expires or is otherwise incorrect, the server will respond with a 401 error. \nThis means "unauthorized", so if you see this, you know you need to check your authorization header.\n\nüêã Dockerized Flask Application\n\nThis application is a simple Flask application that has been Dockerized for consistency across \ndifferent environments.\n\nBuilding the Docker Image\n\nTo build the Docker image, navigate to the directory containing the Dockerfile and run:\n\nReplace "my-app" with the name you want to assign to the Docker image.\n\nRunning the Docker Image\n\nTo run the image, enter:docker run -p 5000:5000 my-appReplace "my-app" with the name of the Docker image you created. This will start a Docker container \nfrom the image and bind it to port 5000.\n\nTesting the Application\n\nOnce the Docker container is running, you can test the application by navigating to \nhttp://localhost:5000 in your web browser.\n\nStopping the Docker Container\n\nTo stop a running Docker container, first determine the container ID by running:docker psThen, stop the container by running:docker stop `\n\nReplace  with the actual container ID.\n\n\nRemember to stop the Docker container when you\'re finished to free up system resources.',
    name: "Python Authentication API Beta",
    category: "Authentication",
    health: 44,
    code: "dRB-2L",
    languages: ["Python", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "cc8bb640-990d-434d-b5c6-9bf46838dea3",
    isApproved: false,
    activeProjects: 5,
    projects: 25,
    description: "A high-performance, distributed memory object caching system",
    readme:
      '\n    \n        \n    \n\n\nMemcached\n\nA high-performance, distributed memory object caching system\n\nNotes:\n\nThis template comes exposed publicly via the TCP proxy, yet it does not come with any authentication mechanism, you may want to remove its public TCP proxy and connect to it exclusively over the private network.\n\nMemcached\n\nFree &amp; open source, high-performance, distributed memory object caching system, generic in nature, but intended for use in speeding up dynamic web applications by alleviating database load.\n\nMemcached is an in-memory key-value store for small arbitrary data (strings, objects) from results of database calls, API calls, or page rendering.\n\nMemcached is simple yet powerful. Its simple design promotes quick deployment, ease of development, and solves many problems facing large data caches. Its API is available for most popular languages.\n\nSee the memcached.org about page for a brief overview.\n\nHow Does It Work?\n\nMemcached is a developer tool, not a "code accelerator", nor is it database middleware. If you\'re trying to set up an application you have downloaded or purchased to use memcached, read your app\'s documentation. This wiki and community will not be able to help you.\n\nWhat is it Made Up Of?\n\nClient software, which is given a list of available memcached servers.\nA client-based hashing algorithm, which chooses a server based on the "key".\nServer software, which stores values with their keys into an internal hash table.\nLRU, which determine when to throw out old data (if out of memory), or reuse memory.\n\nDesign Philosophy\n\nSimple Key/Value Store\n\nThe server does not care what your data looks like. Items are made up of a key, an expiration time, optional flags, and raw data. It does not understand data structures; you must upload data that is pre-serialized. Some commands (incr/decr) may operate on the underlying data, but in a simple manner.\n\nLogic Half in Client, Half in Server\n\nA "memcached implementation" is partially in a client, and partially in a server. Clients understand how to choose which server to read or write to for an item, what to do when it cannot contact a server.\n\nThe servers understand how to store and fetch items. They also manage when to evict or reuse memory.\n\nServers are Disconnected From Each Other\n\nMemcached servers are unaware of each other. There is no crosstalk, no syncronization, no broadcasting, no replication. Adding servers increases the available memory. Cache invalidation is simplified, as clients delete or overwrite data on the server which owns it directly.\n\nO(1)\n\nAll commands are implemented to be as fast and lock-friendly as possible. This gives allows near-deterministic query speeds for all use cases.\n\nQueries on slow machines should run in well under 1ms. High end servers can serve millions of keys per second in throughput.\n\nForgetting is a Feature\n\nMemcached is, by default, a Least Recently Used cache. Items expire after a specified amount of time. Both of these are elegant solutions to many problems; Expire items after a minute to limit stale data being returned, or flush unused data in an effort to retain frequently requested information.\n\nNo "pauses" waiting for a garbage collector ensures low latency, and free space is lazily reclaimed.\n\nSee LRU documentation for more details on the latest algorithm.\n\nCache Invalidation\n\nRather than broadcasting changes to all available hosts, clients directly address the server holding the data to be invalidated.',
    name: "Memcached",
    category: "Other",
    health: 100,
    code: "jhyKTw",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ecf15d20-1851-4931-a390-eacd8ab711fd",
    isApproved: false,
    activeProjects: 25,
    projects: 41,
    description: "Self-hosted bookmark manager that is designed be to be minimal, fast",
    readme:
      "linkding is a bookmark manager that you can host yourself.\nIt's designed be to be minimal, fast, and easy to set up using Docker.\n\nThe name comes from:\nlink which is often used as a synonym for URLs and bookmarks in common language\nDing which is German for thing\n...so basically something for managing your links\n\nFeature Overview:\nClean UI optimized for readability\nOrganize bookmarks with tags\nAdd notes using Markdown\nRead it later functionality\nShare bookmarks with other users\nBulk editing\nAutomatically provides titles, descriptions and icons of bookmarked websites\nAutomatically creates snapshots of bookmarked websites on the Internet Archive Wayback Machine\nImport and export bookmarks in Netscape HTML format\nInstallable as a Progressive Web App (PWA)\nExtensions for Firefox and Chrome, as well as a bookmarklet\nLight and dark themes\nSSO support via OIDC or authentication proxies\nREST API for developing 3rd party apps\nAdmin panel for user self-service and raw data access\n\nYou get variables to login:\nLD_SUPERUSER_NAME will be filled by yourself\nLD_SUPERUSER_PASSWORD will be a random 32-length string",
    name: "linkding",
    category: "Other",
    health: 86,
    code: "BxdomX",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d9086b2c-d1c8-4989-8ba7-ae519a33326b",
    isApproved: false,
    activeProjects: 11,
    projects: 33,
    description: "Open-source collaborative bookmark manager",
    readme:
      "\n    \n        \n    \n\n\nOpen-source collaborative bookmark manager\n\nSelf-hosted collaborative bookmark manager to collect, organize, and preserve webpages and articles\n\nNotes:\n\nCommunication to Postgres is done exclusively over the private network and the database is not exposed externally in any way by default, if you want to enable access from outside of the private network you can go to the databases settings to enable TCP proxying and enter the internal port (5432) the TCP proxy can be again removed at any point to close off external access. A redeploy is needed after adding the TCP proxy.\n\nThe objective is to organize useful webpages and articles you find across the web in one place, and since useful webpages can go away (see the inevitability of Link Rot), Linkwarden also saves a copy of each webpage as a Screenshot and PDF, ensuring accessibility even if the original content is no longer available.\n\nAdditionally, Linkwarden is designed with collaboration in mind, sharing links with the public and/or allowing multiple users to work together seamlessly.\n\nFeatures\n\nüì∏ Auto capture a screenshot, PDF, and readable view of each webpage.\nüèõÔ∏è Send your webpage to Wayback Machine (archive.org) for a snapshot. (Optional)\nüìÇ Organize links by collection, sub-collection, name, description and multiple tags.\nüë• Collaborate on gathering links in a collection.\nüéõÔ∏è Customize the permissions of each member.\nüåê Share your collected links and preserved formats with the world.\nüìå Pin your favorite links to dashboard.\nüîç Full text search, filter and sort for easy retrieval.\nüì± Responsive design and supports most modern browsers.\nüåì Dark/Light mode support.\nüß© Browser extension, managed by the community. Star it here!\n‚¨áÔ∏è Import and export your bookmarks.\nüîê SSO integration. (Enterprise and Self-hosted users only)\nüì¶ Installable Progressive Web App (PWA).\nüçé iOS Shortcut to save links to Linkwarden.\nüîë API keys.\n‚úÖ Bulk actions.\n‚ú® And so many more features!\n\nDocs\n\nFor information on how to get started or to set up your own instance, please visit the documentation.",
    name: "Linkwarden",
    category: "Other",
    health: 86,
    code: "CjEpfR",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5bf7c1e2-e5b6-43e0-9ee5-531e941b5fd1",
    isApproved: false,
    activeProjects: 14,
    projects: 37,
    description: "The Smartest SQL + noSQL Database Client",
    readme:
      "\n    \n        \n    \n\n\nThe Smartest SQL+noSQL Database Client\n\nDatabase manager for MySQL, PostgreSQL, SQL Server, MongoDB, SQLite and others\n\nDbGate is cross-platform database manager. It's designed to be simple to use and effective, when working with more databases simultaneously. But there are also many advanced features like schema compare, visual query designer, chart visualisation or batch export and import.\n\nSupported databases\n\nMySQL\nPostgreSQL\nSQL Server\nOracle (experimental)\nMongoDB\nRedis\nSQLite\nAmazon Redshift\nCockroachDB\nMariaDB\n\nFeatures\n\nTable data editing, with SQL change script preview\nEdit table schema, indexes, primary and foreign keys\nCompare and synchronize database structure\nER diagram\nLight and dark theme\nMaster/detail views, foreign key lookups\nQuery designer\nForm view for comfortable work with tables with many columns\nJSON view on MongoDB collections\nExplore tables, views, procedures, functions, MongoDB collections\nSQL editor\n  execute SQL script\n  SQL code formatter\n  SQL code completion\n  Add SQL LEFT/INNER/RIGHT join utility\nMongo JavaScript editor, execute Mongo script (with NodeJs syntax)\nRedis tree view, generate script from keys, run Redis script\nRuns as application for Windows, Linux and Mac. Or in Docker container on server and in web Browser on client.\nImport, export from/to CSV, Excel, JSON, NDJSON, XML\nFree table editor - quick table data editing (cleanup data after import/before export, prototype tables etc.)\nArchives - backup your data in NDJSON files on local filesystem (or on DbGate server, when using web application)\nCharts, export chart to HTML page\nFor detailed info, how to run DbGate in docker container, visit docker hub\nExtensible plugin architecture\nPerspectives - nested table view over complex relational data, query designer on MongoDB databases",
    name: "DbGate",
    category: "Other",
    health: 100,
    code: "dbgate",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0a9ae9c5-9cd9-41b9-b7ec-f16b5f3b4a45",
    isApproved: false,
    activeProjects: 2,
    projects: 9,
    description: "Doku is an open-source LLMOps tool to monitor & evaluate LLM applications",
    readme:
      '\nDoku: Open Source Observability for LLMs\n\nDocumentation | Quickstart | Python SDK | Node SDK | Helm Chart\n\n\nDoku is an open-source LLMOps tool engineered to enables developers with comprehensive capabilities to monitor, analyze, and optimize LLM applications. \nIt provides valuable real-time data on LLM usage, performance, and costs. Through seamless integrations with leading LLM platforms, including OpenAI, Cohere, Mistral and Anthropic, Doku acts as a central command center for all your LLM needs. It effectively guides your efforts, ensuring that your LLM applications not only operate at peak efficiency but also scale successfully.\n\nThis template automates the installation and pre-configuration of the following components:\nDoku Ingester\nDoku Client\nClickHouse\n\nNext Steps\n\nüîë Access Doku UI and Generate an API Key\n\nWith Doku running, the next step is to access the Doku UI and generate an API key for secure communication between your applications and Doku.\n\nOpen your browser and go to Doku UI at https://doku-client-.up.railway.app/login\nLogin using theb default credentials\n    Email as user@dokulabs.com\n    Password as dokulabsuser\nOnce you have logged into Doku UI, Go to API Keys page and create an API Key. Copy the generated API Key.\n\n&gt; üí° Tip: Alternatively, you can use the HTTP API to create your Doku API Key. For further details, take a look at the API Reference section.\n\n‚ö°Ô∏è Instrument your Application\n\nChoose the appropriate SDK for your LLM application\'s programming language and follow the steps to integrate monitoring with just two lines of code.\n\nPython\n\nInstall the dokumetry Python SDK using pip:\n\npip install dokumetry\n\nAdd the following two lines to your application code:\n\nimport dokumetry\n\ndokumetry.init(llm=client, doku_url="https://doku-ingester-.up.railway.app/", api_key="YOUR_DOKU_TOKEN")\n\nExample Usage for monitoring OpenAI Usage:\n\nfrom openai import OpenAI\nimport dokumetry\n\nclient = OpenAI(\n    api_key="YOUR_OPENAI_KEY"\n)\n\nPass the above client object along with your Doku Ingester URL and API key and this will make sure that all OpenAI calls are automatically tracked.\ndokumetry.init(llm=client, doku_url="https://doku-ingester-.up.railway.app/", api_key="YOUR_DOKU_TOKEN")\n\nchat_completion = client.chat.completions.create(\n    messages=\n        {\n            "role": "user",\n            "content": "What is LLM Observability",\n        }\n    ],\n    model="gpt-3.5-turbo",\n)\n\nRefer to the dokumetry [Python SDK repository for more advanced configurations and use cases.\n\nNode\n\nInstall the dokumetry NodeJS SDK using npm:\n\nnpm install dokumetry\n\nAdd the following two lines to your application code:\n\nimport DokuMetry from \'dokumetry\';\n\nDokuMetry.init({llm: openai, dokuUrl: "https://doku-ingester-.up.railway.app/", apiKey: "YOUR_DOKU_TOKEN"})\n\nExample Usage for monitoring OpenAI Usage:\n\nimport OpenAI from \'openai\';\nimport DokuMetry from \'dokumetry\';\n\nconst openai = new OpenAI({\n  apiKey: "YOUR_OPENAI_KEY", \n});\n\n// Pass the above openai object along with your Doku Ingester URL and API key and this will make sure that all OpenAI calls are automatically tracked.\nDokuMetry.init({llm: openai, dokuUrl: "https://doku-ingester-.up.railway.app/", apiKey: "YOUR_DOKU_TOKEN"})\n\nasync function main() {\n  const chatCompletion = await openai.chat.completions.create({\n    messages: { role: \'user\', content: \'What are the key to effective observability?\' }],\n    model: \'gpt-3.5-turbo\',\n  });\n}\n\nmain();\n\nRefer to the dokumetry [NodeJS SDK repository for more advanced configurations and use cases.\n\nVisualize and Analyze\n\nOnce you have Doku Ingester and DokuMetry SDKs set up, you can instantly get insights into how your LLM applications in the Doku Client UI. Just head over to https://doku-client-.up.railway.app on your browser to start exploring.\n\nDoku Client UI\n\nWith Doku, you get a simple, powerful view into important info like how much you‚Äôre spending on LLMs, which parts of your app are using them the most, and how well they‚Äôre performing. Find out which LLM models are favorites among your applications, and dive deep into performance details to make smart decisions. This setup is perfect for optimizing your app performance and keeping an eye on costs.\n\nAppendix\n\nDoku\nLicense\nDownloads\n\nSlack\nX',
    name: "Doku",
    category: "Observability",
    health: null,
    code: "tZQJlB",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6d73eb04-a343-4c3b-b6c3-4e1d770b1d02",
    isApproved: false,
    activeProjects: 5,
    projects: 34,
    description: "An open source, self-hosted links shortener and sharing platform",
    readme:
      "Slash\n\nSlash is an open source, self-hosted links shortener and sharing platform. It allows you to organize your links with tags, and share them with custom shortened URLs. Slash also supports team sharing of link libraries for easy collaboration.\n\ndemo\n\nBackground\n\nIn today's workplace, essential information is often scattered across the cloud in the form of links. We understand the frustration of endlessly searching through emails, messages, and websites just to find the right link. Links are notorious for being unwieldy, complex, and easily lost in the shuffle. Remembering and sharing them can be a challenge.\n\nThat's why we developed Slash, a solution that transforms these links into easily accessible, discoverable, and shareable shortcuts(e.g., s/shortcut). Say goodbye to link chaos and welcome the organizational ease of Slash into your daily online workflow.\n\nFeatures\n\nCreate customizable s/ short links for any URL.\nShare short links public or only with your teammates.\nView analytics on link traffic and sources.\nEasy access to your shortcuts with browser extension.\nShare your shortcuts with Collection to anyone, on any browser.\nOpen source self-hosted solution.",
    name: "Slash",
    category: "Other",
    health: 100,
    code: "wRT7rD",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "cd643a35-9544-481b-ba71-2fee7c3649b1",
    isApproved: false,
    activeProjects: 12,
    projects: 16,
    description: "The standard MySQL database plus backups to Cloudflare R2",
    readme:
      "Deploys the standard Railway MySQL plus a container which backs up that database to Cloudflare R2.\n\nTo set up properly, modify the backups service to:\n\nDisable restarts\nSet a Cron schedule to back up as often as you'd like in settings\n\nInternally, this uses mydumper to dump the database quickly (saving you compute cost over mysqldump) and rclone to sync the data with a folder in an R2 bucket.\n\nYou can modify the generated rclone config to support virtually any other target for the backup.",
    name: "MySQL With Backups",
    category: "Storage",
    health: 100,
    code: "xNTYS8",
    languages: ["Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "14c2d49e-a9f7-4960-b77a-1890c2b50512",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "Run a single backup of a MySQL database to Cloudflare R2",
    readme:
      "This container runs a single time, backing up a MySQL database to Cloudflare R2. To set up properly:\n\nDisable restarts\nSet a Cron schedule to back up as often as you'd like in settings\n\nInternally, this uses mydumper to dump the database quickly (saving you compute cost over mysqldump) and rclone to sync the data with a folder in an R2 bucket.\n\nYou can modify the generated rclone config to support virtually any other target for the backup.",
    name: "Backup MySQL to Cloudflare R2",
    category: "Automation",
    health: null,
    code: "7GOA4r",
    languages: ["Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d7e4b128-dbb3-417a-aa1b-7a123ea03a15",
    isApproved: false,
    activeProjects: 21,
    projects: 63,
    description: "libSQL is SQLite for modern applications",
    readme:
      "\n    \n        \n    \n\n\nlibSQL Server - A server mode for libSQL\n\nThe sqld (\"SQL daemon\") project is a server mode for libSQL\n\nNote: This template does not come with any authentication enabled by default, to set up authentication see their documentation. If you plan to leave the database without authentication please remove the public domain from the service.\n\nDevelopers love libSQL\n\nBuild on the most deployed database in the world\n\nSQLite is the most deployed database in the world because it's the simplest to write, test and deploy. libSQL, the open contribution fork of SQLite, builds on that foundation while preserving all the benefits developers love.\n\nDevelop, test and deploy with the same database\n\nUnlike Postgres and MySQL, a SQLite database is just a file. That means local testing is fast and doesn't depend on spawning containers or services. libSQL adds an HTTP mode that lets you take the code you just tested straight into production.\n\nRun locally or over the network\n\nlibSQL comes with a server mode, libsql-server, and because of other powerful native features like replication, embedded replicas, multi tenancy and edge nodes in every major geo in the world, that means you can write locally and deploy wherever you like.\n\nFeatures\n\nSQLite dialect layered on top of HTTP.\n\nSQLite-compatible API that you can drop-in with LD_PRELOAD in your application to switch from local database to a remote database.\n\nRead replica support.\n\nIntegration with mvSQLite for high availability and fault tolerance.",
    name: "libSQL Server",
    category: "Other",
    health: 94,
    code: "p121Tx",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d7e41a87-9e24-4f4c-8e3c-62155b53081e",
    isApproved: false,
    activeProjects: 0,
    projects: 11,
    description: "A free, open source, self-hosted customer feedback tool",
    readme:
      "\n    \n        \n    \n\n\nA free, open source, self-hosted customer feedback tool\n\nWhat is Astuto?\n\nAstuto is an open source customer feedback tool. It helps you collect, manage and prioritize feedback from your customers, so you can build a better product.\n\nUnderstand your customers and build a better product\n\nAstuto helps you collect and organize feedback from your users, so you can focus on building what matters.\n\nHow it works\n\n1. Collect\n\nGather ideas and suggestions from your customers.\n\n2. Analyze\n\nOrganize and analyze feedback to decide what to build next.\n\n3. Share\n\nKeep customers in the loop and let them know what you're working on.\n\nFeatures\n\nFeedback: Collect feedback. Organize feedback with custom boards and statuses.\n\nRoadmap: Show your customers what you're working on.\n\nSimple Sign In: Sign in with email or any custom OAuth provider (Google, Facebook, etc).\n\nBrand: Represent your brand with complete customization of style and appearance.\n\nLanguages: English, Spanish, French, German, Italian, Chinese and more.\n\nNotify: Notify interested customers via email on updates.",
    name: "Astuto",
    category: "Other",
    health: null,
    code: "g9cM6x",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7bc53daf-dbe6-4625-a8db-7e5521add5fe",
    isApproved: false,
    activeProjects: 4,
    projects: 7,
    description: "Sends Gotify notifications to iOS devices",
    readme:
      "iGotify\n\nA small Gotify server notification assistant that decrypt the message and trigger a Push Notifications to iOS Devices via Apple's APNs with my service SecNtfy\n\nFeatures\n\n show received notifications with markdown\ndecrypted the message with a public key that is generated from the iGotify device\nsending the decrypted message to SecNtfy and forwarded it to Apple's APN service, without saving the payload\nmultiuser support",
    name: "iGotify",
    category: "Other",
    health: null,
    code: "5-vKTX",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2231c534-b681-41eb-ace1-392eb65a2103",
    isApproved: false,
    activeProjects: 9,
    projects: 26,
    description: "A simple server for sending and receiving messages",
    readme:
      "\n    \n        \n    \n\n\nGotify\n\nIntro\n\nA simple server for sending and receiving messages in real-time per WebSocket. (Includes a sleek web-ui)\n\nFeatures\n\nFeatures\n\nsend messages via REST-API\nreceive messages via WebSocket\nmanage users, clients and applications\nPlugins\nWeb-UI -&gt; ./ui\nCLI for sending messages -&gt; gotify/cli\nAndroid-App -&gt; gotify/android\n\n",
    name: "Gotify",
    category: "Other",
    health: 100,
    code: "HcjHbf",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8f420496-950e-43c1-a261-926003071284",
    isApproved: false,
    activeProjects: 5,
    projects: 19,
    description: "A Database Built for Scale",
    readme:
      "\n    \n        \n    \n\n\nA Database Built for Scale\n\nKeyDB is a fully open source database, backed by Snap, and a faster drop in alternative to Redis\n\nWhat is KeyDB?\n\nKeyDB is a high performance fork of Redis with a focus on multithreading, memory efficiency, and high throughput. In addition to performance improvements, KeyDB offers features such as Active Replication, FLASH Storage and Subkey Expires. KeyDB has a MVCC architecture that allows you to execute queries such as KEYS and SCAN without blocking the database and degrading performance.\n\nKeyDB maintains full compatibility with the Redis protocol, modules, and scripts. This includes the atomicity guarantees for scripts and transactions. Because KeyDB keeps in sync with Redis development KeyDB is a superset of Redis functionality, making KeyDB a drop in replacement for existing Redis deployments.\n\nOn the same hardware KeyDB can achieve significantly higher throughput than Redis. Active-Replication simplifies hot-spare failover allowing you to easily distribute writes over replicas and use simple TCP based load balancing/failover. KeyDB's higher performance allows you to do more on less hardware which reduces operation costs and complexity.\n\nFeatures\n\nKeyDB Speeds Up The User Experience For Any Project.\n\nWhether you're starting small or serving millions of users,\nKeyDB enables you to provide a fast and reliable experience to your users.\n\nHigh Throughput: KeyDB is meant to handle heavy workloads with a single node benchmarking at over 1 million ops/sec. KeyDB is a multithreaded database and will outperform Redis on a per-node basis.\n\nLow Latency: By keeping data in-memory, KeyDB can serve up data with submillisecond latencies.\n\nA Variety of Data Structures: A variety of data structures are supported such as strings, hashes, lists, sets, sorted sets, bitmaps, hyperloglogs, geospatial indexes, and streams\n\nMultiple Persistence Options: Periodically dump the dataset to disk or by appending each command to a disk-based log. Durability preferences for RDB and AOF persistence are configurable.\n\nMVCC Non-Blocking Architecture: With an MVCC implementation at the underlying architecture, KeyDB can query individual snapshots of the database, avoiding otherwise blocking calls such as SCAN and KEYS. Such queries can now be called concurrently at scale without reducing overall performance of existing workloads.\n\nBetter EXPIRation: KeyDB offers Subkey EXPIREs which enables expiration of members within a set. EXPIREs now also have near real time active deletion that removes major lags associated with old models of removing expired keys.\n\nModJS: Create your own commands with KeyDB‚Äôs open source javascript module. Built on the powerful V8 JIT engine, ModJS is faster than LUA and supports many node.js modules to offer extensive library support for common tasks.",
    name: "KeyDB",
    category: "Other",
    health: 100,
    code: "keydb",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f5409203-e276-4a18-bca0-5ef4e2d4678b",
    isApproved: false,
    activeProjects: 21,
    projects: 73,
    description: "A production-ready Conversational AI applications framework in Python. ",
    readme:
      "Overview\n\nChainlit is an open-source async Python framework which allows developers to build scalable Conversational AI or agentic applications.\n\n‚úÖ ChatGPT-like application\n‚úÖ Embedded Chatbot & Software Copilot\n‚úÖ Custom frontend (build your own agentic experience)\n‚úÖ API Endpoint\n\nHighlights\n\nFull documentation is available here. Key features:\n\nüí¨ Multi Modal chats\nüí≠ Chain of Thought visualisation\nüíæ Data persistence + human feedback\nüõù In context Prompt Playground\nüë§ Authentication\n\nChainlit is compatible with all Python programs and libraries. That being said, it comes with integrations for:\n\nLangChain\nLlama Index\nAutogen\nOpenAI Assistant\nHaystack\n\nLearn More\n\nChainlit Website\nChainlit Doc\nChainlit Repo\n",
    name: "Chainlit",
    category: "AI/ML",
    health: 50,
    code: "atS4DW",
    languages: ["Python", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7d254afa-62b6-4848-9d34-28764114426c",
    isApproved: false,
    activeProjects: 1,
    projects: 9,
    description: "Security Building Blocks For Developers",
    readme:
      "BoxyHQ‚Äôs SSO solution allows you to go from the first line of code to deployment in just a few days, saving you time and getting you to market faster. Plus, we offer custom integration support to help you every step of the way.\n\nEffortless integration\nReduced development time\nBecome enterprise ready",
    name: "BoxyHQ / Jackson SSO",
    category: "Authentication",
    health: null,
    code: "xV6lZy",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1e0a34f3-d5ef-463d-8e52-0d84e6cd6a97",
    isApproved: false,
    activeProjects: 1,
    projects: 30,
    description: "Free and open log management",
    readme:
      "Overview\nThis template is based on the official Graylog docker guide. It sets up a Graylog instance with a single Opensearch node, backed by a MongoDB database.\n\nConfiguration\nOnly two environment variables need to be set: GRAYLOG_ROOT_PASSWORD_SHA2 on the graylog service, and  OPENSEARCH_INITIAL_ADMIN_PASSWORD on the opensearch service (otherwise the default is set to admin for both)\n\nDeploy\nNo further configuration is required, simply deploy the template and you're good to go",
    name: "Graylog",
    category: "Observability",
    health: null,
    code: "_GawOC",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "16a4a5b1-0ec8-4cc9-bfe0-f2989b46f978",
    isApproved: false,
    activeProjects: 5,
    projects: 20,
    description: "A modern really-real-time collaborative document editor",
    readme:
      "Etherpad Logo\n\nEtherpad is a real-time collaborative editor scalable to thousands of simultaneous real time users. It provides full data export capabilities, and runs on your server, under your control.\n\nAuthentication\n\nThe default user and admin password can be found in the service variables, they're automatically created. You can set a custom one on deployment of the service.\n\nDocs\n\nCheck out the etherpad wiki for more information here\n\n",
    name: "Etherpad",
    category: "CMS",
    health: 71,
    code: "NG6XMi",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b9e2d674-3641-4ece-9471-3692ff55f4f4",
    isApproved: false,
    activeProjects: 37,
    projects: 147,
    description: "An easy to use, open-source, link shortener web app and API",
    readme:
      "What is this template?\n\nShlink is a self-hosted URL shortener that enables you to create, and track the usage of  \"short\" URLs that redirect to other, longer, URLs. Shlink also provides analytics on URL usage, such as visit counts and geographic location of the visitors.\n\nThis template spins up:\nShlink the official shlink application. This handles short links and serves an authenticated API for management.\nShlink Web Client the official Shlink web client used for managing and monitoring your short links + HTTP basic-authentication via NGINX. \n\nThis template makes deploying Shlink extremely easy; *It can be setup in less than 5 minutes*.\n\nQuick start guide \n\nClick the \"Deploy on Railway\" button above \nFollow the setup steps on Railway \n   Enter a username for the shlink web client.\n   Enter a password for the shlink web client.\n   Click \"deploy!\"\nMonitor your services as the come up; wait until everyting is up with a green checkmark.\nYou're good to go!\n   You can access the web client using your username and password.\n   You can access shlink directly via the API using the API key generated by Railway.\n\nOptional: configuring your own domains\n\nYou'll probably want your shlink service to have a custom domain so the generated shortlinks are shorter than the links you're redirecting to. \n\nSee this guide on Railway for configuring a custom domain.\n\nOptional: configuring app sleeping\n\nIf you want your services to scale down when not in use, you can setup app sleeping on Railway.\n\nSee this guide on Railway for configuring app sleeping.\n\nProject structure & services\n\nThis template is made up of three railway services: \n\nShlink: primary short link application\n   The primary short link application.\n   Serves a REST API that allows users to manage short links.\n   All your generated short links will be at this service's URL.\nShlink Web Client: web app for managing Shlink\n   Web UI for handling your short URLs, creating new ones or monitoring visit stats.\n   The Web UI hooks into the Shlink service's API on template generation and requires no extra setup.\n   This template bolts on HTTP basic-authentication to the web client making it safe to expose to the internet. \nPostgreSQL Database: primary database used by Shlink\n\nAdditional resources\n\nShlink homepage\nShlink documentation\nShlink web client documentation\n\nFeedback\n\nIf you have feedback on this template, please submit a GitHub issue with as much detail as possible. \n\nKnown issues\n\nShlink cannot connect to the database via private networking: this is due to the fact that shlink appears to not support IPV6 networking (which Railway uses for it's private networking features). If you can see a way around this, feel free to leave an explanation in the open issue or file a pull request.\n",
    name: "Shlink",
    category: "Other",
    health: 96,
    code: "kwu__Y",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f0677964-9a01-4837-b011-98ba3aa9a4a0",
    isApproved: false,
    activeProjects: 296,
    projects: 316,
    description: "Self-host page share for page asssist",
    readme:
      "The 'page share' feature is part of the Page Assist extension, allowing you to share chats publicly, similar to ChatGPT's sharing feature.\n\nExtension: https://chromewebstore.google.com/detail/page-assist-a-web-ui-for/jfgfiigpkhlkbnfnbobbkinehhfdhndo\n\nRepo: https://github.com/n4ze3m/page-assist",
    name: "Page Assist (Share)",
    category: "Other",
    health: 50,
    code: "VbiS2Q",
    languages: ["TypeScript", "JavaScript", "Dockerfile", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ac383fa0-595b-43ef-bd5a-58ab7fc92c5e",
    isApproved: false,
    activeProjects: 9,
    projects: 14,
    description: "A simple CORS proxy with optional dynamic caching capabilities",
    readme:
      'Caching CORS Proxy\n\nA simple CORS proxy with optional dynamic caching. To use the cache, use the /cache/{time} endpoint. Time must represent a valid duration. Ex:\n\n1 minute\n2 hours\n\nAllowed durations are:\n\nms\nsecond(s)\nminute(s)\nhour(s)\nday(s)\nweek(s)\nmonth(s)\n\nTo avoid using the cache, simply use /{YOUR URL}. To bypass cache on a specific request, set "x-apicache-bypass": true in the request header.\n\nALL requests will be routed through the CORS server, regardless of whether they are cached or not.\n\nTo enable detailed logs of requests in the console, set the EHNANCED_LOGS environment variable to true.\n\nExamples\n\nhttps://CACHE PROXY URL/cache/10 minutes/https://URL TO BE CACHED/ will be cached for 10 minutes.\nhttps://CACHE PROXY URL/cache/1 hour/https://URL TO BE CACHED/ will be cached for 1 hour.\nhttps://CACHE PROXY URL/https://URL TO BE CACHED/ will not be cached.\n\nFor bug reports or feature requests, please open an issue on our github page.\n\nNotice: The logo for this template is provided by VectorPortal.',
    name: "Caching CORS Proxy",
    category: "Other",
    health: 100,
    code: "VFbUtB",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ab2cc8d6-a05d-4d96-b833-380227332035",
    isApproved: false,
    activeProjects: 427,
    projects: 773,
    description: "A super fast Airtable alternative with database power",
    readme:
      '\n  Postgres-Airtable Fusion\n  Teable is a Super fast, Real-time, Professional, Developer friendly, No-code database built on Postgres. It uses a simple, spreadsheet-like interface to create complex enterprise-level database applications. Unlock efficient app development with no-code, free from the hurdles of data security and scalability. \n\n‚ú®Features\n\nüìä Spreadsheet-like interface\n\nAll you want is here\n\nCell Editing: Directly click and edit content within cells.\nFormula Support: Input mathematical and logical formulas to auto-calculate values.\nData Sorting and Filtering: Sort data based on a column or multiple columns; use filters to view specific rows of data.\nAggregation Function: Automatically summarize statistics for each column, providing instant calculations like sum, average, count, max, and min for streamlined data analysis.\nData Formatting: formatting numbers, dates, etc.\nGrouping: Organize rows into collapsible groups based on column values for easier data analysis and navigation.\nFreeze Columns: Freeze the left column of the table so they remain visible while scrolling.\nImport/Export Capabilities: Import and export data from other formats, e.g., .csv, .xlsx.\nRow Styling &amp; Conditional Formatting: Change row styles automatically based on specific conditions. (coming soon)\nCharts &amp; Visualization Tools: Create charts from table data such as bar charts, pie charts, line graphs, etc. (coming soon)\nData Validation: Limit or validate data that are entered into cells. (coming soon)\nUndo/Redo: Undo or redo recent changes. (coming soon)\nComments &amp; Annotations: Attach comments to rows, providing explanations or feedback for other users. (coming soon)\nFind &amp; Replace: Search content within the table and replace it with new content. (coming soon)\n\nüóÇÔ∏è Multiple Views\n\nVisualize and interact with data in various ways best suited for their specific tasks.\n\nGrid View: The default view of the table, which displays data in a spreadsheet-like format.\nForm View: Input data in a form format, which is useful for collecting data.\nKanban View: Displays data in a Kanban board, which is a visual representation of data in columns and cards. (coming soon)\nCalendar View: Displays data in a calendar format, which is useful for tracking dates and events. (coming soon)\nGallery View: Displays data in a gallery format, which is useful for displaying images and other media. (coming soon)\nGantt View: Displays data in a Gantt chart, which is useful for tracking project schedules. (coming soon)\nTimeline View: Displays data in a timeline format, which is useful for tracking events over time. (coming soon)\n\nüöÄ Super Fast\n\nAmazing response speed and data capacity\n\nMillions of data are easily processed, and there is no pressure to filter and sort\nAutomatic database indexing for maximum speed\nSupports batch data operations at one time\n\nüë®‚Äçüíª Full-featured SQL Support\n\nSeamless integration with the software you are familiar with\n\nBI tools like Metabase PowerBi...\nNo-code tools like Appsmith...\nDirect retrieve data with native SQL\n\nüîí Privacy-First\n\nYou own your data, in spite of the cloud\n\nBring your own database (coming soon)\n\n‚ö°Ô∏è Real-time collaboration\n\nDesigned for teams\n\nNo need to refresh the page, data is updated in real-time\nSeamlessly integrate collaboration member invitation and management\nPerfect permission management mechanism, from table to column level\n\nüß© Extensions (coming soon)\n\nExpand infinite possibilities\n\nBackend-less programming capability based on React\nCustomize your own application with extremely low cost\nExtremely easy-to-use script extensions mode\n\nü§ñ Automation (coming soon)\n\nEmpower data-driven workflows effortlessly and seamlessly\n\nDesign your workflow with AI or Visual programming\nSuper easy to retrieve data from the table\n\nüß† Copilot (coming soon)\n\nNative Integrated AI ability\n\nChat 2 App. "Create a project management app for me"\nChat 2 Chart. "Analyze the data in the order table using a bar chart"\nChat 2 View. "I want to see the schedule for the past week and only display participants"\nChat 2 Action. "After the order is paid and completed, an email notification will be sent to the customer"\nMore actions...\n\nüóÑÔ∏è Support for multiple databases (coming soon)\n\nChoose the SQL database you like\n\nSqlite, PostgreSQL, MySQL, MariaDB, TiDB...',
    name: "Teable",
    category: "CMS",
    health: 100,
    code: "wada5e",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "07f83978-7326-4ac1-8fa3-5fb78be29481",
    isApproved: false,
    activeProjects: 26,
    projects: 82,
    description: "OpenTelemetry Collector with Backend Stack",
    readme:
      'Deploy the OpenTelemetry Collector along with a set of backend services.\n\nCheckout the Railway tutorial for more information.\n\nOpenTelemetry Collector\n\nThe collector is a vendor-agnostic way to receive, process and export telemetry data.  \n\nIt is deployed with a configuration file that enables it to send data to the complementary backend services.\n\nThe zpages extension is enabled, allowing you to connect to the debug UI from your browser.  More information on the extension can be found here.\n\nDocumentation\n\nCollector Documentation\nConfiguration File Documentation\n\nPort map for reference:\n\n    "1888"   # pprof extension\n    "8888"   # Prometheus metrics exposed by the collector\n    "8889"   # Prometheus exporter metrics\n    "13133" # health_check extension\n    "4317"   # OTLP gRPC receiver\n    "4318"   # OTLP HTTP receiver\n    "55679" # zpages extension\n\nZipkin\n\nZipkin is a distributed tracing system.  It receives data from the Otel Collector on port 9411.\nZipkin Documentation\n\nJaeger\n\nJaeger is a distributed tracing system.  It receives data from the Otel Collector on port 4317.\nJaeger Documentation\n\nPrometheus\n\nPrometheus is a systems monitoring and alerting toolkit.  It receives data from the Otel Collector on port 8889.\nPrometheus Documentation',
    name: "OpenTelemetry Collector and Backend",
    category: "Observability",
    health: 100,
    code: "7KNDff",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1bc85f38-300c-4685-a0bd-186b16b7ef6d",
    isApproved: false,
    activeProjects: 7,
    projects: 19,
    description: "Deploy an open-source Pusher-compatible server.",
    readme:
      "Check the Soketi documentation to find out more about how to configure the instance.\n\nSoketi \nhttps://docs.soketi.app/\n\nJavascript (client)\nhttps://github.com/pusher/pusher-js\nhttps://laravel.com/docs/9.x/broadcasting\n\nNode.js (server)\nhttps://github.com/pusher/pusher-http-node\n\nPHP (server)\nhttps://github.com/pusher/pusher-http-php",
    name: "Soketi v1",
    category: "Other",
    health: 100,
    code: "Z6dOtj",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d1056723-8aed-4957-bbc2-0f7b81760428",
    isApproved: false,
    activeProjects: 2,
    projects: 6,
    description: "Ethereum gas price notifier using Etherscan and Resend.",
    readme:
      "Overview \nThis template deploys an app that checks Ethereum gas price every hour using the Etherscan API, and sends email via Resend if the price crosses your pre-defined threshold. Configure the following environment variables while deploying the service:\nETHERSCAN_API_KEY: Etherscan API key to check Ethereum gas price; get it here.\nRESEND_API_KEY: Resend API key to send email notifications; get it here.\nEMAIL_FROM: Email address to send alert from, as configured in Resend.\nEMAIL_TO: Email address to send alert to, as configured in Resend.\nPRICE_THRESHOLD: Send email if Ethereum gas price drops below this threshold (gwei).\n\nNote: The template does not allow cron schedule to be defined, so set up the hourly run (0 * * * *) in the service settings once it's deployed.",
    name: "Ethereum Gas Price Checker",
    category: "Other",
    health: null,
    code: "pDebYY",
    languages: ["Python", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4bb676ec-5bde-48d8-a5ed-b44d0c5fc1c0",
    isApproved: false,
    activeProjects: 4,
    projects: 36,
    description: "Remix + Postgres optimized for Railway",
    readme:
      "Remix Railroad Blues Stack\n\nThe Railroad Blues Stack\n\nThis is a fork of the Remix Blues Stack adapted for deploying to Railway\n\nLearn more about Remix Stacks.\n\nWhat's in the template?\n\nRemix Notes Application\nPostgres database\nEmail/Password Authentication with cookie-based sessions\nDatabase ORM with Prisma\nStyling with Tailwind\nEnd-to-end testing with Cypress\nLocal third party request mocking with MSW\nUnit testing with Vitest\nCode formatting with Prettier\nLinting with ESLint\nStatic Types with TypeScript\n\nLocal Development\n\nStart the Postgres Database in Docker:\n\n  npm run docker\n\n  _ Note: The npm script will complete while Docker sets up the container in the background. Ensure that Docker has finished and your container is running before proceeding._\n\nInitial setup:  \n  only run this the first time\n\n  npm run setup\n\nStart dev server:\n\n  npm run dev\n\nThis starts your app in development mode, rebuilding assets on file changes.\n\nThe database seed script creates a new user with some data you can use to get started:\n\nEmail: rachel@remix.run\nPassword: racheliscool\n\nRelevant code:\n\nThis is a pretty simple note-taking app, but it's a good example of how you can build a full stack app with Prisma and Remix. The main functionality is creating users, logging in and out, and creating and deleting notes.\n\ncreating users, and logging in and out app/models/user.server.ts\nuser sessions, and verifying them app/session.server.ts\ncreating, and deleting notes app/models/note.server.ts\n\nCheck out the stack on GitHub for more details.\n\nCost Estimate\nFor an experiment with no traffic, this should cost about $2/mo to keep deployed without App Sleeping enabled\n",
    name: "Remix Railroad Blues Stack",
    category: "Starters",
    health: 0,
    code: "plonEj",
    languages: ["TypeScript", "JavaScript", "Dockerfile", "Shell", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "833b2c0d-9924-45d3-b001-5e86be31a5fd",
    isApproved: false,
    activeProjects: 66,
    projects: 126,
    description: "A simple 1.22 Golang REST API using julienschmidt/httprouter for routing",
    readme:
      "This is a simple Go api that has one existing endpoint: 'healthcheck'. This api uses julienschmidt/httprouter for routing since it's powerful and simple. You shouldn't need any other 3rd party libraries to get a production API up and running.\n\nStart in the main.go file. Here the application is scaffolded. \n\nThe routes.go file defines routes. Here you can define routes accompanying HTTP methods (GET, PUT, PATCH, etc). \n\nThe nixpacks file is custom only because the defaults Railway uses assumes the file structure is flat. I prefer to have the files in cmd/api so I made updates to that.\n\nOnce you have the service live in Railway, click on it to see the url it's hosted at. It will take a few minutes on first build. Once you're at the URL, add /v1/healthcheck at the end. You should see a json response!",
    name: "Go",
    category: "Starters",
    health: 100,
    code: "q5VPer",
    languages: ["Go"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f18de396-74c0-4d1e-a519-eb5aff098497",
    isApproved: false,
    activeProjects: 1,
    projects: 3,
    description: "DataStax Open Source GenAI Starter",
    readme:
      "UI to create assistants with file upload functionality. Supports various third party LLMs.\n\nPowered by Huggingface chat-ui and astra-assistants-api\n\nAdd the following variables for third party LLM support:\n\nhttps://platform.openai.com/api-keys --> create new secret key\nOPENAI_API_KEY=\n\nhttps://www.perplexity.ai/settings/api  --> generate\nPERPLEXITYAI_API_KEY=\n\nhttps://dashboard.cohere.com/api-keys\nCOHERE_API_KEY=\n\nbedrock models https://docs.aws.amazon.com/bedrock/latest/userguide/setting-up.html\nAWS_REGION_NAME=\nAWS_ACCESS_KEY_ID=\nAWS_SECRET_ACCESS_KEY=\n\nvertexai models https://console.cloud.google.com/vertex-ai\nGOOGLE_JSON_PATH=\nGOOGLE_PROJECT_ID=\n\ngemini api https://makersuite.google.com/app/apikey\nGEMINI_API_KEY=\n\n\nAdditional models can be added to the MODELS variable.",
    name: "astra-assistants-chat-ui",
    category: "AI/ML",
    health: null,
    code: "v2UVYh",
    languages: ["TypeScript", "Svelte", "JavaScript", "HTML", "Dockerfile", "Shell", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e37030b7-c051-4dc7-a79d-202b1e43bb1d",
    isApproved: false,
    activeProjects: 25,
    projects: 41,
    description: "üöÄ v2.10.1 support Google Gemini Pro model.",
    readme:
      "Deploy on Railway\n\nFeatures\nDeploy for free with one-click on Vercel in under 1 minute\nCompact client (~5MB) on Linux/Windows/MacOS, download it now\nFully compatible with self-deployed LLMs, recommended for use with RWKV-Runner or LocalAI\nPrivacy first, all data is stored locally in the browser\nMarkdown support: LaTex, mermaid, code highlight, etc.\nResponsive design, dark mode and PWA\nFast first screen loading speed (~100kb), support streaming response\nNew in v2: create, share and debug your chat tools with prompt templates (mask)\nAwesome prompts powered by awesome-chatgpt-prompts-zh and awesome-chatgpt-prompts\nAutomatically compresses chat history to support long conversations while also saving your tokens\nI18n: English, ÁÆÄ‰Ωì‰∏≠Êñá, ÁπÅ‰Ωì‰∏≠Êñá, Êó•Êú¨Ë™û, Fran√ßais, Espa√±ol, Italiano, T√ºrk√ße, Deutsch, Ti·∫øng Vi·ªát, –†—É—Å—Å–∫–∏–π, ƒåe≈°tina, ÌïúÍµ≠Ïñ¥, Indonesia\nRoadmap",
    name: "ChatGPT-Next-Web",
    category: "Bots",
    health: null,
    code: "K4qfIt",
    languages: ["TypeScript", "SCSS", "JavaScript", "Shell", "Dockerfile", "Rust"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1a126e34-ef67-4dc2-a41e-eec7e8832d34",
    isApproved: false,
    activeProjects: 34,
    projects: 96,
    description: "Self Hosted GitHub Alternative",
    readme:
      '\n  \n    \n  \n\nGitea - Git with a cup of tea\n\nNotes\n\nDue to Railway only allowing 1 port to be forwarded to your project, you must use HTTP for checkout and push to the repositories setup in your Gitea instance.\n\nPurpose\n\nThe goal of this project is to make the easiest, fastest, and most\npainless way of setting up a self-hosted Git service.\n\nAs Gitea is written in Go, it works across all the platforms and\narchitectures that are supported by Go, including Linux, macOS, and\nWindows on x86, amd64, ARM and PowerPC architectures.\nThis project has been\nforked from\nGogs since November of 2016, but a lot has changed.\n\nSetup Instructions\n\nTo deploy the Gitea project on Railway, just click through, all environment variables are already configured for you. Once deployed, visit your domain, and you can start setting up your instance.\n\nFAQ\n\nHow do you pronounce Gitea?\n\nGitea is pronounced /…°…™‚Äôti:/ as in "gi-tea" with a hard g.\n\nLicense\n\nThis project is licensed under the MIT License.\nSee the LICENSE file\nfor the full license text.\n\nScreenshots\n\nLooking for an overview of the interface? Check it out!\n\n|Dashboard|User Profile|Global Issues|\n|:---:|:---:|:---:|\n|Branches|Web Editor|Activity|\n|New Migration|Migrating|Pull Request View|\n|Pull Request Dark|Diff Review Dark|Diff Dark|\n',
    name: "Gitea",
    category: "Storage",
    health: 93,
    code: "ZHGJu6",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b18b5d2c-8843-44a5-9ae7-f49bd01fcf14",
    isApproved: false,
    activeProjects: 195,
    projects: 248,
    description: "a telegram bot using Gemini-pro",
    readme:
      "Make up the word count. Make up the word count. Make up the word count. Make up the word count. Make up the word count. Make up the word count. Make up the word count. Make up the word count. Make up the word count. Make up the word count. Make up the word count. Make up the word count. Make up the word count. Make up the word count. Make up the word count. Make up the word count. ",
    name: "gemini-telegram-bot",
    category: "Other",
    health: 78,
    code: "HIsbMv",
    languages: ["Python", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "31af1a9e-150b-4611-bb12-fe140ad468ed",
    isApproved: false,
    activeProjects: 6,
    projects: 6,
    description: "A web front-end for navigating and querying OWL ontologies",
    readme:
      "A service to load and browse a single ontology (and its imports) on startup, with beautiful rendering for easy navigation.\n\nSupports anything the OWLAPI can load:\nOWL\nRDF\nSKOS / SKOS-XL\nlinked data\nknowledge graphs\n\nFeatures\n\nNavigation of all entities (classes, properties, individuals and datatypes)\nHierarchies, subclass/property/relations/annotations\nEntity usage\nManchester OWL Syntax rendering\nOntology metrics\nSearching\nDL Query (with set subtraction)\nAxioms view (and search)\nPaging\nDark mode\n\nTo load your own, set the root ontology location and reasoner root ontology IRI environment variables:\n\nONTOLOGY_ROOT_LOCATION=your ontology URL\nREASONING_ROOT_IRI=IRI of the ontology to be reasoned with\nPROJECT_NAME=Ontology name\nPROJECT_URL=Project documentation url\nPROJECT_TAGLINE=Project tagline text\nPROJECT_CONTACT=Email address of contact\nLABEL_IRI=IRI of the annotation property to use for rendering\nRESTART_SECRET=used for /restart endpoint secret param\n\nPlease see https://github.com/nickdrummond/ontology-browser for more details",
    name: "Ontology Browser",
    category: "Other",
    health: null,
    code: "hI-_yx",
    languages: ["Java", "JavaScript", "HTML", "CSS", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "62cc4d02-35fa-4f72-ae0e-9b73c74f21ff",
    isApproved: false,
    activeProjects: 21,
    projects: 80,
    description: "A powerful CMS, BaaS, and more. Power any project with Directus ",
    readme:
      "A powerful CMS, BaaS, and more. Power any project with Directus ‚Äì a composable data platform to easily create and deploy data-rich apps.\nA powerful CMS, BaaS, and more. Power any project with Directus ‚Äì a composable data platform to easily create and deploy data-rich apps. ",
    name: "directus",
    category: "CMS",
    health: 25,
    code: "Uxq3ot",
    languages: ["JavaScript", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2d720852-aac7-4f01-a2c7-d43ab34d5ba6",
    isApproved: false,
    activeProjects: 0,
    projects: 13,
    description: "A file-sharing and URL shortening web app written in Rust.",
    readme:
      'Overview\n\nMicroBin is a super tiny, feature rich, configurable, self-contained and self-hosted paste bin web application. It is very easy to set up and use, and will only require a few megabytes of memory and disk storage. It takes only a couple minutes to set it up, why not give it a try now?\n\nWhat is an upload?\n\nIn MicroBin, an upload can be:\n\nA text that you want to paste from one machine to another, eg. some code,\nA file that you want to share, eg. a video that is too large for Discord, a zip with a code project in it or an image,\nA URL redirection.\n\nWhen is MicroBin useful?\n\nYou can use MicroBin:\n\nTo send long texts to other people,\nTo send large files to other people,\nTo share secrets or sensitive documents securely,\nAs a URL shortener/redirect service,\nTo serve content on the web, eg. configuration files for testing, images, or any other file content using the Raw functionality,\nTo move files between your desktop and a server you access from the console,\nAs a "postbox" service where people can upload their files or texts, but they cannot see or remove what others sent you,\nOr even to take quick notes.\n\n...and many other things, why not get creative?\n\nFeatures\n\nEntirely self-contained executable, MicroBin is a single file!\nServer-side and client-side encryption\nFile uploads (eg. server.com/file/pig-dog-cat)\nRaw text serving (eg. server.com/raw/pig-dog-cat)\nQR code support\nURL shortening and redirection\nAnimal names instead of random numbers for upload identifiers (64 animals)\nSQLite and JSON database support\nPrivate and public, editable and uneditable, automatically and never expiring uploads\nAutomatic dark mode and custom styling support with very little CSS and only vanilla JS (see water.css)\nAnd much more!\n\nNote\nThis template is NOT maintained by the team behind PicoShare.',
    name: "MicroBin",
    category: "Other",
    health: null,
    code: "qJ-PpH",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "740144b6-3961-4882-8171-5fb85379defe",
    isApproved: false,
    activeProjects: 5,
    projects: 17,
    description: "A minimalist, easy-to-host service for sharing images and other files",
    readme:
      "Overview\n\nPicoShare is a minimalist service that allows you to share files easily.\n\nLive demo\n\nPicoShare demo\n\nWhy PicoShare?\n\nThere are a million services for sharing files, but none of them are quite like PicoShare. Here are PicoShare's advantages:\n\nDirect download links: PicoShare gives you a direct download link you can share with anyone. They can view or download the file with no ads or signups.\nNo file restrictions: Unlike sites like imgur, Vimeo, or SoundCloud that only allow you to share specific types of files, PicoShare lets you share any file of any size.\nNo resizing/re-encoding: If you upload media like images, video, or audio, PicoShare never forces you to wait on re-encoding. You get a direct download link as soon as you upload the file, and PicoShare never resizes or re-encodes your file.\n\nNote\n\nThis template is NOT maintained by the team behind PicoShare.",
    name: "PicoShare",
    category: "Other",
    health: 100,
    code: "1K5sEZ",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "80316d6c-bb88-4492-ac10-095880656d6d",
    isApproved: false,
    activeProjects: 10,
    projects: 31,
    description: "Playground for running open-source generative AI models on Replicate.",
    readme:
      "Overview\nThis template deploys a simple Streamlit app for running the following open-source text, code, image, and music generation models on Replicate:\nText: Meta Llama 2 70B\nText: Google Gemma 7B Instruct\nText: Mixtral 8x7B Instruct\nImage: Stable Diffusion XL\nCode: Meta Code Llama 70B Instruct\nMusic: Meta MusicGen\n\nPre-requisites\nReplicate API key - get it here.\n\nRead more\nRunning Open-Source Generative AI Models on Replicate\nGitHub repo",
    name: "Replicate Playground",
    category: "AI/ML",
    health: 100,
    code: "uHh2gJ",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0f8f9619-d7c2-4d87-946e-26f0ded27749",
    isApproved: false,
    activeProjects: 41,
    projects: 173,
    description: "ollama container with a demo/testing interface",
    readme:
      "A starter for your next ollama project.\n\nUsing the official ollama docker image and includes a user interface built with SvelteKit. Built to be mobile friendly and with minimal hassle.\n\nYou can load multiple models and test switch between them quickly to test each one.\n\n",
    name: "ollama",
    category: "AI/ML",
    health: 75,
    code: "tXERGO",
    languages: ["Svelte", "TypeScript", "JavaScript", "CSS", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "da2d84a2-fb8c-41f1-a1af-5c4b859a47c2",
    isApproved: false,
    activeProjects: 32,
    projects: 87,
    description: "FastApi template with MySQL database and poetry",
    readme:
      "Getting Started:\n\nSetup Poetry\nCreate the poetry environment\nStart the poetry shellpoetry shellInstall dependencies:poetry installCreate a .env file and input environment variables.\n\nInitialize database tables:alembic upgrade headStart the application in development mode:poetry run dev`\n\nTest the application by making requests to endpoints.\n",
    name: "fastapi-mysql",
    category: "Other",
    health: 10,
    code: "WLyaUV",
    languages: ["Python", "Mako"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a6e2d9f0-76d5-4f17-bdba-a77fb5bb8e19",
    isApproved: false,
    activeProjects: 214,
    projects: 890,
    description: "Full ecommerce solution, manage products, inventory, orders, etc.",
    readme:
      'Meudsa version 2 template is out now!\n\nBut if you prefer the good old...:\n\nThis boilerplate is a all in one medusajs (version 1.X legacy) ecommerce webshop solution, it comes preconfigured with both backend + admin dashbord and connected to the "storefront" (webshop frontend).\n\nDependencies updated: 21-06-2024\n\nVideo demo and tutorial\nalt text\n\nInstructions: https://funkyton.com/medusajs-free-fully-open-source-ecommerce-solution/\n\n\n',
    name: "medusajs ecommerce Nextjs, Postgres, Redis",
    category: "Other",
    health: 48,
    code: "QvfPwp",
    languages: ["TypeScript", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8e4fb37b-9f96-480c-b3ad-42a91535bd59",
    isApproved: false,
    activeProjects: 18,
    projects: 39,
    description: "A minimal python FastAPI server with a declarative frontend",
    readme:
      "A minimal Python API and web server built on top of FastAPI (or any Python server of your choosing) and Pydantic.\n\nAt its heart, FastUI is a set of matching Pydantic models and TypeScript interfaces that allow you to define a user interface. This interface is validated at build time by TypeScript and pyright/mypy and at runtime by Pydantic.\n\nThis is useful for making reliable Python APIs with documentation and visualizations built into the server (ie one step better than Swagger docs)\n\nLearn more:\nFastAPI\nFastUI\nPydantic",
    name: "FastUI",
    category: "Starters",
    health: 100,
    code: "O2XqhT",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "39c1d551-785e-4b3a-9c22-cb7d581e57da",
    isApproved: false,
    activeProjects: 0,
    projects: 3,
    description: "An AI powered file type detection tool",
    readme:
      'Instructions\n\nDeploy and copy the endpoint URL.\nAdd a Bearer Token header with the generated AUTH_TOKEN service variable\nPOST either:\nA file as raw bytes to the /identify_bytes slug\nA URL to the /identify_from_url slug with format:\n\n{"url":"file url here"}\n\nAdditional Information\n\nIt is recommended to only rely on the ct_label value for the file type. More information here\n\nAdd a custom domain routed through Cloudflare',
    name: "Magika",
    category: "AI/ML",
    health: null,
    code: "nnnGdy",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "58424ecb-8fbd-4711-b1b7-0f29b5e29085",
    isApproved: false,
    activeProjects: 733,
    projects: 1273,
    description: "The all-in-one AI application for RAG, agents, MCP, and more.",
    readme:
      "AnythingLLM on Railway is here!\n\nA full-stack application that enables you to turn any document, resource, or piece of content into context that any LLM can use as references during chatting. This application allows you to pick and choose which LLM or Vector Database you want to use as well as supporting multi-user management and permissions.\n\nThis is a fully imaged version of the primary AnythingLLM repo!\n\n‚≠ê Star on Github: https://github.com/Mintplex-Labs/anything-llm\n\nIncludes all features of the main app including:\nPrivate embeddings\nLLM Support\nbuilt-in vector database\nexternal chatbot support\nmulti-user authentication\nAdmin controls\n\nSupported LLMs:\nOpenAI\nAzure OpenAI\nAnthropic ClaudeV2\nGoogle Gemini Pro\nOllama (chat models)\nLM Studio (all models)\nLocalAi (all models)\nTogether AI (chat models)\nMistral\n\nSupported Embedding models:\nAnythingLLM Native Embedder (default)\nOpenAI\nAzure OpenAI\nLM Studio (all)\nLocalAi (all)\n\nSupported Vector Databases:\nLanceDB (default)\nAstra DB\nPinecone\nChroma\nWeaviate\nQDrant\nMilvus\nZilliz\n\nNote: This image is updated often but is not always in sync with the latest tag on Docker for the master branch. If something is missing ping us on Discord!\n\nLICENSE\nAnythingLLM is MIT Licensed.\n\n\n",
    name: "AnythingLLM",
    category: "AI/ML",
    health: 92,
    code: "HNSCS1",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e610bd7f-da89-4b6f-bc20-e7af8586d634",
    isApproved: false,
    activeProjects: 14,
    projects: 39,
    description: "SoraFlows is a browser interface for OpenAI Sora, generate text-to-video. ",
    readme:
      "Introduced by OpenAI, Sora is an advanced AI model capable of generating realistic and imaginative scenes from text instructions. This tool has the unique ability to produce sophisticated videos up to 60 seconds in length, featuring highly detailed scenes, complex camera movements, and characters exhibiting a wide range of emotions. However, Sora is not yet available to the public.",
    name: "SoraFlows",
    category: "AI/ML",
    health: null,
    code: "39bNf0",
    languages: ["TypeScript", "JavaScript", "CSS", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b6745bbb-dd1e-4bd4-aaca-fc5736ebfb42",
    isApproved: false,
    activeProjects: 7,
    projects: 25,
    description: "Create and manage your own social media reference landing page.",
    readme:
      "Your go-to social media reference hub! Streamline your platforms, curate content, and engage your audience effortlessly. Hosted or SaaS options available. This will be updated soon as this template is a work in progress. The ENV variables are fairly self explanatory.",
    name: "Linknexus (Linktree Clone)",
    category: "Blogs",
    health: 50,
    code: "29wYgN",
    languages: ["Svelte", "TypeScript", "JavaScript", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5466602c-5ba9-492d-9580-5d94feb14c9d",
    isApproved: false,
    activeProjects: 155,
    projects: 200,
    description: "ÂºÄÊ∫ê„ÄÅÁÆÄÊ¥Å„ÄÅÂèØËá™ÈÉ®ÁΩ≤ÁöÑRSSÁøªËØëÂô® | Translate RSS feeds into your language! ",
    readme: "Github | English | Demo | Telegram‰∫§ÊµÅÁæ§ | ÂºÄÂèëËøõÂ∫¶",
    name: "RSS Translator",
    category: "Other",
    health: 100,
    code: "KnVkVX",
    languages: ["Python", "Shell", "XSLT", "Dockerfile", "JavaScript", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9f9ab24a-533c-4a6c-8366-63a8d0c49e5b",
    isApproved: false,
    activeProjects: 38,
    projects: 76,
    description: "Alternative, self-hosted implementation of the Bitwarden password manager.",
    readme:
      "Overview\nThis template deploys Vaultwarden, a self-hosted, Rust-based, alternative implementation of the Bitwarden password manager. \n\nThe template deploys a lightweight Vaultwarden service from the official docker image and uses a mounted volume for persistent storage. It offers a full implementation of the Bitwarden Server API, including:\nOrganizations support\nAttachments and Send\nVault API support\nServing the static files for Vault interface\nWebsite icons API\nAuthenticator and U2F support\nYubiKey and Duo support\nEmergency access\n",
    name: "Vaultwarden",
    category: "Other",
    health: 100,
    code: "xNfnyW",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "46eef28d-41e0-446a-a2d0-2ddb0598ea39",
    isApproved: false,
    activeProjects: 15,
    projects: 43,
    description: "Get started with Bun, Elysia and Drizzle ORM",
    readme:
      "This template is for those looking to quickly get started with Bun, Elysia and Drizzle ORM. The database used is a Postgres database.\n\nOnce this template is deployed, follow these steps to ensure everything is working as expected:\nEnsure the DATABASE_URL env variable is set to ${{Postgres.DATABASE_URL}}\nIn the settings of the server, under Networking, make sure a domain is generated\nThe initial deploy will fail on the Drizzle migrate step. Clone the repo created and add your tables to the schema.\n",
    name: "bun-elysia-drizzle",
    category: "Starters",
    health: 75,
    code: "xuXPu7",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "50cade2c-91fe-4194-94cf-c7ce1748a03f",
    isApproved: false,
    activeProjects: 2,
    projects: 14,
    description: "PostgreSQL database with a CRON job that uploads a backup to S3",
    readme:
      "PostgreSQL & S3 Backup\n\nThis template contains a PostgreSQL database and a CRON job that automatically creates a backup and uploads it to S3.\n\nWhat you need\n\nAWS Account with Access Key\nS3 Bucket\n\nVariables\n\n| Name                 | Description                                                                                                                                                                                                                | Optional | Default value |\n|----------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------|---------------|\n| SCHEDULE             | CRON schedule at which the backup is run. The schedule also supports non standard values like @hourly, @daily, @weekly, @monthly and @yearly. If left empty the backup will be run immediately and the container will stop | Yes      |               |\n| BACKUP_KEEP_DAYS     | The number of days to keep a backup file for. If left empty backups will NEVER be automatically deleted                                                                                                                    | Yes      |               |\n| Passphrase           | Passphrase to be used when encrypting the backup using GPG. If left empty NO encryption will be done                                                                                                                       | Yes      |               |\n| S3_REGION            | The region the AWS S3 bucket was created in                                                                                                                                                                                | No       |               |\n| S3_BUCKET            | The name of the bucket to upload your files into                                                                                                                                                                           | No       |               |\n| S3_ACCESS_KEY        | The ID of the your access key used to upload files into the S3 bucket                                                                                                                                                      | No       |               |\n| S3_SECRET_ACCESS_KEY | The secret key of your AWS access key                                                                                                                                                                                      | No       |               |\n| S3_PREFIX            | The prefix to be used when uploading the backup to S3. If left empty the backup will be uploaded to the root of the bucket                                                                                                 | No       | backup        |",
    name: "PostgreSQL & S3 Backup",
    category: "Storage",
    health: 100,
    code: "XV2dlg",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "17ed0f47-6474-40a2-a579-5e862311ebf8",
    isApproved: false,
    activeProjects: 16,
    projects: 46,
    description: "Miniflux is a minimalist and opinionated RSS feed reader",
    readme:
      "Miniflux is a minimalist and opinionated feed reader. This template provides an easy way to deploy Miniflux on Railway.\n\nDeployment\n\nDuring the deployment, you will be asked to provide a username and password for the admin account. Set these to be whatever you want. After the first deployment completes, delete the following environment variables:\n\nCREATE_ADMIN\nADMIN_USERNAME\nADMIN_PASSWORD\n\nYou only need to delete these before the next deployment, and if you don't it won't be too catastrophic, just you probably don't want your password sitting around in an env file for longer than it needs to.\n\nConfiguration\n\nMiniflux provides a number of configuration options that can be set from environment variables. You can discover them here  ",
    name: "Miniflux",
    category: "Other",
    health: 89,
    code: "8W4qCG",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6c39b616-ad70-484f-bec6-1c55befeb34b",
    isApproved: false,
    activeProjects: 385,
    projects: 561,
    description: "Flowise AI with persisted volume, PostGIS & private networking.",
    readme:
      "* üìù Notes: *\nUse the flowise-railway template (https://railway.app/template/pn4G8S) if you don't need pre-configured persisted volume, PostGIS and private networking on Railway.\n\nDeploy Flowise with Railway\n\n‚ú® Features\nPre-configured persisted volume.\nMost of the Flowise configs are pre-configured.\nUse PostGIS as the default database for Flowise.\nThe communication from Flowise to the database is accomplished through the Railway internal private network, reducing unnecessary egress fees.\n\n‚úÖ Prerequisite\nPostgres or PostGIS is deployed to an environment on Railway\nFlowise and PostGIS have to be deployed to the same environment to leverage the benefits of private networking on Railway.\nflowise database is created in PostGIS\n\nüíÅ‚Äç‚ôÇÔ∏è Usage\n\nDeploy on Railway\n\nüöÄ Quick start\n\nClick Deploy Now\n\nChange to your preferred repository name\n\nClick Configure and click Save Config for both services.\n\nClick Deploy.\n\nLet Railway deploy all the services for you.\n\nOnce the process is successful, you will be able to view a deployed URL.\n\nüí° What if I would like to use my current Postgres/PostGIS database server?\n\nClick Deploy Now\n\nChange to your preferred repository name\n\n(Important) Configure the database-related environment variables to point to your current PostGIS database.\n\nDATABASE_HOST (Private or public network database host. i.e. postgre.railway.internal)\n\nDATABASE_NAME (Database name. i.e. flowise)\n\nDATABASE_PASSWORD (Database user password)\n\nDATABASE_PORT (Database private or public network port. i.e. 5432)\n\nDATABASE_USER (Database user - A database user that allows you CRUD the flowise database)\n\nClick Deploy\n\nLet Railway deploy all the services for you.\n\nOnce the process is successful, you will be able to view a deployed URL.\n\nDelete the PostGIS database service that comes with this template if no longer needed.\n\nüíÅ‚Äç‚ôÄÔ∏è Example screenshots\n\nFlowise AI login screen!\n\n\nFlowise AI version screen!\n\nFlowise database!\n\nCredit\n\nInspired from https://railway.app/template/pn4G8S, https://github.com/FlowiseAI/Flowise/tree/main/docker and https://github.com/HenryHengZJ/FlowiseAI-Railway/blob/main/Dockerfile",
    name: "FlowiseAI",
    category: "AI/ML",
    health: 100,
    code: "A7Dwg9",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6180aad6-4037-4a9f-9ab2-ec49f865020c",
    isApproved: false,
    activeProjects: 45,
    projects: 101,
    description: "Hosts Rivet with an Open AI compatible API + Chatbot-UI as a frontend",
    readme:
      'This template allows you to run your Rivet-Graphs (https://rivet.ironcladapp.com/) in the cloud and talk to them via Chatbot-UI interface. Only thing you need to do is add your project files via the fileupload interface and create a custom model in Chatbot-UI!\n\nVideo-tutorial can be found here:\nhttps://youtu.be/WY2t1wFg50M\n\nRequirements:\nSupabase account free\nYour Rivet project file with the following settings:\n  Main graph selected in project settings\n  Chat node(s) that should be used as streaming output need to be renamed to "output"\nOpen AI API Key\n\nInstallation:\nFilebrowser: Just add username + password you want to use\nChatbot-UI: Add all the information from supabase (see variable descriptions)\nRivet-Chat-API: Add your Open-AI-Key\n\nSetup:\nGo to Filebrowser, open the public URL, enter your username + password and upload your rivet project file (remember the name)\nGo to Chatbot-UI, create an account and click the link in the verification e-mail\nGo to "models" and create a custom model\n  Enter any name\n  For Model ID enter your rivet project file name, e.g. "example.rivet-project"\n  For Base URL enter: "http://rivet-chat-api.railway.internal:3100"\n  You do not need an API Key for internal communication\n\nFurther configurations can be done in your superbase account, e.g.:\n  Disallow new users to sign up\n  Edit the template + link in the verification e-mail\n  etc.\n\n',
    name: "Rivet + Chatbot-UI",
    category: "AI/ML",
    health: null,
    code: "XjMVyQ",
    languages: ["TypeScript", "JavaScript", "PLpgSQL", "Shell", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "552f980e-96fc-456a-9694-5de9389e90e3",
    isApproved: false,
    activeProjects: 37,
    projects: 114,
    description: "Open source project management for technical teams",
    readme:
      "\n    \n        \n    \n\n\nOpen source project management for technical teams\nKeep everything and everyone on track.\n\nAccelerate productivity\nCentralize, plan, and track all your work in one place. Focalboard helps your organization maintain a single source of truth, so your teams stay aligned to complete tasks, reach milestones, and achieve their goals.\n\nOrganize and visualize work, your way\nWork in the way that suits you best. Manage all your tasks on a Kanban, table, gallery, and calendar view. Focus on the highest priority items with board filters, and save an unlimited number of filtered views for quick access later.\n\nAlign your teams with real-time collaboration\nKeep everyone in sync with card comments, @mention teammates to get their attention, and set board permissions to share your board with the entire team or specific individuals.\n\nTons of templates to get you started\nGet started fast with our pre-built templates or create a fully custom board from scratch.\n\nFeature Highlights\n\n\tUnlimited boards\n\tGroup, filter, and sort tasks\n\tFile sharing\n\tUnlimited custom attributes\n\tCustomizable templates\n\tMeeting notes\n\tProject cards &amp; tasks\n\tArchiving &amp; back-up snapshots\n\tPriority labeling\n\tUser permissions\n\tTeam and direct messaging\n\tMulti-team views\n\n\nNeed help?\nWe have tons of documentation to help you make the most out of focalboard, head over to our documentation site to learn more about focalboard.\nGo to docs",
    name: "Focalboard",
    category: "Other",
    health: 100,
    code: "PEicbq",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "643e90e9-0a98-4177-9236-88109f1c84aa",
    isApproved: true,
    activeProjects: 3,
    projects: 14,
    description: "A Railway sidecar service for sending logs to a webhook",
    readme:
      'locomotive\n\nA Railway sidecar service for sending webhook events when new logs are received. Supports Discord, Datadog, Axiom, BetterStack and more!\n\nConfiguration\n\nConfiguration is done through environment variables. See explanation and examples below.\n\nGeneric Webhook Log Formats\n\nThese are examples of what the body would look like in the POST request done by locomotive\n\nFor Plaintext logs\n\n\n    {\n        "_metadata": {\n            "deploymentId": "577e2cf2-a1fc-4e0f-b352-2780bca73a94",\n            "deploymentInstanceId": "bbdc4e76-7600-415f-9f6b-e425311cec51",\n            "environmentId": "b5ce7ab5-96f1-4fa3-929b-fc883f89cbd1",\n            "environmentName": "production",\n            "projectId": "8a6502bf-6479-440c-a14f-78ecd52abf09",\n            "projectName": "Railyard",\n            "serviceId": "24335e07-e68b-498f-bc9e-1b9146436867",\n            "serviceName": "Autorack"\n        },\n        "message": "Hello, World!",\n        "level": "info",\n        "severity": "info",\n        "time": "2020-05-22T21:27:33Z",\n        "_time": "2020-05-22T21:27:33Z",\n        "dt": "2020-05-22T21:27:33Z",\n        "datetime": "2020-05-22T21:27:33Z",\n        "ts": "2020-05-22T21:27:33Z",\n        "timestamp": "2020-05-22T21:27:33Z"\n    }\n]\n\nFor Structured JSON logs\n\n[\n    {\n        "_metadata": {\n            "deploymentId": "5b7c81b35-1578-4eb8-8498-44f4f517b263",\n            "deploymentInstanceId": "46cda6d4-f76c-45cb-8642-c7265949e497",\n            "environmentId": "b5ce7ab5-96f1-4fa3-929b-fc883f89cbd1",\n            "environmentName": "production",\n            "projectId": "8a6502bf-6479-440c-a14f-78ecd52abf09",\n            "projectName": "Railyard",\n            "serviceId": "55b1755f-f2c6-4f24-8d51-0ed3754b253e",\n            "serviceName": "Superliner"\n        },\n        "level": "info",\n        "severity": "info",\n        "message": "Hello, World!",\n        "example_string": "foo bar",\n        "example_int": 12345678,\n        "example_float": 1.2345678,\n        "example_int_slice": [123, 456, 789],\n        "example_string_slice": ["hello", "world"],\n        "example_group": {\n            "example_grouped_int": 12345678,\n            "example_grouped_string": "Hello, World!"\n        },\n        "time": "2020-05-22T21:27:33Z",\n        "_time": "2020-05-22T21:27:33Z",\n        "dt": "2020-05-22T21:27:33Z",\n        "datetime": "2020-05-22T21:27:33Z",\n        "ts": "2020-05-22T21:27:33Z",\n        "timestamp": "2020-05-22T21:27:33Z"\n    }\n]\n\nGrafana Loki Plaintext Log Example\n\n{\n    "streams": [\n        {\n            "stream": {\n                "deployment_id": "fb8172c8-a65d-48a4-9d1e-9d5ef986c9c3",\n                "deployment_instance_id": "25dfeb9b-0097-4f91-820b-5dccc5009b1d",\n                "project_id": "dce92382-c4e4-4923-bacd-3a5f7bcab337",\n                "project_name": "Union Pacific Freight",\n                "environment_id": "57d88ccb-8db9-4aef-957e-ecd94c41fdf8",\n                "environment_name": "production",\n                "service_id": "aa8ce660-dad0-4f7d-8921-46295d180c09",\n                "service_name": "Dash 8",\n                "severity": "error",\n                "level": "error"\n            },\n            "values": [["1590182853000000000", "a plaintext message", {}]]\n        }\n    ]\n}\n\nGrafana Loki Structured Log Example\n\n{\n    "streams": [\n        {\n            "stream": {\n                "deployment_id": "fb8172c8-a65d-48a4-9d1e-9d5ef986c9c3",\n                "deployment_instance_id": "25dfeb9b-0097-4f91-820b-5dccc5009b1d",\n                "project_id": "dce92382-c4e4-4923-bacd-3a5f7bcab337",\n                "project_name": "Union Pacific Freight",\n                "environment_id": "57d88ccb-8db9-4aef-957e-ecd94c41fdf8",\n                "environment_name": "production",\n                "service_id": "aa8ce660-dad0-4f7d-8921-46295d180c09",\n                "service_name": "Dash 8",\n                "severity": "error",\n                "level": "error"\n            },\n            "values": [\n                [\n                    "1590182853000000000",\n                    "hello, world",\n                    {\n                        "float": "10.51",\n                        "number": "10",\n                        "string_value": "hello world",\n                        "user": "null"\n                    }\n                ]\n            ]\n        }\n    ]\n}\n\nNotes:\n\nMetadata is gathered once when the locomotive starts, If a project/service/environment name has changed, the name in the metadata will not be correct until the locomotive is restarted.\n\nThe body will always be a JSON array containing one or more log objects.\n\nVarious common timestamp attributes are included in every log object to increase compatibility with external logging services. [ref 1, ref 2\n\nThe default Content-Type for these POST requests is set to application/json\n\nStructured log attributes sent to Grafana Loki must always be a string\n\nAll variables:\n\nRAILWAY_API_KEY - Your Railway API key.\n\n    Project level keys do not work.\n\nENVIRONMENT_ID - The environment ID your service is in.\n\n    Auto-filled to the current environment ID.\n\nTRAIN - The ID of the service you want to monitor.\n\n    Supports multiple service Ids, separated with a comma.\n\nDISCORD_WEBHOOK_URL - The Discord webhook URL to send logs to.\n\n    Optional.\n\nDISCORD_PRETTY_JSON - Pretty print the RAW JSON object in Discord embeds.\n\nSLACK_WEBHOOK_URL - The Slack webhook URL to send logs to.\n\n    Optional.\n\nSLACK_PRETTY_JSON - Pretty print the RAW JSON object in Slack embeds.\n\nSLACK_TAGS - Tags to add to the Slack message.\n\n    Supports multiple tags, separated with a comma.\n    Optional.\n\nLOKI_INGEST_URL - The Loki ingest URL to send logs to.\n\n    Example with no authentication: https://loki-instance.up.railway.app/loki/api/v1/push\n    Example with username/password authentication: https://user:pass@loki-instance.up.railway.app/loki/api/v1/push\n    Optional.\n\nINGEST_URL - The URL to send a generic request to.\n\n    Example for Datadog: INGEST_URL=https://http-intake.logs.datadoghq.com/api/v2/logs\n    Example for Axiom: INGEST_URL=https://api.axiom.co/v1/datasets/DATASET_NAME/ingest\n    Example for BetterStack: INGEST_URL=https://in.logs.betterstack.com\n    Optional.\n\nADDITIONAL_HEADERS - Any additional headers to be sent with the generic request.\n\n    Useful for auth. In the format of a cookie. meaning each key value pair is split by a semi-colon and each key value is split by an equals sign.\n    Example for Datadog: ADDITIONAL_HEADERS=DD-API-KEY=;DD-APPLICATION-KEY=\n    Example for Axiom/BetterStack: ADDITIONAL_HEADERS=Authorization=Bearer API_TOKEN\n\nREPORT_STATUS_EVERY - Reports the status of the locomotive every 5 seconds.\n\n    Default: 5s.\n    Format must be in the Golang time.DurationParse format\n        E.g. 10h, 5h, 10m, 5m 5s\n\nLOGS_FILTER - Global log filter.\n\n    Either ALL, INFO, ERROR, WARN or any custom combination of severity / level.\n    Accepts multiple values, separated with a comma.\n    Defaults to allowing all log levels.\n    Optional.\n\nLOGS_FILTER_DISCORD - Discord specific log filter.\n\n    Same options and behavior as the global log filter.\n\nLOGS_FILTER_SLACK - Slack specific log filter.\n\n    Same options and behavior as the global log filter.\n\nLOGS_FILTER_LOKI - Slack specific log filter.\n\n    Same options and behavior as the global log filter.\n\nLOGS_FILTER_WEBHOOK - Ingest URL specific log filter.\n\n    Same options and behavior as the global log filter.\n\nLog Filtering\n\nYou can filter logs by severity level and content using the following environment variables:\n\nLevel Filters\n\nLOGS_FILTER: Global level filter applied to all outputs\nLOGS_FILTER_DISCORD: Level filter applied to Discord output\nLOGS_FILTER_SLACK: Level filter applied to Slack output\nLOGS_FILTER_LOKI: Level filter applied to Loki output\nLOGS_FILTER_WEBHOOK: Level filter applied to webhook output\n\nLevel filter options: ALL, INFO, ERROR, WARN, or any custom combination of severity / level.\n\nContent Filters\n\nLOGS_CONTENT_FILTER: Global content filter applied to all outputs\nLOGS_CONTENT_FILTER_DISCORD: Content filter applied to Discord output\nLOGS_CONTENT_FILTER_SLACK: Content filter applied to Slack output\nLOGS_CONTENT_FILTER_LOKI: Content filter applied to Loki output\nLOGS_CONTENT_FILTER_WEBHOOK: Content filter applied to webhook output\n\nContent filters support regular expressions or plain text searches.\n\nExamples:\n\n"hello"\n"[A-za-z]ello"',
    name: "locomotive",
    category: "Observability",
    health: 96,
    code: "jP9r-f",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ec546e93-8b25-4c4b-83f7-870e2fe67d39",
    isApproved: false,
    activeProjects: 15,
    projects: 34,
    description: "A self-hosted, ad-free, privacy-respecting metasearch engine",
    readme:
      "Whoogle\n\nDeploy on Railway\n\nWhat is Whoogle?\nWhoogle Search is a privacy-friendly search engine that acts as a proxy between you and Google, providing search results without exposing your personal information to the search giant. Get Google search results, but without any ads, JavaScript, AMP links, cookies, or IP address tracking. Easily deployable in one click as a Docker app, and customizable with a single config file. Quick and simple to implement as a primary search engine replacement on both desktop and mobile.\n\npicture1\npicture2\npicture3\n\nFeatures\nPrivacy-Focused: Whoogle Search acts as an intermediary, preventing Google from directly tracking your searches.\nOpen Source: The project is open-source, allowing users to review and contribute to the codebase.\nCustomizable: Users can configure Whoogle Search to suit their preferences and requirements.\n\nEnvironment variables\n\nWHOOGLE_USER The username for basic auth. WHOOGLE_PASS must also be set if used. (default: empty)\nWHOOGLE_PASS The password for basic auth. WHOOGLE_USER must also be set if used. (default: empty)\nPORT 5000\nWHOOGLE_CONFIG_TOR To enable or disable TOR with boolean value of 0 or 1 (default: 0)\nWHOOGLE_CONFIG_GET_ONLY Search using GET requests only (default: 1)\n\nFor more information regarding Environment vairables, Please do checkout here: https://github.com/benbusby/whoogle-search?tab=readme-ov-file#environment-variables\n\nüìù Notes\nSource repo: https://github.com/benbusby/whoogle-search",
    name: "Whoogle",
    category: "Other",
    health: 100,
    code: "YirLEs",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3c4d1f05-7f5f-4f41-b280-142e6fcad402",
    isApproved: false,
    activeProjects: 5,
    projects: 12,
    description: "Real-time digital product observability.",
    readme:
      "This is a self-hosted option for https://supso.co/, the developer-friendly, real-time digital product observability and analytics.\n\nThe basic setup of Supso requires just the public URL of your app set and https://app.useplunk.com/ token to send authentication emails.\n\nRead more: https://supso.co/docs/",
    name: "Supso",
    category: "Analytics",
    health: null,
    code: "yrOOdm",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b1ac9619-3390-478e-88e7-123acd0b2be2",
    isApproved: false,
    activeProjects: 1,
    projects: 4,
    description: "Minimalist self-hosted customer feedback CMS",
    readme:
      "You need at least one Postgresql instance up and running.\n\nThen you can deploy like a simple Next.js app.\n\nThe environment variables you need:\n\nNEXTAUTH_SECRET=topsecret\nNEXTAUTH_URL=https://yourdomain.com\nDATABASE_URL=postgres://....\n\nSMTP_USER=yoursmtpuser\nSMTP_PASSWORD=yoursmtppass\nSMTP_HOST=yoursmtpserver\nSMTP_PORT=587\n\nMore details documentation is coming.",
    name: "Voi Feedback",
    category: "CMS",
    health: 0,
    code: "kJ5jtI",
    languages: ["TypeScript", "MDX", "Dockerfile", "CSS", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "63fa91c3-0baf-4802-a4c2-4a74271c815c",
    isApproved: false,
    activeProjects: 0,
    projects: 3,
    description: "Cloudflare Tunnel Local Config Managed + Prometheus Metrics",
    readme:
      'This template will create a Cloudflare Tunnel that you can manage with a config.yml file in github, and creates a Prometheus metrics server that is listening to the metrics emitted from the Tunnel.\n\nIn order to use this template you must have your domain managed by Cloudflare.\n\nWhy use Cloudflare Tunnels?\nOne of the biggest reasons to use a Cloudflare Tunnel is so that you do not expose any of your services to the internet directly. Rather than exposing your services through the railway proxy you will only expose them through Cloudflare where you can configure rules for when traffic should be allowed through the firewall.\nYou can also very easily configure Cloudflare Access rules with a Tunnel which will limit access of any service you want to people who are authenticated inside of your own organization, you can for example expose Grafana through the Tunnel and require authentication through Access and now only your employees can access the grafana instance.\n\nHow do I use this template?\n\nBecause this template is using a local config instead of a managed tunnel it does require a bit more setup to use. If you want something a bit easier to deploy I would recommend the following: Cloudflare Tunnel Template\n\nThe first thing you will want to do is install cloudflared and login. You can find out how to install and login from the Cloudflare Tunnel Docs.\n\nAfter you have installed and logged into cloudflared you will want to create a tunnel with the following command:\ncloudflared tunnel create TunnelName]\n\nOnce you create a tunnel it will create a credentials file in the default cloudflared directory. You can find out where that is from the [Cloudflare Tunnel Docs\n(For windows it will be in %USERPROFILE%\\.cloudflared)\n\nThe files name will be .json. Assuming this is the first time you have created a tunnel it should be the only json file in the directory.\n\nUsing this file you will want to extract the 3 values and insert them into a JSON string of the following format:\n{\n  "a": "AccountTag",\n  "t": "TunnelID",\n  "s": "TunnelSecret"\n}\n\nThen you will want to base64 encode the string value. The result of this should be put into the TUNNEL_TOKEN env variable.\n\nAs a helper heres a javascript command you can run to get the token:\nbtoa(JSON.stringify({\n    a: "AccountTag",\n    t: "TunnelID",\n    s: "TunnelSecret"\n}))\n\nOnce you enter in the tunnel token you can now deploy and the tunnel should startup for you and the git repo to manage the tunnel config and prometheus will be created for you.\n\nThe first thing you will want to do after deploying is modify your tunnel config. You can see all of the options for configuration here: https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/configure-tunnels/local-management/configuration-file/\n\nA very basic config is already provided in the initial repo, assuming you already have a service called server running on port 3000 and the promethues server created from this template running on port 9090.\nAll you would need to do in the config is modify the hostname to be your own domain that you want those services accessible at.\n\nOnce you have the config updated to your own domain you will want to update your domains DNS to actually route to the tunnel.\nThe DNS record you will want to create is a CNAME record pointing to TunnelID.cfargotunnel.com\n\nOnce the DNS records are created you should now be able to go to your domain and be served with your service.',
    name: "Cloudflared (local managed) + Prometheus",
    category: "Other",
    health: null,
    code: "cIsLIC",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "638f4276-120f-42a6-89e8-d49b8d92218d",
    isApproved: false,
    activeProjects: 15,
    projects: 56,
    description: "Website Analytics + Uptime Monitor + Server Status",
    readme:
      "Tianji\n\nInsight into everything\n\nWebsite analytics + Uptime Monitor  + Server Status = Tianji\n\nAll in one project!\n\nInstallation\n\nNo configuration is needed, however, I recommend you disable ALLOW_REGISTER by setting it to false in service variables after registering your accounts.\n\nDocumentation\n\nYou can find Tianjy's documentation here:\nhttps://tianji.msgbyte.com/docs/intro\n\nPreview\n\nscreenshot 1\n\nscreenshot 2\n\nscreenshot 3",
    name: "Tianji",
    category: "Observability",
    health: 100,
    code: "T_-mIh",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3cce426f-fa49-457c-95f7-310b24e036b9",
    isApproved: false,
    activeProjects: 8,
    projects: 16,
    description: "Set up logical replication between two PostgreSQL databases.",
    readme:
      "This templates deploys pg_easy_replicate on Railway.\n\npg_easy_replicate is a CLI orchestrator tool that simplifies the process of setting up logical replication between two PostgreSQL databases. pg_easy_replicate also supports switchover. After the source (primary database) is fully replicated, pg_easy_replicate puts it into read-only mode and via logical replication flushes all data to the new target database. This ensures zero data loss and minimal downtime for the application. This method can be useful for performing minimal downtime (up to &lt;1min, depending) major version upgrades between a Blue/Green PostgreSQL database setup, load testing and other similar use cases.\n\nLearn more at https://github.com/shayonj/pg_easy_replicate.",
    name: "pg_easy_replicate",
    category: "Storage",
    health: 67,
    code: "MfqQcU",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6bb10ea4-db7c-48f6-864a-a64e0eb92aab",
    isApproved: false,
    activeProjects: 11,
    projects: 42,
    description: "Flexible and secure way to share files and folders",
    readme:
      "OwnCloud\n\nownCloud is an open-source file sync, share and content collaboration software that lets teams work on data easily from anywhere, on any device. It provides access to your data through a web interface, sync clients or WebDAV while providing a platform to view, sync and share across devices easily - all under your control.\n\nOwnCloud Image\n\nAuthorization\n\nThe default username and password is admin. Recommended to change this immediately after deploying. You can change this in your settings.",
    name: "OwnCloud",
    category: "Storage",
    health: 93,
    code: "rLkDBH",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "58dad4e6-822a-40a0-8574-ac56b5d5478c",
    isApproved: false,
    activeProjects: 2,
    projects: 10,
    description: "Unique non-linear notebook for capturing and organising complex information",
    readme:
      "TiddlyWiki\n\nWelcome to TiddlyWiki, a non-linear personal web notebook that anyone can use and keep forever, independently of any corporation.\n\nTiddlyWiki is a complete interactive wiki in JavaScript. It is highly customisable: the entire user interface is itself implemented in hackable WikiText.\n\nLearn more and see it in action at https://tiddlywiki.com/\n\nAuthentication\n\nUSERNAME;\nYou can set your username when you deploy the template.\n\n\nPASSWORD;\nThe password is set automatically, however you add a custom password when you deploy the template. If you choose to have it done automatically then you can find the password in your service variables. ",
    name: "TiddlyWiki",
    category: "CMS",
    health: null,
    code: "jwXIco",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "15004250-8205-4607-899e-60b2b853d361",
    isApproved: false,
    activeProjects: 24,
    projects: 55,
    description: "Helps you organize your self-hosted services",
    readme:
      "Dashy\n\nDashy helps you organize your self-hosted services by making them accessible from a single place\n\nFeatures üåà\nüìÉ Support for multiple pages\nüö¶ Real-time status monitoring for each of your apps/links\nüìä Use widgets to display info and dynamic content from self-hosted services\nüîé Instant search by name, domain, or tags + customizable hotkeys & keyboard shortcuts\nüé® Many built-in color themes, with UI color editor and support for custom CSS\nüß∏ Many icon options - Font-Awesome, homelab icons, auto-fetching Favicon, images, emojis, etc.\nüíÇ Optional authentication with multi-user access, configurable privileges, and SSO support\nüåé Multi-language support, with 10+ human-translated languages, and more on the way\n‚òÅ Optional, encrypted, free off-site cloud backup and restore feature available\nüíº A workspace view, for easily switching between multiple apps simultaneously\nüõ©Ô∏è A minimal view, for use as a fast-loading browser Startpage\nüñ±Ô∏è Choose app launch methods: new tab, same tab, clipboard, pop-up modal, or open in workspace view\nüìè Customizable layout, sizes, text, component visibility, sort order, behavior, etc.\nüñºÔ∏è Options for a full-screen background image, custom nav-bar links, HTML footer, title, etc.\nüöÄ Easy to setup with Docker, or on bare metal, or with 1-Click cloud deployment\n‚öôÔ∏è Easy single-file YAML-based configuration, and option to configure app through the UI\n‚ú® Under active development with improvements and new features added regularly \nü§è Small bundle size, fully responsive UI, and PWA for basic offline access\nüÜì 100% free and open-source\nüîê Strong focus on privacy\nüåà And loads more...\n\nShowcase\n\nShowcase Gif\n\nConfiguration\n\nThis template fetches Dashy's default configuration from Dashy's GitHub. You can supply your own custom configuration by editing the DASHY_CONFIG_SOURCE service variable. \n\nNOTE: You'll have to wipe the volume when doing this because it won't fetch the config if an existing config is already found.\n\nDocumentation\n\nFor more information, please visit the Dashy docs.",
    name: "Dashy",
    category: "Observability",
    health: null,
    code: "MtdjAQ",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "985ba6e9-b158-45c1-ba69-1d3f31b89e5e",
    isApproved: false,
    activeProjects: 32,
    projects: 104,
    description: "A privacy-first, lightweight note-taking service",
    readme:
      "\n    \n        \n    \n\n\nA privacy-first, lightweight note-taking service. Easily capture and share your great thoughts\n\nIn a world inundated with information, effective note-taking is the key to organizing, retaining, and accessing knowledge. Memos offers a powerful solution for managing your thoughts, ideas, and information. This document will walk you through the art of creating and managing your memos.\n\ndemo\n\nKey points\n\nOpen source and free forever. Embrace a future where creativity knows no boundaries with our open-source solution ‚Äì free today, tomorrow, and always.\nSelf-hosting with Docker in just seconds. Enjoy the flexibility, scalability, and ease of setup that Docker provides, allowing you to have full control over your data and privacy.\nPure text with added Markdown support. Say goodbye to the overwhelming mental burden of rich formatting and embrace a minimalist approach.\nCustomize and share your notes effortlessly. With our intuitive sharing features, you can easily collaborate and distribute your notes with others.\nRESTful API for third-party services. Embrace the power of integration and unleash new possibilities with our RESTful API support.",
    name: "Memos",
    category: "Other",
    health: 70,
    code: "RaK3xU",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c1b0d638-61c0-4c99-b205-1b70fb82ae31",
    isApproved: false,
    activeProjects: 2,
    projects: 25,
    description: "Ultimate open-source web analytics to satisfy all your needs",
    readme:
      "\n    \n        \n    \n\n\nUltimate open-source web analytics to satisfy all your needs\n\nSwetrix is a cookieless Google Analytics alternative that does not invade your users' privacy.\nThis is the way analytics should be: GDPR compliant, lightweight and easy to use.\n\n\n\nSwetrix is a privacy-oriented, simple and fully cookie-less web analytics service.\nIt provides lots of metrics like unique visitors, live visitors monitoring, custom events, pageviews and many more.\n\nThe service also supports many other features, like dashboard metrics &amp; GDPR exports, email reports and more.\n\nThe project's purpose is to fight web analytics giants like Google Analytics while providing better quality and experience of using service.\n\nCore Analytics Features\n\nPowerful and easy analytics to display all the metrics you need. Cookieless. No need to be a data scientist to understand our analytics.\n\nMarketplace &amp; built-in Extensions\n\nNeed additional features? Connect extensions or write your own! Now you do not need to use many sources from different systems - expand and supplement everything in one!\n\nInstall extensions and sell your own. Came up with a great extension for your company? Great! Publish it on the marketplace and share your insights with the whole community.\n\nCore features\nMeasure website traffic with 99% accuracy: The most accurate analytics solution to track all basic metrics and see the RIGHT data.\n\nDemo &amp; Geo reports: Yes, it's a standard. But we keep track of exactly where your users are from as it is.\n\nUTM &amp; Reffers tracking: All the traffic from your companies and websites will be shown without a data loss.\n\nAgile system: A flexible system of settings for the basic rules of use - such as session definition, traffic accounting, and so on, is easy to set up and customise.\n\nCustom events (really easy to setup): User-friendly interface and ease of setting goals will help you measure the effectiveness of your website.\n\nUser flow: Track how users get to your site and where they go. Study the behaviour and patterns of your visitors.\n\nPrivacy compliance\n\nGDPR - data and processing based in EU zone.\nHIPAA - protect sensitive info.\nPCI DSS - payment data security.\nCCPA - control over the personal information.",
    name: "Swetrix",
    category: "Analytics",
    health: 0,
    code: "jnUfyS",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "efd19496-3966-4a71-87a4-3b547d178643",
    isApproved: false,
    activeProjects: 12,
    projects: 59,
    description: "System transforming physical paperwork into a searchable online archive",
    readme:
      "Paperless-ngx\n\nPaperless-ngx is a document management system that transforms your physical documents into a searchable online archive so you can keep, well, less paper.\n\nPaperless-ngx is the official successor to the original Paperless & Paperless-ng projects and is designed to distribute the responsibility of advancing and supporting the project among a team of people.\n\nFeatures\n\nscreenshot\n\nA full list of features and screenshots are available in the documentation.\n\nDocumentation\n\nThe documentation for Paperless-ngx is available at https://docs.paperless-ngx.com.\n\nInstallation\n\nInstalling requires little configuration, only configuration required is an admin username.\n\nThe admin password is set automatically, please see PAPERLESS_ADMIN_PASSWORD in service-variables to find it. You can also set it to a custom value during deployment configuration. \n\nOf course there's a lot of configuration you can add to this service through environment variables. Please see Paperless Config for more information.",
    name: "Paperless",
    category: "CMS",
    health: 90,
    code: "b72Thf",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "efbe0454-a126-4031-91af-67d1c2c3b539",
    isApproved: false,
    activeProjects: 11,
    projects: 22,
    description: "Minimalist, open source online pastebin",
    readme:
      "PrivateBin\n\nPrivateBin is a minimalist, open source online pastebin where the server has zero knowledge of pasted data.\n\nData is encrypted and decrypted in the browser using 256bit AES in Galois Counter mode.\n\nThis is a fork of ZeroBin, originally developed by S√©bastien Sauvage. PrivateBin was refactored to allow easier and cleaner extensions and has many additional features. It is, however, still fully compatible to the original ZeroBin 0.19 data storage scheme. Therefore, such installations can be upgraded to PrivateBin without losing any data.\n\nInstallation \n\nInstallation requires no configuration",
    name: "PrivateBin",
    category: "CMS",
    health: 100,
    code: "tJKuUQ",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ee903c81-bf67-4bc7-88cd-d350662d42f6",
    isApproved: false,
    activeProjects: 92,
    projects: 122,
    description: "PostgreSQL 15 database with data persistence and TCP Proxy",
    readme:
      'Overview\n\nPostgreSQL version 15 database service, deployed with Railway\'s official SSL-enabled image.\n\nA volume is mounted to the service to persist data between builds.\n\nTCP proxying is configured to allow accessing the database from anywhere.\n\nHow to use\n\nReference the DATABASE_URL variable from your service to connect to the database in your tool of choice (e.g. ${{Postgres.DATABASE_URL}})\n\nConnecting\n\nConnect to the database using the proxied domain and port found on the service settings page. The password can be found on the Variables page.\n\nIn a terminal, for example:\n\npsql "postgres://railway:PASSWORD@PROXY_DOMAIN:PROXY_PORT/railway"',
    name: "PostgreSQL 15",
    category: "Storage",
    health: 96,
    code: "nAqEGK",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6a9161cd-3dcd-4b6a-9f59-6cbff79ac434",
    isApproved: false,
    activeProjects: 1,
    projects: 5,
    description: "Realtime logs via websocket",
    readme:
      'Instructions\n\nOpen your preferred web browser and navigate to the provided HTTP endpoint URL to establish the websocket connection.\n\nRequest\n\nSet the request type to POST, and append the /log slug to your endpoint URL\nInclude these headers:\n\nContent-Type: application/json\nAuthorization: Basic AUTH\n\nReplace AUTH with your basic auth credentials (USER:PASS encoded in base64 format). This is critical for authentication.\n\nConstruct the body of your request like so:\n\n{\n  "log": "YOUR APPLICATION LOG"\n}\n\nAdditional Tips\nRefresh the page to clear logs\nRoute your endpoint through a custom domain with a Cloudflare proxy to enhance the security and reliability of your connections.',
    name: "Simple Log Server",
    category: "Other",
    health: null,
    code: "tdgyuV",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3c478eeb-5f4e-4b22-a025-ed5678c4b744",
    isApproved: false,
    activeProjects: 851,
    projects: 1837,
    description: "A powerful workflow automation tool for technical people",
    readme:
      "n8n.io - Workflow Automation\n\nn8n - Workflow automation tool\n\nn8n is an extendable workflow automation tool. With a fair-code distribution model, n8n\nwill always have visible source code, be available to self-host, and allow you to add your own custom\nfunctions, logic and apps. n8n's node-based approach makes it highly versatile, enabling you to connect\nanything to everything.\n\nn8n.io - Screenshot\n\nDemo\n\nüì∫ A short video (&lt; 4 min) that goes over key concepts of\ncreating workflows in n8n.\n\nAvailable integrations\n\nn8n has 200+ different nodes to automate workflows. The list can be found on:\nhttps://n8n.io/integrations\n\nDocumentation\n\nThe official n8n documentation can be found on our documentation website\n\nAdditional information and example workflows on the n8n.io website\n\nThe release notes can be found here and the list of breaking\nchanges here.\n\nLicense\n\nn8n is fair-code distributed under the\nSustainable Use License and the\nn8n Enterprise License.\n\nProprietary licenses are available for enterprise customers. Get in touch\n\nAdditional information about the license model can be found in the\ndocs.",
    name: "N8N (w/ webhook processors)",
    category: "Automation",
    health: 92,
    code: "5j_7LO",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "322760d6-fbd1-4480-a8bb-2f47a6ed0124",
    isApproved: false,
    activeProjects: 9,
    projects: 10,
    description: "A template for deploying Discord bots with Discord4J",
    readme:
      "This is a template for deploying Discord4J bots on Railway. It is based on the example Maven / Spring project from\nthe example repository\n\nIn order to start, you should have made a bot in the Discord Developer Portal. You will need the bot's key in order to deploy this template. Don't share the key with anyone!\n\nIf you wish to test locally, you can make a .env file with a BOT_TOKEN variable. I recommend using a separate bot user for testing and production.",
    name: "Discord4J Bot",
    category: "Bots",
    health: null,
    code: "GnBRzM",
    languages: ["Java", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "06b26664-9aab-4335-a9d4-2a64e2112348",
    isApproved: false,
    activeProjects: 0,
    projects: 8,
    description: "Scan files and URLs for viruses",
    readme:
      'Instructions\n\nDeploy the service and then copy the provided endpoint address for usage.\n\nURLs\n\nTo interact with the URL scanning endpoint, use the following details:\n\nEndpoint: /scan\nRequest Type: POST\n\nHeaders:\nContent-Type: application/json\nAuthorization: Bearer \n\nBody:\n\n{\n  "url": "YOUR_URL_HERE"\n}\n\nFiles\n\nFor scanning files, the endpoint and request setup are slightly different:\n\nEndpoint: /scan_files\nRequest Type: POST\n\nHeaders:\nContent-Type: multipart/form-data\nAuthorization: Bearer \n\nBody:\nWhen sending the request, attach each file under the key files. For example:\n\n{\n  "files": "file_1"\n},\n{\n  "files": "file_2"\n}\n\nRepeat the above format for each file you wish to scan.\n\nAdditional Information\n\nIt is recommended to route your endpoint through a custom domain with a Cloudflare proxy to enhance the security and reliability of your connections.\n',
    name: "Virus Scanner",
    category: "Other",
    health: null,
    code: "wq4sNq",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b87415e1-f694-43dc-8f0d-e05b3d97f379",
    isApproved: false,
    activeProjects: 8,
    projects: 22,
    description: "A minimal production-ready node HTTP server with fastify and typescript",
    readme:
      "A minimal production-ready node HTTP server with Fastify and Typescript.\n\n‚úÖ Typescript\n‚úÖ Graceful shutdown\n‚úÖ Optional Tracing with OpenTelemetry (configurable via environment variables)\n‚úÖ Properly configured request payload size limiting to help prevent Denial of Service attack vectors \n‚úÖ Auto-generated Swagger/OpenAPI documentation \n‚úÖ AbortSignal propagation to prevent unnecessary work (includes example and test)  \n‚úÖ Structured logging with pino \n‚úÖ Rich request logging middleware including request id, trace id, context propagation, and more \n‚úÖ zod for request validation, JSON schema inference, and OpenAPI/Swagger generation \n‚úÖ Testing with tap and undici \n‚úÖ helmet & compression\n",
    name: "Node Fastify",
    category: "Other",
    health: null,
    code: "xeb3TM",
    languages: ["TypeScript", "Dockerfile", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "505a04df-6059-4d6a-8230-35b39b438912",
    isApproved: false,
    activeProjects: 9,
    projects: 103,
    description: "Open-source platform for building internal tools and applications with ease",
    readme:
      "ToolJet\nToolJet is an open-source, low-code platform designed for developing and deploying custom internal tools. It enables developers to quickly build complex applications through a drag-and-drop interface, utilizing over 45 pre-built components. This approach significantly reduces development time and complexity, allowing for the creation of custom applications in minutes.\n\nToolJet\n\nWhy ToolJet\nThe platform supports a wide range of use cases, including the development of business applications that can connect to various data sources such as databases, cloud storages, GraphQL, API endpoints, Airtable, and Google Sheets. ToolJet's architecture is built using JavaScript/TypeScript, making it both flexible and powerful for modern application development.\n\nToolJet also includes specific products like ToolJet Database, which is built on PostgreSQL, offering a no-code solution for managing and scaling tables. Additionally, ToolJet Workflows provides a visual, node-based interface for automating data-centric tasks, enabling users to create detailed queries, manage conditional flows, and execute custom JavaScript code, simplifying complex processes.\n\nKey Features:\n\n Open-source, so you can view and customize the code to your liking\n All-in-one platform which allows you to build all sorts of internal applications and tools.\n A redesigned application builder for an enhanced developer experience.\n An in-built, no-code database powered by PostgreSQL.\n Support for building multi-page applications and using \n Python for frontend logic and data transformations.\n Multiplayer editing capabilities for collaborative team development.\n\nToolJet's approach to app development aims to revolutionize how businesses create and manage their internal tools, providing a versatile and efficient solution for rapid application development‚Äã\n\nDeployment Instructions\nCreate a new project using the template\nGenerate a public domain from the service settings\nEnsure environment variables are correctly populated e.g. TOOLJET_HOST : https://${{RAILWAY_PUBLIC_DOMAIN}}\nWait for deployment to complete and voila!\n\nLinks\nWebsite - https://www.tooljet.com/\nGitHub - https://github.com/ToolJet/ToolJet\nSlack - https://tooljet.com/slack\n",
    name: "ToolJet",
    category: "Other",
    health: 0,
    code: "NLgOKC",
    languages: [
      "JavaScript",
      "TypeScript",
      "SCSS",
      "HTML",
      "Shell",
      "EJS",
      "Dockerfile",
      "Handlebars",
      "MDX",
      "CSS",
      "HCL",
      "Procfile",
      "Batchfile",
    ],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d727dab9-3291-4e62-b69e-b6919bed3aa2",
    isApproved: false,
    activeProjects: 13,
    projects: 50,
    description: "Open Source API Development Ecosystem",
    readme:
      '\n    \n        \n    \n\n\nHoppscotch\n\nOpen Source API Development Ecosystem\n\nHoppscotch is a lightweight, web-based API development suite.\n\nIt was built from the ground up with ease of use and accessibility in mind providing all the functionality needed for API developers with minimalist, unobtrusive UI.\n\nNotes:\n\nThis template comes with Email based authentication by default, the first user to log in will be created as an admin. If you wish to change login methods please do that via the admin interface.\n\nCommunication to Postgres is done exclusively over the private network and the database is not exposed externally in any way by default, if you want to enable access from outside of the private network you can go to the databases settings to enable TCP proxying and enter the internal port (5432) the TCP proxy can be again removed at any point to close off external access.\n\n\n    \n      \n        \n        \n        \n      \n    \n\n\nI highly recommend you take a look at the Hoppscotch Documentation to learn more about the app.\n\nFeatures\n\n‚ù§Ô∏è Lightweight: Crafted with minimalistic UI design.\n\n‚ö°Ô∏è Fast: Send requests and get responses in real time.\n\nüóÑÔ∏è HTTP Methods: Request methods define the type of action you are requesting to be performed.\n\nGET Ôºç Requests retrieve resource information\nPOST Ôºç The server creates a new entry in a database\nPUT Ôºç Updates an existing resource\nPATCH Ôºç Very similar to PUT but makes a partial update on a resource\nDELETE Ôºç Deletes resource or related component\nHEAD Ôºç Retrieve response headers identical to those of a GET request, but without the response body.\nCONNECT Ôºç Establishes a tunnel to the server identified by the target resource\nOPTIONS Ôºç Describe the communication options for the target resource\nTRACE Ôºç Performs a message loop-back test along the path to the target resource\ncustom Ôºç Some APIs use custom request methods such as LIST. Type in your custom methods.\n\nüåà Theming: Customizable combinations for background, foreground, and accent colors ‚Äî customize now.\n\nChoose a theme: System preference, Light, Dark, and Black\nChoose accent colors: Green, Teal, Blue, Indigo, Purple, Yellow, Orange, Red, and Pink\nDistraction-free Zen mode\n\nCustomized themes are synced with your cloud/local session.\n\nüî• PWA: Install as a Progressive Web App on your device.\n\nInstant loading with Service Workers\nOffline support\nLow RAM/memory and CPU usage\nAdd to Home Screen\nDesktop PWA\n\nüöÄ Request: Retrieve response from endpoint instantly.\n\nChoose method\nEnter URL\nSend\n\n\nCopy/share public "Share URL"\nGenerate/copy request code snippets for 10+ languages and frameworks\nImport cURL\nLabel requests\n\nüîå WebSocket: Establish full-duplex communication channels over a single TCP connection.\n\nüì° Server-Sent Events: Receive a stream of updates from a server over an HTTP connection without resorting to polling.\n\nüå© Socket.IO: Send and Receive data with the SocketIO server.\n\nü¶ü MQTT: Subscribe and Publish to topics of an MQTT Broker.\n\nüîÆ GraphQL: GraphQL is a query language for APIs and a runtime for fulfilling those queries with your existing data.\n\nSet endpoint and get schema\nMulti-column docs\nSet custom request headers\nQuery schema\nGet query response\n\nüîê Authorization: Allows to identify the end-user.\n\nNone\nBasic\nBearer Token\nOAuth 2.0\nOIDC Access Token/PKCE\n\nüì¢ Headers: Describes the format the body of your request is being sent in.\n\nüì´ Parameters: Use request parameters to set varying parts in simulated requests.\n\nüìÉ Request Body: Used to send and receive data via the REST API.\n\nSet Content Type\nFormData, JSON, and many more\nToggle between key-value and RAW input parameter list\n\nüìÆ Response: Contains the status line, headers, and the message/response body.\n\nCopy the response to the clipboard\nDownload the response as a file\nView response headers\nView raw and preview HTML, image, JSON, and XML responses\n\n‚è∞ History: Request entries are synced with your cloud/local session storage.\n\nüìÅ Collections: Keep your API requests organized with collections and folders. Reuse them with a single click.\n\nUnlimited collections, folders, and requests\nNested folders\nExport and import as a file or GitHub gist\n\nCollections are synced with your cloud/local session storage.\n\nüìú Pre-Request Scripts: Snippets of code associated with a request that is executed before the request is sent.\n\nSet environment variables\nInclude timestamp in the request headers\nSend a random alphanumeric string in the URL parameters\nAny JavaScript functions\n\nüë®‚Äçüë©‚Äçüëß‚Äçüë¶ Teams: Helps you collaborate across your teams to design, develop, and test APIs faster.\n\nCreate unlimited teams\nCreate unlimited shared collections\nCreate unlimited team members\nRole-based access control\nCloud sync\nMultiple devices\n\nüë• Workspaces: Organize your personal and team collections environments into workspaces. Easily switch between workspaces to manage multiple projects.\n\nCreate unlimited workspaces\nSwitch between personal and team workspaces\n\n‚å®Ô∏è Keyboard Shortcuts: Optimized for efficiency.\n\n&gt; Read our documentation on Keyboard Shortcuts\n\nüåê Proxy: Enable Proxy Mode from Settings to access blocked APIs.\n\nHide your IP address\nFixes CORS (Cross-Origin Resource Sharing) issues\nAccess APIs served in non-HTTPS (http://) endpoints\nUse your Proxy URL\n\nOfficial proxy server is hosted by Hoppscotch - GitHub - Privacy Policy.\n\nüåé i18n: Experience the app in your language.\n\n‚òÅÔ∏è Auth + Sync: Sign in and sync your data in real-time across all your devices.\n\nSign in with:\n\nGitHub\nGoogle\nMicrosoft\nEmail (Default)\n\nüîÑ Synchronize your data: Handoff to continue tasks on your other devices.\n\nWorkspaces\nHistory\nCollections\nEnvironments\nSettings\n\n‚úÖ Post-Request Tests: Write tests associated with a request that is executed after the request\'s response.\n\nCheck the status code as an integer\nFilter response headers\nParse the response data\nSet environment variables\nWrite JavaScript code\n\nüå± Environments: Environment variables allow you to store and reuse values in your requests and scripts.\n\nUnlimited environments and variables\nInitialize through the pre-request script\nExport as / import from GitHub gist\n\n\n  Use-cases\n\nBy storing a value in a variable, you can reference it throughout your request section\nIf you need to update the value, you only have to change it in one place\nUsing variables increases your ability to work efficiently and minimizes the likelihood of error\n\n\n\nüöö Bulk Edit: Edit key-value pairs in bulk.\n\nEntries are separated by newline\nKeys and values are separated by :\nPrepend # to any row you want to add but keep disabled\n\nüéõÔ∏è Admin dashboard: Manage your team and invite members.\n\nInsights\nManage users\nManage teams',
    name: "Hoppscotch",
    category: "Other",
    health: 61,
    code: "2RQWQj",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1e7745d2-ce36-483e-a01e-9a807afaf408",
    isApproved: false,
    activeProjects: 7,
    projects: 23,
    description: "Backup a Postgres DB to your Personal Google Drive",
    readme:
      'Supported Modes\nSingle shot: run once when the app starts or when the Run Now button is clicked.\n  Set the CRON_EXPRESSION to -1 and the RUN_ON_START to true. \n\nScheduled: run on a schedule.\n  Set the CRON_EXPRESSION to a valid cron expression.\n\nHow to setup\n\nGoogle Cloud Platform Setup\nLog-in to the Google Cloud Console.\nEnable Google Drive API.\nThen create a new service account\nClick in the three dots on the right of the service account you just created and click on Manage keys.\nCreate a new json key and download the file.\nNow go to your Google Drive and create a new folder where the backups will be stored.\n    Save the Folder ID, it\'s the string after `https://drive.google.com/drive/folders/{ID HERE}`.\nShare the folder with the service account email (client_email), you can find it on the JSON file you downloaded on the previous step.\n    The email looks like: projectname@project.iam.gserviceaccount.com\n    Make sure to include Editor permissions.\n\nEnvironment Setup\nYou can use .env.default as a template for your environment variables.\n\nSERVICE_ACCOUNT: The downloaded JSON string of the service account.\n\n{"type":"service_account","project_id":"projectname","private_key_id":"123"}\n\nFOLDER_ID: The ID of the folder where the backups will be stored.\n  You can find the ID on the URL of the folder, it\'s the string after https://drive.google.com/drive/folders/.\n  Example: https://drive.google.com/drive/folders/1a2b3c4d5e6f7g8h9i0j1k2l3m4n5o6p7\n  Your ID: 1a2b3c4d5e6f7g8h9i0j1k2l3m4n5o6p7\n\nDATABASE_URL: The connection string of your Postgres database.\n\nCRON_EXPRESSION: A schedule for the backups.\n  Example: 0 0 * * * (every day at midnight)\n  You can use crontab.guru to help you create the expression.\n  If set to -1 the backup will run without a schedule, only once when the app starts.\n\nFILE_PREFIX: A prefix for the backup files.\n  Example: my-database-backup-\n  Result: my-database-backup-2024-02-01.sql.tar.gz\n\nRUN_ON_START: If set to true, the backup will run once when the app starts.\n',
    name: "Postgres Backup to your Google Drive",
    category: "Automation",
    health: 100,
    code: "16Nb5i",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5ed07ef7-6713-4395-ae2b-73362d5d5049",
    isApproved: false,
    activeProjects: 4,
    projects: 28,
    description: "A Q&A platform software for teams at any scales. [ Auto Installation ]",
    readme:
      "Answer\n\nA Q&A platform software for teams at any scales. Whether it‚Äôs a community forum, help center, or knowledge management platform, you can always count on Answer.\n\nCheck out Answer Docs for more details: https://answer.apache.org/docs\n\nInstallation\n\nOnce deployed, you'll need to provide admin login details and a contact email.\n\nIt's set up to auto-install by default, but you can set \"auto-install\" to false for manual installation.\n\nAuthentication\n\nThe password is set automatically and can be found in the ADMIN_PASSWORD service variable. You can also set it to a custom value during deployment of the template.",
    name: "Answer",
    category: "CMS",
    health: 100,
    code: "w3tCgf",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "82ebc8ee-6df3-4022-b517-90cede16679b",
    isApproved: false,
    activeProjects: 32,
    projects: 75,
    description: "Privacy focused finance manager",
    readme:
      "Actual Budget\n\nActual Budget is a super fast and privacy-focused app for managing your finances. At its heart is the well proven and much loved Envelope Budgeting methodology.\nYou own your data and can do whatever you want with it. Featuring multi-device sync, optional end-to-end encryption and so much more.\n\nInstallation\n\nThis template requires no setup or tweaking, you simply deploy the service!\n\nYou can read more about Actual in their documentation:\nhttps://actualbudget.org/docs/\n\nHappy financing!",
    name: "Actual Budget",
    category: "Other",
    health: 100,
    code: "AaOh7O",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "499280dd-a9e7-4c65-b873-96d3ae0455db",
    isApproved: false,
    activeProjects: 20,
    projects: 57,
    description: "Sets up Cloudflare Tunnel within your Railway project",
    readme:
      "Cloudflare Tunnel\n\nThis template deploys a Cloudflare Tunnel within your Railway project.\n\nWhat is a Cloudflare Tunnel?\n\nCloudflare Tunnel provides you with a secure way to connect your resources to Cloudflare without a publicly routable IP address.\n\nSource: Cloudflare Tunnel\n\n‚ÄãPrerequisites Before you start -\n\nIn Railway -\n\nEnsure that there are no domains on the desired service, whether custom or Railway-generated.\n\nHave the service you want to route traffic to listening on IPv6 -\n\n    Since Railway's internal network is IPv6 only the service will need to listen on ::\n\n    Start commands for some popular frameworks -\n\n    Gunicorn - gunicorn main:app -b ::]:${PORT:-3000}\n\n    Uvicorn - uvicorn main:app --host :: --port ${PORT:-3000}\n\n    Hypercorn - hypercorn main:app --bind [::]:${PORT:-3000}\n\n    Next - next start -H :: --port ${PORT:-3000}\n\n    Express / Nest - app.listen(process.env.PORT || 3000, \"::\");\n\nIn Cloudflare -\n\nHave your desired domain setup with Cloudflare's nameservers, they have a general guide for that [here.\n\nHave SSL/TLS mode set to Full.\n\n    SSL/TLS ‚Üí Overview ‚Üí Full\n\n1. Creating the tunnel\n\nGoto your Cloudflare accounts home page ‚Üí Zero Trust ‚Üí Networks ‚Üí Tunnels.\n\nClick Add a tunnel.\n\nLeave the Cloudflared option selected.\n\nClick Next.\n\nName your tunnel\n    \n    We recommend naming it in accordance with the Railway project that contains the service(s) you want to route traffic to.\n\nClick Save tunnel.\n\n2. Getting the tunnel token\n\nChoose the Docker environment.\n\nClick the copy icon.\n\nPaste the command into a note for later use.\n\n    Strip out docker run cloudflare/cloudflared:latest tunnel --no-autoupdate run --token  to leave only the token.\n\nLeave this page open\n\n3. Deploying the tunnel\n\nOpen the project that contains the service you want to route traffic to.\n\nClick Create ‚Üí Template ‚Üí Search for Cloudflare Tunnel.\n\nWhen prompted, enter your tunnel token.\n\n    Make sure there is no leading or trailing whitespace.\n\nClick Deploy Template\n\n4. Setting up the tunnel\n\nGo back to the Configure Cloudflare page.\n\nYou should now see a connector appear!\n\nClick Next.\n\nChoose a subdomain or leave it blank if you want to use the root domain.\n\nChoose a domain.\n\nChoose a path, or leave it blank.\n\nFor type choose HTTP.\n\nFor the URl use your services' private domain and the port your app listens on.\n\n    E.g. api.railway.internal:8080\n \nClick Save tunnel.\n\n5. Add another domain (Optional)\n\nThis is useful if you want to have a www subdomain or simply point different domains to the same Railway service.\n\nThis can even be used to point a subdomain or different domain to another service in the same Railway project.\n\nClick on the tunnel name ‚Üí Click Edit on the slide-out menu.\n\nClick Public Hostname ‚Üí Click Add a public hostname.\n\nFollow the same steps as outlined in step #4.\n\nConclusion\n\nWe are done, you can now open the public domain and you will be routed to your Railway service!\n\nAdditional Resources\n\nHow it works\nSet up a tunnel through the dashboard\nTunnel logs",
    name: "Cloudflare Tunnel",
    category: "Other",
    health: 100,
    code: "cf-tunnel",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a047291f-e9c2-4083-8c1b-7fb3a7778e15",
    isApproved: false,
    activeProjects: 11,
    projects: 66,
    description: "The modern replacement for Airflow",
    readme:
      "\n    \n        \n    \n\n\nüßô A modern replacement for Airflow\n\n\n\nGive your data team magical powers\n\n\n\n\n  Integrate and synchronize data from 3rd party sources\n\n\n\n  Build real-time and batch pipelines to transform data using Python, SQL, and R\n\n\n\n  Run, monitor, and orchestrate thousands of pipelines without losing sleep\n\n\nNotes:\n\nLogin with the default email admin@admin.com and the password admin. Once logged in go to /settings/workspace/users and change the default credentials.\n\nCommunication to Postgres is done exclusively over the private network and the database is not exposed externally in any way by default, if you want to enable access from outside of the private network you can go to the databases settings to enable TCP proxying and enter the internal port (5432) the TCP proxy can be again removed at any point to close off external access.\n\nü¶Ñ Make data magical\n\nWe put the fun in fun-ctional programming. Mage is a hybrid framework that combines the best of both worlds: the flexibility of notebooks with the rigor of modular code.\n\nExtract and synchronize data from 3rd party sources.\nTransform data with real-time and batch pipelines using Python, SQL, and R.\nLoad data into your data warehouse or data lake using our pre-built connectors.\nRun, monitor, and orchestrate thousands of pipelines without losing sleep.\n\nüî® Build\n\nHave you met anyone who loves developing in Airflow? That's why we designed an easy developer experience that you'll enjoy.\n\nSimple developer experience: Start developing locally with a single command or launch a dev environment in your cloud using Terraform.\nLanguage of choice: Write code in Python, SQL, or R in the same pipeline for ultimate flexibility.\nEngineering best practices built-in: Every step in your pipeline is a standalone file with modular code that's reusable and testable. No more DAGs with spaghetti code üçù.\nBring your favorite tools: Write dbt models, use your favorite IDE, track changes with Git, and much much more.\n\nüîç Preview\n\nDon't waste time waiting for your DAGs to finish testing. Get instant feedback from your code every time you run it.\n\nInteractive code: Immediately see results from your code's output with an interactive notebook UI.\nData is a first-class citizen: Each block of code in your pipeline produces data that can be versioned, partitioned, and cataloged for future use.\nCollaborate on cloud: Develop collaboratively on cloud resources, version control with Git, and test pipelines without waiting for an available shared staging environment.\n\nüöÄ Launch\n\nDon't have a large team dedicated to Airflow? Mage makes it easy for a single developer or small team to scale up and manage thousands of pipelines.\n\nFast deploy: Deploy Mage to Railway with only a few clicks.\nScaling made simple: Transform very large datasets directly in your data warehouse or through a native integration with Spark.\nObservability: Operationalize your pipelines with built-in monitoring, alerting, and observability through an intuitive UI.",
    name: "Mage AI",
    category: "Other",
    health: null,
    code: "pRF69q",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "538dc1d7-eee3-480c-babc-9e550f643ed6",
    isApproved: false,
    activeProjects: 9,
    projects: 28,
    description: "The MLflow Tracking is an API and UI for logging ML experiment.",
    readme:
      "The MLflow Tracking is an API and UI for logging parameters, code versions, metrics, and output files when running your machine learning code and for later visualizing the results. MLflow Tracking provides Python, REST, R, and Java APIs.\n\nhttps://mlflow.org/docs/latest/tracking.html",
    name: "MLflow Tracking",
    category: "AI/ML",
    health: 100,
    code: "R1yjwG",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "fe85f112-4db1-452c-918b-802861b97adc",
    isApproved: false,
    activeProjects: 7,
    projects: 30,
    description: "Kotlin Spring WebFlux template with PostgreSQL R2BDC",
    readme:
      "This starter initializes stand-alone Spring Boot web server.\n\nFeatures\nKotlin language\nWebFlux - Reactive programming architechture\nPostgreSQL R2DBC - Reactive database connection for reactive applications\n\nHighlights\nCreate stand-alone Spring applications\nComes with PostgreSQL service",
    name: "Kotlin Spring Boot (Maven)",
    category: "Starters",
    health: 67,
    code: "d7dHuj",
    languages: ["Kotlin"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "bc44c171-78d8-4e8b-8762-7a707326cdfb",
    isApproved: false,
    activeProjects: 598,
    projects: 745,
    description: "Telegram Bot using python-telegram-bot library",
    readme:
      "Python Telegram Bot\n\nTemplate for quick deployment using python-telegram-bot library.\n\nExamples\nThe examples from the library are included in the examples folder. \n\nbot.py is the main file to run the bot.\nSeparating the main logic would be a good idea.",
    name: "Telegram Bot",
    category: "Bots",
    health: 24,
    code: "-6JUpc",
    languages: ["Python", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "283446db-8cff-41d0-bfeb-7cc45944d78a",
    isApproved: false,
    activeProjects: 1,
    projects: 8,
    description: "Simple bookmark manager built with Go",
    readme:
      "Shiori\n\nNotes:\n\nLogin with the username shiori and the password gopher and then add a new owner account from within the settings.\n\nCommunication to Postgres is done exclusively over the private network and the database is not exposed externally in any way by default, if you want to enable access from outside of the private network you can go to the databases settings to enable TCP proxying and enter the internal port (5432) the TCP proxy can be again removed at any point to close off external access.\n\nShiori is a simple bookmarks manager written in the Go language. Intended as a simple clone of Pocket. You can use it as a command line application or as a web application. This application is distributed as a single binary, which means it can be installed and used easily.\n\nFeatures\n\nBasic bookmarks management i.e. add, edit, delete and search.\nImport and export bookmarks from and to Netscape Bookmark file.\nImport bookmarks from Pocket.\nSimple and clean command line interface.\nSimple and pretty web interface for those who don't want to use a command line app.\nPortable, thanks to its single binary format.\nSupport for sqlite3, PostgreSQL and MySQL as its database.\nWhere possible, by default shiori will parse the readable content and create an offline archive of the webpage.\nBETA[web-extension] support for Firefox and Chrome.",
    name: "Shiori",
    category: "Other",
    health: null,
    code: "NJ4mpN",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5ae905da-6fab-48dd-af01-a68dbb4ed349",
    isApproved: false,
    activeProjects: 19,
    projects: 72,
    description: "django + redis + postgres with tailwindcss and celery",
    readme:
      "Django + Redis + Postgres\n\nhttps://github.com/fauzaanu/djangorp/\n\nTailwindcss\n\nThe jstoolchain folder includes a tailwindcss setup\nYou should run npm i to install the dependencies\nThere is also a .xml file for PyCharm users to make it a File Watcher\nThe tailwind.config.js file is configured to search for html and py files\n.py files because forms.py could have tailwindcss classes due to the user of crispy-forms with crispy-tailwind\n\nRole of Redis\n\nRedis is used as a cache firstly\nSecondly, it is used as a message broker for Celery\nThirdly, it is used as a session store\n\nCelery\n\nCelery is used for background tasks that take a long time to complete.\ntasks.py is where the tasks are defined and they can be called from anywhere in the project\ncelery.py is where the celery app is created and configured, explicitly adding the tasks may be required\n\nImportant Notes\n\nGenerate migrations from dev environment and commit them to the repo\nAnything that takes too long to run should be a background task\nThere is no need for a .env file to be committed to the repo as the settings.py file is configured to read from\n  the variables defined in railway\nTo create a superuser install railway cli and run railway run python manage.py createsuperuser\nSplit into apps as much as possible (does not make sense early on but will later on)\nTemplates folder outside will be used for base / navbar / footer templates and anything that is not app specific\nOther templates should be inside the app folder with the recommended naming convention\n  of appfolder/templates/app_name/template_name.html (e.g. users/templates/users/login.html)\nstatic folder outside will be used for base / navbar / footer css and js files and anything that is not app specific\nOther static files should be inside the app folder with the recommended naming convention\n  of appfolder/static/app_name/css/style.css (e.g. users/static/users/css/style.css)\nCSRFTRUSTEDORIGINS might be needed and ifso set to the domain name of the website (e.g. example.com)\n  inside settings.py\n",
    name: "djangorp",
    category: "Starters",
    health: 88,
    code: "AcACbH",
    languages: ["HTML", "Python", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "607a1c15-8c38-402c-bd98-28cbe01b54d6",
    isApproved: false,
    activeProjects: 5,
    projects: 15,
    description: "The power of centralized access",
    readme:
      "\n    \n        \n    \n\n\nUsing the image built and provided by Rocker Project, RStudio Server by Posit enables you to provide a browser-based interface to a version of R running on a remote Linux server, bringing the power and productivity of the RStudio IDE to server-based deployments of R.\n\nLogging In\nUsername: rstudio\nPassword: Created on template deployment",
    name: "RStudio Server",
    category: "Other",
    health: 100,
    code: "FwxPvi",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "43f83c72-1b99-47ca-9feb-08855c5927ee",
    isApproved: false,
    activeProjects: 36,
    projects: 189,
    description: "Team communication platform with strong data protection.",
    readme:
      "Rocket Chat Template\n\nThe ultimate Free Open Source Solution for team communications. Rocket.Chat is an open-source fully customizable communications platform developed in JavaScript for organizations with high standards of data protection.\n\nHow to Install\n\nSimply deploy the template, there is no need to customize any of the environment variables.\n\nDebugging\n\nIf you have trouble during the initial setup at the last step, then try redeploying, this usually solves that problem.",
    name: "Rocket Chat",
    category: "Other",
    health: 100,
    code: "d9aKGD",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f79eeb67-032d-4aad-abb1-b4b2005a62eb",
    isApproved: false,
    activeProjects: 7,
    projects: 10,
    description: "Onchain options market making bot deployed to Arbitrum",
    readme:
      "Full Quick Start Tutorial on Github and Youtube!\n\nPrerequisites:\n1) An Arbitrum Wallet (private and public key)\n2) An Arbitrum RPC like LlamaNode or Alchemy\n\nInsert the Environment Variables and you are can now tell your friends your a Market Maker and Bot Trader!\n\nBut seriously, please it is recommended to watch the video and build your own container with supported tokens and strikes before promoting to production.\n\nDisclaimer:\nThis software is for educational purposes only. Do not risk money which you are afraid to lose. USE THE SOFTWARE AT YOUR OWN RISK. THE AUTHORS AND ALL AFFILIATES ASSUME NO RESPONSIBILITY FOR YOUR TRADING RESULTS\n",
    name: "DeFi Options Crypto Trading Bot - Premia",
    category: "Bots",
    health: 0,
    code: "URNlTZ",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f7750ea8-a4ae-4be7-a1fa-fdc9a020e6aa",
    isApproved: false,
    activeProjects: 4,
    projects: 9,
    description: "Email Authentication service.",
    readme:
      'Email Authenticator\n\nThis service sends one time passwords to the users of your apps. websites etc. You can use this to generate and verify user emails.\n\nHow to use this Template?\n\n/send-verification-mail is a POST method endpoint which takes \n{"email", "access_key"} in body\n\n/verify-code is also a POST method endpoint which takes\n{"email", "access_key", "code"} in body and returns status of the verification.\n\n\nBy default code will disappear in 15 minutes but you can change that.',
    name: "Email authenticator",
    category: "Authentication",
    health: 100,
    code: "Coitf7",
    languages: ["Python", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "df4cba44-b8c8-4ac9-a633-628054557956",
    isApproved: false,
    activeProjects: 6,
    projects: 22,
    description: "The open-source feedback platform for LLMs",
    readme:
      "What is Argilla?\n\nArgilla is an open-source platform for data-centric LLM development. Integrates human and model feedback loops for continuous LLM refinement and oversight.\n\nWith Argilla's Python SDK and adaptable UI, you can create human and model-in-the-loop workflows for:\n\nSupervised fine-tuning\nPreference tuning (RLHF, DPO, RLAIF, and more)\nSmall, specialized NLP models\nScalable evaluation.\n\nWhat is this template about?\n\nDeploy and start using Argilla on Railway in no time. You can find full documentation and configuration details here: Docker Quickstart\n",
    name: "Argilla",
    category: "AI/ML",
    health: 100,
    code: "KNxfha",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2bd82c45-05cf-4b89-80d6-b668c2d6fe95",
    isApproved: false,
    activeProjects: 2,
    projects: 12,
    description: "Streamline your scheduling process and save time",
    readme:
      "\n    \n        \n    \n\n\nDitch the back-and-forth emails\nStreamline your scheduling process and save time.\n\nSchedule group meetings with friends, colleagues and teams. Create meeting polls to find the best date and time to organize an event based on your participants' availability. Save time and avoid back-and-forth emails.\n\nBuilt with Next.js, Prisma, tRPC &amp; TailwindCSS",
    name: "Rallly",
    category: "Other",
    health: null,
    code: "LjpcWZ",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "321cf65b-a4e2-426f-807d-95805b1ea690",
    isApproved: false,
    activeProjects: 0,
    projects: 7,
    description: "The cornerstone of every automated network",
    readme:
      "\n    \n        \n    \n\n\nThe Premier Network Source of Truth\n\nNetBox is the leading solution for modeling and documenting modern networks. By combining the traditional disciplines of IP address management (IPAM) and datacenter infrastructure management (DCIM) with powerful APIs and extensions, NetBox provides the ideal \"source of truth\" to power network automation. Read on to discover why thousands of organizations worldwide put NetBox at the heart of their infrastructure.\n\nBuilt for Networks\n\nUnlike general-purpose CMDBs, NetBox has curated a data model which caters specifically to the needs of network engineers and operators. It delivers a wide assortment of object types carefully crafted to best serve the needs of infrastructure design and documentation. These cover all facets of network technology, from IP address managements to cabling to overlays and more:\n\nHierarchical regions, sites, and locations\nRacks, devices, and device components\nCables and wireless connections\nPower distribution tracking\nData circuits and providers\nVirtual machines and clusters\nIP prefixes, ranges, and addresses\nVRFs and route targets\nFHRP groups (VRRP, HSRP, etc.)\nAS numbers\nVLANs and scoped VLAN groups\nL2VPN overlays\nTenancy assignments\nContact management\n\nCustomizable &amp; Extensible\n\nIn addition to its expansive and robust data model, NetBox offers myriad mechanisms through - which it can be customized and extended. Its powerful plugins architecture enables users to extend the application to meet their needs with minimal development effort.\n\nCustom fields\nCustom model validation\nExport templates\nEvent rules\nPlugins\nREST &amp; GraphQL APIs\n\nAlways Open\n\nBecause NetBox is an open source application licensed under Apache 2, its entire code base is completely accessible to the end user, and there's never a risk of vendor lock-in. Additionally, NetBox development is an entirely public, community-driven process to which everyone can provide input.\n\nPowered by Python\n\nNetBox is built on the enormously popular Django framework for the Python programming language, already a favorite among network engineers. Users can leverage their existing skills coding Python tools to extend NetBox's already vast functionality via custom scripts and plugins.",
    name: "NetBox",
    category: "Other",
    health: null,
    code: "cLm4kn",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "fca7234c-ac04-4456-8720-1c987f8cf8de",
    isApproved: false,
    activeProjects: 1,
    projects: 4,
    description: "Feature flagging, A/B testing, and dynamic configuration microservice in Go",
    readme:
      '\n    \n        \n    \n\n\nFlagr is an open source Go service that delivers the right experience to the right entity and monitors the impact. It provides feature flags, experimentation (A/B testing), and dynamic configuration. It has clear swagger REST APIs for flags management and flag evaluation.\n\nFlagr Concepts\n\nThe definitions of the following concepts are in API doc.\n\nFlag. It can be a feature flag, an experiment, or a configuration.\nTag. This is a descriptive label attached to a flag for easy lookup and evaluation.\nVariant represents the possible variation of a flag. For example, control/treatment, green/yellow/red, etc.\nVariant Attachment represents the dynamic configuration of a variant. For example, if you have a variant for the green button, you can dynamically control what\'s the hex color of green you want to use (e.g. {"hex_color": "#42b983"}).\nSegment represents the segmentation, i.e. the set of audience we want to target. Segment is the smallest unit of a component we can analyze in Flagr Metrics.\nConstraint represents rules that we can use to define the audience of the segment. In other words, the audience in the segment is defined by a set of constraints. Specifically, in Flagr, the constraints are connected with AND in a segment.\nDistribution represents the distribution of variants in a segment.\nEntity represents the context of what we are going to assign the variant on. Usually, Flagr expects the context coming with the entity, so that one can define constraints based on the context of the entity.\nRollout and deterministic random logic. The goal here is to ensure deterministic and persistent evaluation result for entities. Steps to evaluating a flag given an entity context:\n    Take the unique ID from the entity, hash it using a hash function that has a uniform distribution (e.g. CRC32, MD5).\n    Take the hash value (base 10) and mod 1000. 1000 is the total number of buckets used in Flagr.\n    Consider the distribution. For example, 50/50 split for control and treatment means 0-499 for control and 500-999 for treatment.\n    Consider the rollout percentage. For example, 10% rollout means only the first 10% of the control buckets (again, use the previous step example, 0-49 out of 0-499 will be rolled out to control experience).\n\nFor more details, see the full Flagr Overview',
    name: "Flagr",
    category: "Other",
    health: null,
    code: "BZOvXb",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "99bfcb1f-ec66-41ae-9eba-0c395a9726ef",
    isApproved: false,
    activeProjects: 6,
    projects: 7,
    description: "No-nonsense outbound SMS API",
    readme:
      "This is a fork of the original TextBelt project by Ian Webster. I made two changes: \n\nAdd basic auth to the server\nAdd support for environment variables for easier deployment\n   \nYou shouldn't have to change anything in the code to get it to work. Just set the environment variables and run the server.\n\nNOTE: You will need an SMTP server to send text messages. This project uses an email-to-text gateway to send text messages. \nI suggest using SMTP2GO: https://www.smtp2go.com/ \n\nThe environment variables are:\nSMTP_HOST ex: smtp.gmail.com\nSMTP_PASSWORD ex: password123\nSMTP_USERNAME ex: admin\nSMTP_PORT ex: 587\nBASIC_AUTH_USERNAME ex: admin\nBASIC_AUTH_PASSWORD ex: password123\nFROM_NAME ex: TextBelt\nFROM_EMAIL ex: example@example.com",
    name: "Textbelt SMS API",
    category: "Other",
    health: null,
    code: "ntXGdO",
    languages: ["JavaScript", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7fff8135-06cd-4020-91b6-252a18352512",
    isApproved: false,
    activeProjects: 207,
    projects: 296,
    description: "phpMyAdmin is a free database management tool written in PHP.",
    readme:
      "phpMyAdmin is a free software tool written in PHP, intended to handle the administration of MySQL over the Web. phpMyAdmin supports a wide range of operations on MySQL and MariaDB. Frequently used operations (managing databases, tables, columns, relations, indexes, users, permissions, etc) can be performed via the user interface, while you still have the ability to directly execute any SQL statement.\n\nYou can find some more info about configuring env variables here: https://docs.phpmyadmin.net/en/latest/setup.html?highlight=docker#docker-environment-variables",
    name: "phpMyAdmin",
    category: "Other",
    health: 100,
    code: "HHegL4",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "06eae55c-17af-410a-b6b8-5bc7bb699c33",
    isApproved: false,
    activeProjects: 12,
    projects: 15,
    description: "Server-side Swift OpenAI reverse proxy server",
    readme:
      "SwiftOpenAIProxy is a server-side Swift reverse proxy created for iOS and macOS GPT wrappers. SwiftOpenAIProxy secures your OpenAI API while only granting access to paying users. SwiftOpenAIProxy is written in server-side Swift so Swift developers can easily customize it.",
    name: "SwiftOpenAIProxy",
    category: "AI/ML",
    health: null,
    code: "ocPcV2",
    languages: ["Swift", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ce6ebf41-cd64-4243-8ad4-b90598750038",
    isApproved: false,
    activeProjects: 0,
    projects: 9,
    description: "Open-source feature flags management tool",
    readme:
      "\n    \n        \n    \n\n\nPlatform for Managing Feature Flags\n\nNotes\n\nFeatbit will take a minute or so to fully come online despite Railway reporting everything is active, please give it a few minutes to set itself up before attempting to log in. The login page is /en/login.\n\nThe default username is admin@domain.com and the default password is 123456. Please change these by opening the Web UI and going to /en/workspace/profile.\n\nBoth MongoDB and Redis are unexposed to the public by default, If you want to enable public access to these databases go to their respective service settings and add a TCP Proxy, enter 27017 as the internal port for MongoDB, and 6379 as the internal port for Redis.\n\nShip Code Safely. Mitigate risks with Production Testing, roll out new features to 1% of users initially then expanding, and ensure instant error recovery without redeployment.\n\nInnovate Faster. Decouple feature deployment from release to minimize merge conflicts. Deploy at will, and release any feature immediately upon request from the boss.\n\n\n\n\nTargeted Experiences. Release features to specific target users, and continuously measure and improve the product's business value, while reducing the need for developer involvement.\n\nBorn for developers. Use simple if/else statements to control and release features, eliminating complex DevOps tasks. This enables developers to directly drive business value. FeatBit refine tool details, freeing up your energy to better focus on the business.\n\n\n\nUnderstanding Feature Usage Details. FeatBit tracks feature usage, creates on-demand experimentation reports, and exports data to tools like DataDog, Amplitude for diverse business needs.\n\n\n\nMuch more information visit https://www.featbit.co and main github repo https://github.com/featbit/featbit",
    name: "Featbit",
    category: "Other",
    health: null,
    code: "T6zOvm",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "53c93bdc-3994-4688-b0de-5e68d6a4031d",
    isApproved: false,
    activeProjects: 42,
    projects: 68,
    description: "The fastest way to build Flutter apps in Python",
    readme:
      '\n    \n        \n    \n\n\nThe fastest way to build Flutter apps in Python\n\nFlet enables developers to easily build realtime web, mobile and desktop apps in Python. No frontend experience required\n\nFrom idea to app in minutes\n\nAn internal tool or a dashboard for your team, weekend project, data entry form, kiosk app, or high-fidelity prototype - Flet is an ideal framework to quickly hack great-looking interactive apps to serve a group of users.\n\nSimple architecture\n\nNo more complex architecture with JavaScript frontend, REST API backend, database, cache, etc. With Flet you just write a monolith stateful app in Python only and get multi-user, real-time Single-Page Application (SPA).\n\nBatteries included\n\nTo start developing with Flet, you just need your favorite IDE or text editor. No SDKs, no thousands of dependencies, no complex tooling - Flet has a built-in web server with assets hosting and desktop clients.\n\nPowered by Flutter\n\nFlet UI is built with Flutter, so your app looks professional and could be delivered to any platform. Flet simplifies the Flutter model by combining smaller "widgets" to ready-to-use "controls" with an imperative programming model.\n\nSpeaks your language\n\nFlet is language-agnostic, so anyone on your team could develop Flet apps in their favorite language. Python is already supported, Go, C# and others are coming next.\n\nDeliver to any device\n\nDeploy Flet app as a web app and view it in a browser. Package it as a standalone desktop app for Windows, macOS, and Linux. Install it on mobile as PWA or view via Flet app for iOS and Android.\n\nRunning locally for development\n\nInstall dependencies pip install -r requirements.txt\n\nStart the flet development server flet main.py\n\nThis will open a new window and any changes made to main.py will be automatically reflected\n\nWhat makes this work on Railway?\n\nCustom build plan: nixpacks.toml\n\n    Sets the environment variable GIN_MODE to release for production purposes\n    Installs two needed system libraries libgtk-3-0 and libgstreamer1.0-0\n\nHave Flet listen on $PORT\n\n    Setting port to int(os.getenv("PORT", 8502)) in the ft.app constructor, This allows Railway to properly route traffic to and from the Flet app',
    name: "Flet",
    category: "Starters",
    health: 100,
    code: "gIcMS9",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5a86bf10-353b-44b6-af63-40364def2c16",
    isApproved: false,
    activeProjects: 160,
    projects: 327,
    description: " Vector database and vector similarity search engine",
    readme:
      "Qdrant\nQdrant (read: quadrant) is a vector similarity search engine and vector database. It provides a production-ready service with a convenient API to store, search, and manage points‚Äîvectors with an additional payload Qdrant is tailored to extended filtering support. It makes it useful for all sorts of neural-network or semantic-based matching, faceted search, and other applications. \nQdrant is written in Rust ü¶Ä, which makes it fast and reliable even under high load. See benchmarks. \nWith Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more! \n\n\n\n\nLinks\nWebsite: https://qdrant.tech \nDocumentation: https://qdrant.tech/documentation\nWeb UI: https://your_url.up.railway.app/dashboard\n\nLicense\n\nQdrant is licensed under the Apache License, Version 2.0\n",
    name: "Qdrant",
    category: "AI/ML",
    health: 92,
    code: "i1tz3T",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4d6a8350-b52d-4508-9b26-fff40438ed71",
    isApproved: false,
    activeProjects: 2,
    projects: 15,
    description: "A single user WebDAV server",
    readme:
      'Deploys a WebDAV storage server on railway, persisted on railway volumes. \n\nTo access the server, use the following configuration:\n\nURI: davs://yourprojectname.up.railway.app\nUsername: root\nPassword: The PASSWORD environment variable you set\n\nNote: The first time booting up this server will result in a message of "failed to load data", which is completely normal and expected.',
    name: "webdav",
    category: "Storage",
    health: 100,
    code: "FfCrs6",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "33cc6b52-b935-4361-be96-39788bf23afe",
    isApproved: false,
    activeProjects: 4,
    projects: 20,
    description: "Elevate your productivity with this versatile and intuitive template",
    readme:
      "\nJoplin Template\n\nOverview\n\nThis Joplin template provides a convenient starting point for various projects. It's designed to streamline your workflow and enhance productivity.\n\nCredentials\n\nThe default credentials are:\nEmail: admin@localhost\nPassword: admin\n\n( Recommended to change these credentials after deploying Joplin )\n",
    name: "Joplin",
    category: "Other",
    health: null,
    code: "QT1ytL",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8e5b1899-28a9-4649-a5ea-c734140f624e",
    isApproved: false,
    activeProjects: 996,
    projects: 2225,
    description: "Typebot facilita a cria√ß√£o de chatbots avan√ßados.",
    readme:
      "Typebot √© um construtor de chatbot de c√≥digo aberto. Ele permite que voc√™ crie chatbots avan√ßados visualmente, incorpore-os em qualquer lugar em seus aplicativos web/m√≥veis e colete resultados em tempo real\n\nCaracter√≠sticas\n\nTypebot facilita a cria√ß√£o de chatbots avan√ßados. Ele fornece os blocos de constru√ß√£o adapt√°veis ‚Äã‚Äãa qualquer caso de uso de neg√≥cios.\n\nConstrutor de bate-papo com mais de 34 blocos de constru√ß√£o, como:\n\nüí¨ Bolhas: Texto, Imagem/GIF, v√≠deo, √°udio, incorporar.\n\nüî§ Entradas: Texto, e-mail, n√∫mero de telefone, bot√µes, escolha de imagem, seletor de data, pagamento (Stripe), seletor de arquivos... entradas\n\nüß† L√≥gica: ramifica√ß√£o condicional, redirecionamentos de URL, scripts (Javascript), testes A/B\n\nüîå Integra√ß√µes: solicita√ß√µes Webhook / HTTP, OpenAI, Planilhas Google, Google Analytics, Meta Pixel, Zapier, Make.com, Chatwoot, Mais por vir...\nCrie um tema para seu chatbot de acordo com a identidade de sua marca:\n\nüé® Personalize as fontes, plano de fundo, cores, arredondamento, sombras e muito mais\n\nüí™ Temas avan√ßados com CSS personalizado.\n\nüíæ Modelos de temas reutiliz√°veis\nCompartilhe seu typebot em qualquer lugar:\n\nüîó Dom√≠nio personalizado\n\nüë®‚Äçüíª Incorpore facilmente como um cont√™iner, pop-up ou bal√£o de bate-papo com a biblioteca JS nativa.\n\n‚ö° Biblioteca de incorpora√ß√£o extremamente r√°pida. Sem iframe, sem depend√™ncias externas, sem impacto no desempenho.\n\nüíª Execut√°vel com solicita√ß√µes HTTP\nColete seus resultados e obtenha insights:\n\nüìä An√°lises aprofundadas com taxas de desist√™ncia, taxas de conclus√£o e muito mais\n\nüì• Exportar resultados para CSV\nConstru√≠do para desenvolvedores :\n\nüîì Sem bloqueio de fornecedor. Recursos criados com flexibilidade em mente.\n\nüíª APIs f√°ceis de usar .",
    name: "Typebot (Atualizado)",
    category: "Bots",
    health: 96,
    code: "g5MZ4j",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "bc920f22-1966-4270-a823-1aeea9cfbb63",
    isApproved: false,
    activeProjects: 76,
    projects: 125,
    description: "Deploy a discoverable Spring Boot-based microservice with Java",
    readme:
      "Spring Boot Microservice with Java Template\n\nüë®‚Äçüë©‚Äçüëß‚Äçüë¶ Target Audience\n\nThis template is intended for everyone interested in deploying Spring Cloud and Spring Boot based microservices architectures.\n\n‚ú® Features\n\nWith this template you will deploy a Spring Boot-based microservice with Java and Maven. Java version used is 17, but you can change this whenever you want.\n\nThis microservice comes with Spring Cloud Netflix Eureka Discovery Client inside and it will try to register itself against the Eureka Server. \n\nYou also has these dependencies included:\nSpring Boot Starder Data JPA.\nSpring Boot Starter Web.\nSpring Boot Starter Validation (Hibernate Validator)\nSpring Boot Starter Test.\nSpring Boot DevTools.\nLombok.\nH2 in-memory database.\n  Console path: /h2-console.\n  JDBC URL: jdbc:h2:mem:testdb.\n  Username: sa.\n  Password: Leave it blank.\n\nA REST Controller is defined with a straightforward GET mapping for the root path.\n\nMaven is used for dependency management.\n\nüëÄ See also\n\nCheck out Spring Cloud Netflix Eureka template.\n\n\n",
    name: "Spring Boot Microservice with Java",
    category: "Starters",
    health: 100,
    code: "JvYvDw",
    languages: ["Java", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c231905e-3ce3-4699-aec8-2c44d911511f",
    isApproved: false,
    activeProjects: 11,
    projects: 43,
    description: "A full-featured database management tool",
    readme:
      "\n    \n        \n    \n\n\nA full-featured database management tool\n\nAdminer (formerly phpMinAdmin) is a full-featured database management tool written in PHP. Conversely to phpMyAdmin, it consist of a single file ready to deploy to the target server. Adminer is available for MySQL, MariaDB, PostgreSQL, SQLite, MS SQL, Oracle, Elasticsearch, MongoDB and others via plugin.\n\nReplace phpMyAdmin with Adminer and you will get a tidier user interface, better support for MySQL features, higher performance and more security.\n\nAdminer development priorities are: 1. Security, 2. User experience, 3. Performance, 4. Feature set, 5. Size.\n\nFeatures\nConnect to a database server with username and password\nSelect an existing database or create a new one\nList fields, indexes, foreign keys and triggers of table\nChange name, engine, collation, auto_increment and comment of table\nAlter name, type, collation, comment and default values of columns\nAdd and drop tables and columns\nCreate, alter, drop and search by indexes including fulltext\nCreate, alter, drop and link lists by foreign keys\nCreate, alter, drop and select from views\nCreate, alter, drop and call stored procedures and functions\nCreate, alter and drop triggers\nList data in tables with search, aggregate, sort and limit results\nInsert new records, update and delete the existing ones\nSupports all data types, blobs through file transfer\nExecute any SQL command from a text field or a file\nExport table structure, data, views, routines, databases to SQL or CSV\nPrint database schema connected by foreign keys\nShow processes and kill them\nDisplay users and rights and change them\nDisplay variables with links to documentation\nManage events and table partitions (MySQL 5.1)\nSchemas, sequences, user types (PostgreSQL)",
    name: "Adminer",
    category: "Other",
    health: 100,
    code: "Pcgkm8",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1dc2e531-ee3b-41ec-8e4f-cda419b39cf8",
    isApproved: false,
    activeProjects: 21,
    projects: 46,
    description: "A cutting-edge Rust framework for the modern web.",
    readme:
      "This is a starter template for https://leptos.dev/ that gets you up and running with the framework in minutes.\n\nI have chosen Server Side Rendering with Axum. The starter features a server function to demonstrate that this functionality works.\n\nDeployment is done through docker, in an optimized alpine container. Resource usage is about 2MB under load and 0VCPU, thanks to Rust release builds.\n\nThe repository has renovate setup to keep dependencies up to date and supports GitHub Actions to test your code before a deploy happens.",
    name: "Leptos",
    category: "Starters",
    health: 0,
    code: "pduaM5",
    languages: ["Rust", "TypeScript", "Dockerfile", "SCSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "730ba8fd-077b-4f7c-a6d4-821984158300",
    isApproved: false,
    activeProjects: 23,
    projects: 66,
    description: "Search Engine Position Rank Tracking App",
    readme:
      "\n    \n        \n    \n\n\nSerpBear\n\nSerpBear is an Open Source Search Engine Position Tracking App. It allows you to track your website's keyword positions in Google and get notified of their positions.\n\nFeatures\n\nUnlimited Keywords: Add unlimited domains and unlimited keywords to track their SERP.\n\nEmail Notification: Get notified of your keyword position changes daily/weekly/monthly through email.\n\nSERP API: SerpBear comes with built-in API that you can use for your marketing &amp; data reporting tools.\n\nGoogle Search Console Integration: Get the actual visit count, impressions &amp; more for Each keyword. Discover new keywords, and find the most performing keywords, countries, pages.\n\nExport CSV: Export your domain keywords and their data in csv files whenever you want.\n\nMobile App: Add the PWA app to your mobile for a better mobile experience.\n\nZero Cost to RUN: Run the App on mogenius.com or Fly.io for free.\n\nHow it Works\n\nThe App uses third party website scrapers like ScrapingAnt, ScrapingRobot or Your given Proxy ips to scrape google search results to see if your domain appears in the search result for the given keyword.\n\nGetting Started\n\nStep 1: Deploy the App.\n\nStep 2: Access your App and Login.\n\nStep 3: Add your First domain.\n\nStep 4: Get an free API key from either ScrapingAnt or ScrapingRobot. Skip if you want to use Proxy ips.\n\nStep 5: Setup the Scraping API/Proxy from the App's Settings interface.\n\nStep 6: Add your keywords and start tracking.\n\nStep 7: Optional. From the Settings panel, setup SMTP details to get notified of your keywords positions through email. You can use ElasticEmail and Sendpulse SMTP services that are free.",
    name: "SerpBear",
    category: "Other",
    health: 100,
    code: "J29H1Z",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1b5fdb02-eb1e-41d4-9dc6-0c2219591ef2",
    isApproved: false,
    activeProjects: 0,
    projects: 8,
    description: "Deploy Spring Cloud Gateway. It acts as an Anti Corruption Layer (ACL)",
    readme:
      "Spring Cloud Gateway\n\nüë®‚Äçüë©‚Äçüëß‚Äçüë¶ Target Audience\n\nThis template is intended for everyone interested in deploying Spring Cloud and Spring Boot based microservices architectures.\n\n‚ú® Features\n\nWith this template you will deploy a Spring Cloud Gateway instance prepared to fetch data from Netflix Eureka to build the route table for redirections. Hence, it is recommended to use this template with the Spring Cloud Netflix Eureka one. Furthermore, this gateway implementation is set to be an Anti Corruption Layer. A Front-End application will make POST requests all the time to the backend. This gateway can translate those POST requests into GET (with query parameters support) and POST requests. The microservices behind this gateway will receive requests in RESTFUL way, without enforcing the Front-End application to send data in a non-secure way.\n\nüëÄ See also\n\nIf you are looking for a straightforward Spring Cloud Gateway, use this template\n\n###‚ùì What is Spring Cloud Gateway?\n\nSpring Cloud Gateway is a powerful library within the Spring ecosystem, designed for building API gateways in a microservices architecture. It acts as an intermediary for handling requests, routing them to various microservices. This gateway simplifies the complexity of managing multiple services by providing a single entry point for all incoming requests.\n\nKey features of Spring Cloud Gateway include dynamic routing, security, and monitoring. It supports routing based on various criteria like URL paths or headers and can dynamically route requests to different backends. This flexibility is crucial for modern applications with evolving needs.\n\nFurthermore, Spring Cloud Gateway integrates seamlessly with other Spring Cloud components, enhancing its functionality with service discovery, load balancing, and circuit breakers. This integration ensures that applications are not only efficiently routed but also resilient and secure.\n\nIn essence, Spring Cloud Gateway is an indispensable tool for developers looking to streamline their microservices architecture, offering easy management, dynamic routing, and integration with the broader Spring Cloud ecosystem.\n\n",
    name: "Spring Cloud Gateway - ACL",
    category: "Starters",
    health: null,
    code: "CWxqH0",
    languages: ["Java", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "73d5b4d4-df02-4bc1-a515-36f8b4616da1",
    isApproved: false,
    activeProjects: 7,
    projects: 10,
    description: "Deploy a Spring Cloud Gateway instance. Easily integrated with Eureka",
    readme:
      "Spring Cloud Gateway\n\nüë®‚Äçüë©‚Äçüëß‚Äçüë¶ Target Audience\n\nThis template is intended for everyone interested in deploying Spring Cloud and Spring Boot based microservices architectures.\n\n‚ú® Features\n\nWith this template you will deploy a Spring Cloud Gateway instance prepared to fetch data from Netflix Eureka to build the route table for redirections. Hence, it is recommended to use this template with the Spring Cloud Netflix Eureka one. HTTP Resolution is enabled by default.\n\nüëÄ See also\n\nIf you are looking for a complex Spring Cloud Gateway implementation with filters and request translation, use this template\n\n###‚ùì What is Spring Cloud Gateway?\n\nSpring Cloud Gateway is a powerful library within the Spring ecosystem, designed for building API gateways in a microservices architecture. It acts as an intermediary for handling requests, routing them to various microservices. This gateway simplifies the complexity of managing multiple services by providing a single entry point for all incoming requests.\n\nKey features of Spring Cloud Gateway include dynamic routing, security, and monitoring. It supports routing based on various criteria like URL paths or headers and can dynamically route requests to different backends. This flexibility is crucial for modern applications with evolving needs.\n\nFurthermore, Spring Cloud Gateway integrates seamlessly with other Spring Cloud components, enhancing its functionality with service discovery, load balancing, and circuit breakers. This integration ensures that applications are not only efficiently routed but also resilient and secure.\n\nIn essence, Spring Cloud Gateway is an indispensable tool for developers looking to streamline their microservices architecture, offering easy management, dynamic routing, and integration with the broader Spring Cloud ecosystem.\n\n",
    name: "Spring Cloud Gateway - Straightforward",
    category: "Starters",
    health: null,
    code: "OI2sbM",
    languages: ["Dockerfile", "Java"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b6e4a195-ff23-46d2-b9f9-ae0d7dced0d8",
    isApproved: false,
    activeProjects: 25,
    projects: 48,
    description: "Deploy a Spring Cloud Netflix Eureka server",
    readme:
      "Spring Cloud Netflix Eureka\n\nüë®‚Äçüë©‚Äçüëß‚Äçüë¶ Target Audience\n\nThis template is intended for everyone interested in deploying Spring Cloud and Spring Boot based microservices architectures.\n\n‚ú® Features\n\nWith this template you will deploy a Spring Cloud Netflix Eureka server prepared to register microservices in your architecture. For testing purposes, HTTP resolution is enabled. We recommend to disable it for a production deployment.\n\nüëÄ See also\n\nIf you are looking for a reversal proxy for your Spring based microservices architecture, use this template\n\n###‚ùì What is Spring Cloud Netflix Eureka?\n\nSpring Cloud Netflix Eureka is a key tool in the microservices world, offering a robust solution for service discovery. Part of the Spring Cloud ecosystem, it is based on Netflix Eureka. Its main function is to allow services to register in its registry and discover other services through simple queries. This approach facilitates scalability and service management in microservices architectures, where services can vary and change dynamically.\n\nEureka helps developers focus on business logic while the system automatically handles service discovery. This includes load balancing, fault handling, and providing an easy interface for service management. Eureka seamlessly integrates with other Spring Cloud components like Config Server and Circuit Breaker, offering a cohesive ecosystem for microservices development.\n\nIn summary, Spring Cloud Netflix Eureka is an essential tool for building scalable, resilient, and efficient modern microservices-based applications.\n",
    name: "Spring Cloud Netflix Eureka",
    category: "Starters",
    health: 100,
    code: "HM8cFB",
    languages: ["Dockerfile", "Java"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "bdb61144-8841-4dab-b624-14bbb20ae4b8",
    isApproved: false,
    activeProjects: 2,
    projects: 12,
    description: "A self-hosted setup for Atuin, the shell history sync server.",
    readme:
      "Checkout the Atuin docs for how to get your local environment setup: https://docs.atuin.sh/\n\nYou'll want to update the sync_address in your local config (./config/atuin/config.toml) to point at your new self-hosted instance.\n\nAfter that you can run atuin register to register with your self-hosted instance. Might want to set the ATUIN_OPEN_REGISTRATION to false after you register.",
    name: "Atuin Shell History Server",
    category: "Other",
    health: 100,
    code: "5J-Ofu",
    languages: ["Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ccf59349-f3ac-42a8-96d0-dcb662490ffc",
    isApproved: false,
    activeProjects: 8,
    projects: 24,
    description: "Language-agnostic persistent background job server",
    readme:
      "\n    \n        \n    \n\n\nHigh-performance job processing for the polyglot enterprise\n\n\n\n",
    name: "Faktory",
    category: "Queues",
    health: 100,
    code: "Hh00T5",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d7d8eb01-991d-43c6-9866-180d1f6c20f5",
    isApproved: false,
    activeProjects: 1941,
    projects: 3925,
    description: "Open-source ChatGPT clone: multi-model, agents, search, multi-user auth",
    readme:
      "##‚ö†Ô∏è BEFORE DEPLOYMENT, MAKE SURE TO CHECK THIS GUIDE ‚ö†Ô∏è \n\n‚ú® Features\n\nüñ•Ô∏è UI & Experience inspired by ChatGPT with enhanced design and features\n\nü§ñ AI Model Selection:  \n  Anthropic (Claude), AWS Bedrock, OpenAI, Azure OpenAI, Google, Vertex AI, OpenAI Assistants API (incl. Azure)\n  Custom Endpoints: Use any OpenAI-compatible API with LibreChat, no proxy required\n  Compatible with Local & Remote AI Providers:\n    Ollama, groq, Cohere, Mistral AI, Apple MLX, koboldcpp, together.ai,\n    OpenRouter, Perplexity, ShuttleAI, Deepseek, Qwen, and more\n\nüîß Code Interpreter API: \n  Secure, Sandboxed Execution in Python, Node.js (JS/TS), Go, C/C++, Java, PHP, Rust, and Fortran\n  Seamless File Handling: Upload, process, and download files directly\n  No Privacy Concerns: Fully isolated and secure execution\n\nüî¶ Agents & Tools Integration:  \n  LibreChat Agents:\n    No-Code Custom Assistants: Build specialized, AI-driven helpers without coding  \n    Flexible & Extensible: Attach tools like DALL-E-3, file search, code execution, and more  \n    Compatible with Custom Endpoints, OpenAI, Azure, Anthropic, AWS Bedrock, and more\n    Model Context Protocol (MCP) Support for Tools\n  Use LibreChat Agents and OpenAI Assistants with Files, Code Interpreter, Tools, and API Actions\n\nü™Ñ Generative UI with Code Artifacts:  \n  Code Artifacts allow creation of React, HTML, and Mermaid diagrams directly in chat\n\nüíæ Presets & Context Management:  \n  Create, Save, & Share Custom Presets  \n  Switch between AI Endpoints and Presets mid-chat\n  Edit, Resubmit, and Continue Messages with Conversation branching  \n  Fork Messages & Conversations for Advanced Context control\n\nüí¨ Multimodal & File Interactions:  \n  Upload and analyze images with Claude 3, GPT-4.5, GPT-4o, o1, Llama-Vision, and Gemini üì∏  \n  Chat with Files using Custom Endpoints, OpenAI, Azure, Anthropic, AWS Bedrock, & Google üóÉÔ∏è\n\nüåé Multilingual UI:  \n  English, ‰∏≠Êñá, Deutsch, Espa√±ol, Fran√ßais, Italiano, Polski, Portugu√™s Brasileiro\n  –†—É—Å—Å–∫–∏–π, Êó•Êú¨Ë™û, Svenska, ÌïúÍµ≠Ïñ¥, Ti·∫øng Vi·ªát, ÁπÅÈ´î‰∏≠Êñá, ÿßŸÑÿπÿ±ÿ®Ÿäÿ©, T√ºrk√ße, Nederlands, ◊¢◊ë◊®◊ô◊™\n\nüß† Reasoning UI:  \n  Dynamic Reasoning UI for Chain-of-Thought/Reasoning AI models like DeepSeek-R1\n\nüé® Customizable Interface:  \n  Customizable Dropdown & Interface that adapts to both power users and newcomers\n\nüó£Ô∏è Speech & Audio:  \n  Chat hands-free with Speech-to-Text and Text-to-Speech  \n  Automatically send and play Audio  \n  Supports OpenAI, Azure OpenAI, and Elevenlabs\n\nüì• Import & Export Conversations:  \n  Import Conversations from LibreChat, ChatGPT, Chatbot UI  \n  Export conversations as screenshots, markdown, text, json\n\nüîç Search & Discovery:  \n  Search all messages/conversations\n\nüë• Multi-User & Secure Access:\n  Multi-User, Secure Authentication with OAuth2, LDAP, & Email Login Support\n  Built-in Moderation, and Token spend tools\n\n‚öôÔ∏è Configuration & Deployment:  \n  Configure Proxy, Reverse Proxy, Docker, & many Deployment options  \n  Use completely local or deploy on the cloud\n\nüìñ Open-Source & Community:  \n  Completely Open-Source & Built in Public  \n  Community-driven development, support, and feedback\n\nProject repository: https://github.com/danny-avila/LibreChat",
    name: "LibreChat",
    category: "AI/ML",
    health: 100,
    code: "b5k2mn",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c248cecb-cc3a-4a3e-84ff-453388e4736d",
    isApproved: false,
    activeProjects: 38,
    projects: 88,
    description: "The web development framework for building the future",
    readme:
      "SSR Angular + TypeScript\n\nThis project was originally generated with ng new my-app and selecting Yes when asked to use SSR.\n\n‚ú® Features\n\nSSR Angular 19 + TypeScript\n\nüíÅ‚Äç‚ôÄÔ∏è Local Development\n\nInstall required dependencies with npm install\nRun npm run dev for a local development server\nNavigate to http://127.0.0.1:4200/. The application will automatically reload if you change any of the source files.\n\nTo get more help on the Angular CLI use ng help or go check out the Angular CLI Overview and Command Reference page.\n\n‚ùì What was changed from the default Angular 19 Server Side Rendered example?\n\nThe start script was renamed to dev since it starts a local development server.\nThe serve:ssr:my-app script was renamed to start since it starts the production server.\n\nRailway will automatically use the build and start scripts from the package.json.\n\nAngular's server side rendered server will listen on the host 0.0.0.0 and the PORT environment variable that Railway expects the app to.\n\nThats all the changes needed to deploy a server side rendered Angular 19 app on Railway!\n",
    name: "Angular 19 SSR",
    category: "Starters",
    health: 86,
    code: "A5t142",
    languages: ["HTML", "TypeScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "05f58aac-2109-44c6-82e1-8a55faf39fcf",
    isApproved: false,
    activeProjects: 65,
    projects: 219,
    description: "Beautiful, realtime collaborative, feature packed, and markdown compatible.",
    readme:
      "Lost in a mess of Docs? Never quite sure who has access? Colleagues requesting the same information repeatedly in chat? It‚Äôs time to get your team‚Äôs knowledge organized.\n\nDeploy a local storage first Docker Image of the Outline Knowledge Base.\n\nThis template deploys Redis, Postgres and the Outline Docker container linking them for a minimal deployment.\n\nNote: The default environment variables are setup for local storage.\n\nNote: You must use ONE OF EITHER Google, Slack, or Microsoft for a working installation or you'll have no sign-in options.\n\nIt is possible to setup email-only login after you've signed in with one of the options above.",
    name: "Outline Knowledge Base",
    category: "Other",
    health: 100,
    code: "LNLiaz",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "070a3c19-6a0d-4534-bb60-1d70ca15ce0a",
    isApproved: false,
    activeProjects: 11,
    projects: 50,
    description: "Celery Worker and Beat pre configured to just fork and deploy!",
    readme:
      'Celery Beat and Worker\n\nCelery is used to do long or period tasks in the background, this service provides preconfigured Worker and beat in a different service.\n\nConfigurable by variable "celery_broker" to point to a database as  a broker and change concurrency from start command to use multiple workers.\n\nBeware! choosing higher concurrency can lead to higher credit usage. It\'s good for me though :)\n\n',
    name: "Celery Beat Worker",
    category: "Other",
    health: 50,
    code: "EE2f_5",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6b858315-96c9-4a87-bb59-5a95c579042d",
    isApproved: false,
    activeProjects: 2,
    projects: 26,
    description: "An unofficial template for Misskey",
    readme:
      "This is an unofficial template for Misskey.\n\nNote: This template only works with the Hobby plan or higher.\n\nThis template uses a custom docker image that can be configured from environment variables.\n\nFor detailed instructions, please check the README.\n\nhttps://github.com/mkizka/misskey-railway-template\n\nPlease report any issues here. Thank you!\n\n",
    name: "Misskey",
    category: "Blogs",
    health: 100,
    code: "8bBGvg",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1a94ec57-d005-4227-b291-8b5d732869ee",
    isApproved: false,
    activeProjects: 54,
    projects: 195,
    description: "Open source platform for building internal applications",
    readme:
      "Budibase\nBudibase is an all-in-one low-code platform for building, designing, and automating business apps, such as; admin panels, forms, internal tools, client portals, and more. Before Budibase, it could take developers weeks to build simple CRUD apps; with Budibase, building CRUD apps takes minutes.\n\n\n\n\nWhy Budibase\nThere are a variety of tools and frameworks available to you when building a web application. However, we believe Budibase is the best choice for building modern, full-stack business applications.\n‚Ä¢\tOpen-source - You can inspect the codebase, Deploy Budibase on your own infrastructure, and build apps with confidence knowing Budibase will always be around. \n‚Ä¢\tAll-in-one platform - Unlike other platforms, Budibase has a built-in database, External Data Sources, a design GUI, and an automation section - you can build a full-stack app right within Budibase without ever leaving! \n‚Ä¢\tDesign - Budibase apps look beautiful by default. We've spent a lot of time and effort building components that are accessible, performative, and look great. Also, unlike other platforms, Budibase apps work perfectly across desktop and mobile. \n‚Ä¢\tReal apps - With Budibase, you build real, high-performing single-page applications. Your apps can be public-facing apps, private apps, or both - and they can contain multiple screens too!\n\nLinks\nWebsite - https://budibase.com\nDocumentation - https://docs.budibase.com\nDiscord - https://discord.com/invite/ZepTmGbtfF\n\nLicense\n\nYou can consider Budibase to be GPLv3 licensed overall.\n",
    name: "Budibase",
    category: "Other",
    health: 100,
    code: "FNZJ8t",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "656faeb8-e833-4619-b1e4-7618f7d33ac9",
    isApproved: false,
    activeProjects: 15,
    projects: 84,
    description: "Open Source CRM software solution",
    readme:
      "SuiteCRM\nSuiteCRM is an open source CRM solution that provides a 360-degree view of your customers and business.\n\nOur vision is to be the most adopted open source enterprise CRM in the world, giving users full control of their data and freedom to own and customise their business solution.\n\n\nDocumentation\nOfficial documentation can be found at https://docs.suitecrm.com\n\nSupport\n\nIf you need help with support, use the support forum at https://community.suitecrm.com\n\n\nLicense\n\nSuiteCRM is published under the AGPLv3 license.\n\n",
    name: "SuiteCRM",
    category: "Other",
    health: null,
    code: "-7e9P7",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5d01f780-cf8b-4169-9cea-2e2657501d21",
    isApproved: false,
    activeProjects: 251,
    projects: 530,
    description: "Feature rich, multi-protocol messaging and streaming broker",
    readme:
      "\n    \n        \n    \n\n\nFeature rich, multi-protocol messaging and streaming broker\n\nRabbitMQ is the most widely deployed open source message broker.\n\nWith tens of thousands of users, RabbitMQ is one of the most popular open source message brokers. From T-Mobile to Runtastic, RabbitMQ is used worldwide at small startups and large enterprises.\n\nRabbitMQ is lightweight and easy to deploy on premises and in the cloud. It supports multiple messaging protocols and streaming. RabbitMQ can be deployed in distributed and federated configurations to meet high-scale, high-availability requirements.\n\nRabbitMQ runs on many operating systems and cloud environments, and provides a wide range of developer tools for most popular languages.",
    name: "RabbitMQ",
    category: "Queues",
    health: 100,
    code: "_o12zG",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a1240391-1adc-4b68-a94e-32b29545d9c5",
    isApproved: false,
    activeProjects: 11,
    projects: 47,
    description: "An unofficial template for Mastodon",
    readme:
      "This template is deprecated. The image version will not be updated beyond 4.2.13\n\nThis is an unofficial template for Mastodon.\n\nNote: This template only works with the Hobby plan or higher.\n\nIt is set up for single-user mode, but can also be used in regular mode by adding a mail server.\n\nFor detailed instructions, please check the README.\n\nhttps://github.com/mkizka/mastodon-railway-template\n\nPlease report any issues here. Thank you!\n\nTemplate icon: https://joinmastodon.org/ja/branding",
    name: "Mastodon(deprecated)",
    category: "Blogs",
    health: 0,
    code: "Pa4Fcc",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "65cf270c-1239-4524-80a0-5a16f78089ed",
    isApproved: false,
    activeProjects: 25,
    projects: 57,
    description: "Build dynamic websites using Go Templ, HTMX, and Tailwind",
    readme:
      "htmx is a small but mighty libary allowing developers to access modern browser features like AJAX, CSS Transitions, WebSockets, and Server Sent Events directly in HTML. In combination with Templ, a go library, you can build powerful server-side components and modern user interfaces with minimal javascript.",
    name: "Go + Templ + htmx + Tailwind",
    category: "Starters",
    health: 100,
    code: "_U7eCH",
    languages: ["CSS", "Go", "JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1d4eba1a-d739-4fe1-bd3e-c12895da00d3",
    isApproved: false,
    activeProjects: 176,
    projects: 224,
    description: "A simple AI chatbot leverages GPT models.",
    readme:
      "Important: This service is deployed into private network, but bots on Telegram are public. As long as anyone has the bot handle, they have access to the bot.\n\nUseful references:\nObtain Your Bot Token\nWhere do I find my API key?\n\nTL;DR:\n\nObtain API keys\nDeploy and fill-in the variables\nTalk to the Bot over Telegram :)\n\nThis template aims to provide an open-source single-script chatbot using GPT models.\n\nThe Chatbot leverages Python Telegram Bot library. Allows users to interact with different OpenAI models with ease.\n\nKey features include:\nMulti-user sessions.\nHandling both images (require vision model) and text messages.\nKeeping chat history in-memory within the session.\nFine-tuning configurations: customize system prompt and temperature.\n\nThe goal is to provide a minimal yet workable chatbot through the Telegram interface without worrying about middlemen other than OpenAI endpoints.\n\nAny feedback is welcome: https://github.com/kaxing/simple-telegram-gpt-bot/discussions/categories/questions",
    name: "Simple Telegram GPT Bot",
    category: "Bots",
    health: 100,
    code: "sNYhKQ",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4e50966f-b224-408d-abdf-7a7844989ec3",
    isApproved: false,
    activeProjects: 58,
    projects: 269,
    description: "A setup for Payload using postgreSQL",
    readme:
      "Basic setup for deploying Payload CMS with Postgres. \n\n\nThere is a migration script that runs before the npm run serve command which you may want to change, but this was the only way it seems in production to get this to fire. Open to suggestions on this. ",
    name: "Payload CMS Template",
    category: "CMS",
    health: 94,
    code: "3QUkyF",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "47cbba56-1043-4af6-bbbc-842aa25df725",
    isApproved: false,
    activeProjects: 459,
    projects: 1064,
    description: "Open source no-code database and an Airtable alternative",
    readme:
      "Baserow is an open source no-code database tool and Airtable alternative\n\nCreate your own online database without technical experience. Our user-friendly no-code tool gives you the powers of a developer without leaving your browser.\n\n‚Ä¢\tA spreadsheet database hybrid combining ease of use and powerful data organization.\n‚Ä¢\tEasily self-hosted with no storage restrictions or sign-up on https://baserow.io to get started immediately.\n‚Ä¢\tAlternative to Airtable.\n‚Ä¢\tOpen-core with all non-premium and non-enterprise features under the MIT License allowing commercial and private use.\n‚Ä¢\tHeadless and API first.\n‚Ä¢\tUses popular frameworks and tools like Django, Vue.js and PostgreSQL.\n\n\n\n\nüìö Official documentation\nThe official documentation can be found on the website at https://baserow.io/docs/index. The API docs can be found here at https://api.baserow.io/api/redoc/ or if you are looking for the OpenAPI schema here https://api.baserow.io/api/schema.json.\n",
    name: "Baserow",
    category: "CMS",
    health: 92,
    code: "jbG8JG",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3590cf89-9517-4f22-97e9-abbc0b733663",
    isApproved: false,
    activeProjects: 7,
    projects: 10,
    description: "Host your own server for the PenguinMod storage extension",
    readme:
      "Use this to host your own server for the PenguinMod storage extension, on railway.app\n\n If you don't use a volume, your data will be cleared every time you restart the service  \n\n\n###Learn more  \nDocumentation  \nSource code\n",
    name: "PenguinMod storage API",
    category: "Storage",
    health: 100,
    code: "seDKg9",
    languages: ["Go", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a93ef3a9-1a54-4b32-967c-ebff0ed3f110",
    isApproved: false,
    activeProjects: 146,
    projects: 430,
    description: "Automation software that's AI-first, no-code & open-source ",
    readme:
      "ü§Ø Activepieces\n\nAll-in-one AI automation designed to be extensible through a type-safe pieces framework written in TypeScript. When you contribute pieces to Activepieces they become automatically available as MCP servers that you can use with LLMs through Claude Desktop, Cursor or Windsurf!\n\nCompanies use Activepieces to help their teams use AI in their daily workflows ‚Äî and you can, too!\n\n\nüé® Flow Builder\nUser-friendly Workflow Builder! Enjoy building fun and interactive flows with support for Branches, Loops, and Drag and Drop.\n\n\n\n\nüß© Pieces\nActivepieces integrates Google Sheets, OpenAI, Discord, and RSS, along with 80+ other integrations. The list of supported integrations continues to grow rapidly, thanks to valuable contributions from the community.\n\nActivepieces is an open ecosystem; all piece source code is available in the repository, and they are versioned and published directly to npmjs.com upon contributions.\n\nIf you cannot find a specific piece on the pieces roadmap, please submit a request by visiting the following link: Request Piece\n\nAlternatively, if you are a developer, you can quickly build your own piece using our TypeScript framework. For guidance, please refer to the following guide: Contributor's Guide\n\n\n‚öñÔ∏è License\nActivepieces' Community Edition is released as open source under the MIT license and enterprise features are released under Commerical License\n\nRead more about the feature comparsion here https://www.activepieces.com/docs/about/editions\n\nüóÉÔ∏è Documentation\nDetailed documentation is available a https://www.activepieces.com/docs/getting-started/introduction\n",
    name: "Activepieces",
    category: "Automation",
    health: 100,
    code: "kGEO1J",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ca6ccd5d-b54f-4752-a909-c333ef97d257",
    isApproved: false,
    activeProjects: 9,
    projects: 28,
    description: "Deploys Label Studio via a single docker image",
    readme:
      "Overview\n\nDeploys Label Studio to a public endpoint.\n\nHighlights\n\n Uses a single service/docker container to host the service.\n Tasks/Annotations are persisted through the data volume.\n Not suitable for large/production workloads, as it uses the built-in SQLite3 engine.",
    name: "Label Studio (Single Service)",
    category: "AI/ML",
    health: 100,
    code: "X_ZJld",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d8a475db-54c6-45f7-9423-c5cd218c70e4",
    isApproved: false,
    activeProjects: 0,
    projects: 17,
    description: "A Privacy-First Link Shortener üåêüîí",
    readme:
      "nxt - A Privacy-First Link Shortener üåêüîí\n\nWelcome to nxt, a simple, fast, and secure link shortener written in Go. This open-source project is designed with privacy in mind, ensuring that your data is always protected.\n\nFeatures:\nüîí Privacy-First: We only store necessary data for the functionality of our service. We do not share your data with third parties unless required by law.\nüö´ No Accounts: nxt does not require accounts. It fully relies on a passcode to manage your links.\nüìñ Open Source: nxt is open-source and licensed under the MIT License. You're free to use, modify, and distribute the software under the terms of this license.\n\nUsage\n\nThe main interface of nxt is a web page where you can enter a URL to shorten. After submitting the URL, you will be provided with a shortened link and a passcode. The passcode is used to manage your links.",
    name: "nxt",
    category: "Other",
    health: null,
    code: "gSvwgO",
    languages: ["HTML", "Go", "JavaScript", "CSS", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3eb08417-3f3f-4351-9e93-7402137e66fb",
    isApproved: false,
    activeProjects: 1,
    projects: 9,
    description: "Chamber is a web service for containing secrets.",
    readme:
      'The easiest way to use Chamber is with chamber-cli which you can install with the following command (requires Rust and Cargo to be installed):\ncargo install chamber-cli\n\nThen you can use chamber to see all the commands!\n\nThe service will start out in the "sealed" state. You can unseal it by going to the logs, finding the root key and then use chamber unseal followed by the root key. You can rotate the root key and cryptographic key used by using chamber upload, which will take the chamber.bin file used in the current directory.\n\nCheck out the GitHub repo for more info: https://github.com/joshua-mo-143/chamber\n\nThis service is currently a work in progress. If you\'re using this in production, no API stability garuantees can currently be made although most work from the release onwards should be primarily ',
    name: "Chamber - a SecretOps service",
    category: "Other",
    health: null,
    code: "VS9MIg",
    languages: ["Rust", "Dockerfile", "Makefile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c1a45644-26cd-440f-9440-80eab34fac8c",
    isApproved: false,
    activeProjects: 98,
    projects: 291,
    description: "Kali Linux with the tools you love and a shell, all accessible over the web",
    readme:
      'kali-railway\n\nWant to try out Kali Linux or want to have a mini version of kali linux available at all times? Then feel free to give this project a try:\n\nDeploy on Railway\n\nDescription\nThis project uses the official kali linux rolling image to deploy a container which can then be used to install most of the cli tools which comes with kali linux pre-installed. Behind the scenes, it uses ttyd to provide a hassel free and a very accessible way to access the command line.\n\nimage\n\nEnviroment Variables\n  PORT: The port on which the ttyd program will listen on.\n  USERNAME: The username which will be used to login to the web shell.\n  PASSWORD: The password which will be used to login to the web shell.\n\nRailway Default Enviroment Variables\nWhen deploying to Railway, the USERNAME and PASSWORD enviroment variables will be set to a random string, thanks to railway\'s template variables\n  PORT: Defaults to 8080\n  USERNAME: A random string of 16 characters containing only alpha-numeric characters (a-z, A-Z, 0-9)\n  PASSWORD: A random string of 32 characters\n \nNOTE: It is strongly adviced to provide the USERNAME and PASSWORD enviroment variables before deploying the project.\n\nTo view or edit the USERNAME and PASSWORD enviroment variables, click on the deployed template -> Variables tab\n\nimage\n\nUsing locally\n\nUsing docker to create an image and run a container locally\nTo build the container image\ndocker build -t kali-railway \n\nTo run a demo installation on port 8080 with the username set to "admin" and password set to "password"\ndocker run --rm -e USERNAME=admin -e PASSWORD=password -e PORT=8080 -p 8080:8080 kali-railway\n',
    name: "Kali Linux",
    category: "Other",
    health: 86,
    code: "E7oTLJ",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "338df1ac-2799-4034-8d16-74c7e11cd8f4",
    isApproved: false,
    activeProjects: 38,
    projects: 109,
    description: "A scalable, distributed, collaborative, document-graph database",
    readme:
      "\n    \n        \n    \n\n\nSurrealDB is the ultimate cloud  database for tomorrow's applications\n\n\nDevelop easier. &nbsp; Build faster. &nbsp; Scale quicker.\n\nWhat is SurrealDB?\n\nSurrealDB is an end-to-end cloud-native database designed for modern applications, including web, mobile, serverless, Jamstack, backend, and traditional applications. With SurrealDB, you can simplify your database and API infrastructure, reduce development time, and build secure, performant apps quickly and cost-effectively.\n\nKey features of SurrealDB include:\n\nReduces development time: SurrealDB simplifies your database and API stack by removing the need for most server-side components, allowing you to build secure, performant apps faster and cheaper.\nReal-time collaborative API backend service: SurrealDB functions as both a database and an API backend service, enabling real-time collaboration.\nSupport for multiple querying languages: SurrealDB supports SQL querying from client devices, GraphQL, ACID transactions, WebSocket connections, structured and unstructured data, graph querying, full-text indexing, and geospatial querying.\nGranular access control: SurrealDB provides row-level permissions-based access control, giving you the ability to manage data access with precision.\n\nFeatures\n\nx] Database server, or embedded library\n[x] Multi-row, multi-table ACID transactions\n[x] Single-node, or highly-scalable distributed mode\n[x] Record links and directed typed graph connections\n[x] Store structured and unstructured data\n[x] Incrementally computed views for pre-computed advanced analytics\n[x] Realtime-api layer, and security permissions built in\n[x] Store and model data in any way with tables, documents, and graph\n[x] Simple schema definition for frontend and backend development\n[x] Connect and query directly from web-browsers and client devices\n[x] Use embedded JavaScript functions for custom advanced functionality\n\nDocumentation\n\nFor guidance on development, and administration, see Their [documentation.",
    name: "SurrealDB 1.x",
    category: "Other",
    health: 50,
    code: "Axgpqb",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "fba77688-173e-4702-acd0-0004417a3377",
    isApproved: false,
    activeProjects: 0,
    projects: 2,
    description: "Store snippets privately over your own tailnet",
    readme:
      "tclip on Railway\n\nThis template uses the tclip Docker image from Tailscale. Due to data persistence requirements, you need to immediately add a volume for /data directory.\n\nRequirements\n\nA data volume to /data (or any location, as controlled by DATA_DIR variable).\nTailscale authkey for your tailnet for TS_AUTHKEY variable.",
    name: "Personal pastebin over tailnet",
    category: "Storage",
    health: null,
    code: "VMGRyO",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "99fb8011-5125-4b1b-88fd-d1b0ed90fded",
    isApproved: false,
    activeProjects: 39,
    projects: 73,
    description: "Server, NAS, VPS navigation panel, home page and browser home page.",
    readme:
      "A navigation panel that allows for the addition of URLs and redirects is an extremely useful and customizable tool for efficient management of access to various websites and online resources. Typically integrated into a NAS, server, or VPS, this panel facilitates the organization and quick access to specific web pages, enhancing productivity. It enables users to add, edit, and organize links in a way that allows for immediate and orderly redirections to homepages, work sites, or frequently used resources, providing a more streamlined and user-centric internet browsing experience. This functionality is crucial for effectively managing and navigating the digital landscape.",
    name: "Sun Panel",
    category: "Other",
    health: 100,
    code: "BOpuEm",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "559c5e67-1dfe-4d0b-9e0b-48656d40923f",
    isApproved: false,
    activeProjects: 13,
    projects: 56,
    description: "A simple file server using Express and Multer. Also includes an API.",
    readme:
      "StorageApi\n\nThis template wraps a NodeJs application that uses Express and Multer to expose an API for managing storage and backups, as well as a static file server. It's based on Docker Volumes, thats it's included in the template. \n\nFeatures\n\n List storage in tree structure, upload, rename, download and delete\n PostgreSQL Backups (scheduled via cron or just once) and Restore triggered only by API request\n Auth - Every request its authenticated by Auth middleware that check if request includes a token field that is the same token generated on deploy of this template.\n\nFrontEnd\nWhen deploying this template it will auto generate a token thats could be used on Storagex. This is a interface that could manage files, folder and backups (restore will be release soon). To acess your storage by interface you need expose your app on public network and that token, after that not even sky is limit\n\nAlerts \n\n Because this template uses Docker Volumes, assume that default configuration it is important and that any \t\t  changes to the path can make the files accessible only in the running deployment.\n Always start with the basics concepts of IIWDTI (IF IT'S WORKING, DON'T TOUCH IT)\n\nIssues\n\nAny error/bug, dont be silly and open an issue on https://github.com/nsx07/storage/issues.",
    name: "Storage Api",
    category: "Storage",
    health: 83,
    code: "iiWiUr",
    languages: ["TypeScript", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "653433ff-e4e9-4095-a501-b39eb369a3dc",
    isApproved: false,
    activeProjects: 8,
    projects: 20,
    description: "A minimalist, self-hosted WakaTime-compatible backend for coding statistics",
    readme:
      "Railway Wakapi instance\n\nThis project deploys a Wakapi instance to Railway. Wakapi is a language-agnostic developer analytics tool that allows you to track your coding activity.\n\nDeployment\n\nDeploy on Railway\n\nMore Information\n\nFor more information about Wakapi, please refer to the original author's repository at mutey/wakapi.",
    name: "wakapi",
    category: "Analytics",
    health: 100,
    code: "mnOZG-",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a82282ea-1740-41f9-ba20-4ab1fa80712e",
    isApproved: false,
    activeProjects: 25,
    projects: 175,
    description: "Full Django/Postgres stack with Celery tasks and Redis as cache/queue.",
    readme:
      'Deploy a "complete" Django setup - DB, caching and background tasks with Celery are all set up and ready to go. The project also includes Whitenoise for serving static files, and a docker-compose file for local development environment that matches this Railway equivalent.\n\nNOTE: For a fully private setup, remember to delete the TCP proxies for both Redis and Postgres.\n\nCheck out the full readme and brief on GitHub: https://github.com/Antvirf/railway_django_stack\n',
    name: "Django, Celery, Redis & Postgres",
    category: "Starters",
    health: 45,
    code: "NBR_V3",
    languages: ["Python", "Dockerfile", "Shell", "Makefile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "04a8adbe-a6ac-4fc4-9e32-0d1882251ff0",
    isApproved: false,
    activeProjects: 41,
    projects: 158,
    description: "Directus (Docker) + PostGIS (Docker/TCP) + S3",
    readme:
      "Latest updates\nThis has been updated to Directus 11.6\nCreate snapshots with a single command: cd scripts && pnpm create-snapshot\nExtension folder updates: We've updated the extension folders to match the recommended structure. This ensures that you can load your downloaded and custom extensions correctly. Remember to commit the dist folder and package.json for custom extensions. We've included a custom extension as an example.\nAutomatic schema synchronization: (Optional) Run cd scripts && pnpm create-snapshot to create a snapshot of your working schema from your local development environment. Then, push your branch for deployment, and it will - be synced to your Railway environment.\nEnvironment variable management: We've added a .env.example file(duplicate and rename to .env) to manage your environment variables and secrets. Docker Compose will use this file to load the environment variables.\n\nDirectus (Docker + extensions + websocket) + PostGIS (Docker & TCP) + S3\ndescription: A one-click-install Directus instance with PostGIS and S3 for persistent storage.\ntags:\n  Directus\n  Typescript\n  Vue\n  Websocket\n  CMS\n  Data Platform\n  PostgreSQL\n  PostGIS\n  Railway\n\nDirectus railway template\n\nThis example runs a Directus instance with minimal config using PostGIS.\n\n‚ú® Features\n\nDirectus config is pre-configured\nInstall Directus using Docker\nDirectus extensions and websocket are pre-configured\nDirectus version can be updated through Dockerfile\nDirectus extensions can be updated and loaded through Dockerfile\nPostGIS config is pre-configured\nSSL certificates is pre-configured using the self-signed Snakeoil certificate for PostGIS\nRailway Database View is pre-configured \nInstall PostGIS instead of Postgre as Directus recommended for supporting GIS features\nS3 for persistent storage\nThe communication from Directus to the database is accomplished through the private network, saving its users from egress fees. This reduces the users' exposure to unnecessary egress fees.\n\nüíÅ‚Äç‚ôÄÔ∏è How to use\n\nClick the Deploy on Railway button\nLet railway deploy your service, most of the configurations have been preset, but feel free to tweak them as you like before deployment.\nLogin in the admin panel using the defined ADMIN_EMAIL and ADMIN_PASSWORD.\nUse of S3 is a must in this template.\n\nThere's a great video tutorial about how to set up an S3 bucket for Directus https://www.youtube.com/watch?v=U7yXFLAwleY&ab_channel=cheddar. \n\nüíÅ‚Äç‚ôÄÔ∏è Example screenshots\n\n\n\nDirectus extensions\n\nDirectus extensions!\n\nDirectus S3 image upload\n\nDirectus S3 image upload!\n\nDirectus S3 storage\n\nDirectus S3 storage!\n\nRailway Database View for Postgis\n\nRailway Database View for Postgis!\n\n\n\n",
    name: "Directus (docker/websocket/extensions) + PostGIS (docker/TCP) + S3/Local",
    category: "CMS",
    health: 87,
    code: "XQc69P",
    languages: ["JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "159967ef-c298-43fe-be1c-eabe03329443",
    isApproved: false,
    activeProjects: 30,
    projects: 64,
    description: "Sync Postgres with SQLite",
    readme:
      "PowerSync enables an offline-first architecture for real-time reactive apps.\n\nTo use this Template, follow our Railway Integration Guide.\n\nThis template spins up a Postgres instance pre-configured with logical replication. The template also includes a barebones starter Node.js project showing off how PowerSync can integrate with existing backends.\n\nPowerSync currently supports Flutter, React Native, Swift, Kotlin, .NET, JS-web and Node.js on the client side.",
    name: "PowerSync Postgres NodeJS",
    category: "Storage",
    health: 100,
    code: "RfZi6y",
    languages: ["JavaScript", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0af0f4e0-717b-44a2-8043-329f8ee41165",
    isApproved: false,
    activeProjects: 0,
    projects: 7,
    description: "Host, engineer and manage prompt & model configurations.",
    readme:
      "Promptmodel is an open source LLMOps platform for building & integrating AI in your product. Prompt engineering is the fastest way to build a customized AI feature that solves your problems, including summarization, content filtering, customer support automation, Image classification, etc.\n\nYou can easily build and refine your AI models on Promptmodel's intuitive prompt engineering dashboard. The platform offers tools for tracking prompt versions, conducting A/B tests, monitoring production logs, and deploying new prompts seamlessly without code modification & re-deployment. \n\nUsing this template, you can deploy Promptmodel to Railway. It automatically creates a Postgres DB to store your prompts and production logs.\n\nThis template includes\nFrontend dashboard (Next.js)\nBackend server (FastAPI)\nRedis (for realtime)\nPostgreSQL database\nPython script (for realtime)\n\nYou should edit 2 environment variables.\nfrontend\nBACKEND_PUBLIC_URL : Update this to reflect the backend's public URL.\nFRONTEND_PUBLIC_URL: Update this to reflect the frontend's public URL.\n\nbackend\nFRONTEND_PUBLIC_URL: Update this to reflect the frontend's public URL.\n\nIn case of errors, try restarting the containers, or join the Discord to get help:\nhttps://promptmodel.run/discord",
    name: "Promptmodel",
    category: "AI/ML",
    health: null,
    code: "uzaE0r",
    languages: ["TypeScript", "Python", "Dockerfile", "JavaScript", "CSS", "Mako", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "47928951-432c-41d1-b4f3-8085fccd5322",
    isApproved: false,
    activeProjects: 1,
    projects: 13,
    description: "An open source wealth management software built with web technology",
    readme:
      "Ghostfolio is an open source wealth management software built with web technology. The application empowers busy people to keep track of stocks, ETFs or cryptocurrencies and make solid, data-driven investment decisions. The software is designed for personal use in continuous operation.\n\nGhostfolio - Screenshot\n\nGhostfolio is for you if you are...\n\nüíº trading stocks, ETFs or cryptocurrencies on multiple platforms\nüè¶ pursuing a buy & hold strategy\nüéØ interested in getting insights of your portfolio composition\nüëª valuing privacy and data ownership\nüßò into minimalism\nüß∫ caring about diversifying your financial resources\nüÜì interested in financial independence\nüôÖ saying no to spreadsheets\nüòé still reading this list",
    name: "Ghostfolio",
    category: "Analytics",
    health: null,
    code: "koSYWQ",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "77d83d82-767e-4d9a-84d8-9855c3fc88de",
    isApproved: false,
    activeProjects: 3,
    projects: 12,
    description: "Deploy an example LangServe app to Railway",
    readme:
      "This template provides a pre-configured LangServe application, ready for deployment. It's designed to help you easily set up and launch a custom LangChain environment, facilitating smooth integration with Slack via PlugBear. The template includes example code with a FastAPI backend, demonstrating secure request handling and environment variable management for your OpenAI API key and secret key. Deploy this to create an accessible endpoint for Slack interactions, streamlining your development workflow and enabling seamless communication with your LangChain app.",
    name: "PlugBear LangServe Integration",
    category: "Other",
    health: null,
    code: "tCk1po",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7458eb6c-2d5a-42c4-8f96-8b60a3a1d521",
    isApproved: false,
    activeProjects: 4,
    projects: 15,
    description: "Datadog Agent with a Node App, forwarding logs and metrics.",
    readme:
      "Overview\n\nDatadog aggregates events, metrics, and logs across the full devops stack.  The Datadog Agent collects data from your applications to send to Datadog, where you can analyze your monitoring and performance data.\n\nHighlights\n\n One-click deployment of...\n\nDatadog Agent\nNode Application running an Express web server with two endpoints.  Within the endpoints, the application sends metrics and logs to the Agent.\n\nRequirements\n\nYou will need your Datadog API key and Datadog Site value.\n\nLearn More\n\nDatadog Agent GitHub repo\nDatadog Documentation",
    name: "Datadog Agent + Node App",
    category: "Observability",
    health: 100,
    code: "saGmYG",
    languages: ["JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3dcf8198-8dfc-4b37-ab69-c9c9e37af690",
    isApproved: false,
    activeProjects: 36,
    projects: 48,
    description: "A bot to bypass the Anti Forward And Copy rule of the telegram API.",
    readme:
      "\nGhostForwarder is a cutting-edge bot designed to facilitate seamless media transfer from secure, anti-forward/copy chats to designated recipient chats within messaging platforms. This innovative bot acts as a bridge, connecting with user accounts and streamlining the process of sharing media content from highly restricted conversations to specified destinations.\n\nIn anti-forward/copy chats, where content is often protected to maintain privacy and control over information dissemination, GhostForwarder becomes a valuable tool. By interfacing with user accounts, the bot overcomes restrictions imposed by these secure channels, ensuring that media, such as images and videos, can be efficiently forwarded to predetermined chat",
    name: "Pyrogram Bot",
    category: "Automation",
    health: null,
    code: "qHge9_",
    languages: ["Python", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0fab4b2b-56ac-42f7-ba79-94e04f06967b",
    isApproved: false,
    activeProjects: 14,
    projects: 19,
    description: 'A simple "Most Likely To" minigame.',
    readme:
      'MostLikelyTo Bot\n\nSimple Most-Likely-To minigame for your community, provides slash command /most-likely-to which responds with a "who\'s most likely to" question. You and your imaginary friends then reply with whoever they believe is most likely to do whatever was posed in the question.',
    name: "Discord-TS 'Most Likely To Minigame' Bot",
    category: "Bots",
    health: null,
    code: "0luvfZ",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "18b5c714-e3e2-4c86-8ddb-bdb549510b9e",
    isApproved: false,
    activeProjects: 4,
    projects: 11,
    description: "Fun but simple addition to your Discord Server!",
    readme:
      "Simple Discord Chatbot\n\nThe AI uses OpenAI gpt-3.5-turbo ( you can edit this in the code though ) and streams its responses to chat. \nThe bot is meant to be a fun addition to your Discord Server, and is meant to be used by a group of users at the same time.\n\nCustomization\nYou can set the bot to only listen in a specific channel and or listen to users with specific roles. \nYou can further customize the AI parameters itself in the config.ts file.\n\nInstructions\n\nProvide .env\nAdd a .env file, and add the required variables that can be found in env.example.txt.\n\nEdit config.ts\nYou can edit the bot accordingly in config.ts to provide specific parameters and instructions.",
    name: "Simple Discord-TS Chatbot",
    category: "Bots",
    health: null,
    code: "HmC62u",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8a43d669-8740-4780-acdd-38226cee034c",
    isApproved: false,
    activeProjects: 2,
    projects: 11,
    description: "An open-source scheduling and collaboration tool.",
    readme:
      "What is Rallly?\n\nRallly is a tool for creating scheduling polls. It's designed to help people find a common time to schedule a meeting or event.\n\nRallly is pronounced like \"rally\" but with an extra L.\nI wanted to call the product \"Rally\" because that's what it's for - rallying people together to make things happen.\nBut, of course, the domain name was already taken. So, I did what any sane person would do - I added an extra L.\n-- Luke Vella, Creator of Rallly\n\n\n\n\nSee the latest self-hosting documentation:\n\nhttps://support.rallly.co/self-hosting/introduction.\n\n\nRallly is 100% open-source and available under the GNU Affero General Public License v3.0 (AGPL-3.0)\nwhich allows you to run your own instance of Rallly for free for both personal and commercial use.\n\nOfficial Docker Image\n\nThe best way to self-host Rallly is using the official Docker image.\nThis image contains a build that is specifically intended for self-hosting.\nIt is updated regularly but it is not guaranteed to be up-to-date with the latest version of Rallly.\nIf you want to have access to the latest features and bug fixes, you should consider using the official managed service.\n\n\nThough it is technically possible to build and run Rallly from its\n  source-code, it is not recommended and\n  we do not provide support for this.\n\nLive Demo\n\nIf you want to try out Rallly before self-hosting it, you can try the official managed service at app.rallly.co.\nThis version differs slightly from the self-hosted version in that it allows guest users to create polls without having to create an account\nand is updated more frequently but it's still a good way to get a feel for the app.\n\nPricing\n\nRallly is completely free to self-host but for users who wish to contribute to the project,\nplease check out the pricing page.\n\nGet Started\n\nDepending on how comfortable you are with technical things, you can either run Rallly on your own server or choose a managed hosting provider that will do it for you.\n\n\n  \n    Host your own instance of Rallly on your own server using Docker.\n  \n  \n    Choose a provider that will install and run an instance of Rallly for you.\n  \n",
    name: "Rallly",
    category: "Other",
    health: null,
    code: "fEb1qz",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "96b8dbed-4d41-4ef4-b306-ff64a8c0caea",
    isApproved: false,
    activeProjects: 10,
    projects: 23,
    description: "Full stack observability‚Äã",
    readme:
      "\n    \n        \n    \n\n\nFull stack observability\n\nOpenObserve is a cloud native observability platform built specifically for logs, metrics, traces, analytics, RUM (Real User Monitoring - Performance, Errors, Session Replay) designed to work at petabyte scale.\n\nIt is very simple and easy to operate as opposed to Elasticsearch which requires a couple dozen knobs to understand and tune which you can get up and running in under 2 minutes.\n\nIt is a drop-in replacement for Elasticsearch if you are just ingesting data using APIs and searching using kibana (Kibana is not supported nor required with OpenObserve. OpenObserve provides its own UI which does not require separate installation unlike kibana).\n\nFeatures:\n\nSome of the features are:\n\nLogs, Metrics, Traces \nOpenTelemetry support for logs, metrics traces (OTLP)\nRUM (Real user Monitoring) - Performance, Errors, Session Replay\nAlerts, Dashboards (14 different chart types (time series, bar, geo maps, heatmap, scatter, table, pie, etc.)\nIngest and Query functions to aid advanced capabilities like enrichment, redaction, log reduction, compliance, etc. e.g. you can use ingest functions to redact sensitive data like email IDs, AWS keys, etc. from logs before the get stored in logs.\nAdvanced Embedded GUI\nSQL for Logs and Traces. SQL and PromQL for metrics. No need to learn yet another query language.\nSingle binary for installation &amp; running. Binaries available under releases for multiple platforms.\nStorage in local Disk, s3, MinIO, GCS, Azure Blob Storage\nHigh availability and clustering\nDrop in replacement for elasticsearch\nDynamic Schema\nOut of the box authentication\nVastly easier to operate\nSeamless upgrades\nUI in 11 supported languages (English, Turkish, German, French, Spanish, Portuguese, Chinese, Japanese, Korean, Italian, Dutch)\n\nScreenshots\n\nHome\n\nHome\n\nLogs\n\nHome\n\nVisualization and dashboard\n\nDashboard\n\nAlerts\n\nReal time alerts\n\nAlerts Realtime\n\nScheduled alerts\n\nAlerts Scheduled\n\nStreams\n\nHome\n\nIngestion\n\nHome",
    name: "OpenObserve",
    category: "Other",
    health: 100,
    code: "KHTRbg",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2b9be9b0-6f1d-49f3-ae58-8bd2e7f5ede0",
    isApproved: false,
    activeProjects: 5,
    projects: 29,
    description: "Lightweight, high performance log analytics for the cloud native era",
    readme:
      '\n    \n        \n    \n\n\nCloud native log analytics\n\nParseable is a log analytics platform, built for the modern, cloud native era. Parseable uses a index-free mechanism to organize and query data allowing low latency, and high throughput ingestion and query.\n\nFor comparison, Parseable consumes up to 80% lower memory and 50% lower CPU than Elastic for similar ingestion throughput. Read more in the benchmarks directory ‚ÜóÔ∏é.\n\nParseable Console\n\nQuick start\n\nOnce deployed you can open the dashboard from the auto generated Railway Domain. You can login to the dashboard with the credentials from the P_USERNAME and P_PASSWORD service variables.\n\nTo ingest data, run the below command. This will send logs to the test stream. You can see the logs in the dashboard.\n\ncurl --location --request POST \'{service domain}/api/v1/ingest\' \\\n--header \'X-P-Stream: test\' \\\n--header \'Authorization: Basic {base64 encoded username:password}\' \\\n--header \'Content-Type: application/json\' \\\n--data-raw \'\n    {\n        "id": "11f7ce5c-cfaf-4719-bb34-8ed8d0f5b70c",\n        "datetime": "16/Dec/2023:00:00:00 +0000",\n        "host": "Railway"\n    }\n]\'\n\nHighlights\n\nChoose storage backend - local drive or S3 (or compatible) object store.\nIngestion API compatible with HTTP + JSON output of log agents.\nQuery log data with PostgreSQL compatible SQL.\nSingle binary includes all components - ingestion, store and query. Built-in UI.\n\nEnterprise ready\n\n[Alerts ‚ÜóÔ∏é\nRBAC ‚ÜóÔ∏é\nOAuth2 ‚ÜóÔ∏é\nGrafana ‚ÜóÔ∏é\nLLM ‚ÜóÔ∏é\nStats ‚ÜóÔ∏é',
    name: "Parseable",
    category: "Observability",
    health: 100,
    code: "h_WWDP",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9921278a-d05f-460d-b54e-b55d8f4ec9e5",
    isApproved: false,
    activeProjects: 5,
    projects: 24,
    description: "API for URL shortener writtein in Golang",
    readme:
      "API for URL shortener writtein in Golang\n\nThis can shorten URLs and given short URL, the API can tell the long URL. \n\nSupports user signup with passwords.\n\nBackend is written in Golang using Go Fiber\n\nhttps://github.com/championswimmer/onepixel_backend \n\nFor more details get in touch \nhttps://twitter.com/championswimmer",
    name: "onepixel",
    category: "Starters",
    health: null,
    code: "xAJ1-J",
    languages: ["Go", "HTML", "Makefile", "Dockerfile", "CSS", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "23d2bee0-ef3d-4cb6-aaa5-b9557b7dabe3",
    isApproved: false,
    activeProjects: 25,
    projects: 98,
    description: "Lightweight connection pooler for PostgreSQL",
    readme:
      "PgBouncer\n\nLightweight connection pooler for PostgreSQL\n\nNotes\nThis template assumes you have a database named Postgres in your project before deploying this template, if this isn't the case please adjust the reference variables so they reference the correct namespace.\n\npgbouncer is a PostgreSQL connection pooler. Any target application can be connected to pgbouncer as if it were a PostgreSQL server, and pgbouncer will create a connection to the actual server, or it will reuse one of its existing connections.\n\nThe aim of pgbouncer is to lower the performance impact of opening new connections to PostgreSQL.\n\nIn order not to compromise transaction semantics for connection pooling, pgbouncer supports several types of pooling when rotating connections.\n\nExtra configurations can be done with the environment variables found on bitnami's pgbouncer image overview page\n\nHow to add a Userlist to PgBouncer\n\nIf you have already created a new user, skip to step 2.\n\nConnect to the base Postgres database and create a new user -\n\nCREATE USER 'new_user' WITH PASSWORD 'my_password';\nALTER USER new_user WITH LOGIN;\nGRANT ALL PRIVILEGES ON DATABASE railway TO new_user;\nGRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO new_user;\nGRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public TO new_user;\nGRANT ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA public TO new_user;\nALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL ON TABLES TO new_user;\nALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL ON SEQUENCES TO new_user;\nALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL ON FUNCTIONS TO new_user;\n\nReplace new_user and my_password with your desired username and a secure password.\n\nAdd or remove any privileges as you see fit.\n\nGrab the rolpassword for the newly created user\n\nSELECT rolpassword FROM pg_authid WHERE rolname = 'new_user';\n\nReplace new_user with the username created in the first step.\n\nCopy down the returned value from the rolpassword column.\n\nSet the PGBOUNCER_USERLIST service variable.\n\nNotes - \nThis must be done using the Raw Editor option to avoid unnecessary string sanitations.\n\nThe value for this variable should be encapsulated in quotes as shown.\n\nPGBOUNCER_USERLIST=\"\"new_user\" \"rolpassword\"\"\n\nReplace new_user with the username created in the first step, and replace rolpassword with the returned value from the previous step.\n\nDeploy your changes.\n\nDone! - Connect to PgBouncer using the username and password of the user created in the first step!",
    name: "PgBouncer",
    category: "Other",
    health: 92,
    code: "OpUzwe",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "05228e19-723e-4b1b-9758-b466402e4cd6",
    isApproved: false,
    activeProjects: 8,
    projects: 24,
    description: "A lightweight caching engine for Postgres",
    readme:
      "\nReadySet + Postgres\n  \n\n\nReadySet is a transparent database cache for Postgres &amp; MySQL that gives you the performance and scalability of an in-memory key-value store without requiring that you rewrite your app or manually handle cache invalidation.\n\nFeatures\nPre-Configured Postgres 16 Database\nReadySet\n\nHow to use\nDeploy the template\nConnect to the ReadySet enhanced database by referencing the READYSET_DATABASE_PRIVATE_URL or READYSET_DATABASE_URL variables.\nStart caching queries\n\nLimitations\nNo SSL due to a limitation of the platform",
    name: "ReadySet",
    category: "Storage",
    health: null,
    code: "wr1OLZ",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7c50c51d-a149-4c91-b32f-e4af2ccf349d",
    isApproved: false,
    activeProjects: 20,
    projects: 36,
    description: "Efficient and minimal collaborative code editor",
    readme:
      "Rustpad is an efficient and minimal open-source collaborative text\neditor based on the operational transformation algorithm. It lets users\ncollaborate in real time while writing code in their browser.\n\n\n\n\n\n",
    name: "Rustpad",
    category: "Other",
    health: 0,
    code: "Aw9WuR",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "60bccfc6-c5f2-4b3d-9ad6-1ee5f790c61a",
    isApproved: false,
    activeProjects: 0,
    projects: 0,
    description: "A bot for notifying you when a new Raspberry Pi comes in stock",
    readme:
      "A bot for notifying you when a new Raspberry Pi comes in stock. It uses the RSS feed from https://rpilocator.com\n\nSteps to deploy:\n\nCreate a new bot in the Discord application dashboard\nDeploy this template with the TOKEN and APPLICATION_ID environment variables\nUse /opt-in to opt into notifications, and /opt-out to opt out\n\nThe RSS feed is checked once per minute",
    name: "RPILocator",
    category: "Bots",
    health: null,
    code: "VrxHKp",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a8a37ee2-dadf-4ab4-823a-ea03ac55d232",
    isApproved: false,
    activeProjects: 69,
    projects: 203,
    description: "Web UI for Ollama, frontend for LLMs",
    readme:
      "Features ‚≠ê\nüñ•Ô∏è Intuitive Interface: Our chat interface takes inspiration from ChatGPT, ensuring a user-friendly experience.\n\nüì± Responsive Design: Enjoy a seamless experience on both desktop and mobile devices.\n\n‚ö° Swift Responsiveness: Enjoy fast and responsive performance.\n\nüöÄ Effortless Setup: Install seamlessly using Docker for a hassle-free experience.\n\nüíª Code Syntax Highlighting: Enjoy enhanced code readability with our syntax highlighting feature.\n\n‚úíÔ∏èüî¢ Full Markdown and LaTeX Support: Elevate your LLM experience with comprehensive Markdown and LaTeX capabilities for enriched interaction.\n\nüì•üóëÔ∏è Download/Delete Models: Easily download or remove models directly from the web UI.\n\nü§ñ Multiple Model Support: Seamlessly switch between different chat models for diverse interactions.\n\n‚öôÔ∏è Many Models Conversations: Effortlessly engage with various models simultaneously, harnessing their unique strengths for optimal responses. Enhance your experience by leveraging a diverse set of models in parallel.\n\nü§ù OpenAI Model Integration: Seamlessly utilize OpenAI models alongside Ollama models for a versatile conversational experience.\n\nüîÑ Regeneration History Access: Easily revisit and explore your entire regeneration history.\n\nüìú Chat History: Effortlessly access and manage your conversation history.\n\nüì§üì• Import/Export Chat History: Seamlessly move your chat data in and out of the platform.\n\nüó£Ô∏è Voice Input Support: Engage with your model through voice interactions; enjoy the convenience of talking to your model directly. Additionally, explore the option for sending voice input automatically after 3 seconds of silence for a streamlined experience.\n\n‚öôÔ∏è Fine-Tuned Control with Advanced Parameters: Gain a deeper level of control by adjusting parameters such as temperature and defining your system prompts to tailor the conversation to your specific preferences and needs.\n\nüîê Auth Header Support: Effortlessly enhance security by adding Authorization headers to Ollama requests directly from the web UI settings, ensuring access to secured Ollama servers.\n\nüîó External Ollama Server Connection: Seamlessly link to an external Ollama server hosted on a different address by configuring the environment variable during the Docker build phase. Additionally, you can also set the external server connection URL from the web UI post-build.\n\nüîí Backend Reverse Proxy Support: Strengthen security by enabling direct communication between Ollama Web UI backend and Ollama, eliminating the need to expose Ollama over LAN.\n\nüåü Continuous Updates: We are committed to improving Ollama Web UI with regular updates and new features. ",
    name: "ollama-webui",
    category: "AI/ML",
    health: 71,
    code: "k4_cpH",
    languages: [
      "Svelte",
      "Python",
      "TypeScript",
      "JavaScript",
      "CSS",
      "HTML",
      "Dockerfile",
      "Shell",
    ],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0d7314c5-6141-4f9a-8057-6032cce39a11",
    isApproved: false,
    activeProjects: 19,
    projects: 28,
    description: "A barebones TypeScript React starter with TanStack Router & Query setup",
    readme:
      "TanStack React + Vite Template\n\nThis is a lightweight React starter template using Vite, TypeScript with React, and 2 core packages from the TanStack:\n\nTanStack Query\nTanStack Router\n\nIt is deployed with the memory efficient Caddy web server, and can be set up on Railway in a single click.\n\nDeploy on Railway\n\nüöÄ Getting Started\n\ninstall dependencies with bun install\nstart local development with bun run dev\n\n‚ùì Why Caddy for serving the app?\n\nSee: https://github.com/brody192/vite-react-template#-why-use-caddy-when-deploying-to-railway\n\nCaddy is a powerful, enterprise-ready, open source web server, and therefore Caddy is far better suited to serve websites than Vite is, using Caddy will result in much less memory and cpu usage compared to serving with Vite (much lower running costs too).",
    name: "TanStack + React Starter",
    category: "Starters",
    health: null,
    code: "EF4fed",
    languages: ["TypeScript", "JavaScript", "CSS", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5b28d952-e8d6-42e9-a43b-8700f8c39cf0",
    isApproved: false,
    activeProjects: 4,
    projects: 7,
    description: "Get your node up and running in just a few seconds.",
    readme:
      "Presearch is building a decentralized search engine. You can add your own server to Presearch's globally-decentralized search engine and help power the next generation of privacy-first web search!\n\nInstructions\nGo to https://nodes.presearch.com to learn more about nodes and create an account.\nGo go https://nodes.presearch.com/ to grab your registration code.\nSet the REGISTRATION_CODE variable.",
    name: "Presearch",
    category: "Other",
    health: null,
    code: "x7zx_Q",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "67ae56ff-ac12-47e6-84ae-d23562ab1d1f",
    isApproved: false,
    activeProjects: 3,
    projects: 9,
    description: "Check if coordinate is on water (seas, lakes, and rivers) with 1m precision",
    readme:
      "is-on-water\n\nüíßHTTP API using reverse geocoding to check whether a geographic coordinate is on water (seas, lakes, and rivers) with 1m precision\n\nSingle coordinate\n\nGET /api/is-on-water?lat=${lat}&lon=${lon}\n\nBatch coordinates\n\nPOST /api/is-on-water with body containing array of coordinate objects [{ lat, lon }, { lat, lon }, ...]",
    name: "Is On Water",
    category: "Other",
    health: null,
    code: "MfUYQX",
    languages: ["TypeScript", "HTML", "Dockerfile", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2691b0f5-0bdd-45db-8951-878988864f45",
    isApproved: false,
    activeProjects: 86,
    projects: 153,
    description: "A minimal production-ready node HTTP server with Express and Typescript",
    readme:
      "template-node-express\n\nA minimal production-ready node HTTP server with express.\n\nFeatures\n\n‚úÖ Typescript\n‚úÖ Graceful shutdown \n‚úÖ Optional Tracing with OpenTelemetry (configurable via environment variables)\n‚úÖ Properly configured request payload size limiting to help prevent Denial of Service attack vectors\n‚úÖ AbortSignal propagation to prevent unnecessary work (includes example and test)\n‚úÖ Validation with express-validator\n‚úÖ Async error forwarding to default error handler with express-async-errors\n‚úÖ Structured logging with pino\n‚úÖ Rich request logging middleware including request id, trace id, context propagation, and more\n‚úÖ Testing with jest, supertest, and fetch-mock\n‚úÖ helmet & compression\n",
    name: "Node Express",
    category: "Starters",
    health: 75,
    code: "KwYYFA",
    languages: ["TypeScript", "Dockerfile", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "174ffe4f-6ba6-4d69-ba2b-7e20e5e0e9ad",
    isApproved: false,
    activeProjects: 9,
    projects: 22,
    description: "DocsGPT is a cutting-edge open-source solution",
    readme:
      "DocsGPT is a cutting-edge open-source solution that streamlines the process of finding information in the project documentation. With its integration of the powerful GPT models, developers can easily ask questions about a project and receive accurate answers.\n\nSay goodbye to time-consuming manual searches, and let DocsGPT help you quickly find the information you need. Try it out and see how it revolutionizes your project documentation experience. Contribute to its development and be a part of the future of AI-powered assistance.",
    name: "DocsGPT",
    category: "Other",
    health: 0,
    code: "ZEv1r5",
    languages: ["Python", "TypeScript", "CSS", "JavaScript", "HTML", "Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d4f0a61a-a8af-4dfc-a27b-908edfa0e9b5",
    isApproved: false,
    activeProjects: 11,
    projects: 24,
    description: "A minimal production-ready golang HTTP server with go-chi/chi",
    readme:
      "template-go-chi\n\nA minimal production-ready golang HTTP server with go-chi/chi.\n\nFeatures\n\n‚úÖ Graceful shutdown\n‚úÖ Tracing with OpenTelemetry\n‚úÖ Trust proxy\n‚úÖ Structured logging with log/slog\n‚úÖ Rich request logging middleware including bytes written/read, request id, trace id, context propagation, and more\n‚úÖ Panic recovery with rich logging including request id and trace id",
    name: "Go Chi",
    category: "Starters",
    health: 100,
    code: "FdfQPz",
    languages: ["Go"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "878f7344-4bf0-4ef0-ba4b-6a6442d4ece0",
    isApproved: false,
    activeProjects: 29,
    projects: 78,
    description: "A simple project using Docker, Django and HTMX",
    readme:
      "Overview üó£Ô∏è\n\nJumpstart your project using this simple, highly customizable template.\n\nGetting Started üèÅ\n\ndocker compose up will launch the services necessary to get started.\n\nCustomize the Dockerfile and docker-compose.yaml to your needs.\n\nWhen it is time for deployment, railway up will push any changes onto Railway.\n\nEnjoy! üöÉ",
    name: "Django Conductor",
    category: "Starters",
    health: 100,
    code: "BHTYIP",
    languages: ["Python", "HTML", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "03537a25-6ca8-410b-a7a6-f9cb03f41384",
    isApproved: false,
    activeProjects: 4,
    projects: 17,
    description: "A single tool to configure,orchestrate and manage your entire pricing stack",
    readme:
      "Really simple template, just deploys the docker image for run, creates the domain and sets the required env variables.\nJust add your stripe key as requested.\nTo create models, visit https://model.tier.run/edit/new\n\nIf you sync the models with the stripe account associated to the api key you provided as env variable, You'll be able to use the Tier sdk for node.js and it will work using the URL generated by railway as TIER_BASE_URL env variable in your node project.\n\nhttps://github.com/tierrun/node-sdk\n",
    name: "Tier",
    category: "Automation",
    health: null,
    code: "MZl8-G",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "279216bc-fee0-4573-ab79-5973c39eaaee",
    isApproved: false,
    activeProjects: 4,
    projects: 9,
    description: "A minimal Indiekit server",
    readme:
      "Meet Indiekit, the little Node.js server with all the pieces needed to share your content with the open, independent web.\n\nPublish content to your website using apps and services that support the Micropub API\nSave files to a content store such as GitHub, GitLab or an FTP server\nIntegrate with static site generators like Jekyll or Hugo\nShare content on social networks like Mastodon\nCustomise everything from the interface theme to the format of commit messages\n\nIndiekit is extensible via its plugin API and localized for use in a growing number of languages.",
    name: "Indiekit",
    category: "CMS",
    health: null,
    code: "gEboK6",
    languages: ["JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "907882a8-b9f3-4b25-a826-bb2932a0f62b",
    isApproved: false,
    activeProjects: 24,
    projects: 137,
    description: " Self-hostable worker infrastructure, preconfigured to work out of the box.",
    readme:
      "Windmill\n\nOpen-source developer infrastructure for internal tools (APIs, background jobs, workflows and UIs). Self-hostable alternative to Airplane, Pipedream, Superblocks and a simplified Temporal with autogenerated UIs and custom UIs to trigger workflows and scripts as internal apps.\n\nScripts are turned into sharable UIs automatically, and can be composed together into flows or used into richer apps built with low-code. Supported script languages supported are: Python, TypeScript, Go, Bash, SQL, and GraphQL.\n\n\nDefine a minimal and generic script in Python, TypeScript, Go or Bash that\n   solves a specific task. The code can be defined in the\n   provided Web IDE or\n   synchronized with your own GitHub repo\n   (e.g. through\n   VS Code\n   extension):\n\n   Step 1\n\nYour scripts parameters are automatically parsed and\n   generate a frontend.\n\nStep 2\n\nStep 3\n\nMake it flow! You can\n   chain your scripts or scripts made by the community shared on\n   WindmillHub.\n\n   Step 3\n\nBuild complex UIs on top of\n   your scripts and flows.\n\n   Step 4\n\nScripts and flows can also be triggered by a\ncron schedule (e.g.\n'_/5 _ \\* \\* \\*') or through\nwebhooks.\n\nYou can build your entire infra on top of Windmill!\n\nSelfhosting documentation: https://windmill.dev/docs/advanced/self-host\n\n\n",
    name: "Windmill",
    category: "Automation",
    health: 100,
    code: "UI371k",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5a33ed8a-eb6d-4714-860b-7a982728a497",
    isApproved: false,
    activeProjects: 51,
    projects: 118,
    description: "Basic Langserve server with the pirate speak template",
    readme:
      "See the readme for this project for more information:\nhttps://github.com/PaulLockett/LangServe-Railway/tree/main\n\nMake sure to set your environmental variables! The defaults are only placeholders.\n\nNote that when adding a new template you must also add it to the poetry project so that the nix build will pick it up and make the module available to the langServe server.",
    name: "LangServe - Pirate Speak Template",
    category: "AI/ML",
    health: 0,
    code: "pW9tXP",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0df3c381-f9f6-4e41-ab2e-cb6a39246677",
    isApproved: false,
    activeProjects: 0,
    projects: 6,
    description: "Migrate data from a source Redis to a target Redis database",
    readme:
      "This is a service that will migrate data from the source Redis database to the target Redis database.\n\nRequired Variables\n\nSOURCE_REDIS_URL: The Redis URL of the source database.\nTARGET_REDIS_URL: The Redis URL of the target database.\n\nProcess\n\nUses Redis Riot to replicate the data.\n\nNo data is ever deleted from the source\n\nCaveats\n\nYou should stop writing to the source database while the migration is in progress to avoid data not being migrated\nYou should manually update your application to point to the target URL once the migration is done\n\n**If you want to avoid egress charges, you should use the private URL of the target database.",
    name: "Redis Migrator",
    category: "Storage",
    health: null,
    code: "redis-migrator",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a6f07dd8-6a4a-40ff-8661-6dc4d80343a8",
    isApproved: false,
    activeProjects: 16,
    projects: 25,
    description: "DVWA is an intentionally vulnerable web app to help understand attacks.",
    readme:
      'About\n"Damn Vulnerable Web Application (DVWA) is a PHP/MySQL web application that is damn vulnerable. Its main goal is to be an aid for security professionals to test their skills and tools in a legal environment, help web developers better understand the processes of securing web applications and to aid both students & teachers to learn about web application security in a controlled class room environment.\n\nThe aim of DVWA is to practice some of the most common web vulnerabilities, with various levels of difficulty, with a simple straightforward interface. Please note, there are both documented and undocumented vulnerabilities with this software. This is intentional. You are encouraged to try and discover as many issues as possible."\n\nNote\nI have forked the original repo and made some slight modifications to enable easy Railway deployment. If you have any issues with deployment, please create an issue on the w33ts/DVWA repo or ping w33t.io in the Railway Discord. I will keep it up to date as needed.\n\nSources\nOriginal Repo: https://github.com/digininja/DVWA\n\nModified Repo: https://github.com/w33ts/DVWA',
    name: "DVWA (Damn Vulnerable Web App)",
    category: "Other",
    health: 67,
    code: "GFqNIL",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "493f0182-43af-4c29-b620-e0ec650abe12",
    isApproved: false,
    activeProjects: 75,
    projects: 189,
    description: "Open source observability and analytics for LLM applications",
    readme:
      "Langfuse is an open source observability & analytics solution for LLM-based applications. It is mostly geared towards production usage but some users also use it for local development of their LLM applications.\n\nLangfuse is focused on applications built on top of LLMs. Many new abstractions and common best practices evolved recently, e.g. agents, chained prompts, embedding-based retrieval, LLM access to REPLs & APIs. These make applications more powerful but also unpredictable for developers as they cannot fully anticipate how changes impact the quality, cost and overall latency of their application. Thus Langfuse helps to monitor and debug these applications.\n\nUsing this template, you can deploy Langfuse to Railway. It automatically creates a Postgres database to store your production data.\n\nIn case of errors, try restarting the application container or join the Discord to get help: https://langfuse.com/discord",
    name: "Langfuse v2",
    category: "AI/ML",
    health: 100,
    code: "gmbqa_",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "28915b88-cf96-4529-b855-d86a3f242c57",
    isApproved: false,
    activeProjects: 30,
    projects: 83,
    description: "Open Work and Project Management Platform",
    readme:
      "About\n\nWork / Workforce Management\nTime Management / Time Tracking / Activity Tracking\nProductivity Tracking & Metrics\nProjects / Tasks & Issues Management\nOrganizations / Teams\nTags / Labels\nIntegrations (GitHub, GitLab, Bitbucket, JIRA, etc.)\nDark / Black / Light Themes\n\nLinks \n\nhttps://app.ever.team - Ever Teams Platform web application (not yet in production release)\nhttps://ever.team - Check more information about the Ever Teams platform at the official website (WIP).\nhttps://gauzy.co - Check more information about the Ever Gauzy Platform at the official website.\nhttps://ever.co - Get more information about our company products.",
    name: "Ever Teams",
    category: "Other",
    health: 100,
    code: "7_OfzR",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ea8c3441-d918-4e0e-9336-a62cf6a69b7e",
    isApproved: false,
    activeProjects: 11,
    projects: 17,
    description: "ReScript React Template with Caddy",
    readme:
      "Welcome to the Railway-Rescript-Template! This project is tailored for developers who want to combine the power of Railway.app with the safety and expressiveness of ReScript for their frontend development.\nFeatures üåü\n\nOptimized for Railway.app: This template integrates seamlessly with Railway.app, ensuring a quick setup and smooth deployments.\n\nReScript Ready: Dive straight into type-safe and functional frontend development with a pre-configured ReScript environment.\n\nWhy use this template? ü§î\n\nFast Iteration: With Railway.app's rapid deployment capabilities and ReScript's efficient compilation, you'll experience a speedy development cycle.\n\nType Safety: ReScript provides strong type guarantees, helping to catch errors at compile-time rather than runtime.\n\nFunctional Paradigm: If you're a fan of functional programming, ReScript brings those principles to the table, offering a clean and concise way to write frontend logic.\n\nQuick Start üöÄ\n\nTo get started with this template:\n\nClick on \"Use this template\" on the GitHub repository page.\n\nContributions üí™\n\nFeel free to contribute! If you find any bugs or want to suggest improvements, please open an issue or send a pull request. All contributions are welcomed.",
    name: "ReScript Frontend",
    category: "Other",
    health: 100,
    code: "SSNJUD",
    languages: ["JavaScript", "ReScript", "CSS", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9aa447db-f0cf-472f-9f2d-dd03e33f6578",
    isApproved: false,
    activeProjects: 1,
    projects: 8,
    description: "Remix Frontend + PayloadCMS on MongoDB",
    readme:
      "This template allows you to quickstart a Remix site with a PayloadCMS backend. No configuration needed.\n\nDevelop Locally\n\ninstall Docker Desktop and run docker compose up",
    name: "rePay",
    category: "Starters",
    health: null,
    code: "iRjSBO",
    languages: ["TypeScript", "JavaScript", "Dockerfile", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "06e2ddb9-bdcb-47f7-9a34-d09478575a63",
    isApproved: false,
    activeProjects: 26,
    projects: 126,
    description: "Open source background jobs framework for TypeScript.",
    readme:
      "‚ú® Trigger.dev is the open source background jobs framework for TypeScript. With features like API integrations, webhooks, scheduling and delays.\n\nCreate long-running jobs directly in your codebase with features like API integrations, webhooks, scheduling and delays.",
    name: "Trigger.dev",
    category: "Automation",
    health: 92,
    code: "na6kUS",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "113653a1-4099-41cf-aa77-29dd63938ab5",
    isApproved: false,
    activeProjects: 42,
    projects: 73,
    description: "A Go proxy server for routing traffic based on URLs and ports.",
    readme:
      "Simple Golang Proxy Server\n\nThe Simple Golang Proxy Server is a lightweight proxy server implemented in the Go programming language. It provides a simple and flexible way to route incoming traffic to a destination server based on the provided URL and port.\n\nFeatures\n\nURL Routing: Easily route traffic to different destination servers based on URL patterns.\nPort Configuration: Configure the proxy server to listen on a specific port of your choice.\nCustomizable: Extend and customize the proxy server to meet your specific requirements.\nHealth Checks: Optionally add health check endpoints to monitor the server's status.",
    name: "Golang Proxy Server",
    category: "Other",
    health: 50,
    code: "y0AKsJ",
    languages: ["Go", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a90e616c-3dcc-4477-8e49-edf99b6c21c5",
    isApproved: false,
    activeProjects: 3,
    projects: 54,
    description: "Sync secrets across your team/infrastructure and prevent secret leaks.",
    readme:
      "Infisical is the open source secret management platform that teams use to centralize their secrets like API keys, database credentials, and configurations.\n\nthis template deploys everything necessary to run a infisical instance (mongodb and redis) and connects everything.\nAfter it's deployed, you'll need to create an account using the e-mail method at the Infisical UI available at the default deploy URL.\n\nIf you need to configure integrations and everything else, here is the .env.example\nhttps://github.com/Infisical/infisical/blob/main/.env.example",
    name: "Infisical",
    category: "Automation",
    health: null,
    code: "UAZUjV",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3fe2f9c2-63bf-4d9a-94e3-2f5942705d64",
    isApproved: false,
    activeProjects: 5,
    projects: 25,
    description: "Remix Frontend + PayloadCMS on MongoDB",
    readme:
      "This template allows you to quickstart a Remix site with a PayloadCMS backend. No configuration needed.\n\nDevelop Locally\n\ninstall Docker Desktop and run docker compose up",
    name: "rePay",
    category: "Starters",
    health: null,
    code: "vhqnvU",
    languages: ["TypeScript", "JavaScript", "Dockerfile", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a16796b4-d865-4d95-9f40-77fd22989424",
    isApproved: false,
    activeProjects: 15,
    projects: 92,
    description: "Robust & customizable turnkey solution for authentication and authorization",
    readme:
      "Are you searching for a user management tool that is quickly set up like Auth0 and open source like Keycloak?\n\nDo you have a project that requires multi-tenant user management with self-service for your customers?\n\nLook no further ‚Äî ZITADEL is the identity infrastructure, simplified for you.\n\nThis template spins up Zitadel instance and connects it to a Postgres database.\nFirst time you login, you can access the instance by visting your railway public url and with the following credentials:\n\nroot@email.com\nRootPassword1!",
    name: "Zitadel",
    category: "Authentication",
    health: 82,
    code: "Q0uE7q",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a0f35015-c954-4839-aa8b-0e919a5322ba",
    isApproved: false,
    activeProjects: 6,
    projects: 34,
    description: "A UI-first Identity Access Management (IAM) / Single-Sign-On (SSO) platform",
    readme:
      "As an authentication platform, Casdoor implements the authentication by communicating with providers and users. Integrates with several identity providers.\nThis template deploys a Postgres instance and a Casdoor Docker image and links both in a simple way.\n\nYou can access your instance at the URL generated after deploys by using credentials:\nadmin\n123",
    name: "Casdoor",
    category: "Authentication",
    health: 100,
    code: "OJXBP4",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "bcc25a92-4323-4059-ab0f-c18910ba6b48",
    isApproved: false,
    activeProjects: 13,
    projects: 91,
    description: "Open-source Identity Provider that emphasizes flexibility and versatility.",
    readme:
      "Authentik can be seamlessly integrated into existing environments to support new protocols. authentik is also a great solution for implementing sign-up, recovery, and other similar features in your application, saving you the hassle of dealing with them.\n\nThis template deploys the required docker images for it to work.\nFor initial configuration, visit your server url at {URL}/if/flow/initial-setup/",
    name: "Authentik",
    category: "Authentication",
    health: 100,
    code: "nBQI2d",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "bb0ed3ca-db45-4a0c-a6fa-0bc29b4e8d14",
    isApproved: false,
    activeProjects: 2,
    projects: 3,
    description: "The sleek, feature-rich module registry for Deno. üì¶",
    readme:
      "den.ooo is a lightweight module registry for Deno to serve JavaScript, TypeScript and WebAssembly files from GitHub, GitLab, NPM and many others.\n\nOur NPM package and this template are licensed under the MIT license.\n\nDon't want to waste any more time?\n\nClick on the button below to get started right away:\n\nDeploy on Railway\n",
    name: "den.ooo",
    category: "Starters",
    health: null,
    code: "zHcmpg",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9a55b4ef-de3a-471b-b54c-60a35ac82194",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "Dotnet backend quickstart using Openfort to interact with smart wallets.",
    readme:
      "Openfort is a suite of APIs powering blockchain account interactions for games of all sizes. \n\nWith Openfort, you can interact smart accounts that offer the latest capabilities on account abstraction like:\nGasless blockchain transactions.\nPayment of gas in ERC-20 tokens.\nTransfer ownership of a wallet without exposing the private key.\nRecovering a smart wallet when access has been lost\n\nWith just one click, deploy your Dotnet backend API to the Railway cloud platform.",
    name: "Openfort Dotnet Quickstart",
    category: "Other",
    health: null,
    code: "L-kdsI",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "611d0f33-659f-4a11-89e5-0015dc77752c",
    isApproved: false,
    activeProjects: 1,
    projects: 4,
    description: "Node backend quickstart using Openfort to interact with smart wallets.",
    readme:
      "Openfort is a suite of APIs powering blockchain account interactions for games of all sizes. \n\nWith Openfort, you can interact smart accounts that offer the latest capabilities on account abstraction like:\nGasless blockchain transactions.\nPayment of gas in ERC-20 tokens.\nTransfer ownership of a wallet without exposing the private key.\nRecovering a smart wallet when access has been lost\n\nWith just one click, deploy your Dotnet backend API to the Railway cloud platform.",
    name: "Openfort Node Quickstart",
    category: "Other",
    health: null,
    code: "vi0lxN",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b6bce689-fb22-49c4-b3a0-2b40dc52f66e",
    isApproved: false,
    activeProjects: 196,
    projects: 342,
    description: "The open source relational database",
    readme:
      "What is MariaDB?\n\nMariaDB Server is one of the most popular database servers in the world. It's made by the original developers of MySQL and guaranteed to stay open source. Notable users include Wikipedia, DBS Bank, and ServiceNow.\n\nThe intent is also to maintain high compatibility with MySQL, ensuring a library binary equivalency and exact matching with MySQL APIs and commands. MariaDB developers continue to develop new features and improve performance to better serve its users.",
    name: "MariaDB",
    category: "Storage",
    health: 96,
    code: "Onvy0F",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ac9bc70a-23b1-492a-83b8-d24093ffc93d",
    isApproved: false,
    activeProjects: 5,
    projects: 20,
    description: "Build your personal knowledge base with Trilium Notes.",
    readme:
      "This template deploys a Trilium docker image and mounts the required volume for it to run properly.\nIt listens by default on port 8080 and should be accessible instantly (after deployment) without further configuration, just set up a password using it's web interface and you should be golden.",
    name: "Trilium",
    category: "Other",
    health: 50,
    code: "jsMnJe",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7ff5f30a-48a8-4570-a257-2504d63f8c10",
    isApproved: false,
    activeProjects: 127,
    projects: 192,
    description: "OpenAI Proxy (100+ LLMs) - OpenAI, Azure, Bedrock, Anthropic, HuggingFace",
    readme:
      'A fast, and lightweight OpenAI-compatible server to call 100+ LLM APIs.\n\nCall all LLM APIs using the OpenAI format. Use Azure, OpenAI, Cohere, Anthropic, Ollama, VLLM, Sagemaker, HuggingFace, Replicate (100+ LLMs)\n\nTest your deployed proxy\nimport openai \nopenai.api_base = "http://0.0.0.0:8000"\n\nprint(openai.ChatCompletion.create(model="test", messages=[{"role":"user", "content":"Hey!"}]))\n\n',
    name: "openai-proxy",
    category: "AI/ML",
    health: 67,
    code: "YTHiYS",
    languages: ["Python", "Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "995791f9-224f-4fe3-9b9e-a8ad2b4e252b",
    isApproved: false,
    activeProjects: 27,
    projects: 36,
    description: "A HotChocolate C# GraphQL server with support for Apollo Federation",
    readme:
      "The fastest way to deploy a C# HotChocolate GraphQL server! This template is federation-compatible, so you can use this to add C# to an existing graph in just a few minutes.\n\nIncludes GitHub Actions for integrating with Apollo GraphOS, enabling:\n\nChecks for breaking changes\nDetect composition errors\nUpdate your router or gateway automatically\n\nThis template is maintained by Apollo, so it will be kept up to date and always recommends best practices.",
    name: "C# HotChocolate Subgraph (Annotation)",
    category: "Starters",
    health: 100,
    code: "cJcDcc",
    languages: ["C#", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7101c553-9fac-4cd0-b332-1efab34eee5f",
    isApproved: false,
    activeProjects: 236,
    projects: 535,
    description: "PostgreSQL DB enabled with PostGIS",
    readme:
      "PostgreSQL DB enabled with the PostGIS extension\n\nThe image used in this template can be found in Docker Hub, published by the team at PostGIS.\npostgis/postgis\n\nVersions\nPostgreSQL 16\nPostGIS 3.4.0\n\nPostGIS\nExtends PostgreSQL by adding support for storing, indexing, and querying geographic data.\n\nPostGIS is an open source software program that adds support for geographic objects to the PostgreSQL object-relational database. PostGIS follows the Simple Features for SQL specification from the Open Geospatial Consortium\n\nPostGIS Documentation\n\nSSL certificates\nThis template initializes postgres using the self-signed Snakeoil certificate that is available in Debian/Ubuntu systems.  This is controlled by the POSTGRES_INITDB_ARGS environment variable.",
    name: "PostGIS",
    category: "Storage",
    health: 100,
    code: "postgis",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "446bb0e1-ca62-4d0f-8138-94e9dfe30e1d",
    isApproved: false,
    activeProjects: 29,
    projects: 106,
    description: "PostgreSQL DB enabled with TimescaleDB and PostGIS",
    readme:
      "Overview\n\nPostgreSQL database service with TimescaleDB and PostGIS installed.  Deployed with Railway's SSL-enabled image.\n\nNote that postgis is installed but not enabled.  To enable it, simply connect to the DB and execute CREATE EXTENSION postgis;\n\nVersions\nPostgreSQL 16\nTimescaleDB 2.13\nPostGIS 3.4.1\n\nExtensions\n\nTimescaleDB \nA time-series database built on top of PostgreSQL. \n\nEngineered to efficiently handle resource-intensive workloads, like time series, event, and analytics data. Built on PostgreSQL, with expert support at no extra charge.\n\n  Timescale Documentation\n\nPostGIS\nExtends PostgreSQL by adding support for storing, indexing, and querying geographic data.\n\nPostGIS is an open source software program that adds support for geographic objects to the PostgreSQL object-relational database. PostGIS follows the Simple Features for SQL specification from the Open Geospatial Consortium\n\n  PostGIS Documentation",
    name: "TimescaleDB + PostGIS",
    category: "Storage",
    health: 100,
    code: "timescaledb-postgis",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2425aea7-cac7-4843-a0f5-4275f6791bc3",
    isApproved: false,
    activeProjects: 9,
    projects: 70,
    description: "Directus starter with postgres for the db and cloudinary for assets.",
    readme:
      "This starter template will setup the latest version of Directus with Postgres and Cloudinary for the assets. Extensions included are the slug, m2m tags and editor.js.\n\nTo use, enter your admin email, password and Cloudinary details in the environment variables in the setup step.",
    name: "Directus with Cloudinary",
    category: "CMS",
    health: 86,
    code: "jXpoBv",
    languages: ["TypeScript", "Vue", "JavaScript", "SCSS", "CSS", "Liquid", "Dockerfile", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4e7171a3-9f6d-4bba-bd11-37c382095326",
    isApproved: false,
    activeProjects: 1,
    projects: 15,
    description: "GraphQL API collection generator service using Graphman and Flask.",
    readme:
      "GraphQL API Collection Generator and Server\n\nThis repo contains two components which allow Railway to distribute the GraphQL API collection for Railway's public API.\n\nWe have captured this in a template for Railway users to deploy, should they find it useful.\n\nComponents\n\n1. file-server/\n\nA Flask application with the following routes:\n\n/upload (POST): Accepts a JSON body which is compared against the current collection file to be stored in /data if any changes are detected.\n/ (GET): Renders a simple File Explorer of the /data directory and allows for downloading the existing collection file.  An archive directory also exists to store old versions of the file.\n\n2. graphman/\n\nA modified version of the Graphman CLI. It runs on a cron schedule defined in graphman/railway.toml.  It is responsible for:\n\nGenerating the GraphQL API collection.\nSending a POST request to the file-server /upload endpoint with the GraphQL API collection object.\n\nEnvironment Variables\nThe Graphman component expects two environment variables.  Both are preconfigured in the Railway template, as follows -\nAPI_URL=${{file-server.RAILWAY_PUBLIC_DOMAIN}} (URL of the file server)\nGRAPHQL_ENDPOINT=https://backboard.railway.app/graphql/v2 (GraphQL API endpoint from which to generate a colection)\n\nNote: If using this service to generate a collection from another GraphQL API, keep in mind that some API's may have authentication requirements that will require a modification of the Graphman cron.  Refer to the Graphman Documentation for more information.",
    name: "Graphman + File Server",
    category: "Automation",
    health: null,
    code: "graphman",
    languages: ["TypeScript", "Python", "Dockerfile", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "16fe2835-c91d-4c7d-9891-b013a612322a",
    isApproved: false,
    activeProjects: 21,
    projects: 65,
    description: "Vault container in Railway",
    readme:
      'Once the project deployed, you must init it : \n \n1- Generate a domain to access it outside of railway. \n\n2- Download vault cli\n\n3- Run : $env:VAULT_ADDR="https://${{GENERATED_DOMAIN}}"\n\n4- Run : vault operator init\n\n5- Store unseal keys securly ! For more information: https://developer.hashicorp.com/vault/docs/concepts/seal\n\n6- Run $env:VAULT_TOKEN="${{GENERATED_TOKEN}}"\n\n7- Mount services you need (Kvv1, Kvv2, etc...)\n\n8- Create tokens for your services as you need\n\n9- Everything you want...\n\n10- Revoke root token (You can regenerate one using unseal keys, see: https://developer.hashicorp.com/vault/tutorials/operations/generate-root)\n\n11- Remove generated domain (use private network in your railway project)',
    name: "Hashicorp Vault",
    category: "Storage",
    health: 100,
    code: "vOXRB-",
    languages: ["Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1c9a0e25-bdb1-4066-8b28-221ee86ccc6a",
    isApproved: false,
    activeProjects: 6,
    projects: 15,
    description: "A minimal PgBouncer image for Railway",
    readme:
      "Use this template to deploy a PgBouncer instance on Railway. To get started, deploy the template and input your Postgres database details when prompted. Once deployed, you can access your database though PgBouncer using your default credentials and the host and port provided under Your_PgBouncer_Service -> Settings \n -> Networking. ",
    name: "PgBouncer for Railway",
    category: "Other",
    health: 100,
    code: "L09YMd",
    languages: ["Shell", "Dockerfile", "Makefile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b7e1cd06-0d7d-4f1c-b5b9-85696ec167f4",
    isApproved: false,
    activeProjects: 18,
    projects: 72,
    description: "Open-source software for metering and usage-based billing.",
    readme:
      "Original Lago template made by another user was not working so I made this one.\nIt will spin a postgres db, a redis db and both the frontend and api images necessary to run lago in the simplest manner.\nAfter deployed, you can access the service through the frontend url (after creating an account).",
    name: "Lago (working)",
    category: "Other",
    health: 94,
    code: "JkR0z8",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4f2ae985-2bc1-4a93-be89-3beff06e0571",
    isApproved: false,
    activeProjects: 12,
    projects: 46,
    description: "Open-Source Subscription Billing & Payments Platform",
    readme:
      "Template deploys MariaDB, killbill api server and the web interface for management. You can leave all env variables as is.\nInitial credentials are admin:password\nPlease contact beuz at discord if something's not working properly and I'll try to fix it.",
    name: "kill bill",
    category: "Other",
    health: 100,
    code: "oeQY9c",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3e7be6b3-da2c-4d1c-93cb-dc373687b691",
    isApproved: false,
    activeProjects: 1,
    projects: 9,
    description: "EdgeDB template to connect to a managed Railway PostgreSQL instance",
    readme:
      "Refer to the Official EdgeDB Docker Deployment Guide. This template follows that guide as closely as possible.\n\nThis template expects there to already be a running PostgreSQL instance in the project. Retrieve its connection url in URI format, and paste that as the environment variable for EDGEDB_SERVER_BACKEND_DSN.\n\nThis template also expects a password to be set in the field EDGEDB_SERVER_PASSWORD. For this value, set the password to be exactly the same as the PostgreSQL instance.\n\nThere are a few additional environment variables that you can configure:\nAdmin UI is turned on",
    name: "EdgeDB with separate PostgreSQL",
    category: "Storage",
    health: 0,
    code: "6AT4wH",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "09b9fbed-26e4-4c8c-a82e-38a2294c4957",
    isApproved: false,
    activeProjects: 9,
    projects: 38,
    description: "EdgeDB template based on their Docker deployment guide",
    readme:
      "Refer to the Official EdgeDB Docker Deployment Guide. This template follows that guide as closely as possible.\n\nThis template expects the persistence to happen with a mounted volume, NOT a separate PostgreSQL deployment.\n\nThis template expects a password field, which is automatically set right now by the ${{ secret() }} utility function by Railway.\n\nThere are a few additional environment variables that you can configure:\nAdmin UI is turned on",
    name: "EdgeDB",
    category: "Storage",
    health: null,
    code: "uDZcDr",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "92b1e896-0cde-4fa2-b88c-6a3c3014e52d",
    isApproved: false,
    activeProjects: 3,
    projects: 6,
    description: "Postgres backups to Google Cloud Storage (GCS)",
    readme:
      "Specify environment variable config to get automated backups of your Postgres database using pg_dump, compressed, and uploaded to Google Cloud Storage.\n\nRequires:\nGoogle Service Account key JSON\nA postgres DB URL connection string (with authentication)\nMinimal resources for a tiny node app\n",
    name: "Postgres Backup to GCS",
    category: "Automation",
    health: null,
    code: "tqxaEg",
    languages: ["TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "210c239e-8ea1-4e7f-ae18-784451a7cc9e",
    isApproved: false,
    activeProjects: 25,
    projects: 103,
    description: "PayloadCMS v2 with PostgreSQL Database Service",
    readme:
      "Payload CMS v2 with PostgreSQL Database\n\n\nDeploy on Railway\n\nThe original project was created using npx create-payload-app and used the blank template.\n\nHow to Use Locally with Remote PostgreSQL Database\nFollowing these instructions will have the application pointing to the hosted PostgreSQL database\nyarn install to install the needed dependencies\nInstall and configure the Railway CLI\nrailway run yarn dev will start up your application and reload on any changes. At this point changes in the schema will be automatically updated in the remote PostgreSQL database\nto create migration before committing your code railway run yarn payload migrate:create\n\nHow to Use Locally with Local PostgreSQL Database\nyarn install to install the needed dependencies\nCreate your own local Postgres Database and update the .env file with the DATABASE_URI\nSet the other .env file variables\nyarn dev will start up your application and reload on any changes\nPayload will update the database schema locally so you will need to run railway run yarn payload migrate:create before committing to GitHub so the schema changes get committed. The deployment script will run the appropriate migrate command to push changes to the database\n\nPostgreSQL Information\nhttps://www.postgresql.org/download/\nHow To Create a Local PostgreSQL Database\n\nOpen the terminal and run the command\nsudo -u postgres psql\n\nCreate PostgreSQL Database\nCREATE DATABASE myproject;\n\nCreate User\nCREATE USER myprojectuser WITH PASSWORD 'password';\n\nUpdate the .env file variable DATABASE_URI appropriately to point to the correct server\n",
    name: "PayloadCMS + Postgres",
    category: "CMS",
    health: 75,
    code: "B_KVXT",
    languages: ["TypeScript", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9193cebc-f2e3-47d2-b17e-d97949ef9299",
    isApproved: false,
    activeProjects: 35,
    projects: 98,
    description: "Time-series database built on top of Postgres",
    readme:
      'Timescale is a time-series database built on top of PostgreSQL. \n\n"Engineered to efficiently handle resource-intensive workloads, like time series, event, and analytics data. Built on PostgreSQL, with expert support at no extra charge."\n\nRead the docs for usage info docs.timescale.com',
    name: "TimescaleDB",
    category: "Storage",
    health: 96,
    code: "VSbF5V",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "49136d29-9d2b-4301-b95e-1ad7acc508b6",
    isApproved: false,
    activeProjects: 100,
    projects: 235,
    description: "Fast, typo-tolerant open source search engine",
    readme:
      "\n   \n\n\n  Typesense is a fast, typo-tolerant search engine for building delightful search experiences.\n\n\n\n  An Open Source Algolia Alternative &amp; \n  An Easier-to-Use ElasticSearch Alternative\n\n\nNote\n\nTypesense does not support binding to an IPv6 address and therefore isn't accessible over the IPv6 only private network, please use its public URL.\n\nFeatures\n\nTypo Tolerance: Handles typographical errors elegantly, out-of-the-box.\nSimple and Delightful: Simple to set-up, integrate with, operate and scale.\n‚ö° Blazing Fast: Built in C++. Meticulously architected from the ground-up for low-latency (&lt;50ms) instant searches.\nTunable Ranking: Easy to tailor your search results to perfection.\nSorting: Dynamically sort results based on a particular field at query time (helpful for features like \"Sort by Price (asc)\").\nFaceting &amp; Filtering: Drill down and refine results.\nGrouping &amp; Distinct: Group similar results together to show more variety.\nFederated Search: Search across multiple collections (indices) in a single HTTP request.\nGeo Search: Search and sort by results around a latitude/longitude or within a bounding box.\nVector Search: Index embeddings from your machine learning models in Typesense and do a nearest-neighbor search. Can be used to build similarity search, semantic search, visual search, recommendations, etc.\nSemantic / Hybrid Search: Automatically generate embeddings from within Typesense using built-in models like S-BERT, E-5, etc or use OpenAI, PaLM API, etc, for both queries and indexed data. This allows you to send JSON data into Typesense and build an out-of-the-box semantic search + keyword search experience.\nScoped API Keys: Generate API keys that only allow access to certain records, for multi-tenant applications.\nSynonyms: Define words as equivalents of each other, so searching for a word will also return results for the synonyms defined.\nCuration &amp; Merchandizing: Boost particular records to a fixed position in the search results, to feature them.\nRaft-based Clustering: Setup a distributed cluster that is highly available.\nSeamless Version Upgrades: As new versions of Typesense come out, upgrading is as simple as swapping out the binary and restarting Typesense.\nNo Runtime Dependencies: Typesense is a single binary that you can run locally or in production with a single command.\n\nBenchmarks\n\nA dataset containing 2.2 Million recipes (recipe names and ingredients):\n  Took up about 900MB of RAM when indexed in Typesense\n  Took 3.6mins to index all 2.2M records\n  On a server with 4vCPUs, Typesense was able to handle a concurrency of 104 concurrent search queries per second, with an average search processing time of 11ms.\nA dataset containing 28 Million books (book titles, authors and categories):\n  Took up about 14GB of RAM when indexed in Typesense\n  Took 78mins to index all 28M records\n  On a server with 4vCPUs, Typesense was able to handle a concurrency of 46 concurrent search queries per second, with an average search processing time of 28ms.\nWith a dataset containing 3 Million products (Amazon product data), Typesense was able to handle a throughput of 250 concurrent search queries per second on an 8-vCPU 3-node Highly Available Typesense cluster.\n\nAPI Clients\n\nWhile you can definitely use CURL to interact with Typesense Server directly, we offer official API clients to simplify using Typesense from your language of choice. The API Clients come built-in with a smart retry strategy to ensure that API calls made via them are resilient, especially in an HA setup.\n\nJavaScript\nPHP\nPython\nRuby\n\nIf we don't offer an API client in your language, you can still use any popular HTTP client library to access Typesense's APIs directly. \n\nHere are some community-contributed clients and integrations:\n\nGo\n.Net\nJava\nRust\nDart\nPerl\nSwift\nClojure\npython orm client\nPHP SEAL Adapter\nElixir\n\nFramework Integrations\n\nLaravel\nFirebase\nGatsby\nWordPress\nWooCommerce\nSymfony\nInstantSearch\nDocSearch\nDocusaurus\nToolJet\nPlone CMS\nCraft CMS\nSEAL provides integrations of Typesense in Laravel, Symfony, Spiral, Yii and Laminas Mezzio PHP Framework",
    name: "typesense",
    category: "Other",
    health: 100,
    code: "DXBDVS",
    languages: ["Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "35965428-36b9-4981-b1f2-d4794f5a3bbe",
    isApproved: false,
    activeProjects: 15,
    projects: 42,
    description: "A client-side editor for general diagramming and whiteboarding",
    readme:
      "draw.io is a configurable diagramming/whiteboarding visualization application. draw.io is jointly owned and developed by JGraph Ltd and draw.io AG.\n\nThis template instantiates draw.io docker image and sets up the correct env variables for it to run. You'll be able to access the app by visiting your public URL generated by Railway\n\n",
    name: "Draw.io",
    category: "Other",
    health: 100,
    code: "ict_K7",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c6339482-2ea3-40e5-8935-f584ebda5130",
    isApproved: false,
    activeProjects: 30,
    projects: 100,
    description: "Powerful web analytics platform that gives you 100% data ownership",
    readme:
      "Google Analytics alternative that protects your data and your customers' privacy\n\nTake back control with Matomo ‚Äì a powerful web analytics platform that gives you 100% data ownership.\n\nThings of Note:\n\nCommunication to MariaDB is done exclusively over the private network and the database is not exposed externally in any way by default, if you want to enable access from outside of the private network you can go to the databases settings to enable TCP proxying and enter the internal port (3306) the TCP proxy can be again removed at any point to close off external access.\n\nDon‚Äôt damage your reputation with Google Analytics\n\nDon‚Äôt damage your reputation with Google Analytics\nYou could lose your customers‚Äô trust and risk damaging your reputation if people learn their data is used for Google‚Äôs ‚Äúown purposes‚Äù.\n\nBy choosing the ethical alternative, Matomo, you won‚Äôt make privacy sacrifices or compromise your site. You can even use Matomo without needing to ask for consent. Read more.\n\nBe in full control with data ownership and privacy protection\n\nWith 100% data ownership you get the power to protect your user‚Äôs privacy. You know where your data is stored and what‚Äôs happening to it, without external influence. We‚Äôre serious about privacy here at Matomo and keeping your business GDPR and CCPA compliant.\n\nMatomo is a full-featured PHP MySQL software program that you download and install on your own webserver. At the end of the five-minute installation process, you will be given a JavaScript code. Simply copy and paste this tag on websites you wish to track and access your analytics reports in real-time.\n\nMatomo aims to be a Free software alternative to Google Analytics and is already used on more than 1,400,000 websites. Privacy is built-in!\n\nWhat makes Matomo unique from the competition:\n\nYou own your web analytics data: since Matomo is installed on your server, the data is stored in your own database and you can get all the statistics using the powerful Matomo Analytics API.\n\nMatomo is a Free Software which can easily be configured to respect your visitors' privacy.\n\nModern, easy to use User Interface: you can fully customize your dashboard, drag and drop widgets and more.\n\nMatomo features are built inside plugins: you can add new features and remove the ones you don‚Äôt need. You can build your own web analytics plugins or hire a consultant to have your custom feature built-in Matomo.\n\nA vibrant international Open community of more than 200,000 active users (tracking even more websites!)\n\nAdvanced Web Analytics capabilities such as E-commerce Tracking, Goal tracking, Campaign tracking, Custom Variables, Email Reports, Custom Segment Editor, Geo Location, Real-time visits and maps, and a lot more!\n\nDocumentation and more info on https://matomo.org.",
    name: "Matomo",
    category: "Analytics",
    health: 100,
    code: "MiHicG",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3cf56087-b59d-40c8-ab8d-52657bd1a77c",
    isApproved: false,
    activeProjects: 8,
    projects: 50,
    description: "Agents that monitor and act on your behalf. Your agents are standing by!",
    readme:
      "Huginn is a system for building agents that perform automated tasks for you online. They can read the web, watch for events, and take actions on your behalf. Huginn's Agents create and consume events, propagating them along a directed graph. Think of it as a hackable version of IFTTT or Zapier on your own server. You always know who has your data. You do.\n\nThis template instantiates a Huginn instance and connects it with a postgres db.\nInitial credentials are admin:password\nYou can leave all env variables as is.",
    name: "Huginn",
    category: "Automation",
    health: 100,
    code: "YeKqIX",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "199de543-d833-41b7-b339-a8ef2565deab",
    isApproved: false,
    activeProjects: 22,
    projects: 122,
    description: "An open-source modern data exploration and visualization platform.",
    readme:
      "A template that adds the latest version of Apache Superset docker image to your project along with a Postgres Database and Redis to run with it.\n\nDefault credentias are usual admin:admin but it's recommended you change it once your app is deployed through the web interface.",
    name: "Superset",
    category: "Analytics",
    health: 67,
    code: "c0hqeB",
    languages: ["Shell", "Dockerfile", "Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d28f2d87-ae09-42e2-813f-e990d9a295f4",
    isApproved: false,
    activeProjects: 2,
    projects: 8,
    description: "A Prometheus exporter for gathering metrics about your Railway Redis DB",
    readme:
      "auto-magically expose metrics about your Railway MySQL database\n\nThis template will work immediately if your project already includes a Redis database. It will expose metrics formatted in the Prometheus-style. You can use this Prometheus template to scrape your Redis metrics and store them.",
    name: "Redis Metrics Prometheus Exporter",
    category: "Observability",
    health: 100,
    code: "73Vsr6",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "187b59ae-f3b8-4ca8-8484-a7eecaf3e6b1",
    isApproved: false,
    activeProjects: 5,
    projects: 17,
    description: "A Prometheus exporter for gathering metrics about your MySQL DB",
    readme:
      "MySQL Metrics Collector for Railway\n\nDeploy on Railway\n\nHow to replace user root with user exporter\n\nThis template will work immediately on any railway project that has a MySQL database deployed. However, it uses the root user for access, which is not ideal.\n\nFor better security, you should set up a dedicated exporter user in your MySQL DB. The following are detailed instructions for setting that up and adjusting the Railway environmental variables:\n\n1) log into your MySQL DB locally using Railway's connection procedures. These are listed in your MySQL details page.\n\n2) run the following commands to create a new user named exporter. Be sure to replace XXXXXXXX with a strong password of your choosing:\n\nCREATE USER 'exporter'@'localhost' IDENTIFIED BY 'XXXXXXXX' WITH MAX_USER_CONNECTIONS 3;\nGRANT PROCESS, REPLICATION CLIENT, SELECT ON . TO 'exporter'@'localhost';\n\n3) Return to the Railway UI. Navigate to your MySQL Collector service and add one new environmental variable: create a key called MYSQL_EXPORT_PASSWORD and set the value to your new password. The MYSQL_EXPORT_USER variable is already set to exporter.\n\n4) Update the Dockerfile and the .my.cnf file in your github repo. The appropriate replacement lines are already present, but commented out. Comment-out the old lines and uncomment these new lines. Push your changes. Railway will redeploy the collector with the new settings. Your collector is now using a dedicated exporter user instead of the root user!\n",
    name: "MySQL Metrics Prometheus Exporter",
    category: "Observability",
    health: null,
    code: "H5G_9i",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "cd2e0abb-55fc-410f-b163-18b42f29925a",
    isApproved: false,
    activeProjects: 44,
    projects: 242,
    description: "Conversational LLM Application Framework",
    readme:
      "ZEP-MEMORY\n\nZep is a Conversational LLM Application Framework developed by the team at getzep.\n\nOverview\n\n  Manage users, sessions, chat messages, chat roles, and more, not just texts and embeddings.\n  Build autopilots, agents, Q&A over docs apps, chatbots, and more.\n\nLearn more\n\nZep-Memory is an open source project. See more at GitHub\n\nSee more about Zep at getzep.com.",
    name: "zep-memory",
    category: "AI/ML",
    health: 100,
    code: "ugib3R",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "20ade9f1-448a-4fa9-ad5b-2a0764afd44e",
    isApproved: false,
    activeProjects: 4,
    projects: 13,
    description: "An intentionally vulnerable web app focused on secret management hygiene.",
    readme:
      "##Overview\nOWASP WrongSecrets is an open-source intentionally vulnerable web application focused on secret management hygiene. It is designed to help developers and security professionals better understand the risks associated with poor or weak secret management practices. It can be used in security trainings, awareness demos, capture-the-flag events, testing secret detection tools, and honing your web application security skills in general.\n\n##Learn More\nTest Your Secret Management Skills with OWASP WrongSecrets\nOWASP WrongSecrets Github repo",
    name: "OWASP WrongSecrets",
    category: "Other",
    health: null,
    code: "7pnwRj",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8a3404a0-f09b-4fdf-b7d0-dc54e123f3bf",
    isApproved: false,
    activeProjects: 96,
    projects: 339,
    description: "World‚Äôs largest open source marketing automation project.",
    readme:
      "This is a template to 1click deploy Mautic (email marketing solution).\n\nIt will spin a MySQL database and connect it to the Mautic docker image deployed.\n\nConfiguration should be pretty straight forward.\nYou can leave it as is and just follow the installation steps at the mautic ui which should be available at the address auto generated by railway after you deploy.\n\nPlease don't hesitate to make contributions if you feel the template is lacking!",
    name: "Mautic",
    category: "Automation",
    health: 100,
    code: "9yIPIs",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "00db0878-3496-4653-9918-df681d524ea8",
    isApproved: false,
    activeProjects: 170,
    projects: 505,
    description: "Keycloak template with keywind theme + apple and discord providers",
    readme:
      "This template will spin a Postgres instance and use it to power a Keycloak docker image.\n\nI have added a custom keywind theme (will soon include dark mode), Discord identity provider and Apple identity provider.\n\nIt should be pretty straight forward to run, just set up an admin login and password and it should work.\n\nThings of Note:\n\nCommunication to Postgres is done exclusively over the private network and the database is not exposed externally in any way by default, if you want to enable access from outside of the private network you can go to the databases settings to enable TCP proxying and enter the internal port (5432). the TCP proxy can be removed at any point to close off external access.",
    name: "Keycloak",
    category: "Authentication",
    health: 84,
    code: "mSwigX",
    languages: ["FreeMarker", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8f7918de-30fd-4c51-8b3c-6411d8c5d755",
    isApproved: false,
    activeProjects: 4,
    projects: 25,
    description: "A batteries included starter for building an API using bun and Elysia",
    readme:
      "Elysia Starter is a batteries included starter for building an API using bun and Elysia.\n\nIncludes:\nBun toolkit\nElysia API framework\nTypeScript\nLinting\nPrisma and Postgres\nJWT authentication\nStatic file support\n\nTo get started, clone the repo and simply run bun run dev.",
    name: "elysia-starter",
    category: "Starters",
    health: 100,
    code: "2TqJzK",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9f65b2db-9a82-4421-82ae-820449d65163",
    isApproved: false,
    activeProjects: 61,
    projects: 109,
    description: "Simple WebSocket Bun server",
    readme:
      "A simple WebSocket server to get started using Bun.\n\nBun is a:\nToolkit All-in-one\nJavaScript runtime\nPackage manager\nTest runner\nBundler\n\nYou can connect to the template's server using:\n\nbunx wscat -c wss://bun-ws.up.railway.app\n\nOr deploy this template yourself and tinker with it! üî•",
    name: "Bun WebSockets",
    category: "Starters",
    health: 100,
    code: "BLofAq",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5bef4297-9b73-480e-bc3d-09fe9ccbff58",
    isApproved: false,
    activeProjects: 42,
    projects: 133,
    description: "Weaviate is an open source vector database",
    readme:
      "Weaviate is an open source vector database that stores both objects and vectors, allowing for combining vector search with structured filtering with the fault-tolerance and scalability of a cloud-native database, all accessible through GraphQL, REST, and various language clients.\n\n",
    name: "Weaviate",
    category: "Storage",
    health: 100,
    code: "uWRHq5",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7f20ef4d-03bd-4a1a-82cb-348b016c44c9",
    isApproved: false,
    activeProjects: 2,
    projects: 5,
    description: "E-book library manager running over tailscale",
    readme:
      "Calibre is the one-stop solution to all your e-book needs.\n\nTailscale offers free, secure, easy remote access to shared resources.\n\nThis template will automatically set you up for success with Calibre over Tailscale.\n\nEnvironment Variable Configuration\n\nTAILSCALE_AUTHKEY: An API key to access your Tailscale network.\nTZ: The timezone you want library operations to perform in. This is helpful to ensure you see the right info in the UI.",
    name: "Calibre over Tailscale",
    category: "Other",
    health: null,
    code: "hWLSF8",
    languages: ["Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d08b7d2f-c064-40e8-937a-57fc8d008252",
    isApproved: false,
    activeProjects: 87,
    projects: 231,
    description: "A fast, scalable, easy to use, extensible monolith backend using NestJs+TS",
    readme:
      "Generic NestJs Backend\n\nThis is a generic nestjs backend that can be used to create a backend for any project - from high performance, multi-tenant APIs to basic B2C apps and any CRUD application in between. \n\nIt can be deployed anywhere that you can deploy a docker container, and hooked up to any postgres database provider. It also includes instructions and configuration for easy local debugging. \n\nFeatures\n\nPassportJs User authentication (using JWTs, refresh tokens, etc.)\nCreating users and organizations (i.e. multi tenant support)\nCreating and issuing API keys with attached scopes\nTransactional email using resend\n\nTools used\n\nNest.js as the server framework (using fastify under the hood)\nprisma + postgres as the database\ndocker for local development\npassport.js for authentication\njest for testing\neslint for linting\nprettier for formatting\n\nHow to work on the API locally\n\nIf you're using vscode, you can use the Start Debug Server config, which will:\n\nspin up the database and adminer containers\nStart the API in dev mode (i.e. hot reload)\nSpin down the containers when you kill the debugger\n\nOtherwise, just run docker compose up db adminer to spin up the database and adminer containers, and then run npm run start:dev to start the API in dev mode (and docker compose down to spin down the containers when you're done).\n\nRunning the local postgres docker container\n\nThese instructions are cribbed from here.\n\nDownload the latest docker desktop release.\nRun the following command to pull the latest images and then start the container:\n\ndocker compose up db\n\nTo build everything, omit db, which will spin up the server and adminer db UI, all in the docker container. To include adminer but not turn on the server in the container, add adminer (i.e. docker compose up db adminer).\n\nIf you need to rebuild a container, run the following command:\n\ndocker compose up --build # omit container name to rebuild all\n\nTo remove old containers:\n\ndocker compose down # removes all containers\ndocker compose down --volumes # Remove containers and volumes\n\nUpdating the prisma database schema\n\nSee best practices from prisma here.\n\nOverview:\n\nMake changes to the schema in prisma/schema.prisma.\nStart the local database container (see above).\nrun npm run prisma:debug to test the change on the local database (or run npx prisma db push).\nKeep making changes until you're happy with them, using the prisma:debug command to test them.\nOnce you're happy with them, you can git stash to stash the changes you made to the schema and run prisma:debug once more go go back to what you had. Then git stash pop to get the changes back (which you know work, due to your prototyping in steps 1-4).\nFinally, run npm run prisma:dev  (or npx prisma migrate --name ) create a migration that creates the changes. You can skip step 5, but that will create drift in the database that will force you to reset it completely.",
    name: "NestJs Generic Template",
    category: "Starters",
    health: 55,
    code: "5eHaqw",
    languages: ["TypeScript", "Dockerfile", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "97b5e0a5-1f96-4e46-9ded-704ba549677e",
    isApproved: false,
    activeProjects: 31,
    projects: 86,
    description: "A data store built for modern workloads",
    readme:
      "\nThe world's most efficient in-memory data store\n\nDragonfly is a drop-in Redis¬Æ replacement that is optimized for data-intensive, low latency applications. Applications built on Dragonfly get the full speed, reliability, and scalability that modern cloud hardware makes possible, allowing them to deliver incredible experiences to their users while reducing both costs and complexity.\n\nFully compatible with Redis and Memcached APIs, Dragonfly requires no code changes to adopt. Compared to legacy in-memory datastores, Dragonfly delivers 25X more throughput, higher cache hit rates with lower tail latency, and can run on up to 80% less resources for the same sized workload.\n\nDragonfly currently supports ~185 Redis commands and all Memcached commands besides cas. Almost on par with the Redis 5 API, Dragonfly's next milestone will be to stabilize basic functionality and implement the replication API. If there is a command you need that is not implemented yet, please open an issue.\n\nOverview\n\nDragonfly is deployed with their ghcr.io/dragonflydb/dragonfly Docker image\n\nA volume is mounted to the service to persist data between builds.\n\nTCP proxying is configured to allow accessing the database from anywhere.\n\nHow to use\n\nReference the DRAGONFLY_PRIVATE_URL variable in your service, and then use the environment variable in your application. e.g.\n\nDRAGONFLY_URL=${{Dragonfly.DRAGONFLY_PRIVATE_URL}}",
    name: "Dragonfly",
    category: "Storage",
    health: 100,
    code: "dragonfly",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b6aecd58-b1cc-4aad-ae07-d732de5333b8",
    isApproved: false,
    activeProjects: 143,
    projects: 227,
    description: "A template for deploying FlowiseAI with persisted volume.",
    readme:
      "This is a template for deploying FlowiseAI with persisted volume. I made this for @nomocodes users to quickly try out FlowiseAI without figuring out the paths themselves and getting lost.\n\nFor the variables, other than flowise username and passwords, do not change the rest of the variables. Flowise username and passwords are optional and should only be used if you want to gate access to your flowise app.\n\nHappy building with no-code!\n\nJasper @nomocodes",
    name: "flowise-nomocodes",
    category: "AI/ML",
    health: 83,
    code: "fUNRIK",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "fd5418d4-0dee-47e2-a061-001f20c8d5b1",
    isApproved: false,
    activeProjects: 13,
    projects: 25,
    description: "FastAPI server to serve sentence-transformer embeddings",
    readme:
      'Given any sentence transformer model, this template will deploy a quick and easy FastAPI server to serve embeddings for that model.\n\nSetup requires you to choose which model to run, and choose the number of workers. Be careful using models that are too large, since a) they\'ll be expensive since the weights will be loaded into memory N times (i.e. depending on number of workers you chose during setup), and b) they\'ll be running on CPU so inference isn\'t overly quick compared to GPUs.\n\nUsage is simple, just post {"texts":["hello","world"]} to /embed on the exposed server, and you\'ll get back the embeddings in JSON.',
    name: "Sentence Transformers Model",
    category: "AI/ML",
    health: 0,
    code: "oFLL6X",
    languages: ["Python", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "939b8adc-ceb7-444a-b973-0c7d98f0b6e3",
    isApproved: false,
    activeProjects: 11,
    projects: 69,
    description: "Lightweight, fast code hosting and CI service (powered by Drone)",
    readme:
      "Gitness Template\n\nDeploy on Railway\n\nGitness Information\n\nYour lightweight, super fast code hosting and continuous integration service (powered by Drone)\n\nGitness is building on top of Drone to create a new, open source developer platform with code hosting and pipeline capabilities. \n\nGithub Repo\n\nWeb\n\nDocs",
    name: "Gitness",
    category: "Other",
    health: 50,
    code: "BCfNHk",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5cbb51c2-56b5-4c46-aee4-c820d3666008",
    isApproved: false,
    activeProjects: 1,
    projects: 2,
    description: "Official template for deploying the WarpStream Agents.",
    readme:
      "This template will help you deploy the WarpStream Agents to Railway.\n\nBefore proceeding, please create a WarpStream account.\n\nIn addition, you will also need an S3-compatible object store. We recommend CloudFlare R2.",
    name: "WarpStream Agents (Kafka without the disks)",
    category: "Storage",
    health: null,
    code: "30Xa3Y",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "daf027fc-6580-4eb4-bebb-6f7064fec7e5",
    isApproved: false,
    activeProjects: 3,
    projects: 9,
    description: "A Prometheus exporter for gathering metrics about your Railway Postgres DB",
    readme:
      "auto-magically expose metrics about your Railway Postgres database.\n\nthis template uses the popular Prometheus Community's Postgres Exporter under the hood. It is includes all the environmental variables needed to automatically connect to a postgres database inside the same project.",
    name: "Postgres Metrics Prometheus Exporter",
    category: "Observability",
    health: 100,
    code: "gDzHrM",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1e4c0e2c-1dab-4297-ad3f-306f81c5c30e",
    isApproved: false,
    activeProjects: 149,
    projects: 180,
    description: "https://github.com/tailscale-dev/tclip",
    readme:
      "One-click deploy for https://github.com/tailscale-dev/tclip, gives all users on your Tailscale tailnet access to a shared pastebin-like service.\n\nInstructions are available inside the GitHub repo, but you'll need a TS_AUTHKEY which you can generate inside the Tailscale admin console (https://login.tailscale.com/admin/settings/keys).",
    name: "tclip (Tailscale Pastebin)",
    category: "Other",
    health: 0,
    code: "HzYDtl",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "69457b96-2c14-4bec-a1fa-dfeadcb7ce60",
    isApproved: false,
    activeProjects: 103,
    projects: 307,
    description: "Expose web services easily and securely.",
    readme:
      "Overview\nNginx Proxy Manager is a simple web interface that enables users to reverse proxy to web hosts with free TLS termination using Nginx and LetsEncrypt. Based on Tabler, it was developed with the intention of offering users a simple way to:\nExpose web services on home network (or otherwise) easily and securely\nCreate proxy hosts, redirection hosts, streams and 404 hosts without detailed knowledge of Nginx reverse proxy\nEncrypt web traffic using free TLS certificates generated by Let's Encrypt\nDefine access lists and set up basic HTTP authentication for the hosts\n\nMore Info\nExpose Web Services on Your Home Network with Nginx Proxy Manager\nDocker container for Nginx Proxy Manager",
    name: "Nginx Proxy Manager",
    category: "Other",
    health: 100,
    code: "vXq1Wp",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b70a7b8a-b654-4544-93de-334518f324b2",
    isApproved: false,
    activeProjects: 72,
    projects: 93,
    description: "A companion bot for railway users, including usage reports and crash alerts",
    readme:
      "RailwayBot is an open source companion bot for railway users, made for fulfilling the needs of knowing if you've got a memory leak, or one of your services has crashed, all from the comfort of discord. With this template, you'll only need to provide a few details, and everything else will be available to you.",
    name: "RailwayBot",
    category: "Bots",
    health: null,
    code: "alYGiV",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "aebe100e-0335-45a7-bcc0-d60f916653b1",
    isApproved: false,
    activeProjects: 106,
    projects: 329,
    description: "A simple server using Bun",
    readme:
      "Bun is a new JavaScript runtime that is fast and is a drop-in replacement for NodeJS. This template uses Nixpacks to deploy on Railway.\n\nThe server itself just follows the getting started guide on bun.sh. Easy as pie! Deploy to quickly spin up a repo that uses Bun. Or simply browse the repo and copy the code.",
    name: "Bun Server",
    category: "Other",
    health: 95,
    code: "F0K-j3",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "89bd8908-b2c4-44f2-ae2e-f9beff18e54e",
    isApproved: false,
    activeProjects: 36,
    projects: 137,
    description: "A minimal example of the Prometheus time series database",
    readme:
      "Deploy on Railway\n\nDeploy Prometheus on Railway with one click. Pre-configured to self-monitor the Prometheus service and a well-known demo-application\n\nOnce you have deployed this template, modifications are simple.:\n\n1) find and clone your new repo\n\n2) update or replace the prometheus.yml file with your own settings and endpoints\n\n3) push the changes to your GitHub repo and Railway will automatically redeploy the service\n",
    name: "Prometheus",
    category: "Observability",
    health: 88,
    code: "KmJatA",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d5c99f5e-29a9-4c56-8ac8-afb8dcda5ba9",
    isApproved: false,
    activeProjects: 7,
    projects: 27,
    description: "Classic theme in TypeScript",
    readme:
      "Docusaurus v2 - Classic (TypeScript)\n\nDocusaurus is an open-source tool for building, deploying, and maintaining documentation websites. It was developed by Facebook and is designed to facilitate the creation of documentation websites for software projects in a way that is simple and scalable.\n\nFeatures and Benefits\n\nStatic Page Generation\n   Docusaurus creates websites using static page generation, meaning that the pages are generated at the build time rather than at the request time. This has benefits for performance and security.\n   \nMarkdown\n   It allows writing documentation using Markdown, a lightweight markup language that is easy to write and read.\n\nInternationalization (i18n)\n   Docusaurus has built-in support for internationalization, facilitating the translation of your documentation into various languages.\n\nVersioning\n   Docusaurus facilitates the versioning of your documentation, allowing different versions of your documentation to be available and easily accessible.\n\nIntegration with React\n   Docusaurus is built on React, a popular JavaScript library for building user interfaces. This allows great flexibility and power when customizing and extending your website.\n\nSearch\n   Docusaurus integrates a search function (often using Algolia DocSearch) to help users find the information they are looking for more quickly.\n\nStyles and Themes\n   Docusaurus allows you to customize the style and appearance of your documentation website with themes and style sheets.\n\nDocusaurus is widely used in the software development world and is an excellent choice for projects that need a simple and effective way to create and maintain documentation.\n",
    name: "Docusaurus v2",
    category: "Starters",
    health: null,
    code: "OZVYQA",
    languages: ["JavaScript", "TypeScript", "CSS", "Dockerfile", "MDX"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3454ad7d-4bd0-4e11-896c-c8b9f828eac9",
    isApproved: false,
    activeProjects: 41,
    projects: 73,
    description: "A simple service with fundamental components setup.",
    readme:
      "Railway's Express.js + Passport.js starter\n\nThis template deploys a simple service with fundamental components setup, built-in authentication/authorisation, and a fairly organised codebase.\n\nIn this codebase\n\nAlthough important notes will be presented here, it is recommended to explore and emerge yourself in a dfs way, starting here, as there exists plenty comments that will may or may not help you.\n\nTech stack\n\nExpress.js application with Passport.js to protect your precious todos, as well as chai on mocha for testing.\n\nArchitecture notes\n\nRequests to your service flow pass your middlewares to your routes. Both of them are attached to the main application separately, and you can always add more in either src/core/attach-routes.js or src/core/attach-middlewares.js.\nAll the middlewares attached in src/core/attach-middlewares.js are application-level middlewares. They could all be categorised into the following types (1) chore middlewares, i.e. cors, csrf, etc. (2) business middlewares, which play some parts in the logic of your service.\nIf a route-level middleware is what you need, src/modules/account/account.controller.js is an example implementation. But remember, ensureAuthenticated is placed in the common src/middlewares/index.js because it will also be used in other routes and modules; if what you have is local to, say the account module, please put it there. (account.middleware.js is not a bad name)\nThis codebase does not implement any logging mechanism, because only God knows what library you love. It also does not have dotenv built-in, because Railway injects environment variables at runtime. Do install if you are using this starter, not just reading it as a way to procrastinate your life (but thank you!).\nOther implementation details will be documented somewhere near the code.\n\nTesting\n\nThis is separated from the above section because I have actually tried a few testing frameworks, and chai's interface is by far the most convenient to work with. Most of the time, you would want to test route handlers' business logic (TDD), or a fragment of the service flow (BDD), and chai's should APIs or the normal expects are really sweet. Anyway, just organise your test files as per the existing structure, but technically any file in the test directory that has the .test.js extension will be included if you run the predefined test script.\n\nDevelopment\n\nThe predefined dev script uses Node.js v18 experimental --watch flag. If you cannot handle it, please implement nodemon or pm2 yourself.\nSome JSDoc tags used are official ones, but rather a way of notating. They are the only personal thing in this starter, and please feel free to modify them to your team's specs, or your own liking.\nHave a glance at this ESM guide with a cup of coffee, there is a high chance you might learn something new.\n",
    name: "Express.js + Passport.js starter",
    category: "Starters",
    health: null,
    code: "7VIvXX",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "105723eb-a6b3-4ce5-9603-ce0a1724a1a7",
    isApproved: false,
    activeProjects: 66,
    projects: 141,
    description: "Add basic auth to your web app.",
    readme:
      "This is for web application running in railway.app which need a basic auth without modifing source code.\n\nThis template uses nginx:alpine in docker. You can modify your username and password by change enviroment variables.\n\nJust leave ENABLE_ALPINE_PRIVATE_NETWORKING with value true.\n\n",
    name: "railway-docker-nginx-basic-auth",
    category: "Authentication",
    health: 67,
    code: "bYH8Xt",
    languages: ["Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f025f143-e69f-4d0f-b51c-d2016b8d3082",
    isApproved: false,
    activeProjects: 48,
    projects: 169,
    description: "The basic Astro template‚Äé ",
    readme:
      "Astro\n\nThis Project was created with - npm create astro@latest -- --template basics\n\nTo get more help on the Astro CLI use go check out the Astro CLI Overview and Command Reference page.\n\nüöÄ Project Structure\n\nInside of your Astro project, you'll see the following folders and files:\n\n/\n‚îú‚îÄ‚îÄ public/\n‚îÇ   ‚îî‚îÄ‚îÄ favicon.svg\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îú‚îÄ‚îÄ layouts/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Layout.astro\n‚îÇ   ‚îî‚îÄ‚îÄ pages/\n‚îÇ       ‚îî‚îÄ‚îÄ index.astro\n‚îî‚îÄ‚îÄ package.json\n\nTo learn more about the folder structure of an Astro project, refer to their guide on project structure.\n\nüßû Commands\n\nAll commands are run from the root of the project, from a terminal:\n\n| Command                   | Action                                           |\n| :------------------------ | :----------------------------------------------- |\n| npm install             | Installs dependencies                            |\n| npm run dev             | Starts local dev server at localhost:4321      |\n| npm run build           | Build your production site to ./dist/          |\n| npm run preview         | Preview your build locally, before deploying     |\n| npm run astro ...       | Run CLI commands like astro add, astro check |\n| npm run astro -- --help | Get help using the Astro CLI                     |\n\nüëÄ Want to learn more?\n\nFeel free to check our documentation or jump into our Discord server.\n",
    name: "Astro",
    category: "Starters",
    health: 88,
    code: "Ic0JBh",
    languages: ["Astro", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "334b2b99-b31f-4dba-b3d3-b39430db7d28",
    isApproved: false,
    activeProjects: 14,
    projects: 44,
    description: "Your private office anywhere you go!",
    readme:
      "\nONLYOFFICE Docs\n\nONLYOFFICE Docs is an online office suite comprising viewers and editors for texts, spreadsheets and presentations, fully compatible with Office Open XML formats: .docx, .xlsx, .pptx and enabling collaborative editing in real time.\n\nONLYOFFICE sample Page\n\nHighlights\n\nDocument Editor\nSpreadsheet Editor\nPresentation Editor\nMobile web viewers\nCollaborative editing\nHieroglyph support\nSupport for all the popular formats: DOC, DOCX, TXT, ODT, RTF, ODP, EPUB, ODS, XLS, XLSX, CSV, PPTX, HTML\n\nHow To Use\n\nAfter deploy, take note of both the JWT_SECRET that will be randomly generated and the URL that is generated for your server.\nIf not integrating with Nextcloud, please visit the ONLYOFFICE docs for more info.\nIf integrating with Nextcloud, first make sure to install the ONLYOFFICE app, then navigate to Administration Settings &gt; ONLYOFFICE\nEnter the URL from the railway service as the ONLYOFFICE Docs address\nEnter the JWT_SECRET and the Secret Key\nClick Save \nEnjoy ONLYOFFICE!\n\nLearn More\n\nONLYOFFICE website\nONLYOFFICE docs\nLICENSE\n\n\n",
    name: "ONLYOFFICE Document Server",
    category: "Other",
    health: 100,
    code: "3U_har",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "eedfc83d-9125-4c66-8530-5dd1a41c5ad6",
    isApproved: false,
    activeProjects: 31,
    projects: 87,
    description: "Zero dependencies - next gen - fully featured - very lightweight",
    readme:
      "TypeScript\n  Typed environment variables\nBun\n  Debugging\n  ESM & CommonJS compatibility\n  Fast package manager\n  Fast runtime\n  Fast test runner\n  Highly optimized APIs\n  Hot reloading\n  TypeScript first class support\nBiome\n  Fast formatting\n  Fast linting\n  Import sorting\nGitHub\n  One click template\n  Continuous Integration",
    name: "Bun TypeScript starter",
    category: "Starters",
    health: 100,
    code: "G3k1Tv",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ef6e3e44-2ae9-443c-b6c1-abb704bc8e3a",
    isApproved: false,
    activeProjects: 343,
    projects: 846,
    description: "Deploy your Minecraft Server",
    readme:
      "Minecraft Server for Java\n\nRailway is great for hosting your applications, but what if we tried to host a Minecraft Server? The benefits are incredible:\n\nYou only pay for what you use, so it's usually cheap\nNo more upgrading your server resources\nSuper stable\nRailway Support is the best\n\nHow do I connect to it?\n\nGo to settings in your Minecraft Server service \nScroll down until you see public networking section\nCopy the IP. \n\nYou're ready to go.\n\nHow I can configure it?\nAs we use the itzg/minecraft-server docker image, you can practically configure anything you want through environment variables.\n\nSee their docs for more info.\n\nLearn More\nMinecraft Server in Docker Docs",
    name: "Minecraft Server",
    category: "Other",
    health: 30,
    code: "BLEtpx",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "da83a76e-97f0-43c6-a342-e48a39293f48",
    isApproved: false,
    activeProjects: 11844,
    projects: 17572,
    description: "MongoDB  database service",
    readme:
      "Overview\n\nMongo database deployed with the official Docker image.\n\nStart Command\n\nThe Mongo container deployed from this template is started with the following command, to enable communication over IPv6 (required for Private Networking): docker-entrypoint.sh mongod --ipv6 --bind_ip ::,0.0.0.0\n\nHow to use\n\nReference the MONGO_URL variable to connect to MongoDB (e.g. ${{MongoDB.MONGO_URL}}) from another service in your project.\n\nConnecting externally\n\nConnect to the database from outside of Railway using the TCP Proxy.\n\nIn a terminal, for example:\n\nmongo mongodb://mongo:PASSWORD@TCP_PROXY_DOMAIN:TCP_PROXY_PORT",
    name: "MongoDB",
    category: "Storage",
    health: 96,
    code: "mongo",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b4edf8d7-87a1-437c-ae98-ea01df793867",
    isApproved: false,
    activeProjects: 16,
    projects: 26,
    description: "Single Instance Edge Browser Driver",
    readme:
      'Edge in Selenium Standalone Grid Mode\n\nStandalone Edge Example\n\nOverview\n\nStandalone grid mode combines all Selenium Grid components seamlessly into one. \n\nHighlights\n\nRunning a Grid in Standalone mode gives you a fully functional Grid with a single command, within a single process.\nRunning on Railway gives you the ability to have a public selenium grid URL in a matter of seconds.\nSSL/TLS encryption certificate by default\n\nHow To Use\nAfter deploying, just add the generated up.railway.app URL in your selenium tests as the remote web driver URL and you\'ll be testing in no time!\nRemoteWebDriver(new URL("https://CHANGEME.up.railway.app/")\n\nLearn More\n\nSelenium.dev website\nSelenium-docker github repo\nLICENSE\n\n\n',
    name: "Edge - Selenium Standalone Node",
    category: "Automation",
    health: null,
    code: "ycktxy",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a6068ce0-a289-4d76-91b1-472cda3ee8b3",
    isApproved: false,
    activeProjects: 26,
    projects: 74,
    description: "Chrome, Firefox and Edge connected by a Selenium Hub. Deployed with ease.",
    readme:
      'Selenium Grid with Chrome, Firefox and Edge\n\nStandalone Grid Example\n\nOverview\n\nSelenium Grid allows you to run tests in parallel with the execution of WebDriver scripts on remote machines by routing commands sent by the client to remote browser instances.\n\nHighlights\n\nRun all 3 major browsers with just a few clicks to be using the Selenium grid for your tests in minutes.\nRun your tests in parallel to speed up total testing time.\nRunning on Railway gives you the ability to have a public selenium grid URL in a matter of no time.\nSSL/TLS encryption certificate by default\n\nHow To Use\nAfter deploying, just add the generated up.railway.app URL in your selenium tests as the remote web driver URL and you\'ll be ready to test!\nRemoteWebDriver(new URL("https://CHANGEME.up.railway.app/")\n\nLearn More\n\nSelenium.dev website\nSelenium-docker github repo\nLICENSE\n\n\n',
    name: "Selenium Grid",
    category: "Automation",
    health: 100,
    code: "NG8OnB",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1cac3efb-9061-40d4-b90b-40d9017addf8",
    isApproved: false,
    activeProjects: 6430,
    projects: 10348,
    description: "Redis key-value data store",
    readme:
      "Overview\n\nRedis key-value store deployed with the bitnami/redis Docker image.\n\nHow to use\n\nReference the REDIS_URL variable to connect to Redis (e.g. ${{Redis.REDIS_URL}}) from another service in your project.\n\nConnecting externally\n\nConnect to the database from outside of Railway using the TCP Proxy.\n\nIn a terminal, for example:\n\nlogin\nredis-cli -h TCP_PROXY_DOMAIN -p TCP_PROXY_PORT\nauthenticate\nAUTH REDIS_PASSWORD\n\nData persistence\n\nBy default, data is persistence is configured with AOF disabled in favor of RDB snapshotting with the following schedule:\n\nsave 3600 1 \nsave 300 100 \nsave 60 10000\n\nRead more about persistence options in the Redis docs.\n\nReference the bitnami/redis environment variables for information on how to update your Redis service configuration.",
    name: "Redis",
    category: "Storage",
    health: 100,
    code: "redis",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "da106a2a-b086-486e-869f-1c0bfbf6dfc2",
    isApproved: false,
    activeProjects: 297,
    projects: 639,
    description: "Open-source vector similarity search for Postgres",
    readme:
      "Postgres with the pgvector extension installed. TCP proxying is configured to allow accessing the database from anywhere.\n\nHow to use\n\nReference the DATABASE_URL variable from your service to connect to the database in your tool of choice (e.g. ${{pgvector.DATABASE_URL}}\n\nConnecting\n\nYou can connect to your database using the proxied domain and port found on the service settings page. The password can be found on the Variables page.\n\nTesting\n\nOnce connected, test that pgvector is setup with the following SQL.\n\nCREATE EXTENSION vector;\nCREATE TABLE items (id bigserial PRIMARY KEY, embedding vector(3));\nINSERT INTO items (embedding) VALUES ('[1,2,3]'), ('[4,5,6]');\nSELECT * FROM items ORDER BY embedding &lt;-&gt; '[3,1,2]' LIMIT 5;",
    name: "pgvector",
    category: "Storage",
    health: 100,
    code: "3jJFCA",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "672d062a-37ef-4830-a46b-dee6e2191c38",
    isApproved: false,
    activeProjects: 64149,
    projects: 81790,
    description: "Deploy a MySQL database service",
    readme:
      "Overview\n\nMySQL database deployed with the official Docker image.\n\nStart Command\n\nThe MySQL container deployed from this template is started with the command below, to disable Async IO, binary logging, and server events, which helps to reduce usage and cost:\n\ndocker-entrypoint.sh mysqld --innodb-use-native-aio=0 --disable-log-bin --performance_schema=0\n\nHow to use\n\nReference the MYSQL_URL variable to connect to the MySQL database (e.g. ${{MySQL.MYSQL_URL}}) from another service in your project.\n\nConnecting externally\n\nConnect to the database from outside Railway using the TCP Proxy.\n\nIn a terminal, for example:\n\nmysql -h PROXY_DOMAIN -P PROXY_PORT -u root -p",
    name: "MySQL",
    category: "Storage",
    health: 100,
    code: "mysql",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b55da7dc-09be-4140-bc65-1284d15d349c",
    isApproved: false,
    activeProjects: 78886,
    projects: 110143,
    description: "PostgreSQL database service",
    readme:
      'Overview\n\nPostgreSQL database service, deployed with Railway\'s official SSL-enabled image.\n\nHow to use\n\nReference the DATABASE_URL variable to connect to Postgres (e.g. ${{Postgres.DATABASE_URL}}) from another service in your project.\n\nConnecting externally\n\nConnect to the database from outside of Railway using the TCP Proxy.\n\nIn a terminal, for example:\n\npsql "postgres://railway:PASSWORD@PROXY_DOMAIN:PROXY_PORT/railway"',
    name: "PostgreSQL",
    category: "Storage",
    health: 100,
    code: "postgres",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a57e955a-398a-41bc-ac91-ac00391b2508",
    isApproved: false,
    activeProjects: 8,
    projects: 10,
    description: "Remember, Grasshopper, coding is as much about problem-solving as ",
    readme:
      "Remember, Grasshopper, coding is as much about problem-solving as it is about writing code. Think of these errors as puzzles waiting to be solved, and with each puzzle, you become a more adept coder. Let's tackle this one together! Remember, Grasshopper, coding is as much about problem-solving as it is about writing code. Think of these errors as puzzles waiting to be solved, and with each puzzle, you become a more adept coder. Let's tackle this one together!",
    name: "KBZ",
    category: "Other",
    health: null,
    code: "tUSiyV",
    languages: [
      "Rust",
      "JavaScript",
      "SCSS",
      "HTML",
      "Python",
      "TypeScript",
      "CSS",
      "PLpgSQL",
      "Shell",
      "Smarty",
      "Dockerfile",
      "Ruby",
    ],
    tags: null,
  },
  {
    __typename: "Template",
    id: "121dd8e3-0d54-4ae7-8e4e-e913f141ce7c",
    isApproved: false,
    activeProjects: 25,
    projects: 48,
    description: "Single Instance Firefox Browser Driver",
    readme:
      'Firefox in Selenium Standalone Grid Mode\n\nStandalone Firefox Example\n\nOverview\n\nStandalone grid mode combines all Selenium Grid components seamlessly into one. \n\nHighlights\n\nRunning a Grid in Standalone mode gives you a fully functional Grid with a single command, within a single process.\nRunning on Railway gives you the ability to have a public selenium grid URL in a matter of seconds.\nSSL/TLS encryption certificate by default\n\nHow To Use\nAfter deploying, just add the generated up.railway.app URL in your selenium tests as the remote web driver URL and you\'ll be testing in no time!\nRemoteWebDriver(new URL("https://CHANGEME.up.railway.app/")\n\nLearn More\n\nSelenium.dev website\nSelenium-docker github repo\nLICENSE\n\n\n',
    name: "Firefox - Selenium Standalone Node",
    category: "Automation",
    health: 50,
    code: "imFV3Q",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "62b62bc9-fff6-4ea6-b954-f6559714428e",
    isApproved: true,
    activeProjects: 3933,
    projects: 7941,
    description: "Build advanced chatbots visually",
    readme:
      '\n    \n        \n    \n\n\nBuild advanced chatbots visually\n\nTypebot gives you powerful blocks to create unique chat experiences. Embed them anywhere on your web/mobile apps and start collecting results like magic\n\nNotes:\n\nMinIO is used in place of a 3rd party S3 storage provider, Using MinIO in this template allows you to upload media during the bot creation flow and have the bot send the uploaded media back to the users during a chat with the bot.\n\nThe "MinIO Bucket Creator" Is a service to create a public "typebot" bucket in the MinIO service, Typebot will use this bucket to upload media into, the bucket is set to public because your bot would need to be able to send the media to the users who are chatting with the bot. This Service only needs to run once, you may delete it after the logs of the service indicate that it was run successfully.\n\nUpon changing the Railway domain or adding your own custom domain to the service, you will need to redeploy both the "Viewer" and the "Builder" services, this is so that they are aware of the new domains in use.\n\nUsing Gmail as an SMTP host is known to not work on Railway services, this is not limited to Typebot deployments.\n\nUpdating Typebot is as easy as redeploying!\n\nIf you deployed this template before January 25th 2024 and want to access the MinIO console you would need to deploy this template into your existing project.\n\nOverview\n\nTypebot is an open-source chatbot builder. It allows you to create conversational apps/forms (Lead qualification, Customer support, Product launch, User onboarding, AI chats), deploy it on your website or WhatsApp number, and collect results in real-time.\n\nTypebot makes it easy to create advanced chatbots. It provides the building blocks that are adaptable to any business use case.\n\nFeatures\n\nChat builder with 34+ building blocks such as:\n\nüí¨ Bubbles: Text, Image / GIF, video, audio, embed.\nüî§ Inputs: Text, email, phone number, buttons, picture choice, date picker, payment (Stripe), file picker... inputs\nüß† Logic: Conditional branching, URL redirections, scripting (Javascript), A/B testing\nüîå Integrations: Webhook / HTTP requests, OpenAI, Google Sheets, Google Analytics, Meta Pixel, Zapier, Make.com, Chatwoot, More to come...\n\nTheme your chatbot to match your brand identity:\n\nüé® Customize the fonts, background, colors, roundness, shadows, and more\nüí™ Advanced theming with custom CSS.\nüíæ Reusable theme templates\n\nShare your typebot anywhere:\n\nüîó Custom domain\nüë®‚Äçüíª Embed as a container, popup, or chat bubble easily with the native JS library.\n‚ö° Blazing fast embed lib. No iframe, no external dependencies, no performance impact.\nüíª Executable with HTTP requests\n\nCollect your Results and get insights:\n\nüìä In-depth analytics with drop-off rates, completion rates, and more\nüì• Export results to CSV\n\nBuilt for developers:\n\nüîì No vendor-locking. Features built with flexibility in mind.\nüíª Easy-to-use APIs.',
    name: "Typebot",
    category: "Automation",
    health: 96,
    code: "typebot",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "721e7a7d-ce97-4d1e-bd94-2951e814e1ea",
    isApproved: false,
    activeProjects: 206,
    projects: 403,
    description: "Single Instance Chrome Browser Driver ",
    readme:
      'Chrome in Selenium Standalone Grid Mode\n\nStandalone Chrome Example\n\nOverview\n\nStandalone grid mode combines all Selenium Grid components seamlessly into one. \n\nHighlights\n\nRunning a Grid in Standalone mode gives you a fully functional Grid with a single command, within a single process.\nRunning on Railway gives you the ability to have a public selenium grid URL in a matter of seconds.\nSSL/TLS encryption certificate by default\n\nHow To Use\n\nAfter deploying, just add the generated up.railway.app URL in your selenium tests as the remote web driver URL and you\'ll be testing in no time!\nRemoteWebDriver(new URL("https://CHANGEME.up.railway.app/")\n\nLearn More\n\nSelenium.dev website\nSelenium-docker github repo\nLICENSE\n\n',
    name: "Chrome - Selenium Standalone Node",
    category: "Automation",
    health: 83,
    code: "XXPeWN",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "93f6feed-839b-4fa7-be1e-0d2b4a2cf742",
    isApproved: false,
    activeProjects: 19,
    projects: 76,
    description: "The open source CSV importer",
    readme:
      "What is Typebot?\nTableFlow is a powerful data management and visualization tool designed to streamline your data processing needs. Whether you're a business user, data analyst, or developer, TableFlow provides a user-friendly interface and robust backend services to simplify data organization, transformation, and visualization. This README will guide you through TableFlow's features, services, and how to get started.\n\nFeatures\nTableFlow offers a wide range of features to help you manage and work with your data effectively:\n\nAdmin UI: A user-friendly web-based administration interface to manage your data tables, users, and permissions.\nBackend Services: A powerful backend that handles data storage, retrieval, and processing.\nImporters: Built-in and customizable data importers to easily bring data into TableFlow.\nData Manipulation: Tools for data cleaning, transformation, and manipulation.\nVisualization: Create stunning visualizations to gain insights from your data.\nCollaboration: Share data tables and visualizations with team members.\nPermissions: Fine-grained access control to protect sensitive data.\nExport: Export data tables and visualizations in various formats.\nCustomization: Customize the appearance and behavior of your tables and visualizations.\nAutomation: Automate repetitive tasks using scripting and scheduling.\n\n‚ú® Services\n\nAdmin UI\nBackend\nImporter UI\n\nüíÅ‚Äç‚ôÄÔ∏è How to use\n\nClick the Railway button üëÜ\nAdd the required environment variables. \nDeploy.\nDeployment will take some time. Once scylla DB is deployed and running backend service should start.\nAccess the Admin UI by clicking on Railway's public URL. \nDashboard\nYou can create a new importer by clicking on the \"Create New\" button on the top right corner.\nimporter\nYou can add necessary infomration and add new columns to importer based on the data type you want to import.\ncolumn\nYou can view the created importer by clicking on the importer name .\nview\nOnce you save the importer, you can also modify the columns which you created.\nedit\nTable flow also giving example code block which you can add into your website to use the importer.\ncode\nTableflow importer gives feature to import data from CSV with example CSV file which you can download. if you want to preview the importer you can click on preview button.\npreview\nOnce you import the CSV file you can choose the header column and preview the data.\nimporter-header\nAfter previewing the data you can import the data into the tableflow.\ncomplete\nYou can view the imported data on data tab.\ndata\nThere are more features of managing data in tableflow which you can explore by yourself.\nEnjoy üéâ\nüìù Notes\n\nSource repo: https://github.com/tableflowhq/tableflow\nDocs: https://tableflow.com/docs/introduction",
    name: "Tableflow",
    category: "Other",
    health: 67,
    code: "Zj8toL",
    languages: ["Go", "TypeScript", "SCSS", "Dockerfile", "CSS", "JavaScript", "HTML", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e201afbc-615f-4958-ab80-3bbda0061fa4",
    isApproved: false,
    activeProjects: 38,
    projects: 107,
    description: "FastAPI Template for Large Projects",
    readme:
      "Heavyweight(FastAPI) Starter Template for Large Applications\n\nThis repository provides a robust template for creating powerful FastAPI applications that leverage Postgres and Alembic. Inspired by Radoslav Georgiev's Django Structure for Scale lecture and my own personal experience, this template offers a structured approach to building scalable web applications.\n\nProject Structure\n.vscode\nalembic/\napp/\n    common/\n        init.py\n        dependencies.py\n        paginators.py\n        regex.py\n        schemas.py\n        security.py\n        types.py\n    config/\n        init.py\n        database.py\n        settings.py\n    example_module/\n        init.py\n        apis.py\n        models.py\n        schemas.py\n        selectors.py\n        services.py\n    init.py\n    main.py\n.gitignore\nalembic.ini\ndocker-compose.yml\nDockerfile\nenv_sample.txt\nrailway.toml\nrequirements.txt\nstart.sh\n\nComponents\n\n.vscode: Configuration files for Visual Studio Code.\n\nalembic/: Contains Alembic settings and migrations.\n\nconfig/: Holds project settings.\ndatabase.py: Manages database connection, session settings, and the base database model.\nsettings.py: Utilizes pydantic_settings to load environment variables. Change the SECRET_KEY from the default value on Railway.\n\napp/: The main FastAPI project directory.\n  common/::\n    dependencies.py: The common dependencies used by all the modules\n    paginators.py: The collection of helpers for response pagination\n    regex.py: Where common regular expressions will be kept\n    schemas.py: Where you will keep your general/generic schemas\n    security.py: Where the authentication functions are kept\n    types.py: Where general/generic types are kept\n\n  config/: Holds project settings.\n    database.py: Manages database connection, session settings, and the base database model.\n    settings.py: Utilizes pydantic_settings to load environment variables. Change the SECRET_KEY from the default value on Railway.\n\n  example_module/:\n    An Example of how you might structure your different modules/apps, doing it this way makes it easy to decouple/seggregate\n    apis.py: Houses endpoints like user_create, user_login, and user_details.\n    models.py: Uses SQLAlchemy to draft the user table. Alembic handles migrations.\n    schemas.py: Defines schemas for create, details, login, and token requests.\n    selectors.py: Manages GET operations, fetching data from the database.\n    services.py: Handles POST, PUT, PATCH, and DELETE operations, manipulating database data.\n  main.py: Entry point of the application\n\n.gitignore: This specifies which folders/files to not push to github\nenv_sample.txt: Sample environment variable list. Create a .env file and provide values.\n\nGetting Started\n\nSetup Virtual Environment (If you are not using docker)\n   $ py -m venv .venv\n   $ .venv\\Scripts\\activate\n   NOTE: If you are using VsCode and you see a popup that says use env as workspace env then click yes\n\n\nInstall dependencies:\n   Locally\n\n   $ pip install -r requirements.txt\n\n    With Docker\n   \n   docker-compose up\n\n\nCreate a .env file and input environment variables.\n\n\nInitialize database tables:\n   alembic upgrade head\n\n\n\nStart the application in development mode:\n   fastapi dev\nIn production use:\nfastapi run\n\n\n\n\nTest the application by making requests to endpoints.\n\nContribute to the Project\n\nWe welcome contributions from the community to make this FastAPI Starter Template even better. If you have ideas for improvements, new features, or bug fixes, feel free to:\n\nFork the repository and create a new branch for your contribution.\nSubmit pull requests to propose changes to the project.\nEngage in discussions and share your thoughts on enhancements.\n\nBy contributing, you help make this template more valuable for developers building FastAPI applications. Together, we can create a robust foundation for large-scale projects. Thank you for your support!\n\nFor detailed information, refer to the following resources:\n\nFastAPI documentation: https://fastapi.tiangolo.com/\nAlembic documentation: https://alembic.sqlalchemy.org/en/latest/\nDjango Structure for Scale lecture: https://youtu.be/yG3ZdxBb1oo?si=D6A9dHyhKb_Kf-J7\n\nContact\n\nIf you have any questions or suggestions, feel free to reach out to me:\n(P.S I am looking for a job, i consult and i tutor :)\n\nName: Bello Shehu Ango\nEmail: angobello0@gmail.com\nGitHub: https://github.com/Grey-A\nLinkedin: https://linkedin.com/in/angobello0\nUpwork: https://www.upwork.com/freelancers/~01bb1007bf8311388a\nInstagram: https://www.instagram.com/bello_ango0/\n",
    name: "Heavyweight - FastAPI",
    category: "Starters",
    health: 67,
    code: "XJzuMz",
    languages: ["Python", "Mako", "Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2fcfbe04-6e45-4235-af39-44e15b3c3b42",
    isApproved: false,
    activeProjects: 39,
    projects: 161,
    description: "Virtual whiteboard for sketching hand-drawn like diagrams.",
    readme:
      "The Excalidraw editor supports:\n\nüíØ&nbsp;Free & open-source.\nüé®&nbsp;Infinite, canvas-based whiteboard.\n‚úçÔ∏è&nbsp;Hand-drawn like style.\nüåì&nbsp;Dark mode.\nüèóÔ∏è&nbsp;Customizable.\nüì∑&nbsp;Image support.\nüòÄ&nbsp;Shape libraries support.\nüëÖ&nbsp;Localization (i18n) support.\nüñºÔ∏è&nbsp;Export to PNG, SVG & clipboard.\nüíæ&nbsp;Open format - export drawings as an .excalidraw json file.\n‚öíÔ∏è&nbsp;Wide range of tools - rectangle, circle, diamond, arrow, line, free-draw, eraser...\n‚û°Ô∏è&nbsp;Arrow-binding & labeled arrows.\nüîô&nbsp;Undo / Redo.\nüîç&nbsp;Zoom and panning support.\n\nAt the moment, self-hosting your own instance doesn't support sharing or collaboration features.\n\nThis template deploys a client Excalidraw instance via Docker and automatically assigns a custom domain name.\n\nThe Docker image is free of analytics and other tracking libraries.",
    name: "Excalidraw",
    category: "Other",
    health: 100,
    code: "0K2GLW",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ea86a596-c13c-4ee9-805a-9d08dc8f4c42",
    isApproved: false,
    activeProjects: 9,
    projects: 43,
    description: "Quasar + Vue 3 | Vite | SCSS | Eslint | Pinia | Axios | Vue-i18n | Prettier",
    readme:
      "Quasar v2 - Starter App\n\nQuasar v2 | SPA | Vue 3 | Vite | SCSS | Eslint | Pinia | Axios | Vue-i18n | Prettier\n\nInstall the dependencies\n\nyarn\nor\nnpm install\n\nStart the app in development mode (hot-code reloading, error reporting, etc.)\n\nyarn dev\nor\nnpm run dev\n\nLint the files\n\nyarn lint\nor\nnpm run lint\n\nFormat the files\n\nyarn format\nor\nnpm run format\n\nBuild the app for production\n\nyarn build\nor\nnpm run build\n\nStart the app for production\n\nyarn start\nor\nnpm run start\n\nCustomize the configuration\n\nSee Configuring quasar.config.js.\n",
    name: "Quasar",
    category: "Starters",
    health: 0,
    code: "iyQgtj",
    languages: ["JavaScript", "Vue", "HTML", "SCSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d2beab78-1fb0-41ba-89c7-54f039d3f77f",
    isApproved: false,
    activeProjects: 40,
    projects: 105,
    description: "Reflex is an open-source framework for making web apps in pure Python",
    readme:
      "\n    \n        \n    \n\n\nWeb apps in pure Python, Built in a few minutes!\nBuild anything, faster\n\nCreate your whole app in a single language. Don't worry about writing APIs to connect your frontend and backend\n\nDeploy on Railway\n\nAny use case\n\nWith Reflex you can build anything from internal tools and data apps to complex multi-page apps\n\nIt's just Python\n\nThe app state is just a class. State updates are methods in the class. And the UI is a reflection of the state\n\nWrite your entire app in Python Frontend]\n\nNo more switching between languages and frameworks. Use one language for your whole stack\n\n60+ built-in UI Components\n\n    Reflex comes with a large library of UI components ranging from simple buttons to complex graphs and tables.\n\n    [Check out the full library\n\nCustom Components\n\n    Create your own components in a few lines of code. Simply wrap the React component of your choice.\n\n    Wrapping React Guide\n\nCompletely customizable\n\n    All Reflex components are fully customizable. Change the colors, fonts, and styles to match your project\n\n    Styling Guide\n\nNow everyone can work across the full-stack\n\n    With Reflex every engineer can work across the whole stack allowing for a more efficient and productive workflow\n\nSkip the boilerplate and get started faster Backend]\n\nReflex comes with a powerful backend built with FastAPI and SQLAlchemy\n\nBatteries included\n\n    Skip the boilerplate and get started faster. Reflex integrates the frontend and backend so there is no need to write API endpoints\n\n    [State docs\n\nSeamlessly integrate with any Python library\n\n    Never get locked into a framework that doesn't support your existing tech stack\n\nBuilt in database ORM\n\n    Integrate with existing databases with a single line of code. Or use our built in SQLite database\n\n    Database docs\n\nWhat makes this work on Railway?\n\nCustom build plan: nixpacks.toml\n\n    Runs all the necessary commands to setup, initialize, export, and install Caddy\n    Starts the Reflex backend and Caddy server using parallel to avoid having to run two separate services in the project\n\nThe Caddy Server/Proxy: Caddyfile\n\n    Serves the exported frontend Reflex app\n    Proxies all requests to /backend/* through to the Reflex backend server\n\nThe api_url variable: rxconfig.py\n\n    Makes sure the frontend build utilizes the correct backend api url",
    name: "Reflex",
    category: "Starters",
    health: 57,
    code: "A5TaaV",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "872735b0-f25a-4408-993c-4f0beb1f2714",
    isApproved: false,
    activeProjects: 19,
    projects: 62,
    description: "A free and open source personal finance manager",
    readme:
      "\nFirefly III\n\nFirefly III is a free and powerful open source personal finance manager\n\nFirefly III Sample Page\n\nHighlights\n\nFull transaction management: Firefly III features a double-entry bookkeeping system. You can quickly enter and organize your transactions in multiple currencies.\nAdvanced rule engine: Use rules to quickly convert shorthands to detailed transactions or clean up your bank's CSV files.\nImport data from any source: A special Data Importer helps you import data into your Firefly III administration.\n\nLearn More\n\nFirefly III website\nFirefly III docs\nLICENSE\n\n\n",
    name: "Firefly III",
    category: "Other",
    health: 100,
    code: "-7wtOV",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5f753305-2da3-4c20-8cd2-62bfbb9777c9",
    isApproved: false,
    activeProjects: 1289,
    projects: 2412,
    description: "Simple Langflow deployment using PostgreSQL as the database.",
    readme:
      "Langflow is a low-code tool that helps in the development and deployment of LLM apps.\n\nThis template is a simple setup that provides a persistent database with the use of PostgreSQL.\n\nEnvironment variables:\nLOGLEVEL: this is used to set the Langflow's logging level to improve debugging experience and to better control the logs.\n\nOther environment variables can be found in the Langflow repo. All Langflow variables should start with LANGFLOW_.\n\n\n\n",
    name: "Langflow 1.0",
    category: "AI/ML",
    health: 92,
    code: "JMXEWp",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "af3daa2f-4940-434e-a32d-45d1652155fa",
    isApproved: false,
    activeProjects: 1326,
    projects: 2714,
    description: "A complete setup for n8n with workers",
    readme:
      "Instantly create a n8n instance in queue mode with a worker. This allows for infinite horizontal scaling. Simply increase the number of replicas for the n8n worker instance, and n8n will distribute the work across them.\n\nYou can also setup webhook processors by configuring a load balancer.\n\nhttps://docs.n8n.io/hosting/scaling/queue-mode/#webhook-processors",
    name: "n8n with workers",
    category: "Automation",
    health: 96,
    code: "EfkjX2",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c025cde8-0a53-4aff-bbbe-58eed2a65e7f",
    isApproved: false,
    activeProjects: 57,
    projects: 109,
    description: "Express template with examples for middleware & separated routers",
    readme:
      'This expressjs template is a good starter for anyone. It comes pre-built with good examples for middleware, logging and code-splitting into multiple .js files using express\'s router object. Comes with thorough documentation in the form of comments that explains what everything in the app does. Have fun with this example and thanks for choosing mine!\n\nCheck out src/index.js for some good info about how to start out with express, then checkout src/routes/router_example.js to see how you can make your code neat and tidy by splitting it into multiple files.\n\nRoutes:\nGET "/": returns a nice welcome message\nGET "/json": returns json welcome message\nPOST "/post": returns a welcome message and any body you pass through the post request\nGET "/example/router": example nested router spawned in a separate file. Returns a help message.\n\nFiles:\nsrc contains the source code for the server\nsrc/routes contains the routes for the server\nsrc/routes/router_example.js contains examples pertaining to expressjs routers\n',
    name: "Simple ExpressJS Template",
    category: "Starters",
    health: 100,
    code: "Q4mMOs",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "19a08b62-59c1-4a34-b398-e423e4fd071b",
    isApproved: false,
    activeProjects: 8,
    projects: 30,
    description: "highly configurable solution for automated database backup and restore",
    readme:
      "\nFor Influx DB2:\nYour Organization will be mapped to DB_USER and your root token will need to be mapped to DB_PASS. You may use DB_NAME=ALL to backup the entire set of databases. For DB_HOST use syntax of http(s)://db-name\n\nScheduling Options\n| Parameter                | Description                                                                                                                                                                                        | Default                      |\n| ------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------- |\n| DB_DUMP_FREQ           | How often to do a dump, in minutes after the first backup. Defaults to 1440 minutes, or once per day.                                                                                              | 1440                       |\n| DB_DUMP_BEGIN          | What time to do the first dump. Defaults to immediate. Must be in one of two formats                                                                                                               |                              |\n|                          | Absolute HHMM, e.g. 2330 or 0415                                                                                                                                                               |                              |\n|                          | Relative +MM, i.e. how many minutes after starting the container, e.g. +0 (immediate), +10 (in 10 minutes), or +90 in an hour and a half                                                     |                              |\n| DB_DUMP_TARGET         | Directory where the database dumps are kept.                                                                                                                                                       | ${DB_DUMP_TARGET}/archive/ |\n| DB_DUMP_TARGET_ARCHIVE | Optional Directory where the database dumps archives are kept.                                                                                                                                     |                              |\n| DB_CLEANUP_TIME        | Value in minutes to delete old backups (only fired when dump freqency fires). 1440 would delete anything above 1 day old. You don't need to set this variable if you want to hold onto everything. | FALSE                      |\n| DB_ARCHIVE_TIME        | Value in minutes to move all files files older than (x) from DB_DUMP_TARGET to DB_DUMP_TARGET_ARCHIVE - which is useful when pairing against an external backup system.                        |                              |\n\nYou may need to wrap your DB_DUMP_BEGIN value in quotes for it to properly parse. There have been reports of backups that start with a 0 get converted into a different format which will not allow the timer to start at the correct time.\n\nBackup Options\n| Parameter                      | Description                                                                                                                  | Default                   | _FILE |\n| ------------------------------ | ---------------------------------------------------------------------------------------------------------------------------- | ------------------------- | ------- |\n| COMPRESSION                  | Use either Gzip GZ, Bzip2 BZ, XZip XZ, ZSTD ZSTD or none NONE                                                      | ZSTD                    |         |\n| COMPRESSION_LEVEL            | Numberical value of what level of compression to use, most allow 1 to 9 except for ZSTD which allows for 1 to 19 - | 3                       |         |\n| ENABLE_PARALLEL_COMPRESSION  | Use multiple cores when compressing backups TRUE or FALSE                                                                | TRUE                    |         |\n| PARALLEL_COMPRESSION_THREADS | Maximum amount of threads to use when compressing - Integer value e.g. 8                                                   | autodetected            |         |\n| GZ_RSYNCABLE                 | Use --rsyncable (gzip only) for faster rsync transfers and incremental backup deduplication. e.g. TRUE                   | FALSE                   |         |\n| ENABLE_CHECKSUM              | Generate either a MD5 or SHA1 in Directory, TRUE or FALSE                                                                | TRUE                    |         |\n| CHECKSUM                     | Either MD5 or SHA1                                                                                                       | MD5                     |         |\n| EXTRA_OPTS                   | If you need to pass extra arguments to the backup command, add them here e.g. --extra-command                              |                           |         |\n| MYSQL_MAX_ALLOWED_PACKET     | Max allowed packet if backing up MySQL / MariaDB                                                                             | 512M                    |         |\n| MYSQL_SINGLE_TRANSACTION     | Backup in a single transaction with MySQL / MariaDB                                                                          | TRUE                    |         |\n| MYSQL_STORED_PROCEDURES      | Backup stored procedures with MySQL / MariaDB                                                                                | TRUE                    |         |\n| MYSQL_ENABLE_TLS             | Enable TLS functionality for MySQL client                                                                                    | FALSE                   |         |\n| MYSQL_TLS_VERIFY             | (optional) If using TLS (by means of MYSQL_TLS_* variables) verify remote host                                               | FALSE                   |         |\n| MYSQL_TLS_VERSION            | What TLS v1.1 v1.2 v1.3 version to utilize                                                                             | TLSv1.1,TLSv1.2,TLSv1.3 |         |\n| MYSQL_TLS_CA_FILE            | Filename to load custom CA certificate for connecting via TLS                                                                | /etc/ssl/cert.pem       | x       |\n| MYSQL_TLS_CERT_FILE          | Filename to load client certificate for connecting via TLS                                                                   |                           | x       |\n| MYSQL_TLS_KEY_FILE           | Filename to load client key for connecting via TLS                                                                           |                           | x       |\n\nWhen using compression with MongoDB, only GZ compression is possible.\n\nBacking Up to S3 Compatible Services\n\nIf BACKUP_LOCATION = S3 then the following options are used.\n\n| Parameter             | Description                                                                               | Default | _FILE |\n| --------------------- | ----------------------------------------------------------------------------------------- | ------- | ------- |\n| S3_BUCKET           | S3 Bucket name e.g. mybucket                                                            |         | x       |\n| S3_KEY_ID           | S3 Key ID (Optional)                                                                      |         | x       |\n| S3_KEY_SECRET       | S3 Key Secret (Optional)                                                                  |         | x       |\n| S3_PATH             | S3 Pathname to save to (must NOT end in a trailing slash e.g. 'backup')                 |         | x       |\n| S3_REGION           | Define region in which bucket is defined. Example: ap-northeast-2                       |         | x       |\n| S3_HOST             | Hostname (and port) of S3-compatible service, e.g. minio:8080. Defaults to AWS.         |         | x       |\n| S3_PROTOCOL         | Protocol to connect to S3_HOST. Either http or https. Defaults to https.          | https | x       |\n| S3_EXTRA_OPTS       | Add any extra options to the end of the aws-cli process execution                       |         | x       |\n| S3_CERT_CA_FILE     | Map a volume and point to your custom CA Bundle for verification e.g. /certs/bundle.pem |         | x       |\n| OR                |                                                                                           |         |         |\n| S3_CERT_SKIP_VERIFY | Skip verifying self signed certificates when connecting                                   | TRUE  |         |\n\nWhen S3_KEY_ID and/or S3_KEY_SECRET is not set, will try to use IAM role assigned (if any) for uploading the backup files to S3 bucket.\n\nSee Full Config:\nhttps://github.com/JamesWRC/db-backup\n",
    name: "Database Backup + Restore",
    category: "Automation",
    health: 100,
    code: "IWPjnG",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5bf2af33-82a2-48fd-8123-b231392a9222",
    isApproved: false,
    activeProjects: 8,
    projects: 14,
    description: "A simple OCaml Dream starter app",
    readme:
      "Overview\n\nThis is a simple, bare-bones Dream app that serves an HTML page.\n\nDream is a tidy web framework written in OCaml. It offers a great starting point for anyone interested in writing OCaml for their next web application. With a great type system and feature-full set of APIs, you'll have a great time trying out Dream.\n\nLearn More\n\nDocumentation",
    name: "Dream",
    category: "Starters",
    health: null,
    code: "mxESzS",
    languages: ["Dockerfile", "OCaml", "Makefile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f53bb5f4-5087-457c-89c7-3b3d8d1ab349",
    isApproved: false,
    activeProjects: 30,
    projects: 49,
    description: "ModMail Discord Bot (Dragory)",
    readme:
      "How to deploy:\n1.) Fill in the required environment variable values\n\nHow to configure:\nSee https://github.com/Dragory/modmailbot/blob/master/docs/configuration.md#other-options\nhttps://github.com/Dragory/modmailbot/blob/master/docs/configuration.md#environment-variables\n\nHow to migrate existing data:\nIf you already have a modmailbot instance and you want to merge data here, simply upload your db/data.sqlite file so it can be directly downloaded via HTTP(S), discord's CDN works fine.\nAfterwards, insert the download URL on the MIGRATE_URL environment variable during setup.\nYour data file will be downloaded on first run.\n\nHow to update (bot):\nSimply go to your deployment and hit redeploy. That will pull from latest.\n\nHow to update (template):\nRailway should have a way to update it automatically (?)",
    name: "Discord ModMail Bot (Dragory's)",
    category: "Bots",
    health: null,
    code: "sEmr3k",
    languages: ["Dockerfile", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "acb9a5ee-59b5-4f29-94d4-e8d23cb4a9e7",
    isApproved: false,
    activeProjects: 26,
    projects: 68,
    description: "A high-performance NoSQL database system",
    readme:
      "ScyllaDB Version 5.1.4\n\nScyllaDB is a high-performance NoSQL database system, fully compatible with Apache Cassandra. ScyllaDB is released under the GNU Affero General Public License version 3 and the Apache License, ScyllaDB is free and open-source software.\n\nThis template is specifically made for ScyllaDB Version 5.1.4, because later version has an issue with IPv6 support, use ScyllaDB template instead if you need new version of ScyllaDB.\n\nFeatures\nScyllaDB out-of-the-box\n\nUsage\nAdd a project as new service\nEdit a service's configuration to point to scylla's private domain (or scylla's railway public domain). You can find these value from these special variables (Can be found on ScyllaDB service -> Variables tab):\n     $SCYLLA_HOST\n     $SCYLLA_PORT\n     $SCYLLA_PRIVATE_HOST\n     $SCYLLA_PRIVATE_PORT\nYour service(s) should now be connected to the ScyllaDB\n\nKnown Issues\nIf your service(s) can't connect to scylla using its private network domain, try shorten the domain. For example my ScyllaDB service use scylladb.railway.internal private domain, instead of using the full scylladb.railway.internal you remove the .railway.internal suffix so it just says scylladb.\n\nEnvironment Variables\nMEM: Memory limit, default: 2G\nSMP: Restricts ScyllaDB to N logical cores, default: 2\nLISTEN_ADDR: ScyllaDB's listen address, default: :: (You can set this to 0.0.0.0 for IPv4 support)\nAPI_ADDR: ScyllaDB's Rest API address, default: :: (You can set this to 0.0.0.0 for IPv4 support)\n\nSpecial Environment Variables\nSCYLLA_HOST: You can use this variable's value to connect your software to ScyllaDB. You can also use it to connect to ScyllaDB from you favorite DB (Cassandra-compatible) client\nSCYLLA_PORT: You can use this variable's value to connect your software to ScyllaDB. You can also use it to connect to ScyllaDB from you favorite DB (Cassandra-compatible) client\nSCYLLA_PRIVATE_HOST: You can use this variable's value to connect your software to ScyllaDB (Through Railway's Private Network, requires IPv6)\nSCYLLA_PRIVATE_PORT: You can use this variable's value to connect your software to ScyllaDB (Through Railway's Private Network, requires IPv6)\n\nLearn More\nBest Practices for Running ScyllaDB on Docker",
    name: "ScyllaDB 5.1.4",
    category: "Storage",
    health: 100,
    code: "6RHNrS",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "77ecfdd0-fce7-433d-81d3-5b0e8677a5cb",
    isApproved: false,
    activeProjects: 8,
    projects: 9,
    description: "Show the current status of the Apex Legends login/matchmaking servers!",
    readme:
      'Setup\n\nGo to the Discord Developer Portal and set up a new bot. Grab the token and add it to the "DISCORD_TOKEN" environment variable\nGo to the "Generate URL" section in the "OAuth2" category and generate the necessary permissions. You can set it to Administrator (not advised), or invite the bot with the following permissions:\nRead Messages/View Channel\nSend Messages\nManage Channels (for the server status in the channel name)\nUse External Emojis\nGo to the Apex Legends API Website and generate an API key. Copy the key and add it to the "ALS_API" environment variable\nGo to your Discord server and create a new channel for the bot to use and store the message. Copy the Server ID and Channel ID into the "SERVER_ID" and "CHANNEL_ID" environment variables respectively.\n The "MESSAGE_ID" field should default to 0. We\'ll come back to that\nMake sure the "DEBUG" environment variable is set to false and the "ENABLED" environment variable is set to TRUE\nDeploy the bot and wait for it to come online. Once it\'s online, go into the channel you setup and run the "/template" command\nIf the command was successful, you should get a template embed. Copy the ID of the message and insert it into the "MESSAGE_ID" environment variable and redeploy the bot\n???\nProfit',
    name: "Apex Legends Server Status Discord Bot",
    category: "Other",
    health: null,
    code: "TxkIsO",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "02c00f82-4632-49cd-ad42-cbeabd76bf83",
    isApproved: false,
    activeProjects: 79,
    projects: 396,
    description: "Build the tools you can‚Äôt buy off the shelf",
    readme:
      "\n\n  \n\n\n\nOrganizations build internal applications such as dashboards, database GUIs, admin panels, approval apps, customer support dashboards, and more to help their teams perform day-to-day operations. Appsmith is an open-source tool that enables the rapid development of these internal apps. Read more on their website.\n\nWhat is Appsmith\n\nOrganizations build internal applications (also known as admin tools or internal tools) such as dashboards, database GUIs, admin panels, approval apps, customer support tools, and more to help their teams perform specific tasks. Appsmith is an open source developer tool that helps the rapid creation of such internal tools.\n\nYou can drag and drop pre-built widgets to build UI on a grid-style canvas. Appsmith simplifies front-end and back-end integration between the UI and the datasource to optimize building applications. It also supports JavaScript inside widgets, queries, and almost any other component to add logic, transform data, and define complex workflows.\n\nWhy Appsmith\n\nAppsmith makes it easy to build a UI that talks to any datasource. You can create anything from simple CRUD apps to complicated multi-step workflows with the simple steps below:\n\nConnect Datasource: Integrate with a datasource such as a database or an API. Appsmith has plug-and-play support for many databases and the RESTful API interface to connect with most tools seamlessly.\nBuild UI: Use customizable built-in widgets to build an app layout.\n\nAccess Data: Connect UI to the datasource by writing queries and binding the data to widgets. Control everything with JavaScript.\n\nCollaborate, Deploy, Share: Appsmith supports version control using Git to build apps in collaboration using branches to track and roll back changes. Deploy the app and share it with other users.\n\nLearning Resources\nDocumentation\nTutorials\nVideos\nTemplates\n\nNeed Help?\nDiscord\nCommunity Portal\nsupport@appsmith.com",
    name: "Appsmith",
    category: "Other",
    health: 89,
    code: "8cHdPG",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f9015eb0-c05b-449e-90fe-3dd45b7c813f",
    isApproved: false,
    activeProjects: 224,
    projects: 552,
    description: "An open source surveys & experience management solution",
    readme:
      "\n\n    \n  \n\nThe Open Source Survey &amp; Experience Management solution for fast growing companies\n\n\nNOTE:\n\nCommunication to Postgres is done exclusively over the private network and the database is not exposed externally in any way by default, This is done so that there are no egress fees for the database, if you want to enable access from outside of the private network you can go to the databases settings page to enable TCP proxying and enter the internal port 5432. The TCP proxy can be again removed at any point to close off external access.\n\n‚ú® About Formbricks\n\n\n\nFormbricks is your go-to solution for in-product micro-surveys that will supercharge your product experience. Use micro-surveys to target the right users at the right time without making surveys annoying.\n\nüí™ Mission: Make customer-centric decisions based on data.\n\nFormbricks helps you apply best practices from data-driven work and experience management to make better business decisions. Ask users as they experience your product - and leverage a significantly higher conversion rate. Gather all insights you can - including partial submissions and build conviction for the next product decision. Better data, better business.\n\nFeatures\n\nüì≤ Create in-product surveys with our no code editor with multiple question types\nüìö Choose from a variety of best-practice templates\nüë©üèª Launch and target your surveys to specific user groups without changing your application code\nüîó Create shareable link surveys\nüë®‚Äçüë©‚Äçüë¶ Invite your team members to collaborate on your surveys\nüîå Integrate Formbricks with Slack, Posthog, Zapier and more\nüîí All open source, transparent and self-hostable\n\nBuilt on Open Source\n\nüíª Typescript\nüöÄ Next.js\n‚öõÔ∏è React\nüé® TailwindCSS\nüìö Prisma\nüîí Auth.js\nüßò‚Äç‚ôÇÔ∏è Zod",
    name: "Formbricks",
    category: "Analytics",
    health: 88,
    code: "PPDzCd",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c3c15c4c-2fc0-410d-932c-f0bc5c6d1d4c",
    isApproved: false,
    activeProjects: 39,
    projects: 66,
    description: "Hosted IPFS Gateway & HTTP Proxy",
    readme:
      "Hosted IPFS Gateway & HTTP Proxy\n\nUses\n\nipfs/kubo\nbifrost-gateway\nbun\n\nPurpose\n\nOvercome public IPFS gateway limitations, such as 429 Too Many Requests, by hosting your own IPFS Gateway and HTTP Proxy.\n\n429 Example\n\nUsage\n\ngit clone https://github.com/o-az/eyepfs.git\n\nBuild Dockerfile:\n\ndocker buildx build . \\\n  --progress 'plain' \\\n  --file 'Dockerfile' \\\n  --tag 'ipfs_gateway_proxy'\n\nor bun docker:build\n\nRun the image you just built:\n\ndocker run --rm -it \\\n  --name 'my_ipfs_gateway_proxy' \\\n  --env IPFS_GATEWAY_HOST=\"http://127.0.0.1:8081\" \\\n  --publish '3031:3031' \\\n  'ipfs_gateway_proxy'\n\nor bun docker:run\n\nGive it a nice few seconds then smoke test (fetch image):\n\ncurl --location --request GET \\\n  --url 'http://127.0.0.1:3031/bafybeigdyrzt5sfp7udm7hu76uh7y26nf3efuylqabf3oclgtqy55fbzdi' \\\n  --output 'image.jpeg'\n\nDeployment\n\nanywhere that can run a Dockerfile üê≥\n\nRailway.app happens to be the best option\n\nDeploy on Railway\n",
    name: "IPFS Gateway & HTTP Proxy",
    category: "Other",
    health: 100,
    code: "PhPjgz",
    languages: ["Shell", "TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b0c752df-3f90-47d7-86a6-80bb531e5fab",
    isApproved: false,
    activeProjects: 161,
    projects: 391,
    description: "The web development framework for building the future",
    readme:
      "Angular + TypeScript + Caddy\n\nThis project was originally generated with ng new my-app\n\n‚ú® Features\n\nAngular 18 + TypeScript + Caddy\nCaddy v2\n\nüíÅ‚Äç‚ôÄÔ∏è Local Development\n\nInstall required dependencies with npm install\nRun npm run dev for a dev server\nNavigate to http://127.0.0.1:4200/. The application will automatically reload if you change any of the source files.\n\nTo get more help on the Angular CLI use ng help or go check out the Angular CLI Overview and Command Reference page.\n\n‚ùì Why use Caddy when deploying to Railway?\n\nCaddy is a powerful, enterprise-ready, open source web server, and therefore Caddy is far better suited to serve websites than ng serve is, using Caddy will result in much less memory and cpu usage compared to serving with ng serve (much lower running costs too)\n\nTo see how this is achieved with nixpacks, check out the fully documented nixpacks.toml file in this repository\n\nThe configuration for Caddy is called a Caddyfile, and you can edit that file to further suite your needs, by default it comes configured to serve a single page app for Angular, and to also gzip the responses\n\nRelevant Caddy documentation:\n\nThe Caddyfile\nCaddyfile Directives\nroot\nencode\nfile_server\ntry_files",
    name: "Angular 18 Static",
    category: "Starters",
    health: 94,
    code: "13NBfA",
    languages: ["HTML", "TypeScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "23df7683-e8c4-482f-8774-85db0971ac5f",
    isApproved: false,
    activeProjects: 94,
    projects: 256,
    description: "Get started developing with Vue and Vite today!",
    readme:
      "Vue 3 + TypeScript + Vite + Caddy\n\nThis template should help get you started developing with Vue and TypeScript in Vite. The template uses Vue 3 With TypeScript.\n\n‚ú® Features\n\nVue 3 + TypeScript + Vite + Caddy\nCaddy v2\n\nüíÅ‚Äç‚ôÄÔ∏è Local Development\n\nInstall required dependencies with npm install\nStart the server for local development npm run dev\nNavigate to `http://localhost:5173/. The application will automatically reload if you change any of the source files.\n\n‚ùì Why use Caddy when deploying to Railway?\n\nCaddy is a powerful, enterprise-ready, open source web server, and therefore Caddy is far better suited to serve websites than Vite is, using Caddy will result in much less memory and cpu usage compared to serving with Vite (much lower running costs too)\n\nTo see how this is achieved with nixpacks, check out the fully documented nixpacks.toml file in this repository\n\nThe configuration for Caddy is called a Caddyfile, and you can edit that file to further suite your needs, by default it comes configured to serve a single page app for Vue 3, and to also gzip the responses\n\nRelevant Caddy documentation:\n\nThe Caddyfile\nCaddyfile Directives\nroot\nencode\nfile_server\ntry_files",
    name: "Vue 3",
    category: "Starters",
    health: 100,
    code: "Qh0OAU",
    languages: ["Vue", "CSS", "HTML", "TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d7fa0277-b673-46ac-8e62-5eafb2b45abe",
    isApproved: false,
    activeProjects: 11,
    projects: 45,
    description: "Feature Flags and Remote Config",
    readme:
      "Flagsmith lets you manage features across web, mobile and server side applications. Release features with confidence; manage feature flags across web, mobile, and server side applications. \n\nFlagsmith provides an all-in-one platform for developing, implementing, and managing your feature flags. Whether you are moving off an in-house solution or using toggles for the first time, you will be amazed by the power and efficiency gained by using Flagsmith.",
    name: "Flagsmith",
    category: "Other",
    health: 90,
    code: "36mGw8",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6781e60b-11e3-4d03-aba6-406c0ec4e2f9",
    isApproved: false,
    activeProjects: 52,
    projects: 149,
    description: "Railway Cron.. But Better?",
    readme:
      'Railway Cron.. But Better?\n\nThis Service will help you restart (or redeploy) your selected service on a Cron schedule, this differs from the native Cron feature in two ways:\n\nThe restart action: Can trigger a service restart, instead of re-running the image in a new deployment.\n\nThe redeploy action: Will trigger a full redeploy and replace any existing deployments. The native cron feature will wait until the deployment is in a "COMPLETED" state to run the next deployment.\n\nBoth these actions are equivalent to clicking the restart / redeploy options in the deployments 3-Dot menu but on the desired Cron schedule.\n\nCaveats: Since this template uses one token for all the Railway API calls made, the token provided would need to have access to all the projects in the defined schedules.\neg, If you use a token for team \'A\' all the projects in the schedules would need to be within team \'A\'.\n\nIf you used a personal account token, all the projects in the schedules would need to be under your personal account.\n\nIt doesn\'t matter if you deploy this template to the team or personal account, as long as you provide the correct token.\n\nHow to Setup\n\nGet at least one Cron schedule prepared\n\n    This is made easy with a bookmarklet. The pre-made bookmarklet that will help construct our schedule can be added to your bookmark bar via this website\n\n    Once the bookmarklet has been added to your bookmark bar, open your Railway project and desired service, and click the bookmarklet, a popup will ask you to input your Cron expression and action type, then you will be forwarded to a page that contains your schedule config, copy this long string and save it somewhere for later use.\n\n        Field name   | Mandatory? | Allowed values  | Allowed special characters\n        ----------   | ---------- | --------------  | --------------------------\n        Minutes      | Yes        | 0-59            | * / , -\n        Hours        | Yes        | 0-23            | * / , -\n        Day of month | Yes        | 1-31            | * / , - ?\n        Month        | Yes        | 1-12 or JAN-DEC | * / , -\n        Day of week  | Yes        | 0-6 or SUN-SAT  | * / , - ?\n    \n        Examples of some Cron Expressions can be found in the Railway documentation\n\nGenerate a Railway Account Token\n\n    Go to the Tokens page in your Railway Account, click the name field, and provide an accurate name for what the token will be used for, A name like "Cron Schedular" would suffice, Click "Create", then save this token for later use.\n    \n        Note: This must be an Account Token, a project Token will not work\n\nDeploy this template\n\n    Input the schedule configuration string into the SCHEDULE_1 variable.\n\n        More schedules can be added later by using the bookmarklet and by adding the resulting schedule configuration string to a SCHEDULE_2\n variable, and so on.\n\n    Input your Account Token into the RAILWAY_ACCOUNT_TOKEN variable.\n\n    Click "Deploy"\n\n    You will now be able to monitor the Cron Job\'s Progress in the newly deployed template\'s deployment logs',
    name: "Railway Cron",
    category: "Other",
    health: 100,
    code: "fwH-l3",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "165260fe-b6c9-443e-bc99-569985d3b5d9",
    isApproved: false,
    activeProjects: 75,
    projects: 217,
    description: "A Kafka template on Railway.",
    readme:
      'Kafka Deployment on Railway\n\nThis template facilitates the deployment of an instance of Apache Kafka in conjunction with Apache ZooKeeper on Railway.app. It includes examples illustrating Kafka\'s consumer and producer capabilities implemented in NodeJS.\n\nFeatures\n\nKafka and ZooKeeper Integration\nNodeJS Consumer Example (/consumer) (source)\nNodeJS Producer Example (/producer) (source)\n\nUsage\n\nClick the "Deploy on Railway" button above.\nConfigure Kafka and ZooKeeper according to your specific requirements within the designated directories.\nInput the necessary environment variables and establish authentication parameters as needed.\nDeploy the template to initiate your Kafka and ZooKeeper instance.\n\nResources\n\nKafka Official Documentation\nZooKeeper Official Documentation\nKafka Source Code\nZooKeeper Source Code\nNodeJS Consumer & Producer Samples\n',
    name: "Kafka",
    category: "Queues",
    health: 84,
    code: "K5vWpm",
    languages: ["JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "673997a7-8bba-4cd4-bfb5-3b006943e8c6",
    isApproved: false,
    activeProjects: 5,
    projects: 9,
    description: "Connect CEX and DEX exchanges across multi messaging platforms.",
    readme:
      "\n\n\n\n\n\nConnect CEX and DEX exchanges across multi messaging platforms.\nPlace order, inquire your balance and more through plugins.\nEasily deploy via Docker on self-hosted platform or Paas.\n\n\n\n\n\n\n   \n   \n\nDocumentation\n\n\n\n\n\n",
    name: "TalkyTrader Demo",
    category: "Other",
    health: null,
    code: "ZVM0QG",
    languages: ["Python", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6d509f5e-7435-45e7-bce3-4dc83bb96be9",
    isApproved: false,
    activeProjects: 57,
    projects: 86,
    description: "GPT-4 chatbot with context",
    readme:
      "Chat-GPT Discord bot starter\n\nThis is a stater Discord bot that keeps user context in a Postgres database and interacts with OpenAI API.\n\nDeploy on Railway\n\n‚ú® Features\n\nPython\nPy-cord\nOpenAI\nPostgreSQL\n\nü§∑ How to use\n\nInstall Python requirements pip install -r requirements.txt\nSet your DISCORD_TOKEN and OPENAI_API_KEY variables\n\n\n\n\n\n\n\n",
    name: "Chat-GPT Discord bot",
    category: "Bots",
    health: 75,
    code: "1cSU5t",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b3ee7d22-b7da-4c8c-98c2-badb2c8d3292",
    isApproved: false,
    activeProjects: 23,
    projects: 30,
    description: "This Template allow you to deploy weChat robot simply. Default use link ai.",
    readme:
      "This template allows you to deploy a weChat robot simply, \nDefault use link ai. You can register at https://chat.link-ai.tech. And you can add var override the default value. You can find all var and description in file config.py.And you can find open source at GitHub https://github.com/jeady5/chatgpt-on-wechat or Gitee https://gitee.com/jeady5/chatgpt-on-wechat.",
    name: "chatgpt-on-wechat-freely",
    category: "Other",
    health: null,
    code: "Fct8Sl",
    languages: ["Python", "Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c1e24d4c-7f00-4f0d-8000-91115855db85",
    isApproved: false,
    activeProjects: 58,
    projects: 150,
    description: "Powerful and Extensible Open Source Wiki Software",
    readme:
      "\nOverview\n\nThe most powerful and extensible open source Wiki software. Make documentation a joy to write using Wiki.js's beautiful and intuitive interface!\n\nWiki.js Sample Page\n\nHighlights\n\nBeginner and Advanced Users Welcome: Use your choice of editor including AsciiDoc, HTML, Markdown and a Visual Editor based on CKEditor\nAdministration: Manage all aspects of your wiki using the extensive and intuitive admin area.\nVersion Tracking: All content modifications are tracked. You can revert to a previous state or recover a deleted page at any time.&nbsp;\nAsset Manager: Upload and manage your media assets from the Assets Manager. Easily categorize your assets in folders and see where they are used.\n\nLearn More\n\nWiki.js website\nWiki.js docs\nLICENSE\n\n\n",
    name: "Wiki.js",
    category: "CMS",
    health: 81,
    code: "1ASvMI",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "738b8eee-84a7-4ce6-ab5f-1cb23009fc85",
    isApproved: false,
    activeProjects: 2,
    projects: 9,
    description: "The Vonage Video Learning Server",
    readme:
      "A sample server app shows you how to use Vonage Video Node Server SDK to create OpenTok sessions, generate tokens for those sessions, archive (or record) sessions, and download those archives. This backend server can be used to kick-start your own projects or use alongside our existing demos.",
    name: "vonage-video-learning-server",
    category: "Other",
    health: null,
    code: "GHmSB0",
    languages: ["JavaScript", "Pug", "CSS", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5cb39920-c52c-426d-afc5-c359e1389201",
    isApproved: false,
    activeProjects: 14,
    projects: 54,
    description: "A simple script to automatically back up multiple databases to S3.",
    readme:
      '\nDatabase S3 backups\nThis script provides a simple all-in-one automated way to back up your databases to AWS S3.\n\nSupported databases:\npostgres\nmysql\nmongodb\n\nFeatures\nDefine multiple databases of different types in your configuration, and the script will automatically handle the backup process for all of them in one execution.\nBackups can be initiated either upon the script execution or on a scheduled basis using a cron job. \nBackups are compressed to reduce file size.\n\nHow it works \nDefine database connection URI strings for each database you want backed up and the backup schedule \nThe script will connect to the database(s) and do a dump\nThe dump is compressed and uploaded to your defined AWS S3 Bucket\nFinally, the dumps are cleaned up on the local file system\n\nConfiguration\nCreate a .env file in the root directory with the following variables:\n\nRUN_ON_STARTUP=true\nCRON=0 0 * * *\nAWS_ACCESS_KEY_ID=\nAWS_SECRET_ACCESS_KEY=\nAWS_S3_BUCKET=\nAWS_S3_REGION=\nAWS_S3_ENDPOINT=\nDATABASES="mysql://user:password@host:port/database,postgresql://user:password@host:port/database,mongodb://user:password@host:port"\n\nEnvironment variables\n\n| Key                     | Description              | Optional | Default Value |\n|-------------------------|--------------------------|----------|---------------|\n| DATABASES             | Comma-separated connection strings list of database URIs that should be backed up. | No | ]|\n| RUN_ON_STARTUP        | Boolean value that indicates if the script should run immediately on startup. | Yes | false |\n| CRON                  | Cron expression for scheduling when the backup job will run for all databases. See [Crontab.guru for help setting up schedules. | Yes | |\n| AWS_ACCESS_KEY_ID     | AWS access key ID. | No | |\n| AWS_SECRET_ACCESS_KEY | AWS secret access key. | No | |\n| AWS_S3_BUCKET         | Name of the S3 bucket. | No | |\n| AWS_S3_REGION         | Region of the S3 bucket. | No | |\n| AWS_S3_ENDPOINT       | Endpoint for the S3 service. | No | |',
    name: "Database S3 backups",
    category: "Automation",
    health: 100,
    code: "U_wjYd",
    languages: ["JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3ecfee56-5470-4734-a3f9-5e2400415ff3",
    isApproved: false,
    activeProjects: 73,
    projects: 90,
    description: "The Inworld integration token generation project",
    readme:
      "The Inworld integration token generator project.\n\nConnect your Inworld characters with our SDK Platforms. This project contains a server that uses the Inworld API Key, Inworld API Secret and an Inworld Scene ID to generate an authorization token to access Inworld integrations.\n\nAn Inworld account is required: https://inworld.ai/\n\n",
    name: "Inworld Token Generator",
    category: "Other",
    health: 80,
    code: "FIgbO1",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "50645a4f-0287-4a9f-b2bc-a58509fff533",
    isApproved: false,
    activeProjects: 1,
    projects: 8,
    description: "Backup your PostgreSQL database into a S3 bucket using Railway CRON",
    readme:
      "Overview\n\nSimple template to backup in one time your PostgreSQL database using the Railway CRON feature. The code is a basic script to dump your PostgreSQL data to a file and then upload the file to S3.\n\nHighlights\n\nRuns one time, so the cost is really low\nUse the Railway CRON feature to schedule the backup\nConfigure custom S3 URL\n\nUsage\n\nFill the template environment variables and configure the CRON job in the service settings.",
    name: "One Time PostgreSQL S3 Backup",
    category: "Storage",
    health: 100,
    code: "UGKaB8",
    languages: ["TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7978b293-01f9-43f7-a69a-8b748a06c469",
    isApproved: false,
    activeProjects: 2,
    projects: 22,
    description: "Realtime distributed messaging platform.",
    readme:
      'üéì What is NSQ?\nNSQ is a realtime distributed messaging platform.\n\nFeatures\nsupport distributed topologies with no SPOF\nhorizontally scalable (no brokers, seamlessly add more nodes to the cluster)\nlow-latency push based message delivery (performance)\ncombination load-balanced and multicast style message routing\nexcel at both streaming (high-throughput) and job oriented (low-throughput) workloads\nprimarily in-memory (beyond a high-water mark messages are transparently kept on disk)\nruntime discovery service for consumers to find producers (nsqlookupd)\ntransport layer security (TLS)\ndata format agnostic\nfew dependencies (easy to deploy) and a sane, bounded, default configuration\nsimple TCP protocol supporting client libraries in any language\nHTTP interface for stats, admin actions, and producers (no client library needed to publish)\nintegrates with statsd for realtime instrumentation\nrobust cluster administration interface (nsqadmin)\n\n‚ú® Services\n\nNSQ\nNSQ Admin\nNSQ Lookupd\nNGINX\n\nüíÅ‚Äç‚ôÄÔ∏è How to use\n\nClick the Railway button üëÜ\nAdd the required environment variables\nDeploy\nTo Access NSQ Admin visit the URL from railway deployment for Nsqadmin service\ndashboard\nNSQ Admin Dashboard\n    NSQ Admin is a web UI to view aggregated cluster stats in realtime and perform various administrative tasks.\n    It can be used to view the state of the cluster, show metadata for topics and channels, show the message backlog for channels, force re-queued messages to be sent to clients, and show client connections.\n    To view the list of streams, click on streams\n    streams\n    It shows list of NSQd nodes and their status\n    By Clicking on any node, it shows the list of topics and channels\n    topic\n    To view list of producers, click on Nodes\n    nodes\n    NSQAdmin also provides feature to create new topic and channels in Lookup tab\n    You can also manage any topic and channel, by click on topic or channel name\n    topic\n    NSQ has more features like TLS, Authorization, etc. which can be configured in config files\nNSQ Client Libraries\n    There are many officially support client libraries for NSQ. You can check the list here: https://nsq.io/clients/client_libraries.html\n    In this Repository under examples/ folder there are python and node example files to demostrate and how to use NSQ queue system as beginner.\n    Known Issue: NSQ Subscription only works via TCP and HTTP, and currently Railway doesn\'t support TCP/HTTP exposure publicly but it will still work when you deploy a service internally within a project and access it.\n    You can perform basic operation like all CRUD using CURL or any tool to interact with HTTP protocol like POSTMAN.\n    To create a new topic\n        curl -X POSThttps://.up.railway.app/topic/create?topic=name \n    To create a new channel\n        curl -X POST https://.up.railway.app/channel/create?topic=name&amp;channel=name\n    To Get list of Topic or Channels\n        curl -X GET https://.up.railway.app/topics\n        curl -X GET https://.up.railway.app/channels?topic=name\n    To publish a message\n        curl -d "test message" https://.up.railway.app/pub?topic=name\n    There are more operations which can be performed using HTTP protocol, you can check the list here: https://nsq.io/components/nsqd.html#http-api\nEnjoy!\n\nüìù Notes\n\nSource repo: https://github.com/nsqio/nsq\nDocs: https://nsq.io/overview/design.html',
    name: "NSQ",
    category: "Queues",
    health: null,
    code: "okc9Wi",
    languages: ["Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f1db90ba-aa59-4d2e-baa3-19513ed8cb1a",
    isApproved: false,
    activeProjects: 37,
    projects: 198,
    description: "Open source durable execution platform",
    readme:
      "\nTemporal\nLooking to manage the dynamic configuration of Temporal? Check out the Starter Package to see how to configure it.\n\nTemporal is a microservice orchestration platform which enables developers to build scalable applications without sacrificing productivity or reliability. Temporal server executes units of application logic, Workflows, in a resilient manner that automatically handles intermittent failures, and retries failed operations.\n\nTemporal is a mature technology, a fork of Uber's Cadence. Temporal is being developed by Temporal Technologies, a startup by the creators of Cadence.\n\nLearn more about Temporal at https://docs.temporal.io/.\n\nSourced from Temporal's README.\n\nHighlights\n\nTemporal (one click deploy)\nHello World Activity/Workflow Template\nPostgreSQL Backed Storage\n\nUsage\n\nDeploy this template, the relevant environment variables (such as authentication, which should be used in production) and manage your new instance in your browser.\n\nLicense\n\nTemporal is licensed under the MIT License.\n\nHelpful Resources\n\nhttps://github.com/railwayapp-templates/temporal\nhttps://github.com/temporalio/temporal\nhttps://github.com/temporalio/samples-typescript\nhttps://docs.temporal.io/",
    name: "Temporal",
    category: "Queues",
    health: 100,
    code: "AhDDtZ",
    languages: ["Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "75b8369c-3ff3-4322-98e3-988367614005",
    isApproved: false,
    activeProjects: 19,
    projects: 98,
    description: "Deploy Drupal, an open source content management platform",
    readme:
      "Overview\nThis template uses the Drupal https://github.com/docker-library/drupal mantained by the docker community, not the Drupal team itself.\n\nConfiguration\nBy default, the version of Drupal deployed is Drupal 10, served through PHP version 8.2. This can be overriden by updating the Root Directory in the service's General settings.\n\nIt is currently set to the path to the Dockerfile satisfying the above versions of Drupal and PHP /10.0/php8.2/apache-bookworm, though this can be updated to point to any other Dockerfile in the repository that contains the you require.\n\nDatabase\nDrupal supports multiple database services, namely MySQL, MariaDB, Percona Server, PostgreSQL and SQLite (see the docs for more information). This template is set up to deploy a PostgreSQL database for ease of deployment, but this can be replaced with whichever is needed.\n\nDrupal requires the pg_trgm PostgreSQL plugin. In order to install this, run the following command in the PostgreSQL shell in the Query tab of the databse service:\n\nCREATE EXTENSION pg_trgm;\n\nDeploy\nNo further configuration is required, after starting the service, and installing the PostgreSQL plugin, navigate to the project's public url to start configuring your Drupal site üòä",
    name: "Drupal",
    category: "CMS",
    health: 50,
    code: "OmuxnN",
    languages: ["Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4580804b-352e-489c-a903-f4edd5d1da39",
    isApproved: false,
    activeProjects: 12,
    projects: 18,
    description: "Strong password generator API",
    readme:
      'GenratrAPI\n\nGenratrAPI is a simple web service built using Node.js and Express that allows you to generate random passwords with varying degrees of complexity. You can customize the password strength by specifying the character sets you want to include (special characters, lowercase letters, uppercase letters, and numbers) and the desired password length.\n\nAPI Endpoints\n\nGenerate a Random Password\n\nURL: /\nMethod: GET\n\nQuery Parameters\n\nspecial: Include special characters in the password.\nlowercase: Include lowercase letters in the password.\nuppercase: Include uppercase letters in the password.\nnumbers: Include numbers in the password.\nlength: Desired length of the password (integer, default is 12).\n\nInvalid Request\n\nTrying to generate a password without specifying any strength settings:\n\ncurl "http://localhost:8080/?length=10"\n\nResponse\n\n{\n  "error": "Invalid request"\n}\n\nSample Request\n\nGenerate a password with specific settings (20 characters, includes special characters, lowercase and uppercase letters, and numbers):\n\ncurl "http://localhost:8080/?special&amp;lowercase&amp;uppercase&amp;numbers&amp;length=20"\n\nResponse\n\n{\n  "password": "ZTd,BCsj2.$uk^4}!R%5"\n}\n\nSample Frontend\n\n\n    Special characters \n  \n     Lowercase characters\n  \n  \n     Uppercase characters\n  \n    Numbers \n  \n    Length:\n    \n  \n  Generate Password\n\nPassword: \n',
    name: "GenratrAPI",
    category: "Other",
    health: 100,
    code: "s_q0r3",
    languages: ["JavaScript", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "21ee892b-c1a6-4c02-ad5a-5172894f1a4b",
    isApproved: false,
    activeProjects: 43,
    projects: 130,
    description: "Deploys MariaDB with Adminer UI from a repo",
    readme:
      "What is MariaDB?\nMariaDB Server is one of the most popular database servers in the world. It's made by the original developers of MySQL and guaranteed to stay open source. Notable users include Wikipedia, DBS Bank, and ServiceNow.\n\nThe intent is also to maintain high compatibility with MySQL, ensuring a library binary equivalency and exact matching with MySQL APIs and commands. MariaDB developers continue to develop new features and improve performance to better serve its users.\n\n‚ú® Services\nMariaDB\nAdminer (Web GUI for Database management)\n\nüíÅ‚Äç‚ôÄÔ∏è How to use\n\nClick the Railway button üëÜ\nAdd the required environment variables. For more environment variables check the official docs\ninit_db.sql &amp; create_user.sql are custom scripts that will be executed on startup. You can customize them as per your needs.\nDeploy\nTo access the Adminer GUI, use the railway public url. For example: https://PROJECT_NAME.up.railway.app/\nlogin\nYou can login into adminier with Server as database and username & password which you configured during service configuration or you can find under environmental variable for database service in Railway UI.\nYou can utilize the railway internal network to connect to the database from other services.  For example database.railway.internal should be your database host.\nYou can view list of databases and tables in the Adminer GUI\nadminer\nTo view tables within a database, click on the database name\ntables\nAdminer also provides option to view table column infomration \ncolumns\nYou can edit and modify table structure using Adminer\nedit\nTable can be created from UI as well\ncreate\nIt also provider option to execute custom sql queries. By clicking on SQL Command you should be able to write your own sql and query the table you want.\ncustom\nTo include your application make sure to create a separate folder and add new service. Use internal network to connect to db.\nEnjoy!\n\nüìù Notes\n\nSource repo: https://github.com/MariaDB/mariadb-docker\nDocs: https://mariadb.com/kb/en/\nAdminer: https://www.adminer.org/",
    name: "MariaDB Starter Package",
    category: "Starters",
    health: 100,
    code: "BrjaHe",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "da540143-4a58-4044-9e73-666b922d4cdb",
    isApproved: false,
    activeProjects: 89,
    projects: 169,
    description: "Seamless multi-master syncing database with an intuitive HTTP/JSON API",
    readme:
      "What is CouchDB?\nCouchDB is an open source NoSQL database that stores your data with JSON documents, which you can access via HTTP. It allows you to index, combine, and transform your documents with JavaScript.\n\nWhy use CouchDB?\nApache CouchDB ‚Ñ¢ lets you access your data where you need it. The Couch Replication Protocol is implemented in a variety of projects and products that span every imaginable computing environment from globally distributed server-clusters, over mobile phones to web browsers.\n\nStore your data safely, on your own servers, or with any leading cloud provider. Your web- and native applications love CouchDB, because it speaks JSON natively and supports binary data for all your data storage needs.\n\nThe Couch Replication Protocol lets your data flow seamlessly between server clusters to mobile phones and web browsers, enabling a compelling offline-first user-experience while maintaining high performance and strong reliability. CouchDB comes with a developer-friendly query language, and optionally MapReduce for simple, efficient, and comprehensive data retrieval.\n\nLearn more\n\n‚ú® Services\n\nCouchDB\n\nüíÅ‚Äç‚ôÄÔ∏è How to use\n\nClick the Railway button üëÜ\nAdd the required environment variables to your Railway project\nIf you need to make any changes to the configuration, edit custom.ini in the couchdb folder and commit the changes\nIf you need Add your application, then make sure to create a folder and copy the file inside Docker with all dependencies installed. Check Dockerfile for more details\nTo Expose CouchDB in different ports, Add a new environment variable COUCHDB_CLUSTER_PORT_NUMBER and set the value to the port number you want to expose. Update the PORT value in railway to the same port number.\nDeploy\nVisit the public URL from Railway to access CouchDB\nTo connect to CouchDB, You can get the URL, Username and Password from Railway UI Under Database service environment variables tab.\nYou can access the CouchDB Web UI by opening your web browser and navigating to Railway's public URL with path _utils something like this https://.up.railway.app/_utils/. You should be able to see the CouchDB Dashboard.\ndashboard\nTo Create new database click on Create Database and enter the database name and click on Create\ncreate-db\nTo view the database click on the database name from the list of databases on dashboard. You can view any document by clicking on the document id.\nview-db\nYou can connect your client application to CouchDB and create databases. Refer to the Examples for python code to connect to CouchDB and perform CRUD operations.\nCode Editor\nCouchDB also has options to write custom queries from Dashboard\nQuery\nFrom dashboard you can nagivate to tasks to view and manage the tasks\nTasks\nDashboard also has configuration settings where you can change the configuration of CouchDB\nConfiguration\nYou can also manager users from dashboard\nUsers\nFor more information on CouchDB refer to the Documentation\nEnjoy! üéâ\n\nüìù Notes\n\nSource repo: https://github.com/apache/couchdb\nDocs: https://docs.couchdb.org/en/stable/\nDocker Image: https://hub.docker.com/r/bitnami/couchdb",
    name: "CouchDB",
    category: "Storage",
    health: 100,
    code: "eRC98l",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f9645037-9738-4e95-bb69-8d47abf03a9e",
    isApproved: false,
    activeProjects: 0,
    projects: 23,
    description: "Modern, privacy-friendly web analytics that works without cookies or JS.",
    readme:
      "Instructions\n\nClick the Deploy template button above.\nLeave the ADMIN_EMAIL variable empty. (In order to apply the provision and the migrations of the DB)\nWait for the first deployement to succeed.\nAdd to the Shynet service the environment variable ADMIN_EMAIL with your email address.\nA new deployment will be triggered, make sure to check out the \"Deploy Logs\" and see the password for the admin user in the logs.\n\nVideo tutorial\n\nOverview\n\nShynet is a privacy-friendly, cookie-free web analytics tool. It's open source and self-hosted, allowing you to retain ownership of your data. Shynet provides valuable visitor information such as page views, sessions, load times, bounce rates, referrers, locations, and device types. It supports multiple users and sites, and offers collaboration features. While ideal for personal projects and small to medium-sized websites, Shynet may not be suitable for ultra-high traffic sites and requires technical expertise to deploy and maintain.\n\nHighlights\n\nPrivacy-Friendly: Shynet is designed to prioritize user privacy and does not require the use of cookies or collect excessive personal data.\nSelf-Hosted: You have full control over your data as Shynet can be hosted on your own server.\nLightweight Tracking: Shynet's tracking script is lightweight and falls back to a transparent pixel if JavaScript is unavailable.\nMultiple Users and Sites: You can track multiple websites and have multiple users on a single Shynet instance.\nMetrics: Shynet provides various metrics including hits, sessions, page load time, bounce rate, duration, referrers, locations, operating systems, browsers, geographic location, network, and device type.\nFlexible Deployment: Shynet can run on a single machine or across a large Kubernetes cluster, making it scalable for different traffic levels.\nCollaboration: Administrators can easily share services with other users, allowing for collaborative data analysis.\nAccount Management: Shynet includes a comprehensive account management workflow powered by Django Allauth.\nDo Not Track (DNT) Support: Shynet allows you to specify whether to collect data from users with DNT enabled.\nExtensibility: Shynet is built using Django, making it customizable and extendable.\nHelpful Interface: Shynet offers a user-friendly interface for easily accessing and interpreting analytics data.\n\nLearn More\n\nShynet repo\nTemplate repo\n@MatteoGauthier_ Twitter\n",
    name: "Shynet",
    category: "Analytics",
    health: null,
    code: "yW3Kos",
    languages: ["Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a04d24c3-710e-4f97-8af9-36425784bf56",
    isApproved: false,
    activeProjects: 22,
    projects: 75,
    description: "A PostgreSQL instance with `vector` extension enabled.",
    readme:
      "This template deploys a Postgres instance with pgvector, an extension which gives your normal Postgres database the power of a vector database.\n\n‚ú® Features\n\nEverything of a normal Postgres database.\nGoodies of a vector database made by a mature ecosystem.\n\nüíÅ‚Äç‚ôÄÔ∏è How to use\n\nClick the Railway button.\nAdd the required environment variables.\nDeploy.\n\nüìù Notes\n\npgvector: https://github.com/pgvector/pgvector\nPostgreSQL: https://www.postgresql.org/docs/",
    name: "Standalone `pgvector` Service",
    category: "AI/ML",
    health: 100,
    code: "uYYYQy",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "87f301e2-2278-47d6-ba75-d9aafc05a69d",
    isApproved: false,
    activeProjects: 75,
    projects: 378,
    description: "Deploys RabbitMQ and two example apps.",
    readme:
      "\n    \n        \n    \n\n\nFeature rich, multi-protocol messaging and streaming broker\n\nRabbitMQ is the most widely deployed open source message broker.\n\nWith tens of thousands of users, RabbitMQ is one of the most popular open source message brokers. From T-Mobile to Runtastic, RabbitMQ is used worldwide at small startups and large enterprises.\n\nRabbitMQ is lightweight and easy to deploy on premises and in the cloud. It supports multiple messaging protocols and streaming. RabbitMQ can be deployed in distributed and federated configurations to meet high-scale, high-availability requirements.\n\nRabbitMQ runs on many operating systems and cloud environments, and provides a wide range of developer tools for most popular languages.\n\nHighlights\n\nRabbitMQ (one click deploy)\nHello World Consumer\nHello World Producer\n\nLicense\n\nRabbitMQ Server is licensed under MPL 2.0.\n\nHelpful Resources\n\nhttps://github.com/railwayapp-templates/rabbitmq\nhttps://github.com/rabbitmq/rabbitmq-server\nhttps://rabbitmq.com/\nhttps://hub.docker.com/_/rabbitmq",
    name: "RabbitMQ Starter Package",
    category: "Starters",
    health: 76,
    code: "0ELOuE",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6d371192-9eec-48dc-a9a9-19ad01c883de",
    isApproved: false,
    activeProjects: 117,
    projects: 636,
    description: "An easy to use, privacy-friendly, open-source Google Analytics alternative",
    readme:
      "What is this template?\n\nPlausible Analytics is a simple, open-source, lightweight (&lt; 1 KB) and privacy-friendly alternative to Google Analytics. Plausible is trusted by 10,000+ paying subscribers to deliver their website and business insights.\n\nThis template makes it trivial to deploy an instance of Plausible Analytics with all of it's required services on Railway.\n\nSee the Plausible Analytics docsite for a more in-depth explanation of its feature set.\n\nAs of 2024-06-06 this template has been migrated to the Plausible Analytics Community Edition (CE) release\n\nQuick start guide\n\nClick the \"Deploy on Railway\" button above, or click here\nFollow the setup steps in Railway\n   For information on the \"optional\" variables in the template, see \"Optional Variables\" below.\nMonitor your services as they come up; wait until they're all up. \nSetup your websites with Plausible Analytics.\n   Navigate to the domain for your Plausible Analytics service.\n   Follow the prompts to create an account on the service\n   Follow the prompts to set up tracking on your website.\n   For more information on how to use Plausible, check their site.\n\nOptional variables\n\nThere are several \"optional\" environment variables for this template. This variables aren't needed to get Plausible Analytics running on Railway, but they add some niceties.\n\nSMTP Mailer Setup: these optional values enable your Plausible Analytics instance to send you emails. These can be weekly updates, or timely notifications if your site is getting a spike in traffic. You can read more about these settings on Plausible Analytics docsite here.\n  MAILER_EMAIL: This is the email that all outgoing emails will come from (i.e. analytics@yoursite.com)\n  MAILER_NAME: This is the name that all outgoing emails will come from (i.e. Plausible Analytics for YourSite.com)\n  SMTP_HOST_ADDR: The host address of the SMTP server you'd like Plausible Analytics to use to send emails (i.e. send.mailserver.com)\n  SMTP_HOST_PORT: The port you'd like to use with SMTP_HOST_ADDR to send emails (i.e. 25, 225)\n  SMTP_USER_NAME: If your SMTP server of choice uses authentication, put the username here (i.e. smtp_user, admin@send.mailserver.com)\n  SMTP_USER_PWD: If your SMTP server of choice uses authentication, put the password here\n  SMTP_HOST_SSL_ENABLED: If your SMTP server support TLS encrypted traffic, enable it here (i.e true, false)\n\nProject structure &amp; services\n\nThis template is made up of three \"services\":\n\nPlausible Analytics: the primary application.\n  The Plausible Analytics service is what you'll primarily be interacting with as a user. The service exposes a web application that users log in to, view analytics on, setup new sites with, change settings in, etc.\n  Plausible Analytics is run via a Docker image the Plausible Analytics team publishes to DockerHub. Railway makes deploying images from DockerHub very easy.\nClickHouse Database: the analytics database.\n  ClickHouse is used to store Analytics data for Plausible Analytics. ClickHouse's architecture makes analytics data more efficient to query than PostgreSQL does, especially as data scales. This is likely why Plausible Analytics uses it for Analytics data. (PostHog has a great article on this if you're interested in learning more.)\n  ClickHouse is run via a custom dockerfile, some custom ClickHouse config to tune things up for Railway, and a railway.json file to define deployment configuration for the service.\nPostgreSQL Database: the users, settings, and metadata database\n  PostgreSQL is used to store user data, settings, and metadata for Plausible Analytics.\n  PostgreSQL is ran as one of Railway's one-click database services and is just a standard PostgreSQL database.\n\nAdditional resources\n\nIf you'd like to customize your instance of Plausible Analytics, I would recommend reviewing the documentation for both ClickHouse DB, and Plausible Analytics. Here are some links to get you started:\n\nPlausible welcome guide\nPlausible self-hosting docs\nClickHouse docker docs\n\nFeedback\n\nIf you experience any issues or have any feedback at all, you can create a GitHub issue here\n\nKnown issues\n\nNone right now! \n",
    name: "Plausible Analytics",
    category: "Analytics",
    health: 88,
    code: "mzYEXO",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b43e0324-6e4e-463a-99f0-55112118ed94",
    isApproved: false,
    activeProjects: 187,
    projects: 335,
    description: "ExpressJS API Starter with basic examples",
    readme:
      "ExpressJS API Server\n\nThis is a boilerplate/starter project for quickly building RESTful APIs using Node.js and Express, written in JavaScript. It will help you get started with a simple to follow format with some examples for routes, logging and middleware.\n\nFeatures \n\nMorgan - HTTP request logger middleware for Node.js\nCORS - Middleware to enable CORS with options.\nExample logger to create or redirect your logs to the service of your choice\nExample middleware to further expand to use for auth\nNodemon to help develop locally.\n\nDetails\n\nThe server runs a simple Express API server.\n\n/ returns status: ok \n\n/hello  returns message: Hello World!\n\nUnknown endpoints are handled in a middleware file.\n\nThe hello route is defined  in the helloRoute   \n\n",
    name: "ExpressJS API Server",
    category: "Starters",
    health: 62,
    code: "Vp8hse",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a266fb20-7f46-4a83-84fc-144c4ced27e3",
    isApproved: false,
    activeProjects: 49,
    projects: 98,
    description: "A simple web-server written in Rust using axum",
    readme:
      "This template provides a simple web-server, featuring the key concepts of axum and tokio.\n\nThis template has lots of comments to walk you through how everything works, and how it can be modified.\n\nThis template uses axums Router, to create an app router, to which routes are added. A server is then initialised, which starts listening for requests. These route functions talk about the different way a route function can work, ie, some returning strings, and some providing much more complex responses.",
    name: "Rust starter",
    category: "Other",
    health: 83,
    code: "5HAMxu",
    languages: ["Rust"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f58670ed-b25a-474a-8dc7-e2c648aedec8",
    isApproved: false,
    activeProjects: 14,
    projects: 148,
    description: "The Open Source Retool Alternative",
    readme:
      "What is Openblocks?\nOpenblocks is a developer-friendly open-source low code platform to build internal apps within minutes.\nTraditionally, building an internal app requires complex frontend and backend interactions with hundreds and thousands lines of code, not to mention work on packaging, integration and deployment. Openblocks significantly reduces the work you need to do to build an app.\nIn Openblocks, all you need to do is drag and drop pre-built or self-customized components onto the What-You-See-Is-What-You-Get (WYSIWYG) canvas, along with ready-to-connect databases and APIs, Openblocks helps you build an app quickly and focus on business logic.\n\n‚ú® Services\n\nOpenblocks (Frontend, Node Backend and API)\nMongoDB (Database)\nRedis (Cache)\n\nWhy choose Openblocks?\nOpen source: Makes your ideas more feasible.\nAll-in-one platform: Connection to all kinds of data sources and APIs such as MySQL, PostgreSQL, SQL Server, MongoDB, Redis, and Elasticsearch, and ensures your data security.\nHigh scalability: Allows to execute JavaScript almost anywhere you would like to customize your business processes and UI components.\nClean design: Follows the principles of Ant Design and supports display on screens of different sizes. We have a number of templates and UI components, based on which you can freely build dashboard, admin panel, and content management system (CMS).\nBuilt-in features: Provide cloud and self-hosted deployment, multi-tenant management, fine-grained access control, and audit logs.\n\nHow to build an app in Openblocks?\nBuilding an internal app basically takes 5 steps:\nQuickly connect to your data sources, including PostgreSQL, MongoDB and online APIs.\nWrite a few lines of SQL or set up request parameters to build queries.\nUse pre-built or user-customized UI components to build your app UI, bind and display queries' data with UI components.\nSet up event handlers to trigger queries, control components or other actions in reaction to user interactions.\nPreview and share your app with others.\n\nüíÅ‚Äç‚ôÄÔ∏è How to use\n\nClick the Railway button üëÜ\nUpdate only required environment variables. Most of them are already set and doesn't need to be changed. If you want to configure or add more environment variables, follow this guide\nDeploy\nDeploy\nVisit the URL Railway provides\nFollow the instructions to set up your admin account\nLogin Page\nLogin with your admin account\nTo Create a new App, Click on New and then App\nCreate Page\nAdding a New component is simple and easy by dragging and dropping the components from the left panel to the canvas\nDrag and Drop\nCenter canvas is the canvas where you can drag and drop the components and build your app\nFlow\nRight panel is the properties panel where you can set the properties of the components\nBottom panel is the data panel where you can set the data source for the components and query the data\nData\nOnce you are done with the app, you can click on the Preview button on the top right corner to preview the app\nYou can also share the app with others by clicking on the Share button on the top right corner\nYou can export the app by clicking on the Export button on the top right corner and import it later \nYou can also deploy the app by clicking on the Publish button on the top right corner\nEnjoy üéâ\n\nüìù Notes\n\nSource repo: https://github.com/openblocks-dev/openblocks\nDocs: https://docs.openblocks.dev/self-hosting",
    name: "Openblocks",
    category: "Other",
    health: null,
    code: "z-IiRE",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "957c58aa-4e8d-4296-b2e2-b5562ac05d67",
    isApproved: false,
    activeProjects: 112,
    projects: 305,
    description: "Django Rest Framework Starter Template",
    readme:
      "Getting Started with Django REST + Postgres Starter\n\nWelcome to the Django REST + Postgres Starter! This guide will walk you through the steps to get started with the project after deploying the service. Before you begin, make sure you have deployed the template.\n\nStep 1: Set the SECRET_KEY Variable\n\nThe SECRET_KEY is a critical security parameter used by Django to secure cryptographic signatures and session data. To enhance the security of your project, it's essential to change the default SECRET_KEY to a unique and secure value.\n\nOpen the your railway service variables.\nLocate the SECRET_KEY variable and update it with your desired value.\n\nExample:\n\nSECRET_KEY = 'your_secret_key_here'\n\nStep 2: Update CSRF_TRUSTED_ORIGINS\n\nDjango uses Cross-Site Request Forgery (CSRF) protection to prevent malicious attacks. When deploying the project to Railway or a custom domain, you need to specify the trusted origins that are allowed to send POST, PUT, PATCH, or DELETE requests.\n\nOpen the project local_settings file.\nLocate the CSRF_TRUSTED_ORIGINS variable and update it with the URLs of your Railway app or custom domain.\nDont forget to also do the same at your production_settings.py\n\nExample:\n\nCSRF_TRUSTED_ORIGINS = ['your_railway_app_url_here', 'your_custom_domain_url_here']\n\nStep 3: Run the Development Server\n\nWith the SECRET_KEY and CSRF_TRUSTED_ORIGINS updated, you can now run the development server to test your Django REST + Postgres Starter locally.\n\nOpen a terminal or command prompt.\nNavigate to the root directory of your project.\nRun the following command:\n\npython manage.py runserver\n\nThe development server should start, and you can access your project at http://127.0.0.1:8000/.\n\nStep 4: Start Building Your API\n\nWith the project set up and the development server running, you are ready to start building your API. The Django REST + Postgres Starter provides a solid foundation to create powerful RESTful APIs. You can define your models, serializers, views, and URLs to implement your desired functionality.\n\nRefer to Django REST Framework documentation (https://www.django-rest-framework.org/) for detailed information on how to create APIs, handle authentication, permissions, and much more.\n\nConclusion\n\nCongratulations! You have successfully set up the Django REST + Postgres Starter and made the necessary changes to enhance the security and compatibility with Railway or a custom domain. Now you can begin building your API and start your exciting development journey with Django and Postgres.\n\nHappy coding! üöÄ",
    name: "Django REST Template",
    category: "Starters",
    health: 33,
    code: "Rj_70k",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7dfb4f9b-7aac-4cab-a36a-cfda68ab8c0f",
    isApproved: false,
    activeProjects: 92,
    projects: 354,
    description: "the AI-native open-source embedding database",
    readme:
      "Chroma - the AI-native open-source embedding database. \n\nIt has all the tools you need to use embeddings.\n\nThis template allows you to spin-up a chroma DB in just a few clicks.\n\nUses official chroma docker image and mounts a volume, you can talk to chroma on internal networking port 8000.\n\nLearn about Chroma\n\nGetting started\n\nLicense\n\nChroma is licensed under the Apache 2.0 license.\n",
    name: "Chroma",
    category: "AI/ML",
    health: 100,
    code: "tifygm",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d75cff57-3b05-4396-96e9-2ad4f80017c7",
    isApproved: false,
    activeProjects: 64,
    projects: 106,
    description: "Fast and secure standalone server for resizing and converting remote images",
    readme:
      "\nOverview\nImgproxy is a performant 1-container server for resizing, converting, cropping, and manipulating images on-the-fly. The guiding principles behind imgproxy are security, speed, and simplicity.\n\nImgproxy was built with security in mind. This template will automatically set the imgproxy key and salt. Make sure your application use these key or else imgproxy will refuse to serve the request.\n\nHighlights\nFast and performant: Imgproxy was built using libvips, the most efficient image processing library available.\nFeature rich: You can crop, resize, zoom, enlarge, rotate, add backgrounds, and add watermarks all for free. Pro version comes with even more features for advanced users.\nStability: This template is automatically configured with a health check to make sure your imgproxy instance is always up and running.\n\nConfiguration\nBy default, this template will generate the IMGPROXY_KEY, IMGPROXY_SALT, IMGPROXY_USE_ETAG, and IMGPROXY_TTL to a sensible default value. For further customization, please take a look at the documentation\n\nGenerating key and salt\nimgproxy expects the IMGPROXY_KEY and IMGPROXY_SALT to be hex-encoded. The template will automatically configure this for you.\n\nIf you want to generate your own, run the following on a linux machine:\n\necho $(xxd -g 2 -l 64 -p /dev/random | tr -d '\\n')\n\nSee this page for more info.\n\nUpdating\nThis template currently deploys imgproxy version 3.18.2 which is the latest version as of August 4th, 2023. You can edit the docker image version manually if a newer version is available.\n\nLicense and Links\nimgproxy is distributed with the MIT License. A \"pro\" version of imgproxy is available and may be licensed under a different license. ",
    name: "imgproxy",
    category: "Other",
    health: 100,
    code: "d7gCBH",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "41f8ced2-ecd0-4c14-82ae-299ebea46082",
    isApproved: false,
    activeProjects: 313,
    projects: 708,
    description: "SQLite3 is a lightweight database",
    readme:
      "\n\nSQLite Template\n\nSQLite3 is a lightweight, serverless, open-source database engine used for local storage in applications. It requires no configuration and supports SQL for data manipulation.\n\n‚ú® Features\n\nSQLite3 database\nSQLite Web Interface\ntrains table with sample data about Thomas &amp; Friends (do you still need more features?)\n\nü§î How to use\n\nüåé WebUI Usage\n\nOpen the project named \"SQLite Template\"\n\nGo to the \"Variables\" tab and view the SQLITE_WEB_UI_PASSWORD variable, this is the password you'll need to access the web interface\n\nBack to Deployments, in the top you'll see a URL which you can use to access the web interface\n\nClick on the URL and you'll be redirected to the web interface, type your password and you'll be able to manage your database\n\nThat's it! You can now manage your SQLite3.\n\n‚öôÔ∏è seed_db.sql Usage\n\nAfter you've deployed this template, you'll find a copy of this project in your Github.  \nFrom there you can populate seed_db.sql with your own SQL code.  \nThe file will only be executed when you change anything in it and will run only once.\n\n‚öôÔ∏è init_db.sql Usage\n\nThis file is used to initialize the database.  \nIt includes sample data for a trains table.\n\nüìô Learn more\n\nSQLite3\nSQLite Web\n",
    name: "SQLite3",
    category: "Storage",
    health: 96,
    code: "jOiNFt",
    languages: ["Shell", "Python", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c25e624e-e112-4f08-a3b3-7cfe6b8f8923",
    isApproved: false,
    activeProjects: 485,
    projects: 1100,
    description: "The Open Source Airtable Alternative",
    readme:
      "\nNocoDB\nThe Open Source Airtable Alternative\nNocoDB turns any MySQL, PostgreSQL, SQL Server, SQLite &amp; MariaDB into a smart spreadsheet. Create endless solutions, collaborate just like spreadsheets, automate business workflows and create headless APIs.\n\nNocoDB is a no-code database platform that allows teams to collaborate and build applications with ease of a familiar and intuitive spreadsheet interface. This allows even non-developers or business users to become software creators.\n\nNocoDB works by connecting to any relational database and transforming them into a smart spreadsheet interface! This allows you to build no-code applications collaboratively with teams. NocoDB currently works with MySQL, PostgreSQL, Microsoft SQL Server, SQLite, Amazon Aurora &amp; MariaDB databases.\n\nAlso NocoDB's app store allows you to build business workflows on views with combination of Slack, Microsoft Teams, Discord, Twilio, Whatsapp, Email &amp; any 3rd party APIs too. Plus NocoDB provides programmatic access to APIs so that you can build integrations with Zapier / Integromat and custom applications too.\n\nSourced from https://docs.nocodb.com/\n\nHighlights\n\nNocoDB (one click deploy)\nPostgreSQL backed database\nRedis backed cache\n\nUsage\n\nDeploy this template, fill out the required environment variables (and more, from NocodeDB), and check out your new instance in your browser.\n\nLicense\n\nNocoDB is licensed under AGPLv3.\n\nHelpful Resources\n\nhttps://github.com/railwayapp-templates/nocodb\nhttps://docs.nocodb.com/\nhttps://docs.nocodb.com/getting-started/environment-variables",
    name: "NocoDB",
    category: "Automation",
    health: 100,
    code: "opu-NU",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "65184492-52eb-4418-8746-f12a43392d3b",
    isApproved: false,
    activeProjects: 2,
    projects: 2,
    description: "Fast image manipulation API in Rust",
    readme:
      "A fast image manipulation API that can modify images on the fly.\n\nUsage\n\nGET /v1/resize/w/?url=\n    resize image `` pixels wide, without changing the aspect ratio\n\nGET /v1/resize/h/?url=\n    resize image to `` pixels tall, without changing the aspect ratio\n\nGET /v1/crop////?url=\n    crop image to `x pixels, starting from position (, `)\n\nGET /v1/convert/?url=\n    convert image to `` format\n    format: png, jpeg, webp\n\nGET /v1/flip/?url=\n    flip image  to `` orientation\n    orientation: horizontal, vertical\n\nGET /v1/grayscale?url=\n    convert image to grayscale\n\nGET /v1/invert?url=\n    invert image\n\nGET /v1/brighten/?url=\n    brighten image by ``, negative values decrease the brightness and positive values increase it\n\nGET /v1/blur/?url=\n    blur image with `` sigma (this is a slow endpoint and could potentially timeout)\n\nGET /v1/rotate/?url=\n    rotate image by `` degrees, degree can be 90, 180, 270\n\nGET /v1/unsharpen//?url=\n    unsharpen image, sigma is the amount to blur the image by, threshold is a control of how much to sharpen.",
    name: "Rust Image API",
    category: "Other",
    health: null,
    code: "zHlq1G",
    languages: ["Rust", "HTML", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2c481846-0f1d-4635-ac13-e735a3a1cc67",
    isApproved: false,
    activeProjects: 9,
    projects: 20,
    description: "A fullstack web app for the Litestar Framework",
    readme:
      "Litestar Fullstack\n\nBuilt by @cofin\n\nhttps://github.com/cofin/litestar-fullstack\n\nThis template deploys a fullstack, ready to use web app built on the Litestar framework, SAQ background workers, PostgreSQL database, Redis worker queue, Vite, Vue, and more!\n\nThis is a reference application that you can use to get your next Litestar application running quickly.\n\nIt contains most of the boilerplate required for a production web API.\n\nFeatures:\n\nLatest Litestar configured with best practices\nIntegration with SQLAlchemy 2.0, SAQ (Simple Asynchronous Queue), and litestar-saqlalchemy\nExtends built-in litestar click CLI\nFrontend integrated with vitejs and includes Jinja2 templates that integrate with Vite websocket/HMR support\nMulti-stage docker build using a Google Distroless (distroless/cc) Python 3.11 runtime image.\npre-configured user model that includes teams and associated team roles\nexamples of using guards for superuser and team based auth.\n",
    name: "Litestar Fullstack",
    category: "Starters",
    health: 0,
    code: "KmHMvQ",
    languages: [
      "Python",
      "TypeScript",
      "Dockerfile",
      "Makefile",
      "JavaScript",
      "Mako",
      "CSS",
      "Jinja",
      "Shell",
    ],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8ea64efe-3f2f-4e32-9e93-d26c90a576fe",
    isApproved: false,
    activeProjects: 11,
    projects: 54,
    description: "Change Detection is an open source tool for monitoring websites for changes",
    readme:
      "Change Detection is an open source tool for monitoring websites and sending notifications on change.\n\nMake sure to adjust the BASE_URL variable after deploying and adding a domain, to ensure urls inside notifications are correct.",
    name: "Change Detection",
    category: "Automation",
    health: 100,
    code: "sXmRro",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f8729c9b-7c53-48c9-82e9-bdbc8a9c819c",
    isApproved: false,
    activeProjects: 51,
    projects: 195,
    description: "The Open Source DocuSign Alternative.",
    readme:
      "Overview\n\nDocumenso aims to be the world's most trusted document-signing tool.  You can think of it as a self-hosted alternative to DocuSign.\n\nHighlights\nDeploy production-ready documenso instance with PostgreSQL for free.\nOne-click deploys with the required PostgreSQL database automatically provisioned\n\nLearn More\nDocumenso\nGithub\n",
    name: "documenso",
    category: "Other",
    health: 93,
    code: "DjrRRX",
    languages: ["TypeScript", "MDX", "JavaScript", "Shell", "Dockerfile", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a0c85165-1758-42cc-98bd-f5965e70249c",
    isApproved: false,
    activeProjects: 21,
    projects: 25,
    description: "Quart is an async reimplementation of the popular Flask microframework API.",
    readme:
      "Quart is an asyncio reimplementation of the popular Flask microframework API. This means that if you understand Flask you understand Quart. See Flask evolution to learn more about how Quart builds on Flask.\n\nLike Flask Quart has an ecosystem of extensions for more specific needs. In addition a number of the Flask extensions work with Quart.\n\nQuart is developed on Github. If you come across an issue, or have a feature request please open an issue.If you want to contribute a fix or the feature-implementation please do (typo fixes welcome), by proposing a merge request. If you want to ask for help try on discord.",
    name: "Quart",
    category: "Starters",
    health: 100,
    code: "fHCvqD",
    languages: ["Python", "CSS", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "945a9f0a-8870-416a-90bb-e32e7b192f2f",
    isApproved: false,
    activeProjects: 7,
    projects: 20,
    description: "A template to deploy for DApp mvp with kuai",
    readme:
      "This is the minimum viable product(MVP) designed to demonstrate Kuai's ability to manipulate a group of cells on the Nervos Common Knowledge Base (CKB).\n\nThe Kuai MVP DApp is a partially implemented data.did.id, which serves as a decentralized account profile. In comparison to the fully implemented version, the Kuai MVP DApp focuses solely on on- and off-chain data management. On-chain state verification will be supported in the next stage of development.\n\nYou can find an online preview of the Kuai MVP DApp at https://kuai-mvp-dapp-ui.vercel.app/.",
    name: "kuai-mvp",
    category: "Other",
    health: 67,
    code: "KO6Gvb",
    languages: [
      "TypeScript",
      "SCSS",
      "JavaScript",
      "HTML",
      "Rust",
      "CSS",
      "Shell",
      "Dockerfile",
      "Makefile",
    ],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d65f1f24-ac70-42cf-bc9b-b2eaf7c5a354",
    isApproved: false,
    activeProjects: 133,
    projects: 492,
    description: "A Web File Browser using volumes",
    readme:
      "Logo\n\nüìÇ Web File Browser\n\nFilebrowser provides a file managing interface within the attached volume and it can be used to upload, delete, preview, rename, and edit your files.\n\nFileBrowser Features\n\nUpload, Delete, Rename, and Create Files and Folders\nPreview, Edit and Share Files\n\nTemplate Features\n\nAutomatically uses attached volume as the storage location\n\nUsername and Password are set by service variables\n\nBy default, the storage location is set to the storage subdirectory in the root of the volume, but by setting a service variable USE_VOLUME_ROOT to 1 you can opt to use the root of the volume as the storage location instead\n\nCaveats\n\nSetting a password in Filebrowser's settings will not persist across deployments, this is because the password from the WEB_PASSWORD variable is used instead on every deployment, in order to keep the login password in sync with what is set in the variable",
    name: "Filebrowser",
    category: "Storage",
    health: 44,
    code: "Nan7Bs",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a030a62c-2168-4b97-96bf-5eb21e17c3e8",
    isApproved: false,
    activeProjects: 72,
    projects: 194,
    description: "Set up the latest Directus from Docker and a volume for SQLite",
    readme:
      "https://docs.directus.io/self-hosted/config-options.html\n\nKEY and SECRET env vars should be random strings. You can use whatever you like here, or just generate some uuids.\n\nADMIN_EMAIL and ADMIN_PASSWORD will set up the initial admin account for Directus. You can omit these if you want, and Directus will generate them for you. These can be found in the deploy logs.",
    name: "Directus (Docker) + SQLite",
    category: "CMS",
    health: 92,
    code: "gyh9cG",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f625fcac-d9bd-4ef6-8fc2-c59b55f9d28b",
    isApproved: false,
    activeProjects: 12,
    projects: 16,
    description: "Visually build a discord bot, using Flyde - the OS Visual-Programming tool",
    readme:
      'This is a simple Discord bot using Flyde and Discord.js.\nIt exposes a "/joke" command that will send a random joke (using https://jokeapi.dev/) to the channel where the command was sent.\n\n\nFlyde  is a powerful visual flow-based programming toolkit that enables you to create and edit code using a visual flow-based programming interface. With Flyde, you can build backend flows quickly and intuitively, making it ideal for novice developers, non-developer technical teams, and experienced developers who want to prototype and test ideas fast.',
    name: "Flyde Discord Bot ‚ö°Ô∏è",
    category: "Bots",
    health: null,
    code: "I6wHQZ",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5fb45720-a902-41ce-80a9-41567bf98536",
    isApproved: true,
    activeProjects: 1164,
    projects: 2920,
    description: "A customer communication platform",
    readme:
      "\n    \n        \n    \n\n\nCustomer communication platform\n\nChatwoot gives you all the tools to manage conversations, build relationships and delight your customers from one place.\n\nNotes:\n\nBy default, the Community edition is deployed, change the source images tag to Enterprise in the services settings after the deployment to deploy the Enterprise edition of Chatwoot instead. This requires an Enterprise level Chatwoot subscription\n\nCommunication to Postgres and Redis is done exclusively over the private network and the databases are not exposed externally in any way by default, if you want to enable access from outside of the private network you can go to the databases settings to enable TCP proxying and enter the internal port (5432 for Postgres and 6379 for Redis) and then redeploy the database in question. The TCP proxy can be again removed at any point to close off external access.\n\nChatwoot - Screenshot\n\nChatwoot is an open-source customer communication platform that enables businesses to engage, support, and delight their customers across various channels. It provides a unified inbox for managing conversations from multiple channels, such as website chat, Facebook Messenger, WhatsApp, Twitter, and more.\n\nFeatures\n\nChatwoot supports the following conversation channels:\n\n Website: Talk to your customers using our live chat widget and make use of our SDK to identify a user and provide contextual support.\n Facebook: Connect your Facebook pages and start replying to the direct messages to your page.\n Instagram: Connect your Instagram profile and start replying to the direct messages.\n Twitter: Connect your Twitter profiles and reply to direct messages or the tweets where you are mentioned.\n Telegram: Connect your Telegram bot and reply to your customers right from a single dashboard.\n WhatsApp: Connect your WhatsApp business account and manage the conversation in Chatwoot.\n Line: Connect your Line account and manage the conversations in Chatwoot.\n SMS: Connect your Twilio SMS account and reply to the SMS queries in Chatwoot.\n API Channel: Build custom communication channels using our API channel.\n Email: Forward all your email queries to Chatwoot and view it in our integrated dashboard.\n\nAnd more.\n\nOther features include:\n\nCRM: Save all your customer information right inside Chatwoot, use contact notes to log emails, phone calls, or meeting notes.\nCustom Attributes: Define custom attribute attributes to store information about a contact or a conversation and extend the product to match your workflow.\nShared multi-brand inboxes: Manage multiple brands or pages using a shared inbox.\nPrivate notes: Use @mentions and private notes to communicate internally about a conversation.\nCanned responses (Saved replies): Improve the response rate by adding saved replies for frequently asked questions.\nConversation Labels: Use conversation labels to create custom workflows.\nAuto assignment: Chatwoot intelligently assigns a ticket to the agents who have access to the inbox depending on their availability and load.\nConversation continuity: If the user has provided an email address through the chat widget, Chatwoot will send an email to the customer under the agent name so that the user can continue the conversation over the email.\nMulti-lingual support: Chatwoot supports 10+ languages.\nPowerful API &amp; Webhooks: Extend the capability of the software using Chatwoot‚Äôs webhooks and APIs.\nIntegrations: Chatwoot natively integrates with Slack right now. Manage your conversations in Slack without logging into the dashboard.\n\nDocumentation\n\nDetailed documentation is available at chatwoot.com/help-center.\n\nLicense\n\nChatwoot is released under the MIT License, allowing for the free use, modification, and distribution of the software.",
    name: "Chatwoot",
    category: "Other",
    health: 100,
    code: "chatwoot",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9b80711c-8cad-40a5-aff0-1d66544161a6",
    isApproved: false,
    activeProjects: 8,
    projects: 16,
    description: "Litestar is a Python framework for building web apps, ML/AI, and APIs.",
    readme:
      "Litestar\n\nEffortlessly build performant APIs with Litestar\nThe powerful, lightweight and flexible ASGI framework.\n\nA comprehensive, yet easy-to-use API builder that emphasizes fast development and high performance. Perfectly suited for building web applications, constructing ML/AI pipelines, and crafting robust APIs.\n\nKey Features:\nSynchronous & Asynchronous Execution: Supports both for optimal performance.\nData Validation & Parsing: Uses type hints for efficient data management.\nOpen Ecosystem: Enables schemas definition with standard types or custom integration.\nOpenAPI: Provides automatically generated OpenAPI schemas.\nInteractive API Documentation: Through Swagger, Stoplight Elements, and Redoc, enhancing developer experience.\nMiddlewares: Built-in solutions for common tasks.\nData Stores: Interfaces for various key/value stores for seamless integration.\nORM Integration: First-class SQLAlchemy support reduces code duplication.\nDependency Injection: Advanced system aids in code decoupling and reduces repetition.\nCaching: Response caching to speed up response times.\nWebSockets: Easy-to-use integration for high- and low-level APIs.\nRuntime Safety: Ensures through strict validation.\nAuthentication and Authorization: Provides session and JWT-based utilities.\n2.0 Launches soon: Experience the great new features coming with Litestar v2.0 including support for distributed messaging via channels, enhanced websocket support, HTMX support, enhanced ORM integration, and more!\n\n|Links|\n|:-|\n|Website|\n|Documentation|\n|Twitter|\n|Blog|\n|Discord|\n|r/Litestar|\n|PyPI|\n\n",
    name: "Litestar with TailwindCSS",
    category: "Starters",
    health: 0,
    code: "zx1KGh",
    languages: ["CSS", "HTML", "Makefile", "Python", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a5ab7187-ee51-4dbd-9298-1afa4523fb2e",
    isApproved: false,
    activeProjects: 71,
    projects: 199,
    description: "Self-hosted Ghost with SQLite and persistent volume.",
    readme:
      "###Overview\nGhost is a full-featured blogging platform and an open-source alternative to Medium, Substack, WordPress etc. It offers a comprehensive set of features to publish content, send newsletters, and offer paid subscriptions to members. It also offers detailed engagement analytics for your audience and content.\n\n###Template\nThis template deploys the community-maintained Docker image, along with an attached volume and a local SQLite database, so that configuration and content can persist across deployments.\n\nNote: Once deployed, launch https://RAILWAY_URL]/ghost to access the admin page and set up Ghost for the first time.\n\n###Mail Configuration\nIf you want to send transactional emails, please configure the following optional variables with valid details:\nmail__from: \nmail__transport: SMTP\nmail__options__host: \nmail__options__port:\nmail__options__auth__user:\nmail__options__auth__pass: \n\nFor bulk email newsletter delivery, you'll also need to configure the Mailgun service from Ghost Settings.\n\nNote: This template should ideally be used for non-critical or lightweight blogs. For a production-ready Ghost deployment with MySQL, see [this template instead.",
    name: "Ghost + SQLite",
    category: "Blogs",
    health: 100,
    code: "9VGb60",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f17bf53d-35ad-41cd-9667-c5093b5136fe",
    isApproved: false,
    activeProjects: 133,
    projects: 288,
    description: "Unite your frontend & backend into one domain",
    readme:
      'Caddy Frontend & Backend Reverse Proxy\n\nCombine your separate frontend and backend services into one domain!\n\nView the example public project here - Utilizes sleeping frontend and backend services with wake via the private network\n\nAccess the frontend from / and access the backend from /api/ on the same domain\n\nFrontend - Vue 3: https://mysite.up.railway.app/\n\nBackend - Go Mux: https://mysite.up.railway.app/api/\n\nThe proxy configurations are done in the Caddyfile everything is commented for your ease of use!\n\nWhen deploying your Reverse Proxy service it will require you to set four service variables: FRONTEND_DOMAIN / FRONTEND_PORT and BACKEND_DOMAIN / BACKEND_PORT\n\nNote: You will first need to have set a fixed PORT variable in both the frontend and backend services before deploying this template.\n\nThese are the four template variables that you will be required to fill out during the first deployment of this service, it is highly recommended to use reference variables.\n\nExample:\n\nFRONTEND_DOMAIN=${{Frontend.RAILWAY_PRIVATE_DOMAIN}}\nFRONTEND_PORT=${{Frontend.PORT}}\n\nBACKEND_DOMAIN=${{Backend.RAILWAY_PRIVATE_DOMAIN}}\nBACKEND_PORT=${{Backend.PORT}}\n\nRelevant Caddy documentation:\n\nThe Caddyfile\nCaddyfile Directives\nreverse_proxy\n\nSome prerequisites to help with common issues that could arise:\n\nBoth the frontend and backend need to listen on fixed ports, in my example project I have configured my frontend and backend to both listen on port 3000\n    This can be done by configuring your frontend and backend apps to listen on the $PORT environment variable, then setting a PORT service variable to 3000\n\nSince Railway\'s internal network is IPv6 only the frontend and backend apps will need to listen on :: (all interfaces, both IPv4 and IPv6)\n\n    Start commands for some popular frameworks:\n\n    Gunicorn: gunicorn main:app -b ::]:${PORT:-3000}\n\n    Uvicorn: uvicorn main:app --host :: --port ${PORT:-3000}\n\n        Uvicorn does not support dual-stack binding (IPv6 and IPv4) from the CLI, so while that start command will work to enable access from within the private network, this prevents you from accessing the app from the public domain if needed, I recommend using [Hypercorn instead\n\n    Hypercorn: hypercorn main:app --bind [::]:${PORT:-3000}\n\n    Next: next start -H :: --port ${PORT:-3000}\n\n    Express/Nest: app.listen(process.env.PORT || 3000, "::");\n',
    name: "Reverse Proxy",
    category: "Starters",
    health: 96,
    code: "7uDSyj",
    languages: ["Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f6b7ff9a-f61e-4792-9a07-02d881cc998a",
    isApproved: false,
    activeProjects: 6,
    projects: 13,
    description: "This is an online learning application to Grow up your skills",
    readme:
      "We believe every learner is an individual and every course is an opportunity to build job-ready skills. Through our human-centered approach to learning, we will empower you to fulfil your professional and personal goals and enjoy career success.\nWe believe every learner is an individual and every course is an opportunity to build job-ready skills. Through our human-centered approach to learning, we will empower you to fulfil your professional and personal goals and enjoy career success.",
    name: "dyan-up",
    category: "Blogs",
    health: null,
    code: "FpQ2va",
    languages: ["Java"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "52ae4a39-c417-46c4-a882-04a36c8d8ada",
    isApproved: false,
    activeProjects: 136,
    projects: 282,
    description: "The streamlit hello demo app",
    readme:
      "Welcome to Streamlit! üëã\nStreamlit is an open-source app framework built specifically for Machine Learning and Data Science projects.\n\nThis project highlights Streamlit's new multipage app functionality. Now deployable directly to Railway!\n\nCheckout the source repositories Readme for more in-depth information on this template and how it runs on Railway!\n\nWant to learn more about Streamlit?\nCheck out streamlit.io\nJump into our documentation\nAsk a question in our community forums\nSee more complex demos\nUse a neural net to analyze the Udacity Self-driving Car Image Dataset\nExplore a New York City rideshare dataset",
    name: "Streamlit Hello",
    category: "Starters",
    health: 88,
    code: "nj-Wms",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "185cbe00-a860-4353-a45d-b54ac989e8d6",
    isApproved: false,
    activeProjects: 325,
    projects: 798,
    description: "Self-hosted Ghost with MySQL and persistent volume.",
    readme:
      "###Overview\nGhost is a full-featured blogging platform and an open-source alternative to Medium, Substack, WordPress etc. It offers a comprehensive set of features to publish content, send newsletters, and offer paid subscriptions to members. It also offers detailed engagement analytics for your audience and content.\n\n###Template\nThis template deploys the community-maintained Docker image, along with an attached volume and a separate MySQL database, so that configuration and content can persist across deployments.\n\nNote: Once deployed, launch https://[RAILWAY_URL]/ghost to access the admin page and set up Ghost for the first time.\n\n###Mail Configuration\nIf you want to send transactional emails, please configure the following optional variables with valid details:\nmail__from: \nmail__transport: SMTP\nmail__options__host: \nmail__options__port:\nmail__options__auth__user:\nmail__options__auth__pass: \n\nFor bulk email newsletter delivery, you'll also need to configure the Mailgun service from Ghost Settings.\n",
    name: "Ghost + MySQL",
    category: "Blogs",
    health: 100,
    code: "tcsVLc",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1785a1bf-a83f-43bd-88fd-c44b714f6305",
    isApproved: false,
    activeProjects: 266,
    projects: 336,
    description: "Your own API Hub to learn & master API interaction",
    readme:
      "FreeAPI.app\n\nProblem\n\nWe are trying to build a single source API hub that can be used to learn api handling in any programming language. Users can build their front end portfolio in web and mobile apps using this api hub.\n\nWhat is FreeAPI.app\n\nThe FreeAPI project is an innovative and community-driven initiative aimed at providing developers with free and accessible APIs for their projects.\n\nThe project focuses on delivering a wide range of APIs that cater to various domains and functionalities, enabling developers to seamlessly integrate these APIs into their applications.\n\nKey highlights of the FreeAPI project include:\n\nAccessibility: The FreeAPI project is committed to eliminating barriers by providing free access to its collection of APIs.\n   Developers can leverage these APIs without any cost limitations, allowing them to experiment, learn, and build innovative applications.\n\nDiverse API Collection: The project offers a diverse and comprehensive collection of APIs that span across different industries, domains, and functionalities.\n   Whether you require social media integrations, payment gateways, machine learning algorithms, or IoT device connectivity, the FreeAPI project has you covered.\n\nSimplified Integration: The FreeAPI project understands the challenges developers face when integrating APIs into their applications. To address this, the project provides clear documentation, code samples, and SDKs, simplifying the integration process and reducing development time and effort.\n\nCommunity-Driven Development: The project fosters a vibrant and collaborative community of developers. Contributors are encouraged to share their knowledge, engage in discussions, and collaborate on API-related projects. This collective effort ensures the continuous improvement and reliability of the APIs offered by the FreeAPI project.\n\nLearning and Skill Development: The FreeAPI project aims to empower developers by providing a platform for learning and skill development. Through access to various APIs and educational resources, developers can enhance their understanding of API integration, expand their knowledge, and showcase their expertise through building complete projects.\n\nOverall, the FreeAPI project is a valuable resource for developers seeking accessible and diverse APIs.\n\nBy fostering a supportive community, the project empowers developers to learn, create, and innovate, ultimately contributing to the growth and advancement of the API integration landscape.\n\nFeatures:\n\nIntroducing our groundbreaking open source API hub project, a dynamic platform designed to revolutionize the way developers interact with APIs.\n\nWith an emphasis on openness, accessibility, and learning, our API hub empowers developers of all levels to explore, experiment, and grow their skills in API integration.\n\nHighlights:\n\nOpen Source: Our API hub is built on the principles of open source, ensuring transparency, collaboration, and community-driven development. This means that the source code is freely available, allowing developers to customize, extend, and contribute to the project.\n\nFree to Use: We firmly believe in removing barriers to entry, which is why our API hub is completely free to use. Whether you're a seasoned developer or just starting your coding journey, you can leverage our platform without any cost limitations.\n\nLocal or Deployment: Flexibility is at the core of our API hub. You have the option to use it locally, running on your own machine, or deploy it to a server, making it accessible to others. This versatility ensures that you can adapt the platform to your specific development environment.\n\nLearning Resource: Our API hub is designed as a comprehensive learning resource, offering a wealth of educational materials, tutorials, and documentation. Whether you're a beginner or seeking to expand your API knowledge, our platform provides the resources you need to learn and improve.\n\nCustom Endpoints for Beginners: For developers at the beginner level, our API hub offers custom endpoints that provide a hands-on experience in handling API responses. These beginner-friendly APIs allow you to practice and familiarize yourself with the basics of working with APIs.\n\nAdvanced APIs for Portfolio Building: In addition to beginner-level endpoints, our API hub also provides advanced APIs to challenge and stretch your skills. These APIs enable you to tackle more complex integration scenarios, helping you build a robust portfolio of projects to showcase your expertise.\n\nBy combining open source principles, accessibility, and a focus on learning, our API hub project paves the way for developers to thrive in the world of API integration. Join our vibrant community and embark on an exciting journey of discovery, growth, and innovation.",
    name: "FreeAPI.app",
    category: "Other",
    health: 75,
    code: "B2f7Hq",
    languages: ["JavaScript", "HTML", "Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a6c99bed-88bb-4a41-88c2-b5ffa968e5e1",
    isApproved: false,
    activeProjects: 76,
    projects: 221,
    description: "A single-node ClickHouse database",
    readme:
      "ClickHouse is the fastest and most resource efficient open-source database for real-time apps and analytics.\n\nBlazing fast\nLinearly scalable\nHighly reliable\n\nClickHouse processes analytical queries 100-1000x faster than traditional row-oriented systems with the same available I/O throughput and CPU capacity. Columnar storage format allows fitting more hot data in RAM, which leads to shorter response times.",
    name: "ClickHouse",
    category: "Storage",
    health: 91,
    code: "clickhouse",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9b4b2c0d-08e0-4d70-aa47-d4fbfe06ba48",
    isApproved: false,
    activeProjects: 47,
    projects: 170,
    description: "Use Railway Volumes with Django",
    readme:
      "Django with Volume Support Example\n\nThis example template starts a Django server utilizing volume support on Railway for storing and serving assets.\n\n‚ú® Features\n\nDjango\nRailway Volumes\nPython 3\n\nüíÅ‚Äç‚ôÄÔ∏è How to use\n\nClone locally and install packages with pip using pip install -r requirements.txt\nRun locally using python manage.py migrate && python manage.py collectstatic --noinput && gunicorn mysite.wsgi\n\nüìù Troubleshooting\nIf you get the following error No such file or directory: '/app/media/directory/...' make sure your directory exists since your folder structure has to be build from scratch for production purpose on the persistent storage.\n\nYou can use something like this:\n\nnew_directory = os.path.join(settings.MEDIA_ROOT, 'directory')\nif not os.path.exists(new_directory):\n  os.makedirs(new_directory)\n",
    name: "Django with Volume Support",
    category: "Starters",
    health: 90,
    code: "AWUIv6",
    languages: ["Python", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0d118ce9-e7e7-41b0-b51e-37934fd05cbb",
    isApproved: false,
    activeProjects: 97,
    projects: 155,
    description: "Deploying Flowise with Password and Username",
    readme:
      "This Template will deploy Flowise with two variables. This template will be updated with the latest repo of Flowise. \n\nMake sure after deployment to change your usernam and password. Default values are\n\n\nFLOWISE_USERNAME=Aisimp\nFLOWISE_PASSWORD=BuildingBots\n\n\nyou can then easily change them in the Flowise environment",
    name: "AISIMP-Railway-Flowise",
    category: "Other",
    health: 100,
    code: "K6fhmJ",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d88283df-6401-4274-bcc4-18dd77a5f56f",
    isApproved: false,
    activeProjects: 71,
    projects: 260,
    description: "Nextcloud server on Railway!",
    readme:
      "Tired of Google, OneDrive, Dropbox? Why not use Nextcloud on Railway to store all your files!\n\nThis template will automatically set you up for success with Nextcloud.\n\nEnvironment Variable Configuration\nPORT should be set to 80. Anything else and it won't work\nSQLITE_DATABASE you can give this any name you want with the .db file extension.\nNEXTCLOUD_TRUSTED_DOMAINS (not set by default) Optional space-separated list of domains\n\nIf there are any issues with it, just let me know in the Railway Discord, and I'll gladly fix them!",
    name: "Nextcloud",
    category: "Other",
    health: 100,
    code: "LddOJ1",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "01d538b6-4e54-449e-b3f3-c6dea187ab72",
    isApproved: false,
    activeProjects: 147,
    projects: 247,
    description: "A template for Telegram bot in JavaScript using grammY",
    readme:
      "Telegram-JavaScript-Bot is a simple Telegram bot made with JavaScript. It uses grammY\n\nFeatures:\nCategories for commands\nCommand handler (add commands in commands)\nError handler\nCommand aliases (check 8ball command, can add multiple aliases)\n\nCommands\n/start - Start the bot\n\nCategories\n\nUtilities\n/help - Show help\n\nFun\n/8ball - Ask the magic 8-ball a question\n\nEnvironment Variables\nBOT_TOKEN - Telegram bot token, get it from @BotFather\n",
    name: "Telegram JavaScript Bot",
    category: "Bots",
    health: 50,
    code: "5lRkWa",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "bf795bb4-c53f-4d94-9d4e-06d7bb00ab75",
    isApproved: false,
    activeProjects: 43,
    projects: 162,
    description: "Directus, PostgreSQL, Redis, S3",
    readme:
      "This railway deploy button combines Directus, Redis, PostgreSQL, and S3 to enable anyone to quickly deploy everything they need right away.\n\nThis will be updated soon to allow you to easily add any extension by editing the deployed config file. \n\nThis deploys Directus 10.5",
    name: "Directus Starter Kit",
    category: "CMS",
    health: 71,
    code: "ZOQXZf",
    languages: ["JavaScript", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1635338a-5451-483a-8ee6-af8ed9fa9877",
    isApproved: false,
    activeProjects: 3,
    projects: 8,
    description: "Quickly deploy directus docker with redis, pg and azure blog storage",
    readme:
      "The railway deploy button leverages Directus, Redis, and Azure Blob Storage for seamless railway management. Directus empowers admins to configure routes and schedules, while Redis optimizes data access speed. Azure Blob Storage efficiently handles multimedia content. Streamlined railway operations at your fingertips!",
    name: "Directus Azure and Redis",
    category: "CMS",
    health: null,
    code: "bFcsEC",
    languages: ["JavaScript", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e0304f30-bf3c-4bbd-950a-3d08d20e2833",
    isApproved: false,
    activeProjects: 5308,
    projects: 7611,
    description: "Flowise - low-code LLM apps builder",
    readme:
      "Click Deploy Now\n\nChange to your preferred repository name\n\nClick Deploy\n\nIf succeeds, you should be able to see a deployed URL\n\nTo add authorization, navigate to Variables tab and add:\nFLOWISE_USERNAME\nFLOWISE_PASSWORD\n\nYou can also add volume to the template by right clicking and select Add Volume\n\nSpecify a volume mount path. For instance: /opt/railway/.flowise\n\nThen add the following env variables:\nDATABASE_PATH - /opt/railway/.flowise\nAPIKEY_PATH - /opt/railway/.flowise\nLOG_PATH - /opt/railway/.flowise/logs\nSECRETKEY_PATH - /opt/railway/.flowise\n\nOr you can use the prebuilt template with volume -  https://railway.app/template/nEGbjR",
    name: "flowise-railway",
    category: "AI/ML",
    health: 100,
    code: "pn4G8S",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d6dd023f-1deb-4ffe-aae3-308e99a3055b",
    isApproved: false,
    activeProjects: 59,
    projects: 145,
    description: "The most popular admin web interface for PostgreSQL databases.",
    readme:
      "Overview\nThis template deploys pgAdmin, the most popular open-source administration and development platform for PostgreSQL databases.\n\nSee this page for the complete feature set, and this page for additional environment variables that can be configured during/after deployment to enhance pgAdmin capabilities.",
    name: "pgAdmin",
    category: "Other",
    health: 100,
    code: "h1EXJT",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "502a394a-08e6-4f2d-969f-4d6343956ed2",
    isApproved: false,
    activeProjects: 2,
    projects: 2,
    description: "An endpoint for kicking users with the ActiveFence extension.",
    readme:
      "Agora ActiveFence Kicker\n\nThe Agora ActiveFence Kicker is a Go package that provides a library for kicking users from Agora channels via the REST API. It is designed to work seamlessly with the ActiveFence backend, specifically expecting the same POST request format used at the \"/kick\" endpoint.\n\nSummary\n\nThis package serves as an essential component for managing user access and security within Agora channels. It integrates with the Agora platform, allowing you to enforce user removal when required, especially in conjunction with the ActiveFence extension.\n\nUsage\n\nTo incorporate this package into your own server, follow these steps:\n\nSet the following environment variables to configure the Agora integration:\n\n    APP_ID: Your Agora app ID.\n    CUSTOMER_KEY: Your Agora customer key.\n    CUSTOMER_SECRET: Your Agora customer secret.\n\nUtilize the provided methods and functionality within your server code to manage user kicks and enforce security protocols.\n\nGetting Started\n\nTo get started with the Agora ActiveFence Kicker, consider the following:\n\nInstallation: Clone the repository and build the package according to your project's needs.\nConfiguration: Ensure that the required environment variables are properly set for Agora integration.\n\nFor detailed usage examples and implementation guidelines, refer to the project's documentation and README.\n\nLicense\n\nThis project is open-source and available under the MIT License.\n\nNote: This is a basic overview. Refer to the project's documentation and README for comprehensive usage instructions and additional details.\n",
    name: "ActiveFence Kicker",
    category: "Other",
    health: null,
    code: "piHt63",
    languages: ["Go", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7f36097a-1377-4e07-bb24-f2c13ec7eed3",
    isApproved: false,
    activeProjects: 173,
    projects: 459,
    description: "Next.js 14.2.3 bundled with TailwindCSS and Shadcn UI",
    readme:
      "This template is a standard NextJS 14.2.3 deployment, configured with Typescript and the new App Router functionality. It's configured to use TailwindCSS out of the box, and is configured with shadcn UI for stylinigs. \n\nIt's meant to be a building block for quick projects using the newest NextJS features. ",
    name: "Next.js 14.2 (App Router)",
    category: "Starters",
    health: 88,
    code: "0csXuv",
    languages: ["TypeScript", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ff4b3ba0-8016-478d-b7dc-b8072fa1994d",
    isApproved: false,
    activeProjects: 11,
    projects: 22,
    description: "The cyber Swiss army knife.",
    readme:
      "##Template\nThis template deploys CyberChef, the cyber Swiss army knife. Just wait 1-2 mins after deployment for the web interface to be available.\n\n##Overview\nCyberChef, by GCHQ, is a simple web application for performing cryptographic operations like encoding/decoding, calculating hashes/checksums, and more, in the browser itself. It is designed for technical and non-technical professionals, and helps manipulate data in various ways without having to learn complex algorithms, install the underlying binaries, or maintain special environments for the tools. A cyber Swiss army knife if you will! CyberChef runs entirely client-side, in the browser, and does not send data to any web server.\n\nHere are some operations that you can perform with CyberChef:\nEncode a string in base-64 format / decode a base-64 encoded string\nAutomatically detect layers of nested encodings\nEncrypt/decrypt data with AES/DES/Blowfish and other ciphers\nConvert data from hexdump, and decompress the data\nConvert date/time to a different timezone, display multiple timestamps\nDecrypt and disassemble shell code\nSave, load, and share recipes i.e. sequences of repeatable steps\n\n##Learn More\nCyberChef: The Cyber Swiss Army Knife",
    name: "CyberChef",
    category: "Other",
    health: 100,
    code: "qsqC-R",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "870669cd-4932-4039-a7f3-b730e56bf31e",
    isApproved: false,
    activeProjects: 12,
    projects: 43,
    description: "A feature management/rollout software",
    readme:
      "Unleash - Feature management/rollout service\n\nUnleash - Feature management/rollout service\n\nUnleash is an open-source feature management/rollout service that provides a scalable and efficient way to manage feature toggles in software applications. It allows developers to easily enable or disable features in their applications without the need for redeployment, providing flexibility and control over feature releases.\n\nUnleash - Screenshot\n\nLicense\n\nUnleash is released under the MIT License, which allows for the free use, modification, and distribution of the software.\n\nDocumentation\n\nFor detailed documentation and usage instructions, please refer to the Unleash Documentation website.",
    name: "Unleash",
    category: "Observability",
    health: 100,
    code: "E53y3u",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8afeb7fd-e8ca-4de9-9bbb-29c81c99e392",
    isApproved: false,
    activeProjects: 2,
    projects: 13,
    description: "A simple NodeJS application to backup your MySQL database to S3 via a cron.",
    readme:
      "Overview\n\nThis template starts a small Node.js app that automatically creates a database dump and saves it to an S3 bucket by schedule.\n\nSetup\n\nTo start the app just need to add environment variables to specify the database (DB name, host, user, password), the S3 bucket you want the dump to be saved to (access ID, secret ID, bucket name, bucket region), and cron schedule.\n\nBy default, the cron is running daily at 5 am.",
    name: "MySQL backups to S3",
    category: "Automation",
    health: 0,
    code: "GRx3Mi",
    languages: ["TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "292dbcfa-eb54-4b29-b934-4db92865e86b",
    isApproved: true,
    activeProjects: 1642,
    projects: 4561,
    description: "A content management system (CMS) written in PHP",
    readme:
      "WordPress - Content management system (CMS)\n\nWordPress - Content management system (CMS)\n\nWordpress is a content management system (CMS) written in PHP. With a GNU Public License, an open-source software license that provides legal protection for the CMS and its derivative work, such as themes and plugins. WordPress empowers you to effortlessly create, manage, and customize stunning websites, making it the ultimate content management solution.\n\nWordPress - Screenshot\n\nDemo\n\nüì∫ A short video (&lt; 4 min) that goes over key concepts of\ncreating pages and posts in WordPress.\n\nAvailable plugins\n\nWordPress has 58,000+ different plugins to automate and simplify content management. The list can be found on:\nhttps://wordpress.org/plugins/\n\nDocumentation\n\nThe official WordPress documentation can be found on our documentation website\n\nAdditional information and example lessons on the Learn WordPress website\n\nThe release notes can be found here and the list of security\nchanges here.\n\nLicense\n\nWordPress is distributed under the\nGNU Public License.\n\nAdditional information about the license model can be found in the\ndocs.",
    name: "WordPress",
    category: "CMS",
    health: 100,
    code: "EP4wIt",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8ad65783-8ebd-497a-b813-e8ec2fd02736",
    isApproved: false,
    activeProjects: 200,
    projects: 451,
    description: "Open-source digital document signing",
    readme:
      "DocuSeal is an open-source, self-hosted platform for seamless digital document signing. Easily integrate, customize, and deploy with Railway for a hassle-free e-signature experience. Ideal for developers and enterprises seeking a reliable, customizable e-signature solution that integrates seamlessly with existing workflows.",
    name: "DocuSeal",
    category: "Automation",
    health: 100,
    code: "IGoDnc",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c05cebb1-8866-4a4f-b172-3d78e287d389",
    isApproved: false,
    activeProjects: 14,
    projects: 48,
    description: "Open-source LLM memory management.",
    readme:
      'Mot√∂rhead ü§ò\nMot√∂rhead is an open-source memory and information retrieval server for LLMs. It allows you to persist chat messages and other pieces of information to "memory" for a much longer period than the duration of a chat conversation. At its essence, Mot√∂rhead allows you to store messages, retrieve stored messages, and delete stored messages.\n\nRead More\nLLM Memory Management with Mot√∂rhead\nMot√∂rhead GitHub repo',
    name: "Mot√∂rhead",
    category: "AI/ML",
    health: 100,
    code: "WcLYat",
    languages: ["Rust", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f5053e64-b965-4cb5-bba6-cd4b49c6b04c",
    isApproved: true,
    activeProjects: 35265,
    projects: 49340,
    description: "A powerful workflow automation tool for technical people",
    readme:
      "n8n.io - Workflow Automation\n\nn8n - Workflow automation tool\n\nn8n is an extendable workflow automation tool. With a fair-code distribution model, n8n\nwill always have visible source code, be available to self-host, and allow you to add your own custom\nfunctions, logic and apps. n8n's node-based approach makes it highly versatile, enabling you to connect\nanything to everything.\n\nn8n.io - Screenshot\n\nDemo\n\nüì∫ A short video (&lt; 4 min) that goes over key concepts of\ncreating workflows in n8n.\n\nAvailable integrations\n\nn8n has 200+ different nodes to automate workflows. The list can be found on:\nhttps://n8n.io/integrations\n\nDocumentation\n\nThe official n8n documentation can be found on our documentation website\n\nAdditional information and example workflows on the n8n.io website\n\nThe release notes can be found here and the list of breaking\nchanges here.\n\nLicense\n\nn8n is fair-code distributed under the\nSustainable Use License and the\nn8n Enterprise License.\n\nProprietary licenses are available for enterprise customers. Get in touch\n\nAdditional information about the license model can be found in the\ndocs.",
    name: "N8N (w/ workers)",
    category: "Automation",
    health: 84,
    code: "r2SNX_",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b4066bb7-7fed-48d8-9454-d6759b0c78cb",
    isApproved: false,
    activeProjects: 9,
    projects: 24,
    description: "Node app to backup MySQL database and upload it to Cloudinary.",
    readme:
      "MySql Backup - Cloudinary\n\nNode.js application that performs scheduled backups of your MySQL database and uploads them to Cloudinary for secure storage. It utilizes a cron job to automate the backup process based on your desired frequency. The backups are saved in SQL format and can be easily restored if needed.\n\nPrerequisites\n\nNode.js and npm installed in the runtime environment.\nValid Cloudinary credentials and access to a MySQL database.\n\nSteps\n\nCreate a .env file in the project root(based on .env.example) and replace the values with your production keys(for production deployment, just create the keys on your server).\nConfigure the cron job in index.ts according to your preferences(take a look at the config.ts file ). For example, if you want to perform daily backups at 12:00 PM, use the following value:\n    const job = new CronJob(env.CRON_SCHEDULE.DAILY, async () =&gt; {\n  // ...\n  });\n\nUsage\n\nThe application will automatically perform scheduled backups of your database and upload them to Cloudinary. You can adjust the backup frequency by modifying the configuration in index.ts. If you want to run an immediate backup, you can uncomment the line void backup(); in index.ts before starting the cron job.\n\nScreenshots\n\nCloudinary\n\nDatabase\nThe folder for backups will be automatically created with the following name: databaseBackups/{currentYear}/Month-{currentMonth}\n\nSql backup script\n\nScreenshot 2\n",
    name: "MySql backups to Cloudinary",
    category: "Automation",
    health: 100,
    code: "mT6Hiw",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d1aeaac6-92de-43a8-a0a5-88515ca680fd",
    isApproved: false,
    activeProjects: 5,
    projects: 20,
    description: "Minimal Actix web application pre-configured with SQLx and database pooling",
    readme:
      "Overview\nActix is a powerful and highly performant web framework for building web servers in Rust. SQLx is an asynchronous, pure rust SQL library that provides compile-time checked queries without the need for a DSL.\n\nFeatures\nPerformance: Actix is designed with performance in mind. It leverages asynchronous and non-blocking I/O, making it capable of handling high levels of concurrency and achieving excellent throughput\nScalability: Actix is an actor framework for Rust. This allows Actix applications to handle thousands of concurrent connections efficiently\nActix Web servers are known for their low memory footprint compared to some other web frameworks\nCompile-time checked queries: Write typed, asynchronous SQL without the overhead of an ORM\nDatabase connection pooling: Improve performance by re-using existing database connections, rather than establishing a new database connection per request\n\nLearn More\nActix docs\nSQLx docs",
    name: "Actix Sqlx",
    category: "Starters",
    health: null,
    code: "4lz789",
    languages: ["Rust"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0015a0ca-e14d-482b-888b-6c7eee679dfe",
    isApproved: false,
    activeProjects: 22,
    projects: 46,
    description: "A Self-Hosted & Modern Roleplaying Platform",
    readme:
      'Important note - Buying a license\nThis template will fail if you don\'t provide a licensed account in the template settings. You need to buy a license from their official website (https://foundryvtt.com/) and add your username and password to the configuration of the template so it works properly.\n\nOverview\nFoundry Virtual Tabletop (Foundry VTT or "FVTT" for short) is an application built specifically for experiencing multiplayer tabletop role-playing games with your friends and party members over the internet. Foundry VTT works using modern web technologies where one player (the host) runs an application which hosts the game server and other players can connect using a web browser. As a "virtual tabletop", the software provides a set of digital tools which are designed to imitate and expand upon the experience of playing a game in-person with your friends. Support for character sheets, rolling dice, exploring battle maps, and moving heroic tokens are just a few of the many features which enable this experience. Foundry Virtual Tabletop goes well beyond the basic feature set, however, with rich dynamic lighting, fog of war, audio playlists, video chat using webcams, and way more. Foundry VTT gives you everything you need (and then some) to forge thrilling and memorable moments with your gaming group!\n\nDockerized version\nThis is based on the dockerized version of the software from https://github.com/felddy/foundryvtt-docker.',
    name: "Foundry Virtual Tabletop",
    category: "Other",
    health: 100,
    code: "X5tR6G",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8a0fc192-ae3c-4c8b-bbdb-fd842e2f837c",
    isApproved: false,
    activeProjects: 12,
    projects: 31,
    description: "A minimal Axum web server",
    readme:
      "Overview\nAxum is a web framework for building asynchronous and highly scalable applications in Rust with a strong focus on ergonomics and modularity.\n\nFeatures\nAsynchronous and Scalable: Build asynchronous applications that can handle high levels of concurrency\nErgonomic and Composable: Axum focuses on providing a clean and ergonomic API for web development. It offers intuitive and expressive abstractions for handling routing, middleware, and request/response handling\nPerformance: Axum is a thin layer on top of Hyper, which is a fast and correct HTTP implementation for Rust\nBuilt entirely with safe Rust\n\nLearn More\nAxum Repo",
    name: "Axum",
    category: "Starters",
    health: 100,
    code: "j-hp3L",
    languages: ["Rust"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2172efe2-2899-4da1-a973-bf5de0e8c95b",
    isApproved: false,
    activeProjects: 21,
    projects: 72,
    description: "Sveltekit with Prisma already configured",
    readme:
      "Overview\nBare-bones Sveltekit project with Typescript and Prisma.\n\nFeatures\nKeep your database schema close to your code with Prisma\n  Perform Typesafe queries\nESLint\nPrettier\nVitest\nPlaywright\n\nLearn More\nSveltekit Docs\nPrisma Docs",
    name: "Sveltekit Prisma",
    category: "Starters",
    health: 100,
    code: "sRATcT",
    languages: ["JavaScript", "TypeScript", "HTML", "Svelte"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b086727a-5700-4857-b3bc-98e2362c47ad",
    isApproved: true,
    activeProjects: 388,
    projects: 842,
    description: "A fancy self-hosted monitoring tool",
    readme:
      "\n    \n        \n    \n\n\nA fancy self-hosted monitoring tool\n\nUptime Kuma is an easy-to-use self-hosted monitoring tool.\n\nSupported databases\n\nMySQL\nPostgreSQL\nSQL Server\nOracle (experimental)\nMongoDB\nRedis\nSQLite\nAmazon Redshift\nCockroachDB\nMariaDB\n\nFeatures\n\nTable data editing, with SQL change script preview\nEdit table schema, indexes, primary and foreign keys\nCompare and synchronize database structure\nER diagram\nLight and dark theme\nMaster/detail views, foreign key lookups\nQuery designer\nForm view for comfortable work with tables with many columns\nJSON view on MongoDB collections\nExplore tables, views, procedures, functions, MongoDB collections\nSQL editor\n  execute SQL script\n  SQL code formatter\n  SQL code completion\n  Add SQL LEFT/INNER/RIGHT join utility\nMongo JavaScript editor, execute Mongo script (with NodeJs syntax)\nRedis tree view, generate script from keys, run Redis script\nRuns as application for Windows, Linux and Mac. Or in Docker container on server and in web Browser on client.\nImport, export from/to CSV, Excel, JSON, NDJSON, XML\nFree table editor - quick table data editing (cleanup data after import/before export, prototype tables etc.)\nArchives - backup your data in NDJSON files on local filesystem (or on DbGate server, when using web application)\nCharts, export chart to HTML page\nFor detailed info, how to run DbGate in docker container, visit docker hub\nExtensible plugin architecture\nPerspectives - nested table view over complex relational data, query designer on MongoDB databases",
    name: "Uptime Kuma",
    category: "Observability",
    health: 100,
    code: "p6dsil",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6e3d2e2f-3776-4a40-bdbc-7381ba1d210b",
    isApproved: false,
    activeProjects: 435,
    projects: 1257,
    description: "Open source object storage with an S3 compatible API",
    readme:
      "\n    \n        \n    \n\n\nOpen source object storage with an S3 compatible API\n\nMinIO is a High Performance Object Storage Server API compatible with S3\n\nOverview\n\nMinIO is a high-performance, S3 compatible object store. It is built for\nlarge scale AI/ML, data lake and database workloads. It is software-defined\nand runs on any cloud or on-premises infrastructure.\n\nS3 Compatibility\n\nS3 compatibility is a hard requirement for cloud-native applications. MinIO is unyielding in its adherence to the API and with tens of thousands of users - both commercial and community - MinIO's S3 implementation is the most widely tested and implemented alternative to AWS S3 in the world.\n\nHighlights\n\nThe Bucket service contains the MinIO server and attached volume.\nThe Console service contains the MinIO admin console.\n\nUploaded files are stored in a Railway persistent volume.\n\nLearn more at https://min.io",
    name: "MinIO",
    category: "Storage",
    health: 100,
    code: "SMKOEA",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "69661df6-365c-40e7-ad0f-b6089753d5fd",
    isApproved: false,
    activeProjects: 659,
    projects: 1401,
    description: "Open Source backend for your next SaaS and Mobile app in 1 file",
    readme:
      "Pocketbase\n\nOpen Source backend for your next SaaS and Mobile app in 1 file.\n\nRealtime Database\nEmbedded performant database with schema builder, data validations, realtime subscriptions and easy to use REST api.\n\nAuthentication\nManage your app users and handle email/password and OAuth2 sign ups (Google, Facebook, GitHub, GitLab) without the hassle.\n\nFile Storage\nSanely store files locally or in a S3 storage. Easily attach media to your database records and generate thumbs on the fly.\n\nExtendable\nUse as a standalone app or as Go framework, that you can extend via hooks to create your own custom portable backend. Provides official client SDKs for painless integration.\n",
    name: "Pocketbase",
    category: "Other",
    health: 100,
    code: "XfUmjI",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4d1c625d-d8ac-4a93-87d7-88b7edb526d6",
    isApproved: false,
    activeProjects: 226,
    projects: 566,
    description: "Meilisearch is a flexible and powerful user-focused search engine.",
    readme:
      "This template deploys a Meilisearch instance on Railway. Meilisearch is a flexible and powerful user-focused search engine that can be added to any website or application. \n\nLearn more at https://www.meilisearch.com/ and https://www.meilisearch.com/docs.",
    name: "Meilisearch",
    category: "Other",
    health: 88,
    code: "meilisearch",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a1e923de-7b73-472b-a392-4d3bbfaa10a5",
    isApproved: false,
    activeProjects: 9,
    projects: 35,
    description: "A minimal Actix web server",
    readme:
      "Overview\nActix is a powerful and highly performant web framework for building web servers in Rust\n\nFeatures\nPerformance: Actix is designed with performance in mind. It leverages asynchronous and non-blocking I/O, making it capable of handling high levels of concurrency and achieving excellent throughput\nScalability: Actix is an actor framework for Rust. This allows Actix applications to handle thousands of concurrent connections efficiently\nActix Web servers are known for their low memory footprint compared to some other web frameworks\n\nLearn More\nActix docs",
    name: "Actix",
    category: "Starters",
    health: null,
    code: "yOpd5I",
    languages: ["Rust"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4f604d37-c6ba-40ef-85a5-f019a3a78192",
    isApproved: false,
    activeProjects: 4,
    projects: 15,
    description: "Your Self-Hosted Notion-Style Note Taking App",
    readme:
      "Notea is a markdown, notion-like note-taking app stored using compatible S3 storage and accessible via any modern web browser. Works great as a Progressive Web App (PWA) on any device, including Android, iOS and iPad.\n\nDeploying with the 2 default parameters assumes you are using https://storj.io as your S3 storage provider. Please change or remove them if that is not the case.\n\nSee github for more details:\nhttps://github.com/bamtests/notea",
    name: "notea",
    category: "Other",
    health: null,
    code: "OhFC4F",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "363b78b1-cbbc-41ea-8f9e-14d216a20145",
    isApproved: false,
    activeProjects: 4,
    projects: 5,
    description: "Utility to convert between various subscription format",
    readme:
      "Railway-Subconverter\n\nÂú® railway.app ‰∏äÊê≠Âª∫ subconverter\n\nÂ∞ÜÈÖçÁΩÆÊñá‰ª∂Á≠âÊîæÂú® base/Êñá‰ª∂Â§πÂÜÖ\n\nrailway.app Â¶ÇËã•ÁΩëÁªú‰∏çÁïÖÔºåÂèØ‰ª•Ëá™Ë°åÊû∂ËÆæ cloudflare worker ‰Ωú‰∏∫‰∏≠ËΩ¨‰ª£ÁêÜÔºåÂêåÊó∂ÈôêÂà∂‰ªñ‰∫∫ÂØπÊé•Âè£ÁöÑÊª•Áî®Ôºö\n\nÂ§çÂà∂ cloudflare-worker.js ‰∏≠ÁöÑÂÜÖÂÆπÂà∞ cloudflare worker ÁºñËæëÈ°µÈù¢‰∏≠ÔºåÂπ∂‰∏î‰øÆÊîπ 1-27 Ë°åÔºàÊúâÊ≥®ÈáäÔºâ\n‰øÆÊîπÁ¨¨ 2 Ë°åÁöÑÁΩëÂùÄ‰∏∫‰Ω†ÁöÑ Railway ÂêéÁ´ØÂú∞ÂùÄÔºà‰∏çÂ∏¶Êú´Â∞æÁöÑ/ÊñúÊù†Ôºâ\nÂåπÈÖçÈªëÂêçÂçïÂÜÖ‰∏≠ÁöÑÂÖ≥ÈîÆËØçÊàñÊ≠£ÂàôÁöÑËÆ¢ÈòÖÁΩëÂùÄ‰ºöË¢´Â±èËîΩÔºåÈªòËÆ§Á¶ÅÁî®ËäÇÁÇπÊ±†ÁΩëÁ´ô‰ª•ÂèäÊîæÂú® github ‰∏äÁöÑËÆ¢ÈòÖÈìæÊé•\nÂè™ÊúâÁôΩÂêçÂçï‰∏≠ÁöÑ IP ‰ºöË¢´ÂÖÅËÆ∏‰ΩøÁî®ÔºàËøôÂäüËÉΩÂ•ΩÂÉèÊ≤°Áî®Ôºâ\n\nÊèê‰æõ‰∏Ä‰∏™ demo, firefly-sub.up.railway.app",
    name: "Firefly-Subconverter",
    category: "Other",
    health: null,
    code: "NNpoFR",
    languages: ["JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "655e45d4-ed62-42bc-8f7f-b5960f735a77",
    isApproved: false,
    activeProjects: 23,
    projects: 39,
    description: "Track all facets of your life!",
    readme:
      "Imagine you have a special notebook where you can write down all the media you have\nconsumed, like books you've read, shows you have watched, video games you have played or\nworkouts you have done. Now, imagine that instead of a physical notebook, you have a\nspecial tool on your computer or phone that lets you keep track of all these digitally.",
    name: "Ryot - Roll You Own Tracker!",
    category: "Analytics",
    health: null,
    code: "lwzKXe",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "fe2fd97c-881e-4bd0-8f0f-4713ac2d0448",
    isApproved: false,
    activeProjects: 3,
    projects: 12,
    description: "GoatCounter is an open source, privacy-friendly, web analytics platform",
    readme:
      'Overview\nGoatCounter is an open source web analytics platform available as a free donation-supported hosted service or self-hosted app. It aims to offer easy to use and meaningful privacy-friendly web analytics as an alternative to Google Analytics or Matomo. More about why it was made here.\n\nConfiguration\nThere are two environment variables that require manual updates (the default values for the rest are sufficient):\n\nSITE_USER_EMAIL=admin@email.com\nSITE_USER_PASSWORD=password\n\nThe site user email and password are both required to setup the goatcounter inital user. The email used need not exist, it will simply be used as the username for the goatcounter user - no activation email will be sent for this user. Additional users can be added in-app after signing in as this initial user.\n\nDeploy\nService\nIn order to successfully build and deploy the service, the Build Command and Start Command in the services\' General settings need to be updated.\nThe value for the Build Command should be set to:\n\ngo build ./cmd/goatcounter\n\nThe value for the Start Command should be set to:\n\n./goatcounter db create site -vhost ${HOST_DOMAIN} -user.email ${SITE_USER_EMAIL} -user.password ${SITE_USER_PASSWORD} -db ${DATABASE} -createdb &amp;&amp; ./goatcounter serve -db ${DATABASE} -listen 0.0.0.0:${PORT} -tls http\n\nNote: The Start Command above is only valid for the first time the service is deployed - it will create the database entries for the site and initial user.\nAfter the service has successfully deployed for the first time. This Start Command will need to be updated to remove the ./goatcounter db create site command.\nSo for subsequent deploys to be successful, it should be updated ot the following:\n\n./goatcounter serve -db ${DATABASE} -listen 0.0.0.0:${PORT} -tls http\n\nFailing to do so will result in the following deployment error:\n\ngoatcounter: there is already a site for the host ""\n\nWebsite\nSending metrics to your new goatcounter requires adding a `',
    name: "GoatCounter",
    category: "Analytics",
    health: null,
    code: "39H_-2",
    languages: ["Go", "JavaScript", "CSS", "HTML", "Shell", "PLpgSQL"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "345c5d2b-a27b-49a0-ae64-b6fc575a552a",
    isApproved: false,
    activeProjects: 284,
    projects: 609,
    description: "Create chatbots with ease",
    readme:
      "Dialoqbase is an open-source web application that allows you to create custom chatbots with your own knowledge base. It uses powerful llms to generate responses and PostgreSQL for vector search and storing the knowledge base.\n\n\nProject repo: https://github.com/n4ze3m/dialoqbase\n",
    name: "Dialoqbase",
    category: "AI/ML",
    health: 96,
    code: "TXdjD7",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "10fd27cf-3581-436b-8dcb-0b79a388496c",
    isApproved: false,
    activeProjects: 30,
    projects: 62,
    description: "An advanced boilerplate for bots using discord.py",
    readme:
      "Overview\n\nThis bot comes bundled with a bunch of things to make sure you kick-start your bot with most basic items that it needs.\n\nHighlights\n\nIntuitive cog-based architecture\nBase context and cogs for better scalability\n\nComes bundled with:\n  Logging\n  Boilerplate help command\n  Owner commands\n  Global error handler",
    name: "DiscordPy Advanced",
    category: "Bots",
    health: 50,
    code: "vdTx0A",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ab6247bf-df1b-4d32-9033-24c097544e33",
    isApproved: false,
    activeProjects: 591,
    projects: 2011,
    description: "Deploy an ecommerce backend and admin using Medusa",
    readme:
      "Note: this deploys a Medusa backend with two services supporting worker mode which is ideal for a production deployment. For testing, development, or simple use cases, you can use this template instead.\n\nDeploy a fully-fledged ecommerce backend and admin dashboard using Medusa.\n\nOnce the deployment finishes, you can access the admin dashboard at /app. Refer to this documentation to learn how to create an admin user.\n\nYou can refer to the Admin and Store API references to learn how to send requests to the Medusa backend.\n\nPlease note that this template doesn't use Redis or the production module for events and caching. Refer to the documentation to learn how to set them:\n\nSet redis_url in Medusa's configurations\nInstall and use the Redis Event Bus module\nInstall and use the Redis Cache module\n\nYou can refer to the Medusa documentation for guides related to troubleshooting, development, plugins, and more.\n\nPlease consider giving Medusa a star on GitHub.",
    name: "(v1) Medusa Backend with Worker Modes",
    category: "Other",
    health: 52,
    code: "zC7eOq",
    languages: ["TypeScript", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2415d6a0-75a7-4add-8925-370104b541c1",
    isApproved: false,
    activeProjects: 4,
    projects: 12,
    description: "VS Code in the browser, with full packages",
    readme:
      "Overview\n\nCoder is your self-hosted remote development platform.\n\nCoder shifts software development from local machines to on-prem and public cloud infrastructure. Onboard new developers in minutes, build code on powerful servers‚Äîall while keeping source code and data secure behind your firewall.\n\nThis template creates a dev environment that you can access from any device.\n\nHighlights\n\nCreate a code-server deployment on Railway\nWith Full Packages, like git-lfs, Ruby, Python, C, Node.js, HomeBrew, CMake, GitHub CLI, Deno, \nGo, Botway CLI, Rust, .NET, MongoDB, MySQL, Redis, PostgreSQL, Railway CLI and more\nRedeploy automatically after each change",
    name: "Botway CE",
    category: "Starters",
    health: 0,
    code: "9wleNz",
    languages: [
      "TypeScript",
      "Go",
      "Dockerfile",
      "Rust",
      "JavaScript",
      "Ruby",
      "Python",
      "PHP",
      "Dart",
      "C#",
      "PowerShell",
      "SCSS",
      "Kotlin",
      "Shell",
      "C",
      "Swift",
      "C++",
      "Nim",
    ],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ded91f40-c356-45b1-8d3a-de6f566e34ea",
    isApproved: false,
    activeProjects: 5,
    projects: 11,
    description: "Example Interval app for browsing your Spotify playlists.",
    readme:
      "Example app built with Interval for managing your Spotify playlists.\n\nIncludes a few features not found in the official Spotify app:\nShows key and tempo for tracks in playlists\nShows which playlist(s) tracks in your Liked Songs list are in\n\nRequirements\n\nRunning this app requires:\nA Spotify account and a registered Spotify app. You can register a new app here.\nA free Interval account.\n\nAfter creating your Spotify app, add the client ID and client secret to the project variables along with your Interval API key.\n\nYou'll also need to add the authorization URLs to the Spotify developer dashboard in order for the OAuth flow to work. Interval actions have two modes: Dev mode and Live mode. You'll need to add both URLs to the Spotify developer dashboard:\n\n// dev mode\nhttps://interval.com/dashboard/YOUR_ORG_SLUG/develop/actions/spotify/authorize\n// live mode\nhttps://interval.com/dashboard/YOUR_ORG_SLUG/actions/spotify/authorize\n\nTo add these URLs in the Spotify developer dashboard:\n\nClick Edit Settings\nGo to the Redirect URIs section\nPaste each URL into the text input and click Add\n\nIf you get an Invalid Redirect URI error, double check that the action URL in your browser matches the URL you added to Spotify.\n\nNeed help with this app? Come chat with us in the Interval discord: http://interval.com/discord\n\nOr open an issue on the GitHub repo: https://github.com/danphilibin/interval-spotify-app",
    name: "Interval Spotify Manager",
    category: "Starters",
    health: null,
    code: "tkbFsY",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6bab3311-3fc4-4666-9ddf-ac56f44d3ad5",
    isApproved: false,
    activeProjects: 10,
    projects: 15,
    description: "A template for running a Gleam + Mist webserver on Railway.",
    readme:
      "This is a template for running a fault-tolerant Mist webserver written in Gleam on the Erlang BEAM VM. Gleam is a simple, statically-typed functional language with Rust-like syntax and a lightning-fast compiler.",
    name: "railway-gleam",
    category: "Starters",
    health: null,
    code: "ICq88z",
    languages: ["Gleam", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "7ef8f4e6-ea0b-42ff-bc68-f19e01a10fa0",
    isApproved: false,
    activeProjects: 6,
    projects: 29,
    description: "CodiMD - The best platform to write and share markdown.",
    readme:
      "CodiMD is an open-source real-time collaborative markdown editor. It allows multiple users to edit markdown documents simultaneously and see each other's changes in real-time. Markdown is a lightweight markup language that is easy to read and write, and CodiMD provides a convenient platform for collaborative editing and document sharing.\n\nCodiMD is designed to be user-friendly and intuitive, providing a simple and clean interface for creating and editing markdown documents. It supports various markdown features such as headings, lists, links, images, code blocks, and more. Users can also preview their markdown content in real-time, making it easier to see how the final document will look.\n\nOne of the key features of CodiMD is its real-time collaboration capabilities. Multiple users can access and edit the same document simultaneously, and their changes are synced in real-time. This makes it an excellent tool for team collaboration, allowing users to work together on documents, take notes, brainstorm ideas, and more.\n\nCodiMD can be self-hosted, meaning you can install it on your own server or use a hosted version provided by an organization or service. It is built using web technologies such as JavaScript, Node.js, and WebSocket for real-time communication.\n\nOverall, CodiMD is a versatile and powerful tool for collaborative markdown editing, making it easier for teams to work together on documents and share ideas in real-time.",
    name: "CodiMD",
    category: "CMS",
    health: null,
    code: "YcOXBV",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "cfb815c0-9930-43c0-a71d-8be983272da4",
    isApproved: false,
    activeProjects: 99,
    projects: 166,
    description: "Sample Pinecone apps for document summarization and question-answering.",
    readme:
      "Template\nThis template deploys sample Streamlit web apps for document summarization and generative question-answering using LangChain and Pinecone.\n\nHighlights\nLangChain is an open-source framework created to aid the development of applications leveraging the power of large language models (LLMs). It can be used for chatbots, text summarisation, data generation, code understanding, question answering, evaluation, and more. Pinecone, on the other hand, is a fully managed vector database, making it easy to build high-performance vector search applications without infrastructure hassles. Once you have generated the vector embeddings using a service like OpenAI Embeddings, you can store, manage and search through them in Pinecone to power semantic search, recommendations, and other information retrieval use cases. See this post on LangChain Embeddings for a primer on embeddings and sample use cases.\n\nLearn More\nSummarize Documents with LangChain and Pinecone\nlangchain-pinecone-summary GitHub repo\nGenerative Question-Answering with LangChain and Pinecone\nlangchain-pinecone-qa GitHub repo\n",
    name: "Pinecone",
    category: "AI/ML",
    health: 100,
    code: "Rg70kF",
    languages: ["Python", "Jupyter Notebook"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "363111d2-c469-408b-9fd4-f988ce38e0d5",
    isApproved: false,
    activeProjects: 117,
    projects: 343,
    description: "The open and composable observability and data visualisation platform.",
    readme:
      "The Grafana Template is a comprehensive starting point for creating a monitoring dashboard with Grafana. This template is specifically designed to help administrators visualise and analyse critical data related to infrastructure, operations and performance.\n\nIt is an open-source data visualization and monitoring platform that allows users to create, explore, and share interactive dashboards. It provides a powerful and flexible way to visualize time series data from various sources, such as databases, cloud services, and custom applications.\n\nOne of the key features of Grafana is its ability to connect to a wide range of data sources, including popular databases like MySQL, PostgreSQL, and Prometheus, as well as cloud platforms like Amazon Web Services (AWS) and Microsoft Azure. This flexibility enables users to consolidate data from different systems into a single interface for monitoring and analysis.\n\nWith Grafana, users can create visually appealing dashboards by adding various panels, such as graphs, tables, and gauges, to display their data. These panels can be customized with different visualization options, such as line charts, bar charts, heatmaps, and more. Users can also apply functions and transformations to the data, perform aggregations, and set alert conditions based on specific thresholds.\n\nIt supports interactive exploration of data, allowing users to zoom in and out of time ranges, drill down into specific data points, and apply filters to focus on specific aspects of the data. It also provides features for annotation, where users can add contextual notes and comments to the dashboards, helping to provide additional insights and explanations.\n\nAnother notable feature of Grafana is its plugin system, which allows users to extend its capabilities and integrate with additional data sources, visualization options, and authentication methods. The plugin ecosystem is extensive, with a wide range of community-developed plugins available for use.\n\nIt has gained popularity in various industries and is widely used for monitoring and observability purposes, including infrastructure monitoring, application performance monitoring (APM), and business intelligence. Its user-friendly interface, rich visualization options, and extensibility make it a popular choice for organizations and individuals looking to gain insights from their data in a flexible and customizable manner.",
    name: "Grafana",
    category: "Analytics",
    health: 96,
    code: "anURAt",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3108c93a-cf16-4dad-ab66-d12795a25919",
    isApproved: false,
    activeProjects: 116,
    projects: 187,
    description: "Flow-based programming tool for wiring together hardware devices, APIs, ‚Ä¶",
    readme:
      "Demo\n\n| Key            |  Value    |\n|------------|---------|\n| Username  |  admin  |\n| Password   |  admin  |\n\nBackend: https://demo-nodered.up.railway.app/\n\nWhat is Node-RED\n\nNode-RED is an open-source, flow-based programming tool that provides a visual interface for connecting and wiring together hardware devices, APIs (Application Programming Interfaces), and online services. It simplifies the process of creating complex workflows by allowing users to drag and drop nodes representing different functions and connect them to define the flow of data and interactions between various components. With its extensive library of pre-built nodes, Node-RED enables the rapid development of IoT (Internet of Things) applications, data integrations, and automation tasks without the need for traditional coding. Its intuitive visual interface, combined with a vast ecosystem of contributed nodes, makes Node-RED a powerful tool for building scalable and interconnected systems with ease.",
    name: "Node-RED",
    category: "Automation",
    health: 100,
    code: "56bdr8",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "bf71f608-f609-4c4d-a3ab-b626b1cb246c",
    isApproved: false,
    activeProjects: 29,
    projects: 68,
    description: "InfluxDB is a programmable and performant time series database.",
    readme:
      "InfluxDB is an open-source, high-performance time-series database designed to handle large volumes of timestamped data. It is commonly used for storing, querying, and analyzing time-series data generated by various applications, systems, and sensors.\n\nKey Features of InfluxDB:\n\nTime-Series Data Storage: InfluxDB is optimized for efficiently storing and retrieving time-stamped data, such as metrics, events, and sensor readings. It organizes data based on time, allowing for fast and efficient retrieval of historical and real-time data.\n\nSchema-less Design: InfluxDB does not enforce a rigid schema for data storage, providing flexibility in adding or modifying data points without requiring predefined tables or columns. This makes it easy to adapt to changing data structures and evolving requirements.\n\nTagging and Field Concept: InfluxDB uses a tagging system to add metadata to data points, which helps in organizing and categorizing the data. Additionally, each data point consists of one or more fields that represent the actual measured values. This combination of tags and fields enables efficient querying and filtering of data.\n\nQuerying Language: InfluxDB provides its own query language called InfluxQL (Influx Query Language) that is specifically designed for time-series data. It supports various functions and operators for filtering, aggregating, and manipulating data, allowing users to perform complex queries and calculations.\n\nContinuous Queries: InfluxDB allows the creation of continuous queries, which are predefined queries that automatically aggregate data at a specified interval. This feature is useful for downsampling data to reduce storage requirements while retaining key metrics over longer time periods.\n\nRetention Policies: InfluxDB supports retention policies, which define the duration for which data is retained in the database. This feature enables efficient data management by automatically purging or down-sampling data based on the defined policies.\n\nHigh Write and Query Performance: InfluxDB is designed to handle high write and query loads efficiently. It utilizes a time-structured storage format and various optimizations to ensure fast data ingestion and retrieval, making it suitable for real-time monitoring and analytics applications.\n\nIntegration with Other Tools: InfluxDB integrates with a wide range of tools and frameworks commonly used in the data ecosystem, such as Grafana (for visualization), Telegraf (for data collection), and Kapacitor (for real-time stream processing and alerting).\n\nInfluxDB finds applications in various domains, including monitoring and observability, IoT (Internet of Things) analytics, financial data analysis, industrial process control, and more. Its focus on time-series data and its performance characteristics make it a popular choice for storing and analyzing time-stamped data efficiently.",
    name: "InfluxDB",
    category: "Analytics",
    health: 87,
    code: "fwbafn",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "beabb436-a3b6-4c92-bb18-fac3dc503987",
    isApproved: false,
    activeProjects: 3,
    projects: 7,
    description: "A high-performance gateway for GraphQL microservices",
    readme:
      'Apollo Federation allows you to create a single graph from multiple GraphQL microservices‚Äîproviding the convenience of a single GraphQL server for the frontend without the burden of a monolith on the backend.\n\nApollo Router is a high-performance entrypoint for your federated microservices packed with performance and security features.\n\nThis template lets you quickly deploy a router that you can point at your Apollo GraphOS account to immediately start building a federated "supergraph".',
    name: "Apollo Router",
    category: "Starters",
    health: 100,
    code: "A-6SvK",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ceb2c2fa-d9e6-470f-95a5-eff978b250db",
    isApproved: false,
    activeProjects: 44,
    projects: 82,
    description: "A starter template for Ktor.",
    readme:
      "Ktor is a highly flexible and versatile Kotlin framework that offers a powerful set of tools for building modern web applications. Ktor is designed with simplicity, scalability, and reliability in mind, making it an excellent choice for developers who want to create highly performant and scalable web applications.\n\nHighlights\n\nLightweight and versatile Kotlin framework\nEasy-to-use API for fast development and deployment\nModular design for customized feature selection\nSupports HTTP, WebSockets, routing, and more\nHighly customizable and extensible with modules\nBuilt-in testing and debugging tools\nScalable and reliable for microservices, REST APIs, and backend apps\nDesigned for simplicity and productivity.",
    name: "Ktor Starter",
    category: "Starters",
    health: null,
    code: "zB6nSu",
    languages: ["Kotlin"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "00004a57-4d37-4004-88d0-6561554e560e",
    isApproved: false,
    activeProjects: 51,
    projects: 104,
    description: "Chat Chat, your own unified chat and search to AI platform.",
    readme:
      "Chat Chat\n\nYour own unified chat and search to AI platform, with a simple and easy to use interface.\n\nOpenAI + Cohere + Google Gemini + Anthropic + ...\n\nGet real-time data from AI Search\n\nAI may generate inappropriate content, please use it with caution.",
    name: "Chat Chat",
    category: "AI/ML",
    health: 100,
    code: "-WWW5r",
    languages: ["TypeScript", "CSS", "Dockerfile", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c5222f23-c395-40d7-bd46-2016b9042e4a",
    isApproved: false,
    activeProjects: 329,
    projects: 696,
    description: "An Express server written in TypeScript.",
    readme:
      "Overview\n\nExpress is a Fast, unopinionated, minimalist web framework for Node.js. TypeScript is a statically typed superset of JavaScript that adds optional type annotations, enabling safer and more maintainable code.\n\nThis template combines Express and Typescript to make a perfect starter for building APIs and early development.\n\nHighlights\n\nExpress\nTypescript\nVersioned API route on /api/v1/hello\nEnvironment variable setup using dotenv\n\nLearn More\n\nExpress\nTypescript",
    name: "ExpressJS API",
    category: "Starters",
    health: 88,
    code: "n_2mnn",
    languages: ["TypeScript", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1c7635c6-63e1-4f4b-be55-b44f3002fbe7",
    isApproved: false,
    activeProjects: 4,
    projects: 6,
    description: "A simple KTOR Blog server made with Kotlin",
    readme:
      "Welcome to Blog App (API)!\n\nBlog app backend REST API is built with Ktor framework with H2 as database and deployed on Railway.\nCurrently the api is deployed on web-production-147b.up.railway.app link\n\nüìÑ Visit the documentation of this project (Swagger/OpenAPI) to get more information in detail.\nDeploy To Railway\nDeploy on Railway\nYou can use this link to deploy your instance at railway (https://railway.app/template/Ty7Bjd?referralCode=lanL14)\n\nFeatures\nEasy structure\nAuthentication ( JWT )\nCI/CD deployment using railway.app\ntest cases to be added\n\nAbout This Project\n\nBuilt with üõ†\n\nKtor - Ktor is an asynchronous framework for creating microservices, web applications, and more. It‚Äôs fun, free, and open source.\nExposed - An ORM/SQL framework for Kotlin.\nH2 DB   --   Embedded and server modes; in-memory databases,-   Very fast, open source, JDBC API\n\n",
    name: "Ktor Blog App",
    category: "Other",
    health: 100,
    code: "Ty7Bjd",
    languages: ["Kotlin", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "fe8277c1-aabb-4dea-b940-c27b36b1522f",
    isApproved: false,
    activeProjects: 11,
    projects: 29,
    description: "Sample LangChain app to demo LLM observability using Helicone.",
    readme:
      "Template\nThis template deploys a sample Streamlit web application to demo LLM observability using LangChain and Helicone.\n\nHighlights\nLangChain is an open-source framework created to aid the development of applications leveraging the power of large language models (LLMs). It can be used for chatbots, text summarisation, data generation, code understanding, question answering, evaluation, and more. Helicone, on the other hand, is an open-source tool for tracking costs, usage, and latency for LLM-powered applications.\n\nLearn More\nOpen-Source LLM Observability with Helicone\nlangchain-helicone GitHub repo\nhelicone GitHub repo\nOpen Python notebook in Google Colab",
    name: "Helicone",
    category: "AI/ML",
    health: null,
    code: "zu7Q6k",
    languages: ["Python", "Jupyter Notebook"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "110d2efe-48cc-4f38-ad8c-b6dcdf12e948",
    isApproved: false,
    activeProjects: 7,
    projects: 9,
    description: "quote message generator api",
    readme:
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus nec vulputate elit. Vivamus ultricies tristique lacus, vel elementum massa posuere at. Maecenas tempus accumsan magna in tempus. Duis pretium posuere erat, vitae fermentum libero egestas at. Cras nec dolor est. Morbi faucibus velit nec libero commodo, sed feugiat ex semper. Donec eu nibh magna. Etiam gravida condimentum consequat. Sed turpis velit, dignissim eget odio ut, consectetur placerat nisi. Fusce metus arcu, egestas ut faucibus id, pellentesque id dui. Morbi lobortis mattis mattis. Donec tristique est at congue molestie.\n\nNullam risus enim, fermentum non sem a, dictum tristique enim. Mauris et pharetra augue, sed euismod sapien. Phasellus ut efficitur tortor. In sodales dapibus neque lobortis ultricies. Aliquam porttitor elementum ex ut pulvinar. Nullam vehicula sollicitudin varius. Etiam fermentum, urna in vestibulum consequat, lectus lectus varius urna, non hendrerit ligula libero et est. Etiam venenatis ipsum nibh. Aliquam quis felis eu sem maximus vulputate. Vestibulum non est condimentum, aliquet dolor vel, porta dolor. Phasellus sodales varius vehicula. Phasellus scelerisque id eros in mattis.",
    name: "QUOTE-API",
    category: "Other",
    health: null,
    code: "0K26m0",
    languages: ["JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6521d550-5d53-4822-b84e-6f8402eaa3d7",
    isApproved: false,
    activeProjects: 798,
    projects: 1121,
    description: "An open-source ChatGPT UI alternative.",
    readme:
      "Overview\nChatGPT Next Web is an open-source ChatGPT UI alternative built using Next.js, TypeScript, and CSS. It can be deployed locally, or hosted on platforms like Railway, Vercel, and more.\n\nProvide the following values during deployment or later:\nOPENAI_API_KEY: OpenAI API key\nCODE (optional): Comma-separated codes to password-protect your deployment\n\nFeatures\nOne-click deploy on Railway and Vercel\nPrivacy first, all data stored locally in the browser\nResponsive design, dark mode and PWA\nFast first screen loading speed (~100kb), support streaming response\nCreate, share and debug your chat tools with prompt templates (mask)\nAwesome prompts powered by awesome-chatgpt-prompts-zh and awesome-chatgpt-prompts\nAutomatically compresses chat history to support long conversations while also saving your tokens\nOne-click export all chat history with full Markdown support\n\nLearn More\nGitHub Repo",
    name: "ChatGPT Next Web",
    category: "Other",
    health: 90,
    code: "Mvjjpn",
    languages: ["TypeScript", "SCSS", "JavaScript", "Shell", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f4afe3d3-176d-400f-9ebf-de963805ca0d",
    isApproved: false,
    activeProjects: 39,
    projects: 165,
    description: "üßô A modern replacement for Airflow.",
    readme:
      "\n  \n    \n  \n\n\n  üßô A modern replacement for Airflow.\n\nGive your data team magical powers\n\n\n\n\n  Integrate and synchronize data from 3rd party sources\n\n\n\n  Build real-time and batch pipelines to transform data using Python, SQL, and R\n\n\n\n  Run, monitor, and orchestrate thousands of pipelines without losing sleep\n\n\n\n\n1Ô∏è‚É£ üèóÔ∏è\nBuild\n\n  Have you met anyone who said they loved developing in Airflow?\n  \n  That‚Äôs why we designed an easy developer experience that you‚Äôll enjoy.\n\n\n|   |   |\n| --- | --- |\n| Easy developer experienceStart developing locally with a single command or launch a dev environment in your cloud using Terraform.Language of choiceWrite code in Python, SQL, or R in the same data pipeline for ultimate flexibility.Engineering best practices built-inEach step in your pipeline is a standalone file containing modular code that‚Äôs reusable and testable with data validations. No more DAGs with spaghetti code. |  |\n\n\n  ‚Üì\n\n\n2Ô∏è‚É£ üîÆ\nPreview\n\n  Stop wasting time waiting around for your DAGs to finish testing.\n  \n  Get instant feedback from your code each time you run it.\n\n\n|   |   |\n| --- | --- |\n| Interactive codeImmediately see results from your code‚Äôs output with an interactive notebook UI.Data is a first-class citizenEach block of code in your pipeline produces data that can be versioned, partitioned, and cataloged for future use.Collaborate on cloudDevelop collaboratively on cloud resources, version control with Git, and test pipelines without waiting for an available shared staging environment. |  |\n\n\n  ‚Üì\n\n\n3Ô∏è‚É£ üöÄ\nLaunch\n\n  Don‚Äôt have a large team dedicated to Airflow?\n  \n  Mage makes it easy for a single developer or small team to scale up and manage thousands of pipelines.\n\n\n|   |   |\n| --- | --- |\n| Fast deployDeploy Mage to AWS, GCP, or Azure with only 2 commands using maintained Terraform templates.Scaling made simpleTransform very large datasets directly in your data warehouse or through a native integration with Spark.ObservabilityOperationalize your pipelines with built-in monitoring, alerting, and observability through an intuitive UI. |  |\n\nüßô Intro\n\nMage is an open-source data pipeline tool for transforming and integrating data.\n\nInstall\nDemo\nTutorials\nDocumentation\nFeatures\nCore design principles\nCore abstractions\nContributing\n\nLooking for help? The fastest way to get started is by checking out our documentation here.\n\nLooking for quick examples? Open a demo project right in your browser or check out our guides.\n\nüéÆ Demo\n\nLive demo\n\nBuild and run a data pipeline with our demo app.\n\n&gt; WARNING\n&gt;\n&gt; The live demo is public to everyone, please don‚Äôt save anything sensitive (e.g. passwords, secrets, etc).\nDemo video (5 min)\n\nMage quick start demo\n\nClick the image to play video\n\nüë©‚Äçüè´ Tutorials\n\nLoad data from API, transform it, and export it to PostgreSQL\nIntegrate Mage into an existing Airflow project\nTrain model on Titanic dataset\nSet up dbt models and orchestrate dbt runs\n\nüîÆ Features\n\n|   |   |   |\n| --- | --- | --- |\n| üé∂ | Orchestration | Schedule and manage data pipelines with observability. |\n| üìì | Notebook | Interactive Python, SQL, &amp; R editor for coding data pipelines. |\n| üèóÔ∏è | Data integrations | Synchronize data from 3rd party sources to your internal destinations. |\n| üö∞ | Streaming pipelines | Ingest and transform real-time data. |\n| ‚ùé | dbt | Build, run, and manage your dbt models with Mage. |\n\nA sample data pipeline defined across 3 files ‚ûù\n\nLoad data ‚ûù\n    @data_loader\n    def load_csv_from_file():\n        return pd.read_csv('default_repo/titanic.csv')\nTransform data ‚ûù\n    @transformer\n    def select_columns_from_df(df, *args):\n        return df['Age', 'Fare', 'Survived']]\nExport data ‚ûù\n    @data_exporter\n    def export_titanic_data_to_disk(df) -&gt; None:\n        df.to_csv('default_repo/titanic_transformed.csv')\n\nWhat the data pipeline looks like in the UI ‚ûù\n\n\n\nNew? We recommend reading about [blocks and\nlearning from a hands-on tutorial.\n\nAsk us questions on Slack\n\nüèîÔ∏è Core design principles\n\nEvery user experience and technical design decision adheres to these principles.\n\n|   |   |   |\n| --- | --- | --- |\n| üíª | Easy developer experience | Open-source engine that comes with a custom notebook UI for building data pipelines. |\n| üö¢ | Engineering best practices built-in | Build and deploy data pipelines using modular code. No more writing throwaway code or trying to turn notebooks into scripts. |\n| üí≥ | Data is a first-class citizen | Designed from the ground up specifically for running data-intensive workflows. |\n| ü™ê | Scaling is made simple | Analyze and process large data quickly for rapid iteration. |\n\nüõ∏ Core abstractions\n\nThese are the fundamental concepts that Mage uses to operate.\n\n|   |   |\n| --- | --- |\n| Project | Like a repository on GitHub; this is where you write all your code. |\n| Pipeline | Contains references to all the blocks of code you want to run, charts for visualizing data, and organizes the dependency between each block of code. |\n| Block | A file with code that can be executed independently or within a pipeline. |\n| Data product | Every block produces data after it's been executed. These are called data products in Mage. |\n| Trigger | A set of instructions that determine when or how a pipeline should run. |\n| Run | Stores information about when it was started, its status, when it was completed, any runtime variables used in the execution of the pipeline or block, etc. |\n\nü§î Frequently Asked Questions (FAQs)\n\nCheck out our FAQ page to find answers to some of our most asked questions.\n\nü™™ License\nSee the LICENSE file for licensing information.\n\n\n\n",
    name: "Mage AI",
    category: "AI/ML",
    health: 88,
    code: "Cr5cge",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "905e8aec-ec98-449d-9056-79511685065b",
    isApproved: false,
    activeProjects: 13,
    projects: 41,
    description: "A working Kotlin Spring template",
    readme:
      "Shipping a Kotlin Spring app is easy with Gradle and Railway. Just add the necessary packages to your build.gradle file and you're good to go! Whether you need database connectivity, RESTful APIs, or any other functionality, Gradle makes it simple to manage dependencies and package your app for deployment. With Gradle's powerful build system, you can focus on developing your app and trust that Gradle will handle the heavy lifting of packaging and shipping.\n",
    name: "Kotlin Spring",
    category: "Starters",
    health: null,
    code: "4d79dj",
    languages: ["Kotlin"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9892537d-dc29-4906-b694-17800f66d896",
    isApproved: false,
    activeProjects: 29,
    projects: 55,
    description: "A MidJourney Wrapper named DandJourney!",
    readme:
      "Êú∫Âô®‰∫∫ÂàõÂª∫\n\nÊ≥®ÂÜå‰∏Ä‰∏™Êú∫Âô®‰∫∫\n\nËøõÂÖ•DiscordÂºÄÂèëËÄÖÂπ≥Âè∞\nÁÇπÂáªÊ≥®ÂÜåÁªÑ‰ª∂\nimage\n\nÁÇπÂáªÊ≥®ÂÜåÁªÑ‰ª∂Âπ∂Â°´ÂÜô‰ø°ÊÅØ\n\nimage\n\nÁÇπÂáªBotËøõÂÖ•Êú∫Âô®‰∫∫ËÆæÁΩÆÈ°µÈù¢\nimage\n\nÂãæÈÄâ‰∏ãÊñπÁöÑ‰∏â‰∏™ÈÄâÈ°π(ÊòØÂê¶ÂÖÅËÆ∏Êú∫Âô®‰∫∫Êî∂ÂèëÊ∂àÊÅØÁ≠â)Âπ∂Ëé∑ÂæóÂèòÈáè BOT_TOKEN(String)\nimage\nimage\n\nÁÇπÂáªOAuth2 -> URL GeneratorÔºåË∞ÉÊï¥ËÆæÁΩÆÁîüÊàêÈìæÊé•\n\nimage\nimage\n\nËÆøÈóÆÁîüÊàêÁöÑÈìæÊé•ÔºåÈÄâÊã©ÊúçÂä°Âô®Ôºå‰ªªÂä°ÂÆåÊàêüéâ\n\nËé∑ÂæóÈ¢ëÈÅì‰ø°ÊÅØ\n\nËøõÂÖ•‰Ω†ÊâÄÈúÄË¶ÅÁöÑÈ¢ëÈÅì\nÊ≠§Êó∂urlÁöÑÂÜÖÂÆπ‰∏∫ https://discord.com/channels/ SERVER_ID(Integer) /  CHANNEL_ID(Integer)\n\nÊ∞™ÈáëÁé©ÂÆ∂ÁöÑ‰ª£Âè∑\n\n‰ΩøÁî®Ê∞™ÈáëË¥¶Âè∑Èöè‰æøÊâßË°å‰∏ÄÊù°Êåá‰ª§\nÂú®ÂºÄÂèëËÄÖÂ∑•ÂÖ∑ -> ÁΩëÁªú ‰∏≠ÊâæÂà∞ÊúÄËøëÁöÑ interactions ËØ∑Ê±ÇÔºåÂú®ËØ∑Ê±ÇÊ†áÂ§¥‰∏≠ÊâæÂà∞ authorization: VIP_TOKEN(String) \n\nËá™Ê≠§ÔºåÂÖ≥‰∫éDandJourneyÂÆèËßÇÈÖçÁΩÆÁöÑÂõõ‰∏™ÂèòÈáèÂ∑≤ÁªèÊî∂ÈõÜÂÆåÊØï\n\nTips: ÈúÄË¶ÅÂ∞ÜÊú∫Âô®‰∫∫ÁöÑÈÖçÁΩÆËÆæÁΩÆ‰∏∫Â¶ÇÂõæÊâÄÁ§∫Ôºå‰ª•ÂÖçËá™Â∏¶ÂèÇÊï∞ÂΩ±ÂìçÂõæÁâáÁîüÊàê\nimage\nÊú∫Âô®‰∫∫ÈÉ®ÁΩ≤\n\nÈÉ®ÁΩ≤ÂâçÁöÑÂáÜÂ§á\n\nÁõÆÂâçËøòÁº∫Â§±‰∏§‰∏™ÂèÇÊï∞ÔºöBOT_NAME Âíå CHANNEL_SIGN\n\nBOT_NAME ‚òû Êú∫Âô®‰∫∫ÁöÑÂêçÁß∞\nCHANNEL_SIGN ‚òû ÊòØÂê¶ÈúÄË¶ÅÈÄÇÂ∫î‰∏çÂêåÈ¢ëÈÅì(ÈªòËÆ§‰∏∫True)",
    name: "DandJourney",
    category: "Bots",
    health: null,
    code: "aWVdcq",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a47a23f4-2dc8-4fa7-b0aa-a0e8f9fd5127",
    isApproved: false,
    activeProjects: 46,
    projects: 120,
    description: "A lightweight FastAPI starter, with some batteries included.",
    readme:
      "ü™∂ Featherweight Template\n\nA lightweight FastAPI starter that packs a punch, with some batteries included.\n\nGet more done with less by relying on powerful open-source tools to do the heavy lifting.\n\nFastAPI generates and handles REST endpoints compliant with HTTP spec\nAutomatic API doc generation with OpenAPI\nRequest & Response validation powered by Pydantic\nGreat type support with the native Python type hint system\nLightning fast caching with Redis\nBuilt-in and configurable rate limiting to prevent API abuse\n\nRather than starting with a template that requires you to rip all sorts of things out, this template starts with a minimal amount of code in a flat directory to let you kick the tires and expand from there.",
    name: "Featherweight (FastAPI)",
    category: "Starters",
    health: 50,
    code: "l2yE91",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4ce1e0ef-790b-4ec8-bbb5-9ffe8b3f648f",
    isApproved: false,
    activeProjects: 649,
    projects: 1635,
    description: "The default Vite + React starter, with Caddy",
    readme:
      "Vite + React + Caddy\n\nThis is the default Vite + React starter provided by Vite, with Caddy added to serve the statically built site.\n\nWhy use Caddy when deploying to Railway?\n\nCaddy is a powerful, enterprise-ready, open source web server, and therefore Caddy is far better suited to serve websites than Vite is, using Caddy will result in much less memory and cpu usage compared to serving with Vite (much lower running costs too)\n\nTo see how this is achieved with nixpacks, check out the fully documented nixpacks.toml file in this repository\n\nThe configuration for Caddy is called a Caddyfile, and you can edit that file to further suite your needs, by default it comes configured to serve a single page app for Vue 3, and to also gzip the responses\n\nRelevant Caddy documentation:\n\nThe Caddyfile\nCaddyfile Directives\nroot\nencode\nfile_server\ntry_files",
    name: "Vite + React",
    category: "Starters",
    health: 92,
    code: "NeiLty",
    languages: ["JavaScript", "CSS", "HTML"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "33c6edfd-7a26-486a-9ae6-58e835d35968",
    isApproved: false,
    activeProjects: 24,
    projects: 254,
    description: "A suite of product and data tools. Built on the modern data stack.",
    readme:
      "PostHog is a suite of product and data tools built on the modern data stack, designed for builders. The platform provides APIs to build custom apps, augment or transform data, and automate actions based on customer activity. Event pipelines enable users to connect all their data to PostHog, while SQL-like syntax allows them to query their data directly. PostHog also offers an app platform that lets users extend the platform's functionality with custom apps or build an app for the PostHog community.\n\nPostHog's open-source analytics platform is built to help users build products that their users want. It offers a full suite of products, including event pipelines, SQL-like syntax, and an app platform, that work natively together, allowing users to send their data to one place and provision their account without having to deal with salespeople. PostHog also provides honest, transparent pricing that doesn't force users to talk to a human, and users can watch a recorded demo at their own pace or request a personalized demo if their business has bespoke needs.\n\nPostHog is focused on giving users full control of their customer data, with privacy controls that allow users to track users without cookies, anonymize users, and configure a reverse proxy. Users can choose their hosting location, with options to store user data in the US or EU depending on their needs. The platform also provides full access to customer data, with APIs offering total access to customer and event data. Users can audit the entire PostHog codebase on GitHub for compliance or peace of mind.\n\nPostHog has a track record of shipping new features at a rapid pace, with a major new feature, company news, or something cool happening almost every month. The platform offers a future roadmap that it publishes, and users can tell PostHog what they should build next to get early access. With over 10K stars on GitHub across its repos, PostHog has a large open-source community of 60k+ developers and 375+ contributors.",
    name: "PostHog",
    category: "Analytics",
    health: 43,
    code: "16rDub",
    languages: [
      "Python",
      "TypeScript",
      "C++",
      "Rust",
      "SCSS",
      "HTML",
      "JavaScript",
      "Shell",
      "Perl",
      "MDX",
      "ANTLR",
      "Go",
      "Dockerfile",
      "PLpgSQL",
      "EJS",
      "Smarty",
      "Less",
      "C",
    ],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e34d16a5-34d7-438c-96cd-667802561e64",
    isApproved: false,
    activeProjects: 123,
    projects: 234,
    description: "Sample LangChain apps for search, text, document, URL, and news summaries.",
    readme:
      "Template\nThis template deploys a collection of Streamlit apps that utilize the LangChain framework for interacting with large language models (LLMs).\n\nSearch (langchain-search)\nA sample Streamlit web application for live Google search queries using LangChain and SerpApi. Read more below:\nGitHub repo\nGoogle Colab notebook\n\nSearch with Tavily API (langchain-search-tavily)\nA sample Streamlit web application for live Google search queries using LangChain and Tavily Search API. Read more below:\nGitHub repo\n\nText Summary (langchain-text-summary)\nA sample Streamlit web application for summarizing text using LangChain and OpenAI. Read more below:\nSummarize Text with LangChain and OpenAI\nGitHub repo\nGoogle Colab notebook\n\nDocument Summary (langchain-doc-summary)\nA sample Streamlit web application for summarizing documents using LangChain and Chroma. Read more below:\nSummarize Documents with LangChain and Chroma\nGitHub repo\nGoogle Colab notebook\n\nURL Summary (langchain-url-summary)\nA sample Streamlit application for URL summaries using LangChain and OpenAI. Read more below:\nGitHub repo\n\nNews Search & Summary (langchain-news-summary)\nA sample Streamlit application for Google news search and summaries using LangChain and Serper API. Read more below:\nSummarize Google News Results with LangChain and Serper API\nGitHub repo",
    name: "LangChain Apps",
    category: "AI/ML",
    health: 100,
    code: "oE8sWo",
    languages: ["Python", "Jupyter Notebook"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "12bd26e1-9577-4b3e-9923-0e0b2a573247",
    isApproved: false,
    activeProjects: 28,
    projects: 119,
    description: "Simple, open source error tracking with Sentry SDK",
    readme:
      "GlitchTip\n\nCollect every error from your project in real time, organize them to make them useful, and receive alerts when and where you want...without breaking the budget.\n\n\nHave some bugs in your code?\n\n\n\n\n\n\nGlitchTip makes monitoring software easy. Track errors, monitor performance, and check site uptime all in one place. Compatible with Sentry client SDKs, but easier to run.\n\nIt's also open source, so you can view, modify, and use the code as you see fit.\n\nGlitchTip is the right choice if you value simplicity, affordability, and the freedom provided by open source.\n\n\nResources\n\nShould I choose GlitchTip? (Reddit)\nGlitchTip Organization\nGlitchTip Website",
    name: "GlitchTip",
    category: "Observability",
    health: 96,
    code: "AMx6AD",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "90ebcf00-d07f-417f-8cf7-167f2d82ae0d",
    isApproved: false,
    activeProjects: 398,
    projects: 824,
    description: "A starter Create React App that uses Caddy",
    readme:
      "This is the standard Create React App starter, with Caddy added to serve the build folder. Caddy is used in place of the default start command because the default start command does not start the app in production mode.\n\nSee the template's readme.md for more information on why Caddy is used, and why the default start command is undesirable.",
    name: "Create React App",
    category: "Starters",
    health: 76,
    code: "6sjhSn",
    languages: ["HTML", "CSS", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "33e3e17c-9f86-4ab9-a00d-d7de546fd2bb",
    isApproved: false,
    activeProjects: 186,
    projects: 428,
    description: "Next gen - fully featured - very lightweight - no dependencies",
    readme:
      "TypeScript\n  Environment variables typing\n  TypeScript & JavaScript compatibility\n  ES Modules & CommonJS compatibility\nNode.js\n  Live Reload\n  Debugging\nesbuild\n  Fast bundling\n  Fast transpiling\nBiome\n  Fast linting\n  Fast formatting\n  Import sorting\nGitHub\n  One click template\n  Continuous integration with dependency caching",
    name: "Node.js TypeScript starter",
    category: "Starters",
    health: 67,
    code: "8AWlL5",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "88aefce5-ae16-4437-9a03-b330c3d85f1d",
    isApproved: false,
    activeProjects: 255,
    projects: 420,
    description: "WebSocket chatrooms server",
    readme:
      "This is a functional WebSocket server that will get you started with a very solid base around WebSockets that you can adapt to your use case!\n\nKey features:\nWebSockets\n  Lightweight\n  KeepAlive\n  State Map\nTypeScript\n  Environment variables typing\n  TypeScript & JavaScript compatibility\n  ES Modules & CommonJS compatibility\nNode.js\n  Live Reload\n  Debugging\nesbuild\n  Fast bundling\n  Fast transpiling\nRome\n  Fast linting\n  Fast formatting\n  Import sorting\nGitHub\n  One click template\n  Continuous integration with dependency caching",
    name: "Node.js TypeScript WebSockets",
    category: "Starters",
    health: 100,
    code: "DZV--w",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a4e2dcef-423a-46e9-b85c-dd3d4ae20d12",
    isApproved: false,
    activeProjects: 50,
    projects: 105,
    description: "A simple Discord bot using Typescript and discord.js",
    readme:
      "Discord TS Bot\nDeploy a Discord bot powered by Typescript, discord.js, and Node.js.\n\n##Instructions\nTo deploy this template, you will need to set up a bot on Discord and obtain its Client_ID and Discord_Token. Then, deploy the template and you're good to go!\nHow to set up a Discord Bot Application\nFind Discord_Token (aka Bot Token)\nFind Client_ID (aka Application ID)\n\n##How to add your bot to your server\nAfter you've deployed the template, you can add a bot to your server using this guide\nmake sure to select `Send Messages and Use Slash Commands` under bot permissions\n\n##Learn More\ndiscord.js\ntemplate repo",
    name: "Discord TS Bot",
    category: "Bots",
    health: 92,
    code: "EWKFBX",
    languages: ["TypeScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4b7f8fe8-c007-429d-bb4c-87c5e153706b",
    isApproved: false,
    activeProjects: 547,
    projects: 1204,
    description: "A drag-and-drop web interface for LangChain.",
    readme:
      "##Template\nThis template deploys a drag-and-drop web interface for LangChain, an open-source framework for integrating applications with large language models (LLMs).\n\n##Overview\nLangFlow is a GUI for LangChain, designed with react-flow to provide an effortless way to experiment and prototype flows with drag-and-drop components and a chat box. Drag sidebar components onto the canvas and connect them together to create your pipeline. LangFlow provides a range of LangChain components to choose from, including LLMs, prompt serializers, agents, and chains.\n\n##Learn More\nPrototype LangChain Flows Visually with LangFlow\nlangflow GitHub repo",
    name: "LangFlow",
    category: "AI/ML",
    health: 96,
    code: "LcJLmZ",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "01c50b88-27af-4005-affe-bdca1958d1bc",
    isApproved: false,
    activeProjects: 71,
    projects: 207,
    description: "A lightweight web-based admin tool for MongoDB databases.",
    readme:
      "##Template\nThis template deploys Mongo Express, a lightweight web-based administrative tool for MongoDB databases. It also creates a sample MongoDB database instance to test Mongo Express capabilities. Just wait 1-2 minutes after deployment for the web interface to be ready.\n\n##Overview\nMongo Express is a web-based administrative interface for MongoDB that allows you to easily manage your databases. It provides a simple, yet powerful way to view, add, edit, and delete data in your MongoDB databases.\n\n##Learn More\nMongo Express: MongoDB Management Made Easy",
    name: "Mongo Express",
    category: "Other",
    health: 100,
    code: "P7J0lk",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ff476426-30ae-429b-963d-a16ac95df3e3",
    isApproved: false,
    activeProjects: 9,
    projects: 37,
    description: "An open-source website analytics tool.",
    readme:
      "##Template\nThis template deploys Fathom Lite, an open-source version of the Fathom Analytics website analytics service.\n\n##Overview\nFathom Analytics is a privacy-focused website analytics service that allows website owners to track visitor statistics and gain insights into website performance, without collecting any personally identifiable information (PII) from visitors. Fathom Lite, is the open-source version of Fathom Analytics. It can be self-hosted, but comes without SLAs and additional features that come with the paid version.",
    name: "Fathom Lite",
    category: "Analytics",
    health: 100,
    code: "dXJiR5",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "9bf45a5b-6d08-424b-901b-24d3ce31b80d",
    isApproved: false,
    activeProjects: 8,
    projects: 37,
    description: "An open-source video transcoder.",
    readme:
      "##Template\nThis template deploys HandBrake, an open-source video transcoder, on Railway.\n\n##Overview\nHandbrake is a popular open-source video transcoder for Windows, Mac, and Linux. With Handbrake, users can convert videos from one format to another, compress videos to save space, crop or resize videos, and adjust video quality settings. It can handle a wide range of video formats, including popular formats like MP4, MKV, and AVI. It also supports a variety of codecs, including H.264 and H.265, which are commonly used for high-quality video compression.\n\n##Learn More\nHandBrake GitHub repo",
    name: "HandBrake",
    category: "Other",
    health: null,
    code: "indNPy",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6bf63748-c4ee-45cc-837f-f788839d9796",
    isApproved: false,
    activeProjects: 63,
    projects: 140,
    description: "Streamlit apps for stock financial analysis using YFinance/Polygon API.",
    readme:
      "##Overview\nStreamlit is an open-source Python library that allows you to create and share interactive web apps and data visualisations in Python with ease. You create web apps using Python code, but with powerful add-on capabilities by Streamlit. It includes built-in support for several data visualisation libraries like matplotlib, pandas, and plotly, making it easy to create interactive charts and graphs that update in real-time based on user input.\n\n##Template\nThis template uses Streamlit to deploy two simple web apps, respectively using the YFinance API and Polygon API to retrieve stock quote information.\n\n##Learn More\nBuild an Interactive Python Web App with Streamlit\nStock Financial Analysis with Streamlit and YFinance API\nstreamlit-yfinance GitHub repo\nstreamlit-polygon GitHub repo",
    name: "Stock Financial Analysis",
    category: "Starters",
    health: 60,
    code: "H1p-V2",
    languages: ["Python", "Jupyter Notebook"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "76b50a00-55b7-4821-b9ca-1adfd622a57d",
    isApproved: false,
    activeProjects: 143,
    projects: 391,
    description: "Open Source backend for your next SaaS and Mobile app in 1 file",
    readme:
      '\n    \n        \n    \n\nPocketBase is an open source Go backend, consisting of:\n\nembedded database (SQLite) with realtime subscriptions\nbuilt-in files and users management\nconvenient Admin dashboard UI\nand simple REST-ish API\n\nFor documentation and examples, please visit https://pocketbase.io/docs.\n\n&gt; !WARNING]\n&gt; Please keep in mind that PocketBase is still under active development\n&gt; and therefore full backward compatibility is not guaranteed before reaching v1.0.0.\n\nAPI SDK clients\n\nThe easiest way to interact with the API is to use one of the official SDK clients:\n\nJavaScript - [pocketbase/js-sdk (browser and node)\nDart - pocketbase/dart-sdk (web, mobile, desktop)\n\nOverview\n\nUse as standalone app\n\nYou could download the prebuilt executable for your platform from the Releases page.\nOnce downloaded, extract the archive and run ./pocketbase serve in the extracted directory.\n\nThe prebuilt executables are based on the examples/base/main.go file and comes with the JS VM plugin enabled by default which allows to extend PocketBase with JavaScript (for more details please refer to Extend with JavaScript).\n\nUse as a Go framework/toolkit\n\nPocketBase is distributed as a regular Go library package which allows you to build\nyour own custom app specific business logic and still have a single portable executable at the end.\n\nHere is a minimal example:\n\nInstall Go 1.21+ (if you haven\'t already)\n\nCreate a new project directory with the following main.go file inside it:\n    package main\n\n    import (\n        "log"\n        "net/http"\n\n        "github.com/labstack/echo/v5"\n        "github.com/pocketbase/pocketbase"\n        "github.com/pocketbase/pocketbase/apis"\n        "github.com/pocketbase/pocketbase/core"\n    )\n\n    func main() {\n        app := pocketbase.New()\n\n        app.OnBeforeServe().Add(func(e *core.ServeEvent) error {\n            // add new "GET /hello" route to the app router (echo)\n            e.Router.AddRoute(echo.Route{\n                Method: http.MethodGet,\n                Path:   "/hello",\n                Handler: func(c echo.Context) error {\n                    return c.String(200, "Hello world!")\n                },\n                Middlewares: ]echo.MiddlewareFunc{\n                    apis.ActivityLogger(app),\n                },\n            })\n\n            return nil\n        })\n\n        if err := app.Start(); err != nil {\n            log.Fatal(err)\n        }\n    }\n\nTo init the dependencies, run go mod init myapp &amp;&amp; go mod tidy.\n\nTo start the application, run go run main.go serve.\n\nTo build a statically linked executable, you can run CGO_ENABLED=0 go build and then start the created executable with ./myapp serve.\n\n&gt; [!NOTE]\n&gt; PocketBase embeds SQLite, but doesn\'t require CGO.\n&gt;\n&gt; If CGO is enabled (aka. CGO_ENABLED=1), it will use [mattn/go-sqlite3 driver, otherwise - modernc.org/sqlite.\n&gt; Enable CGO only if you really need to squeeze the read/write query performance at the expense of complicating cross compilation.\n\nFor more details please refer to Extend with Go.\n\nBuilding and running the repo main.go example\n\nTo build the minimal standalone executable, like the prebuilt ones in the releases page, you can simply run go build inside the examples/base directory:\n\nInstall Go 1.21+ (if you haven\'t already)\nClone/download the repo\nNavigate to examples/base\nRun GOOS=linux GOARCH=amd64 CGO_ENABLED=0 go build\n   (https://go.dev/doc/install/source#environment)\nStart the created executable by running ./base serve.\n\nNote that the supported build targets by the pure Go SQLite driver at the moment are:\n\ndarwin  amd64\ndarwin  arm64\nfreebsd amd64\nfreebsd arm64\nlinux   386\nlinux   amd64\nlinux   arm\nlinux   arm64\nlinux   ppc64le\nlinux   riscv64\nlinux   s390x\nwindows amd64\nwindows arm64\n\nTesting\n\nPocketBase comes with mixed bag of unit and integration tests.\nTo run them, use the standard go test command:\n\ngo test ./...\n\nCheck also the Testing guide to learn how to write your own custom application tests.\n\nSecurity\n\nIf you discover a security vulnerability within PocketBase, please send an e-mail to support at pocketbase.io.\n\nAll reports will be promptly addressed, and you\'ll be credited accordingly.\n\nContributing\n\nPocketBase is free and open source project licensed under the MIT License.\nYou are free to do whatever you want with it, even offering it as a paid service.\n\nYou could help continuing its development by:\n\nContribute to the source code\nSuggest new features and report issues\n\nPRs for new OAuth2 providers, bug fixes, code optimizations and documentation improvements are more than welcome.\n\nBut please refrain creating PRs for new features without previously discussing the implementation details.\nPocketBase has a roadmap and I try to work on issues in specific order and such PRs often come in out of nowhere and skew all initial planning with tedious back-and-forth communication.\n\nDon\'t get upset if I close your PR, even if it is well executed and tested. This doesn\'t mean that it will never be merged.\nLater we can always refer to it and/or take pieces of your implementation when the time comes to work on the issue (don\'t worry you\'ll be credited in the release notes).',
    name: "Pocketbase",
    category: "Storage",
    health: 100,
    code: "tFjgN5",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "6742c69c-534f-4da4-b899-ef9e26f46a4e",
    isApproved: false,
    activeProjects: 30,
    projects: 140,
    description: "The easiest way to develop typesafe full stack apps",
    readme:
      "Overview\nThe create T3 app starter contains a next app pre-configured with trpc, tailwind, nextauth ( complete with database setup ) and prisma.  Since we are deploying on Railway a database is already setup and linked to your project, with migrations that run at deployment time!\n\nHighlights\nPre-configured database\nFullstack typesafety\nPre-configured Tailwind, Trpc, Next-auth and Prisma\nExcellent developer experience \n\nLearn More\nFor more information about create-t3-app please head over to https://create.t3.gg/en/introduction or join the discord https://t3.gg/discord\n\nNotes\nTo enable nextauth head over to the src/server/auth.ts file and configure any providers you would like on line 31.\n",
    name: "create-t3-app",
    category: "Starters",
    health: 0,
    code: "1DI67q",
    languages: ["TypeScript", "JavaScript", "Shell", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "33292ee2-8839-44eb-a725-e35ac5f5d084",
    isApproved: false,
    activeProjects: 170,
    projects: 333,
    description: "An open-source ChatGPT UI alternative.",
    readme:
      "##Overview\nChatbot UI is an open-source ChatGPT UI alternative built using Next.js, TypeScript, and Tailwind CSS. Chatbot UI can be deployed locally, or hosted on cloud and web app hosting platforms like AWS, Google Cloud, Railway, Vercel, and more.\n\nNote: Chatbot UI now requires a Supabase backend. Please create an account and get the details for the required variables first.\nNEXT_PUBLIC_SUPABASE_URL\nNEXT_PUBLIC_SUPABASE_ANON_KEY\nSUPABASE_SERVICE_ROLE_KEY\n\n##Highlights\nSince the launch, Chatbot UI has seen several enhancements:\nAbility to create folders, prompt templates, and customise system prompt\nAbility to name conversations, highlight code syntax, and support Markdown\nAbility to import/export chats, stop message generation, and search chats\nGoogle Search integration and more (coming soon...)\n\n##Learn More\nOpen-Source ChatGPT UI Alternative with Chatbot UI",
    name: "Chatbot UI",
    category: "AI/ML",
    health: 100,
    code: "dSKMsy",
    languages: ["TypeScript", "PLpgSQL", "JavaScript", "CSS", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "93636c5f-10e5-40c6-990a-545c49c815e8",
    isApproved: false,
    activeProjects: 213,
    projects: 621,
    description: "Self-Hosted Cloud Development Environments",
    readme:
      "Coder enables organizations to set up development environments in the cloud. Environments are defined with Terraform, connected through a secure high-speed Wireguard¬Æ tunnel, and are automatically shut down when not in use to save on costs. Coder gives engineering teams the flexibility to use the cloud for workloads that are most beneficial to them.\n\nDefine development environments in Terraform\n  EC2 VMs, Kubernetes Pods, Docker Containers, etc.\nAutomatically shutdown idle resources to save on costs\nOnboard developers in seconds instead of days\n\nQuickstart\n\n1. Fill the environment variables\n\nCODER_WILDCARD_ACCESS_URL is an optional environment variable. Set this to a wildcard subdomain that resolves to Coder (e.g. *.coder.example.com). This is optional but will enable web-based port forwarding. See our docs for details.\n\nNote: For port-forwarding to work, you must use a custom domain with Railway and cannot use Railway's built-in domain.\n\nNote: You can configure Coder by setting more environment variables. Go to Railway Dashboard &gt; Coder (Service) &gt; Settings &gt; Environment Variables.\n\n2. Attach a custom domain\n\nYour Coder deployment will always be accessible at https://app-name.up.railway.app. If you want to use a custom domain, you can do so by going to Railway Dashboard &gt; Coder (Service) &gt; Settings &gt; Domains and adding your domain and optionally a wildcard subdomain if you specified CODER_WILDCARD_ACCESS_URL in the previous step.\n\n3. Create your first user\n\nCreate your first user by going to https://app-name.up.railway.app or your custom domain.\n\nWelcome to Coder\n\n3. Create your first template\n\nTemplates: Templates are written in Terraform and describe the infrastructure for workspaces. Coder provides a set of starter templates to help you get started.\n\nYou can choose a template to set up your first workspace. You can also create your templates to define your custom infrastructure with your preferred cloud provider.\nstarter templates\n\n4. Create your first workspace\n\nWorkspaces: Workspaces contain the IDEs, dependencies, and configuration information for software development. You can create workspaces from templates.\n\nCoder on GitHub\nCoder docs\nVS Code: Open any Coder workspace in VS Code with a single click.\nJetBrains IDEs: Open any Coder workspace in JetBrains Gateway with a single click.\nCoder Registry: Find official and community submitted modules and templates to create and extend your templates. \nCoder discord\nCoder GitHub Action: A GitHub Action to setup Coder CLI.\n",
    name: "Coder",
    category: "Other",
    health: 92,
    code: "coder",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "d4e71dde-8e49-464f-bb75-fcb7357f5d92",
    isApproved: false,
    activeProjects: 84,
    projects: 170,
    description: "Simple webhook client and server demo apps.",
    readme:
      "Template\nThis template deploys two services - one each for the webhook server and client. The webhook server is built with Node.js and Express, while the webhook client is built with Streamlit.\n\nOverview\nThe webhook server listens on port 3000, and exposes two endpoints /webhook-1 and /webhook-2. The webhook client takes Webhook URL and JSON Payload as inputs, and makes an HTTP POST request to the specified webhook endpoint URL along with the payload. Please note that this is an extremely simple example, and should not be used as-is in any production capacity without appropriate security measures.\n\nLearn More\nGetting Started with Webhooks: Part 1 - Webhook Servers\nGetting Started with Webhooks: Part 2 - Webhook Clients\nwebhook-client-server GitHub repo",
    name: "Webhooks",
    category: "Starters",
    health: 100,
    code: "WJuLbj",
    languages: ["JavaScript", "Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c7014b37-28b8-4fc4-8e3b-1ccf4fe38999",
    isApproved: false,
    activeProjects: 257,
    projects: 407,
    description: "Sample LlamaIndex apps for chatting with PDFs and URL summaries.",
    readme:
      "Overview\nThis template deploys a collection of Streamlit apps that utilize the LlamaIndex framework for interacting with large language models (LLMs). LlamaIndex is an open-source project that provides a simple interface between LLMs and external data sources like APIs, PDFs, SQL etc. It provides indices over structured and unstructured data, helping to abstract away the differences across data sources.\n\n###Pre-requisites\nYou'll need API keys from OpenAI and LlamaCloud for this project.\n\n###Learn More\nChat with PDF using LlamaIndex and LlamaParse\nBlinkist for URLs with LlamaIndex and OpenAI\nllama-index GitHub repo",
    name: "LlamaIndex Apps",
    category: "AI/ML",
    health: 80,
    code: "GpZ0J4",
    languages: ["Python"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "686d302d-3c44-4dfe-a735-0a9ad4359c21",
    isApproved: false,
    activeProjects: 45,
    projects: 58,
    description: "A dockerized Node.js app using Google distroless container image.",
    readme:
      "##Overview\nGoogle's Distroless container images are minimal Docker images designed for running applications. These images are built from scratch, signed using Sigstore Cosign, and contain only the minimal set of libraries and packages needed to run an application, making them smaller and more secure than other images like Debian or Alpine. Distroless images do not contain package managers, shells or other similar programs; since they have a smaller attack surface, they are also less vulnerable to security exploits.\n\n##Template\nThis template dockerizes a Node.js application using a Google distroless container image for better security, performance, and manageability.\n\n##Learn More\nDockerize a Node.js App using a Distroless Image\nnodejs-distroless GitHub repo",
    name: "Node.js Distroless",
    category: "Starters",
    health: 0,
    code: "JHtIIj",
    languages: ["JavaScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0ddb55b7-e274-4763-a9bd-6536a3b7fe28",
    isApproved: false,
    activeProjects: 1,
    projects: 23,
    description: "A Gofiber api with gorm as orm using mysql",
    readme:
      "This is golang useing gofbier web framworks as a api then we hava gorm as the orm using a mysql database\n\nin the template they is a user model, and a setup file to run the mirgation on the database in the main file they database conntion is run and the mirgation and it start the api on the port Railway gives it\n\nto deploy you will need a mysql database give login env aka MYSQLUSER, MYSQLHOST and you will need to grenate a url for the api",
    name: "Go Fiber And Gorm",
    category: "Other",
    health: null,
    code: "n_Nx2x",
    languages: ["Go"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8b4b25a5-1b4e-4195-a9dd-f120710f4bc6",
    isApproved: false,
    activeProjects: 241,
    projects: 478,
    description: "JupyterLab Is A Next-Generation Notebook Interface",
    readme:
      "\n    \n        \n    \n\n\nJupyterLab Is A Next-Generation Notebook Interface\n\nJupyterLab is the latest web-based interactive development environment for notebooks, code, and data. Its flexible interface allows users to configure and arrange workflows in data science, scientific computing, computational journalism, and machine learning. A modular design invites extensions to expand and enrich functionality.\n\nThe Jupyter Notebook is the original web application for creating and sharing computational documents. It offers a simple, streamlined, document-centric experience.",
    name: "JupyterLab",
    category: "Other",
    health: 90,
    code: "WpjhAn",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "870a589b-ea89-49de-b52a-4d1b8ac44447",
    isApproved: false,
    activeProjects: 9,
    projects: 14,
    description: "A starter project for cobol",
    readme:
      "This starter project contains an empty Cobol project that takes full advantage of the nixpacks GNU Cobol  support nixpacks. To get started simply update the main cobol.\n\nFor more information on gnu cobol:\nhttps://gnucobol.sourceforge.io/\n\nFor more information on how to configure your build:\nhttps://nixpacks.com/docs/providers/cobol",
    name: "cobol-starter",
    category: "Starters",
    health: null,
    code: "GC5s2A",
    languages: ["COBOL"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "8811749e-c143-4086-b50f-2a31e25915f0",
    isApproved: false,
    activeProjects: 46,
    projects: 61,
    description: "Discord Bot template using Sapphire and Typescript",
    readme:
      "About\n\nSapphire is a next-gen object-oriented Discord.js bot framework.\n\nKey Features\n\nAdvanced plugin support\nSupports both CommonJS and ESM\nCompletely modular and extendable\nDesigned with first class TypeScript support in mind\nIncludes optional utilities that you can use in any project",
    name: "Discord Sapphire Bot",
    category: "Bots",
    health: 50,
    code: "4v1jeR",
    languages: ["TypeScript", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "89d35db4-3f3d-4317-aa47-ad53ccbbf587",
    isApproved: false,
    activeProjects: 11701,
    projects: 15610,
    description: "A minimal Node.js web application.",
    readme:
      "##Overview\nNode.js (sometimes referred to as NodeJS) is an open-source, event-driven JavaScript runtime environment, frequently used to build server-side web applications. It is built on top of the Google Chrome V8 JavaScript engine, making it extremely fast and efficient for real-time data-intensive applications. It also has a large and active developer community, with plenty of modules and libraries for easy integration and extensibility.\n\n##Template\nThis template deploys a minimal Node.js web app, one that simply returns Hello World.\n\n##Learn More\nHow to Deploy a Node.js App on Railway\nnodejs GitHub repo",
    name: "Node.js",
    category: "Starters",
    health: 92,
    code: "Abo1zu",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1194c2ee-be1f-4390-a134-05c254e7ea10",
    isApproved: false,
    activeProjects: 948,
    projects: 1543,
    description: "A minimal Flask web application.",
    readme:
      "Overview\nFlask) is a lightweight web application framework written in Python. It is based on the Werkzeug WSGI toolkit and the Jinja2 template engine, and is one of the most popular Python frameworks around. It does not require specific tools or libraries, but supports a wide range of extensions for building web applications.\n\n##Template\nThis template deploys a minimal Flask web app, one that simply returns Hello World.\n\nLearn More\nHow to Deploy a Python Flask App on Railway\nflask GitHub repo",
    name: "Flask",
    category: "Starters",
    health: 76,
    code: "igzwwg",
    languages: ["Python", "HTML", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "eb9fd743-461c-4e58-a313-d93c8d2241d5",
    isApproved: false,
    activeProjects: 228,
    projects: 452,
    description: "Host personal VPN on Railway using Tailscale",
    readme:
      "Railway Tailscale VPN\n\nOverview\n\nHost personal VPN on Railway using Tailscale\n\nDeploy on Railway\n\nHow to setup\n\nTo get started, you should create an account on tailscale, if you already have an account skip to next step\n\nGo to you tailscale admin console settings then to keys\n\nClick on 'Generate auth key ...'\n\n    admin_console_keys.png\n\nGive you key a description then click 'Generate key' when you are finished\n\n    generating_auth_key.png\n\n    Remember to take a note of the key because you'll see it only once\n\nGo to railway and paste in the key in TAILSCALE_AUTHKEY variable\n\nDeploy!\n\nGo to your tailscale machines and approve railway-app as an exit node\n\n    approve_exit_node.png\n\nDisable key expiry for the machine you just deployed\n\n    disable_key_expiry.png\n\nUse this command to connect to your VPN\n\n    tailscale up --exit-node railway-app # or replace railway-app with your hostname\n\nMore Info\n\nTailscale\n\nTailscale Exit nodes\n\nUsing Tailscale Auth Keys\n",
    name: "tailscale-vpn",
    category: "Other",
    health: 100,
    code: "uIBpGp",
    languages: ["Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "99b5f636-09bf-48ba-bc99-29520de24ee8",
    isApproved: false,
    activeProjects: 68,
    projects: 251,
    description: "A sample NextJS app using tRPC",
    readme:
      "Overview\n\nThis is an example¬†NextJS app that uses¬†Prisma with¬†tRPC\n\nHighlights\n\nE2E typesafety with¬†tRPC\nFull-stack React with Next.js\nDatabase with Prisma\nVSCode extensions\nESLint + Prettier\nValidates your env vars on build and start\n\nLearn More\n\nView the official tRPC website.",
    name: "Next Prisma tRPC",
    category: "Starters",
    health: 0,
    code: "CgBw9O",
    languages: ["TypeScript", "JavaScript"],
    tags: ["trpc", "next", "typescript", "web"],
  },
  {
    __typename: "Template",
    id: "3961458b-df04-46e8-9b92-8f9256bc44dc",
    isApproved: false,
    activeProjects: 19,
    projects: 36,
    description: "A federation-compatible TypeScript GraphQL server",
    readme:
      "Quickly add a new subgraph to your federated supergraph with just a couple clicks!\n\nFeatures\n\nExamples for federated entities, including tests\nGitHub Actions which integrate with Apollo GraphOS (detect breaking changes, update your router automatically)\nSDL-first developer experience leveraging graphql-codegen\nMaintained by Apollo",
    name: "Apollo Server TypeScript Subgraph",
    category: "Starters",
    health: null,
    code: "WdJd2w",
    languages: null,
    tags: null,
  },
  {
    __typename: "Template",
    id: "2e0f2106-47e4-4690-8b7e-66d181f71658",
    isApproved: false,
    activeProjects: 106,
    projects: 140,
    description: "An open-source platform to run capture-the-flag events.",
    readme:
      "##Overview\nCTFd is an open-source platform that can be used to run CTF events for free. It offers a user-friendly web interface for both administrators and players, and has a modular system allowing for integrations with other external services. CTFd is very popular among security enthusiasts and has been used to host some of the largest CTF events in the world.\n\n##Learn More\nRun Capture-The-Flag Events with CTFd",
    name: "CTFd",
    category: "Other",
    health: null,
    code: "Feq69b",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "ce10d5d2-0cf1-41a9-bbf8-54d9d9928bc5",
    isApproved: false,
    activeProjects: 92,
    projects: 111,
    description: "An intentionally vulnerable web app for security skills testing.",
    readme:
      "##Overview\nOWASP Juice Shop is an intentionally vulnerable web application that allows security enthusiasts to test their skills. It is designed to help developers and security professionals better understand the risks and techniques associated with web application attacks. It can be used in security trainings, awareness demos, capture-the-flag events, testing security tools, and honing your web application hacking skills. It covers vulnerabilities from the highly popular OWASP Top Ten list, and also includes some flaws found in real-world applications.\n\n##Learn More\nPractice Hacking Skills with OWASP Juice Shop",
    name: "OWASP Juice Shop",
    category: "Other",
    health: 100,
    code: "6JBGcJ",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "01789257-f94c-4c1a-b39c-afbafdbafa78",
    isApproved: false,
    activeProjects: 2598,
    projects: 6599,
    description: "A popular self-hosted CMS",
    readme:
      "\n    \n        \n    \n\n\nOpen-source headless CMS, self-hosted or Cloud you‚Äôre in control.\n\nThe leading open-source headless CMS, 100% JavaScript/TypeScript, flexible and fully customizable.\n\nStrapi is an open-source headless CMS that empowers developers to create stunning, content-rich applications with ease.\n\nWith Strapi, you can manage your content in a customizable admin panel, which can be easily adapted to suit your specific needs. This powerful CMS provides you with complete control over your content, allowing you to create, edit, and publish content across multiple platforms and devices.\n\nWith just one click, you can deploy your Strapi project to the Railway cloud platform, and in about 5 minutes of avg. build time: you get a template that gives you a foundation for your blogs and websites.\n\nStrapi Community Edition is a free and open-source headless CMS enabling you to manage any content, anywhere.\n\nModern Admin Pane: Elegant, entirely customizable and a fully extensible admin panel.\nMulti-database support: You can choose the database you prefer: PostgreSQL, MySQL, MariaDB, and SQLite.\nCustomizable: You can quickly build your logic by fully customizing APIs, routes, or plugins to fit your needs perfectly.\nBlazing Fast and Robust: Built on top of Node.js and TypeScript, Strapi delivers reliable and solid performance.\nFront-end Agnostic: Use any front-end framework (React, Next.js, Vue, Angular, etc.), mobile apps or even IoT.\nSecure by default: Reusable policies, CORS, CSP, P3P, Xframe, XSS, and more.\nPowerful CLI: Scaffold projects and APIs on the fly.\n\nNOTES\n\nWhen this template is running on Railway Strapi will connect to the Postgres Database through the private network, saving you on database egress fees\n\nDeveloping locally\n\nWhen developing locally this Strapi template will connect to the Postgres server from its public TCP Proxy\n\nWithin the service settings of the Strapi service click the Eject button on the upstream repository\nClone that newly created repository locally\nInstall Strapi's dependencies with yarn install or npm install\nInstall the Railway CLI\n    Instructions for that can be found here\n    If this is your first time using the CLI make sure to login with railway login\nWithin the local repository run railway link to link the local repository to the Strapi service on Railway\nStart Strapi for development with railway run yarn run develop or railway run npm run develop\n    This command will run Strapi in development mode with the service variables available locally\nOpen your browser to http://127.0.0.1:1337/admin",
    name: "Strapi",
    category: "CMS",
    health: 92,
    code: "strapi",
    languages: ["JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1df86c81-8e26-40df-9209-7ba478971ffe",
    isApproved: false,
    activeProjects: 9,
    projects: 29,
    description: "API for detecting disposable email adresses.",
    readme:
      "A simple application written in Go that creates an API endpoint that matches an email address against a list of disposable domains that is refreshed periodically once every 24 hours. You can also define your own list of disposable domains or use a predefined list that is publicly available on github.",
    name: "Disposable Email Checker",
    category: "Other",
    health: null,
    code: "tHOg9a",
    languages: null,
    tags: null,
  },
  {
    __typename: "Template",
    id: "d185dd72-69cb-4f9a-81e0-5b283a2dd825",
    isApproved: false,
    activeProjects: 22,
    projects: 51,
    description: "Open Graph image generator for Railway",
    readme: "A long description",
    name: "OG Generator",
    category: "Automation",
    health: 100,
    code: "xWRIhd",
    languages: null,
    tags: null,
  },
  {
    __typename: "Template",
    id: "43d1518f-3609-45db-aa3c-42db42c7573e",
    isApproved: false,
    activeProjects: 2055,
    projects: 2826,
    description: "ü§ñÔ∏è Deploy ChatGPT on WeChat in 2 steps! ü§ñÔ∏è",
    readme:
      'ü§ñÔ∏è Deploy ChatGPT on your WeChat in 2 steps! ü§ñÔ∏è\n\nPlease refer to this GitHub Repo for more details!\n\nConfigure on Railway\n\nFill in the following blanks:\n\nYour forked repo name (can be any name you like)\nChoose make it private or not (also up to you)\nEnvironment variables (for how to get OpenAI API keys, please refer to Get your OpenAI API Keys\n\nDeploy & Login on Railway\n\nThe deploy process is automatic. It may take a few minutes for the first time. As you see the Success, click the tab to see the details. (which is your secret WeChat console!)\n\nClick Deply Logs and you will see everything is setting up, wait for a QR Code to pop up. Scan it as if you are login to your desktop WeChat, and click "Log in" on your mobile WeChat.\n\nFinally, everything is good to go! You will see the logs when people message you, as well as your chatbot auto-replies.\n\nü§ñ Enjoy your powerful chatbot! ü§ñ',
    name: "ChatGPT-On-WeChat",
    category: "Bots",
    health: 100,
    code: "zKIfYk",
    languages: null,
    tags: null,
  },
  {
    __typename: "Template",
    id: "dd1aee6a-2066-46a9-8df4-2ec2ee73e053",
    isApproved: false,
    activeProjects: 62,
    projects: 74,
    description: "Token server for Agora SDKs",
    readme:
      'Agora Node Token Server\nThis is an example of a simple Node/Express server that generates tokens for Agora applications. \n\nRun the server\nInstall the dependencies\nnpm install\nCreate a copy of the .env.example file and save it as .env\nAdd your Agora App ID and App Certificate:\nAPP_ID=ca123xxxxxx\nAPP_CERTIFICATE=12za123xxxxxx\nYou can obtain these values by selecting your project in the Agora console projects section. Optionally, you can also define a port.\n\nStart the service\nnpm start\n\nEndpoints\n\nPing\nendpoint structure\n/ping\nresponse:\n{"message":"pong"}\n\nRTC Token\nThe rtc token endpoint requires a channelName, role (\'publisher\' or \'audience\'), tokentype (\'uid\' || \'userAccount\') and the user\'s uid (type varies based on tokentype (example: 1000 for uid, ekaansh for userAccount). \n(optional) Pass an integer to represent the token lifetime in seconds.\n\nendpoint structure \n/rtc/:channelName/:role/:tokentype/:uid/?expiry=\n\nresponse:\n{"rtcToken":" "}\n\nRTM Token\nThe rtm token endpoint requires the user\'s uid. \n(optional) Pass an integer to represent the privelege lifetime in seconds.\nendpoint structure \n/rtm/:uid/?expiry=\n\nresponse:\n{"rtmToken":" "}\n\nBoth Tokens\nThe rte token endpoint generates both the rtc and rtm tokens with a single request.\n(optional) Pass an integer to represent the token lifetime in seconds.\n\nendpoint structure \n/rte/:channelName/:role/:tokentype/:uid/?expiry=\n\nresponse:\n{\n  "rtcToken":" ",\n  "rtmToken":" " \n}\nsource: github.com/AgoraIO-Community/Agora-Node-TokenServer',
    name: "Agora Node Token Server",
    category: "Other",
    health: 0,
    code: "huuDOY",
    languages: null,
    tags: null,
  },
  {
    __typename: "Template",
    id: "fb5165f9-3137-4870-bc38-8d00441a350c",
    isApproved: false,
    activeProjects: 227,
    projects: 378,
    description: "A lightweight front-end based commenting system",
    readme:
      "Valine is a beautifully styled, easy-to-use, and efficient-to-deploy commenting system. \n\nFor more information see: https://waline.js.org/guide/get-started/",
    name: "Waline",
    category: "Blogs",
    health: 100,
    code: "UZB84v",
    languages: ["Dockerfile", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "555dacb2-ce2c-4129-9ad3-d6e4a12204ca",
    isApproved: false,
    activeProjects: 1007,
    projects: 1168,
    description: "Token generator for Agora RTM, Video SDK, and Chat.",
    readme:
      'Agora Token Service\n\nThe Agora Token Service is a convenient utility for generating tokens required for various functionalities of the application, including Agora Real-Time Messaging (RTM), Video SDK, and Chat services. This service simplifies the token generation process and provides an easy-to-use API.\n\ngetToken API Endpoint\n\nThe getToken API endpoint enables you to generate tokens for different application features. This section outlines how to utilize the getToken endpoint through HTTP POST requests.\n\nEndpoint URL\n\nPOST /getToken\n\nRequest Body\n\nTo generate tokens, the request body should contain a JSON payload with specific parameters based on the token type:\n\nRTC Token:\n\n   tokenType: "rtc"\n   channel: Your channel name.\n   role: "publisher" or "subscriber."\n   uid: Your unique identifier.\n   expire (optional): Expiration time in seconds (default: 3600).\n\nRTM Token:\n\n   tokenType: "rtm"\n   uid: Your unique identifier.\n   channel (optional): Stream channel (wildcard "*" is an option).\n   expire (optional): Expiration time in seconds (default: 3600).\n\nChat Token:\n\n   tokenType: "chat"\n   uid (optional): User-specific chat token.\n   expire (optional): Expiration time in seconds (default: 3600).\n\nResponse\n\nUpon successful token generation, the API responds with an HTTP status code of 200 OK. The token is included in the response body with the key "token".\n\nIn case of errors or invalid request parameters, the API provides an appropriate HTTP status code along with an error message in the response body.\n\nSample Usage\n\nHere\'s an example of how to use the getToken API endpoint with a POST request using cURL:\n\nRequest:\n\ncurl -X POST -H "Content-Type: application/json" -d \'{\n    "tokenType": "rtc",\n    "channel": "my-video-channel",\n    "role": "publisher",\n    "uid": "user123",\n    "expire": 3600\n}\' "https://your-api-domain.com/getToken"\n\nResponse:\n\n{\n  "token": "your-generated-token-here"\n}\n',
    name: "Agora Token Deployment",
    category: "Authentication",
    health: 100,
    code: "NKYzQA",
    languages: ["Go", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "875389cc-b36d-4cd9-95d6-338de32e8176",
    isApproved: false,
    activeProjects: 29,
    projects: 113,
    description: "A simple Bao.js webserver running Bun",
    readme:
      "Overview\n\nBun is a fast all-in-one JavaScript runtime. Bao.js is a fast, minimalist web framework for the Bun runtime. \n\nThis template features a simple¬†Bao.js¬†webserver running on the¬†Bun¬†JavaScript runtime.\n\nNote: Both this example and Bun are currently experimental and should not be used in production\n\nHighlights\n\nBun runtime\nBao.js webserver\nTypeScript\n\nLearn More\n\nBun\nBao.js",
    name: "Bun + Bao.js",
    category: "Starters",
    health: 100,
    code: "gxxk5g",
    languages: null,
    tags: null,
  },
  {
    __typename: "Template",
    id: "689c5136-e6db-45fb-99cd-c03513f307ac",
    isApproved: false,
    activeProjects: 67,
    projects: 180,
    description: "A static website using a Caddy web server.",
    readme:
      "Overview\nCaddy¬†is a powerful yet simple, Go-based¬†open-source¬†web server. Written in a memory-safe language, it compiles to a single, static binary, making it easy to run Caddy practically anywhere, even in containers. Caddy obtains and renews TLS certificates automatically, staples OCSP responses, and even performs automatic HTTPS rewrites.\n\nThe modular architecture serves a whole host of use cases from simple static file serving (which we will cover today) to more complex use cases like dynamic reverse proxying and handling Kubernetes ingress.\n\nHighlights\nStatic website on Railway using Caddy server\nAutomatic certificate management\nCustom domain configuration\n\nLearn More\n\nHow to Deploy a Static Website with Caddy on Railway\ncaddy-server GitHub repo",
    name: "Caddy",
    category: "Starters",
    health: 93,
    code: "TETV8z",
    languages: ["HTML", "CSS", "Dockerfile"],
    tags: ["static site", "caddy"],
  },
  {
    __typename: "Template",
    id: "525d1453-d3b7-49ce-9ed7-b1b903a22f20",
    isApproved: false,
    activeProjects: 5,
    projects: 13,
    description: "A federation-compatible GraphQL server implemented in Rust",
    readme:
      "The fastest way to deploy a Rust GraphQL server! This template is federation-compatible, so you can use this to add Rust to an existing graph in just a few minutes. Leverages the async-graphql crate‚Äîa code-only GraphQL framework.\n\nIncludes GitHub Actions for integrating with Apollo GraphOS, enabling:\n\nChecks for breaking changes\nDetect composition errors\nUpdate your router or gateway automatically\n\nThis template is maintained by Apollo, so it will be kept up to date and always recommends best practices. ",
    name: "Rust async-graphql Subgraph",
    category: "Starters",
    health: null,
    code: "1KF0vV",
    languages: ["Rust"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f0517ac4-fbcd-441f-8762-bcc6c52b358f",
    isApproved: false,
    activeProjects: 30,
    projects: 75,
    description: "Starter for BFF, API Rest and microservice with NestJS",
    readme:
      "NestJS is a progressive Node.js framework for creating efficient, reliable and scalable server-side applications, which is built and fully compatible with TypeScript and JavaScript, combining elements of object-oriented programming, functional programming and functional reactive programming.\n\nDemo: https://nestjs-starter.tresdoce.com.ar/v1/docs",
    name: "NestJS Starter",
    category: "Starters",
    health: 0,
    code: "BOGqHd",
    languages: ["TypeScript", "Dockerfile", "JavaScript"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e9ebd0a8-5d01-4ec6-bcfa-8d083bc99496",
    isApproved: false,
    activeProjects: 72,
    projects: 245,
    description: "A queueing solution with a dashboard to visualize, monitor, retry and...",
    readme:
      "Overview\n\nBullMQ is a Node.js library that implements a fast and robust queue system built on top of Redis that helps in resolving many modern age micro-services architectures.\n\nThis template deploys a robust queueing system on Railway using BullMQ and Redis.\n\nHighlights\n\nA queueing system with BullMQ and Redis\nA dashboard built with¬†bull-board\nA Fastify server to trigger jobs via an¬†/add-job¬†API endpoint\n\nLearn More\n\nBullMQ\nQueues on Railway",
    name: "BullMQ with BullBoard",
    category: "Queues",
    health: 100,
    code: "odzp-I",
    languages: ["TypeScript"],
    tags: ["queues", "JavaScript", "TypeScript"],
  },
  {
    __typename: "Template",
    id: "fc91641d-b7cf-44d4-91c1-96842581407d",
    isApproved: false,
    activeProjects: 32,
    projects: 78,
    description: "Full two-way sync of Linear and GitHub tickets.",
    readme:
      "SyncLinear\n\nFor open-source teams who enjoy working in Linear. Visit SyncLinear.com to see it in action.\n\nDeploying SyncLinear on Railway only requires a few API keys and OAuth IDs.\n\nSee the self-hosting guide for full setup instructions.",
    name: "SyncLinear.com",
    category: "Automation",
    health: 33,
    code: "L__0PR",
    languages: ["TypeScript", "CSS", "Dockerfile", "JavaScript", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "3dc7a525-fe3c-40ed-8fa0-77c4b9ee8fd3",
    isApproved: false,
    activeProjects: 1,
    projects: 2,
    description: "A starter template to deploy a slash-create server.",
    readme:
      "\n\n\n\n/create is a way to create and sync Discord slash commands and serve them over a server.\n\n\n\n\nLearn More - Template Instructions\n\n\n\n",
    name: "slash-create TypeScript Server",
    category: "Bots",
    health: null,
    code: "GL2qbv",
    languages: null,
    tags: null,
  },
  {
    __typename: "Template",
    id: "80e5425f-fd7f-47c8-94b6-de69e15bd42c",
    isApproved: false,
    activeProjects: 4,
    projects: 5,
    description: "A starter template to deploy a slash-create server.",
    readme:
      "\n\n\n\n/create is a way to create and sync Discord slash commands and serve them over a server.\n\n\n\n\nLearn More - Template Instructions\n\n\n\n",
    name: "slash-create Server",
    category: "Bots",
    health: null,
    code: "h6aVmv",
    languages: null,
    tags: null,
  },
  {
    __typename: "Template",
    id: "b3471e9b-6897-4f72-a7f2-9f659c776727",
    isApproved: false,
    activeProjects: 32,
    projects: 56,
    description: "A basic Discord bot written using the Eris library",
    readme:
      "Overview\n\nEris is a Node.JS Discord library. This template launches a server with a Discord bot with a couple of basic commands. \n\nHighlights\n\nSpeedy\nLightweight\nConsistent\nPredictable\nFlexible\n\nLearn More\n\nEris\nGitHub",
    name: "Discord Eris",
    category: "Bots",
    health: null,
    code: "ioRn64",
    languages: null,
    tags: ["discord", "eris", "javascript"],
  },
  {
    __typename: "Template",
    id: "073aa6f4-cf81-4af5-a800-62c107fdc776",
    isApproved: false,
    activeProjects: 529,
    projects: 935,
    description: "A basic Discord bot written in JavaScript",
    readme:
      "Overview\n\ndiscord.js is a powerfulÔøΩNode.js module that allows you to interact with theÔøΩDiscord APIÔøΩ very easily. It takes a much more object-oriented approach than most other JS Discord libraries, making your bot's code significantly tidier and easier to comprehend.\n\nHighlights\n\nObject-oriented\nSpeedy and efficient\nFeature-rich\nFlexible\n100% Promise-based\n\nLearn More\n\ndiscord.js\ndiscord.js Guide\nDocumentation",
    name: "DiscordJS bot",
    category: "Bots",
    health: 0,
    code: "jX0xQo",
    languages: ["JavaScript"],
    tags: ["discord", "javascript"],
  },
  {
    __typename: "Template",
    id: "35f93daa-07ff-482f-affd-ac5fc7174aff",
    isApproved: false,
    activeProjects: 112,
    projects: 160,
    description: "A simple Discord bot written in Go",
    readme:
      "Overview\n\nDiscordGo is a¬†Go package that provides low level bindings to the¬†Discord chat client API. \n\nHighlights\n\nNearly complete support for all of the Discord API endpoints\nWebsocket interface\nVoice interface\n\nLearn More\n\nGitHub",
    name: "DiscordGo",
    category: "Bots",
    health: 0,
    code: "TZ2dBZ",
    languages: null,
    tags: ["discord", "golang"],
  },
  {
    __typename: "Template",
    id: "8ef77c3f-a3c7-4f7e-aa37-e7b4faf3982b",
    isApproved: false,
    activeProjects: 1680,
    projects: 2464,
    description: "A simple Discord Bot written in Python",
    readme:
      "Overview\n\ndiscord.py is a modern, easy to use, feature-rich, and async ready API wrapper for Discord.\n\nThis template creates a server running discord.py.\n\nHighlights\n\nModern Pythonic API using async/await syntax\nSane rate limit handling that prevents 429s\nCommand extension to aid with bot creation\nEasy to use with an object oriented design\nOptimised for both speed and memory\n\nLearn More\n\ndiscord.py\nGitHub",
    name: "Discord Python Bot",
    category: "Bots",
    health: 0,
    code: "PxM3nl",
    languages: null,
    tags: ["python", "discord"],
  },
  {
    __typename: "Template",
    id: "ce40c2a7-45a6-4f9d-b7c8-67d289054b01",
    isApproved: false,
    activeProjects: 31,
    projects: 119,
    description: "Collect events and metrics from hosts and send them to Datadog",
    readme:
      "Overview\n\nDatadog aggregates metrics and events across the full devops stack.\n\nThe Datadog Agent is open source software that runs on your hosts. It collects events and metrics from hosts and sends them to Datadog, where you can analyze your monitoring and performance data.\n\nHighlights\n\nOne-click deployment of Datadog Agent\n\nLearn More\n\nGitHub\nDocumentation",
    name: "Datadog Agent",
    category: "Observability",
    health: 60,
    code: "78cMS9",
    languages: null,
    tags: null,
  },
  {
    __typename: "Template",
    id: "00da2617-7525-4cae-b02d-3ee71ebb4131",
    isApproved: false,
    activeProjects: 284,
    projects: 824,
    description: "A simple NodeJS app to back up your PostgreSQL database to S3 via a cron",
    readme:
      "Overview\n\nThe template uses node-cron or Railway cron, written in TypeScript to dump your PostgreSQL data to a file and then upload the file to S3.\n\nHighlights\n\nConfigurable backup schedule: By default, the cron runs at 5 AM every day but is configurable via the BACKUP_CRON_SCHEDULE  environment variable.\n\nSupport for custom buckets: The script also supports using a AWS_S3_ENDPOINT  environment variable to use any S3 compliant storage bucket (eg: Wasabi).\n\nConfiguration\n\nAWS_ACCESS_KEY_ID - AWS access key ID.\n\nAWS_SECRET_ACCESS_KEY - AWS secret access key, sometimes also called an application key.\n\nAWS_S3_BUCKET - The name of the bucket that the access key ID and secret access key are authorized to access.\n\nAWS_S3_REGION - The name of the region your bucket is located in, set to auto if unknown.\n\nBACKUP_DATABASE_URL - The connection string of the database to backup.\n\nBACKUP_CRON_SCHEDULE - The cron schedule to run the backup on. Example: 0 5 * * *\n\nAWS_S3_ENDPOINT - The S3 custom endpoint you want to use. Applicable for 3-rd party S3 services such as Cloudflare R2 or Backblaze R2.\n\nAWS_S3_FORCE_PATH_STYLE - Use path style for the endpoint instead of the default subdomain style, useful for MinIO. Default false\n\nRUN_ON_STARTUP - Run a backup on startup of this application then proceed with making backups on the set schedule.\n\nBACKUP_FILE_PREFIX - Add a prefix to the file name.\n\nBUCKET_SUBFOLDER - Define a subfolder to place the backup files in.\n\nSINGLE_SHOT_MODE - Run a single backup on start and exit when completed. Useful with the platform's native CRON schedular.\n\nSUPPORT_OBJECT_LOCK - Enables support for buckets with object lock by providing an MD5 hash with the backup file.\n\nBACKUP_OPTIONS - Add any valid pg_dump option, supported pg_dump options can be found here. Example: --exclude-table=pattern\n",
    name: "Postgres S3 backups",
    category: "Automation",
    health: 96,
    code: "I4zGrH",
    languages: ["TypeScript", "Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "80256bc9-4f59-4295-add0-7cd728c5e016",
    isApproved: false,
    activeProjects: 11,
    projects: 56,
    description: "Open platform to collect and prioritize feedback",
    readme:
      "\n  \n  \n    Fider is a feedback portal for feature requests and suggestions.\n  \n  Give your customers a voice and let them tell you what they need. Spend less time guessing and more time building the right product.\n\nHighlights\n\nShare ideas, vote and discuss: Give voice to your community, get valuable suggestions and prioritize what they need the most.\nKeep everyone informed: Whenever you start, complete or decline a suggestion, Fider will notify everyone that subscribed to that topic.\nYour Brand: Use custom CSS feature to style Fider the way you want. Your logo, your colors, your identity.\nIntegrations: Fider can integrate with any system that supports Webhook, such as Slack and Discord.\nMarkdown: Style your text with the popular Markdown markup language.\nMulti-language: We speak your language! Fider is translated in 10+ languages, such as English, Spanish, German, French and Portuguese!\nOrganize your content: Tag your content to make it easier to find, group and decide. Tags can be either Public or Private.\nOpen Source: Fider is 100% Open Source.\n\nLearn More\n\nFider",
    name: "Fider",
    category: "Other",
    health: 93,
    code: "21E4xW",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "f8709740-02bb-4a0c-b0c0-caad0db38964",
    isApproved: false,
    activeProjects: 108,
    projects: 277,
    description: "A webserver written in Rust using Rocket",
    readme:
      "Overview\n\nA Rust Rocket is a web application server framework for the Rust programming language. It is designed to provide an easy-to-use and efficient framework for building fast and reliable web applications.\n\nHighlights\n\nThis deploys a simple web-server with a single route served directly from the / route. This starter deploys as quickly in 2 minutes. \n\nLearn More\n\nFor more info: see the railwayapp-templates/rocket repo.",
    name: "Rocket",
    category: "Starters",
    health: 67,
    code: "FkW8oU",
    languages: null,
    tags: ["webserver", "rust"],
  },
  {
    __typename: "Template",
    id: "32fb7f8f-a5f3-4f48-a239-620adaa72804",
    isApproved: false,
    activeProjects: 59,
    projects: 134,
    description: "A comment widget that just works",
    readme:
      "Overview\n\nCommento++ is a free, open source, fast, and lightweight comments box that you can embed in your static website instead of Disqus.\n\nHighlights\n\nMarkdown support\nImport from Disqus\nVoting\nAutomated spam detection (Askimet and Perspective integration)\nModeration tools\nSticky comments\nThread locking\nOAuth login (Google, Github, Twitter) and single sign-on\nHot-reloading of comments\nEmail notifications\n\nLearn More\n\nGitHub\nDocumentation",
    name: "Commento++",
    category: "Blogs",
    health: 71,
    code: "hame0C",
    languages: ["Go", "JavaScript", "SCSS", "HTML", "PLpgSQL", "Makefile", "Shell", "Dockerfile"],
    tags: ["disqus", "comments"],
  },
  {
    __typename: "Template",
    id: "179e74f7-6a64-4108-b8b8-c944526aa819",
    isApproved: false,
    activeProjects: 144,
    projects: 338,
    description: "A basic Kotling Spring Boot server",
    readme:
      "Overview\n\nSpring makes programming Java quicker, easier, and safer for everybody. Spring‚Äôs focus on speed, simplicity, and productivity has made it the¬†world's most popular Java framework.\n\nSpring Boot makes it easy to create stand-alone, production-grade Spring based Applications that you can \"just run.‚Äù\n\nHighlights\n\nCreate stand-alone Spring applications\nEmbed Tomcat, Jetty or Undertow directly (no need to deploy WAR files)\nProvide opinionated 'starter' dependencies to simplify your build configuration\nAutomatically configure Spring and 3rd party libraries whenever possible\nProvide production-ready features such as metrics, health checks, and externalized configuration\nAbsolutely no code generation and no requirement for XML configuration\n\nLearn More\n\nSpring Boot",
    name: "Kotlin Spring Boot",
    category: "Starters",
    health: null,
    code: "w502ro",
    languages: null,
    tags: ["kotlin", "spring boot"],
  },
  {
    __typename: "Template",
    id: "02071093-1c49-49fa-af9f-13b3f7b40120",
    isApproved: false,
    activeProjects: 112,
    projects: 365,
    description: "A basic NuxtJS example app",
    readme:
      "Overview\n\nNuxt is an open source Vue.js framework making web development simple and powerful.\n\nHighlights\n\nNuxtJS\nVue.js\nTypeScript\n\nLearn More\n\nView the official Nuxt docs.",
    name: "NuxtJS",
    category: "Other",
    health: 100,
    code: "lQQgLR",
    languages: null,
    tags: ["nuxt", "typescript"],
  },
  {
    __typename: "Template",
    id: "f62647b7-76d3-4e97-83fc-9c44755e6681",
    isApproved: false,
    activeProjects: 1512,
    projects: 2743,
    description: "An HTTP module server",
    readme:
      "Overview\n\nThis template starts an example Node.js HTTP Module server. The server started simply returns a Hello World payload. The server code is located in server.mjs.\n\nHighlights\n\nStart a Node.js HTTP Module server\n\nLearn More\n\nGitHub",
    name: "HTTP NodeJS",
    category: "Starters",
    health: 83,
    code: "ZweBXA",
    languages: null,
    tags: ["webserver", "javascript"],
  },
  {
    __typename: "Template",
    id: "22589c1c-78df-489c-b4ac-a87a804b0edf",
    isApproved: false,
    activeProjects: 5708,
    projects: 9069,
    description: "A minimal Flask application",
    readme:
      "Overview\n\nThis is a¬†Flask¬†app that serves a simple JSON response.\n\nFlask is a micro web framework written in Python. It is classified as a microframework because it does not require particular tools or libraries. It has no database abstraction layer, form validation, or any other components where pre-existing third-party libraries provide common functions.\n\nHighlights\n\nPython\nFlask\n\nLearn More\n\nDocumenation",
    name: "Flask",
    category: "Starters",
    health: 100,
    code: "zUcpux",
    languages: null,
    tags: ["flask", "python"],
  },
  {
    __typename: "Template",
    id: "376a0bac-86f6-4a83-b44f-f11b9f3842b0",
    isApproved: false,
    activeProjects: 11,
    projects: 40,
    description: "A one-click example Hapi server",
    readme:
      "Overview\n\nHapi. js (derived from Http-API) is¬†an open-source Node.js framework used to build powerful and scalable web applications. Hapi is commonly used to build Application Programming Interface servers, HTTP-proxy applications, and websites.\n\nHapi is the simple, secure framework developers trust. Build powerful, scalable applications, with minimal overhead and full out-of-the-box functionality - your code, your way.\n\nHighlights\n\nEnd-to-end Code Hygiene¬†‚Äî hapi requires the most secure settings to manage, control, and distribute code, including 2FA for all contributors\nSecure Defaults, Updated Regularly¬†‚Äî every hapi component comes with the most secure defaults out-of-the-box. Along with protecting server load with payload limits and request timeouts, hapi blocks error messages that could leak information or echo back exploits\nIntegrated Authorization and Authentication Architecture¬†‚Äî the most comprehensive authorization and authentication API available in a Node framework\nAdvanced Features¬†‚Äî with encrypted and signed cookies, secret or key rotation, and HTTP security headers, there are no excuses for building insecure applications\nReliable, Predictable Ownership¬†‚Äì when something goes wrong, you know who to contact. Security updates are handled under a strict, well-defined protocol\nRich ecosystem¬†‚Äì hapi‚Äôs extensive set of official plugins means no more blindly trusting some middleware you found for critical functionality just because it has a high count on npm\nIn-house Security Expertise¬†‚Äì created by Eran Hammer, the author of the OAuth specifications and other identity protocols\n\nLearn More\n\nhapi\nIntroduction to Hapi.js",
    name: "Hapi",
    category: "Starters",
    health: 0,
    code: "cixNdw",
    languages: null,
    tags: ["hapi", "typescript"],
  },
  {
    __typename: "Template",
    id: "bd1cbe9e-cc57-4691-86f5-d2e038ea350f",
    isApproved: false,
    activeProjects: 166,
    projects: 376,
    description: "A simple webserver written in Go using Gin",
    readme:
      "Overview\n\nGin is a web framework written in Golang. It features a Martini-like API, but with performance up to 40 times faster than Martini. If you need performance and productivity, you will love Gin.\n\nThis template creates a simple Go server with Gin. \n\nHighlights\n\nFast\nMiddleware support\nCrash-free\nJSON validation\nRoutes grouping\nError management\nRendering built-in\nExtendable\n\nLearn More\n\nGin Web Framework\nGitHub",
    name: "Gin",
    category: "CMS",
    health: 100,
    code: "dTvvSf",
    languages: null,
    tags: ["golang", "webserver"],
  },
  {
    __typename: "Template",
    id: "a6a25479-4bc3-4def-b89c-b177bead6eac",
    isApproved: false,
    activeProjects: 1158,
    projects: 2856,
    description: "An example NextJS app using Prisma",
    readme:
      "Overview\n\nDeploy a¬†NextJS todo app that uses¬†Prisma to store todos in a PostgreSQL database.\n\nHighlights\n\nPrisma\nNextJS\nPostgres\nTypeScript\n\nLearn More\n\nView the official NextJS and Prisma websites.",
    name: "NextJS Prisma",
    category: "Starters",
    health: 96,
    code: "HRZqTF",
    languages: ["TypeScript", "CSS"],
    tags: ["typescript", "frontend", "web"],
  },
  {
    __typename: "Template",
    id: "ee646753-6759-4e38-b365-6ff316e7bb33",
    isApproved: false,
    activeProjects: 1904,
    projects: 4365,
    description: "An example Laravel application",
    readme:
      "Overview\n\nLaravel is the PHP Frameworkfor Web Artisans. Laravel is a web application framework with expressive, elegant syntax. We‚Äôve already laid the foundation ‚Äî freeing you to create without sweating the small things.\n\nHighlights\n\nDockerfile: The¬†Dockerfile¬†and associated files in¬†docker/¬†are based on¬†Laravel Sail PHP 8.0\nPlugin Config: To connect to a Railway Plugin, Postgres for example, you will need to utilize the environment variables listed for that plugin in the¬†Railway Docs. See the¬†.env.example¬†for an example of using these with Postgres.\nWeb server port: Railway dynamically assigns a port for your webserver. We grab the¬†$PORT¬†environment variable in¬†docker/start-container¬†to set this on Artisan¬†serve\nLogging: Because the disk on Railway containers is ephemeral, we pipe the logs normally output to¬†storage/logs/laravel.log¬†to¬†stdout¬†as seen here\nAPP_KEY: This starter will automatically generate the¬†APP_KEY¬†(php artisan key:generate¬†in the¬†docker/start-container)\nMigrations: This starter automatically runs migrations on deploy (in the¬†docker/start-container)\n\nLearn More\n\nLaravel",
    name: "Laravel",
    category: "Starters",
    health: 96,
    code: "fWEWWf",
    languages: ["PHP", "Blade", "JavaScript"],
    tags: ["php"],
  },
  {
    __typename: "Template",
    id: "537c7b41-94bb-4026-9995-5baf94814aba",
    isApproved: false,
    activeProjects: 254,
    projects: 593,
    description: "A simple Fiber webserver",
    readme:
      "Overview\n\nFiber is a Go web framework built on top of Fasthttp, the¬†fastest¬†HTTP engine for Go. It's designed to¬†ease¬†things up for fast development with¬†zero memory allocation¬†and¬†performance¬†in mind.\n\nHighlights\n\nRobust routing\nServe static files\nExtreme performance\nAPI ready\nFlexible middleware support\nLow memory footprint\nRapid programming\nTemplate engines\nWebSocket support\nRate limiter\n\nLearn More\n\nFiber",
    name: "Go Fiber",
    category: "Starters",
    health: 92,
    code: "7di0JR",
    languages: null,
    tags: ["golang", "webserver"],
  },
  {
    __typename: "Template",
    id: "4314ad98-f3e5-4eea-8241-96cca0dfa028",
    isApproved: false,
    activeProjects: 32,
    projects: 100,
    description: "A game of life tutorial in Rust and WebAssembly",
    readme:
      "Overview\n\nDeploy the¬†Conway's Game of Life Rust Wasm tutorial. The frontend is served as a¬†NextJS app with TypeScript and Tailwind.\n\nHighlights\n\nRust\nWASM\nTypeScript\nNextJS\nTailwind\n\nLearn More\n\nView the official Tutorial",
    name: "Rust Wasm",
    category: "Other",
    health: 0,
    code: "Qda1TD",
    languages: null,
    tags: ["rust", "wasm", "typescript", "nextjs"],
  },
  {
    __typename: "Template",
    id: "79907cac-ccdd-47d5-b578-c20bdcf44521",
    isApproved: false,
    activeProjects: 249,
    projects: 814,
    description: "An example ExpressJS application using Prisma",
    readme:
      "Overview\n\nPrisma is a Next-generation¬†Node.js¬†and¬†TypeScript¬†ORM. \n\nPrisma unlocks a new level of¬†developer experience¬†when  working with databases thanks to its intuitive data model, automated migrations, type-safety, and¬†auto-completion.\n\nHighlights\n\nExpressJS Rest API uses Prisma to connect to a Postgres database and CRUD todos\n\nLearn More\n\nGitHub\nPrisma",
    name: "ExpressJS Prisma",
    category: "Starters",
    health: 81,
    code: "LqCw_O",
    languages: ["TypeScript", "Procfile"],
    tags: ["webserver", "typescript"],
  },
  {
    __typename: "Template",
    id: "ea5f91f0-de46-4fc2-802c-77c41a7e5dd5",
    isApproved: false,
    activeProjects: 491,
    projects: 1154,
    description: "An example Express app connected to a Mongo database",
    readme:
      "Overview\n\nMongoose is node.js library for elegant mongodb object modeling. Mongoose provides a straight-forward, schema-based solution to model your application data.\n\nHighlights\n\nBuilt-in type casting\nValidation out of the box\nQuery building out of the box\nBusiness logic hooks out of the box\n\nLearn More\n\nmongoose\nGitHub",
    name: "ExpressJS Mongoose",
    category: "Starters",
    health: 65,
    code: "RM1WxR",
    languages: ["TypeScript", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "db18a3fd-f82d-43cc-a8c4-94ca88497e05",
    isApproved: false,
    activeProjects: 389,
    projects: 1019,
    description: "An ExpressJS application connected to a PostgreSQL database",
    readme:
      "Overview\n\nExpress is a Fast, unopinionated, minimalist web framework for¬†\nNode.js. Express is ideal for web applications and APIs and provides a thin layer of fundamental web application features without obscuring Node.js features that you know and love. \n\nHighlights\n\nStarts an ExpressJS server that connects to a Railway PostgreSQL database\n\nLearn More\n\nGitHub\nExpress",
    name: "ExpressJS PostgreSQL",
    category: "Starters",
    health: 100,
    code: "VUVlu3",
    languages: ["TypeScript", "Procfile"],
    tags: ["webserver", "typescript"],
  },
  {
    __typename: "Template",
    id: "44c5d2f3-08ce-4ad6-ac04-632d28b02f54",
    isApproved: false,
    activeProjects: 111,
    projects: 331,
    description: "Fast and low overhead web framework, for Node.js",
    readme:
      "Overview\n\nFastify is a web framework highly focused on providing the best developer experience with the least overhead and a powerful plugin architecture, inspired by Hapi and Express. As far as we know, it is one of the fastest web frameworks in town.\n\nHighlights\n\nHighly performant:¬†as far as we know, Fastify is one of the fastest web frameworks in town, depending on the code complexity we can serve up to 30 thousand requests per second.\nExtensible:¬†Fastify is fully extensible via its hooks, plugins and decorators.\nSchema based:¬†even if it is not mandatory we recommend to use¬†JSON Schema¬†to validate your routes and serialize your outputs, internally Fastify compiles the schema in a highly performant function.\nLogging:¬†logs are extremely important but are costly; we chose the best logger to almost remove this cost,¬†Pino!\nDeveloper friendly:¬†the framework is built to be very expressive and to help developers in their daily use, without sacrificing performance and security.\nTypeScript ready:¬†we work hard to maintain a¬†TypeScript¬†type declaration file so we can support the growing TypeScript community.\n\nLearn More\n\nDocumentation",
    name: "Fastify",
    category: "Starters",
    health: 75,
    code: "ZZ50Bj",
    languages: null,
    tags: ["typescript", "server"],
  },
  {
    __typename: "Template",
    id: "e87c91d0-6d99-47bb-a337-acdd98f1a091",
    isApproved: true,
    activeProjects: 543,
    projects: 1404,
    description: "Fast analytics and integrated tooling for companies exploring their data",
    readme:
      "\nFast analytics with friendly UX and integrated tooling to let your company explore data on their own.\n\nMetabase sets up in five minutes, connecting to your database, and bringing its data to life in beautiful visualizations.\n\nAn intuitive interface makes data exploration feel like second nature‚Äîopening data up for everyone, not just analysts and developers.\n\nNOTES:\n\nCommunication to Postgres is done exclusively over the private network and the database is not exposed externally in any way by default, if you want to enable access from outside of the private network you can go to the databases settings to enable TCP proxying and enter the internal port (5432) the TCP proxy can be again removed at any point to close off external access.\n\nHighlights\n\nVisual Query Builder: Free your data from the confines of SQL, letting everyone query in a UI humans actually love. Need joins, drill-downs and calculated columns? We've got you.\n\nDashboards: Easily create and share interactive dashboards, from TB-scale analytical workloads to day-to-day operational workflows, with 15+ visualization types.\n\nModels: Craft metadata-rich, semantic models which let people query on their own, keeping things consistent and avoiding repetition. With a single tab open and no CLI needed.\n\nFeatures\n\nSingle Sign-On: Integrate with SSO IdPs (SAML, LDAP, JWT, Google) and map to Metabase groups.\n\nPermissions: Control access to data, content and features with group permissions.\n\nSandboxing: Segment access and unlock multi-tenant analytics via row-level data sandboxes.\n\nCaching: Go faster with result and model caching. No schedulers or pipelines needed.\n\nAudit: Inspect user behavior across content, data access and data downloads.\n\nVerification: Discern between official and broadly-created content with official and verified badges.\n\nSQL Snippets: Manage and share complex SQL logic across your team with shared snippets.\n\nSecurity and Privacy: Enterprise-scaled compliance (SOC 2 Type II, GDPR) built right in from day one.\n\nEmbedded Analytics\nCustomer facing analytics in days, not sprints.\n\nPower your product's reporting by embedding charts, dashboards or all of Metabase.\n\nLaunch faster than you can pick a charting library with our iframe or JWT-signed embeds.\n\nMake it your own with easy, no-code whitelabeling.\n\nIterate on dashboards and visualizations with zero code, no eng dependencies.\n\n    Learn more ‚Üí",
    name: "Metabase",
    category: "Analytics",
    health: 80,
    code: "metabase",
    languages: [],
    tags: ["analytics", "business intelligence", "data"],
  },
  {
    __typename: "Template",
    id: "d4712f04-2ece-4e96-b3c8-38569343b4b5",
    isApproved: false,
    activeProjects: 962,
    projects: 2218,
    description: "Static website served with NGINX",
    readme:
      "Overview\n\nNginx is a performant web server that can serve static files in a performant and memory-efficient way. This starter runs an NGINX Docker container that serves a /site directory containing an example HTML-based website.\n\nHighlights\n\nAble to handle 10,000 simultaneous connections with little memory overhead\nServes static files from /site in a performant way\n\nLearn More\n\nDocumentation: https://nginx.org/en/docs/",
    name: "NGINX Static Site",
    category: "Starters",
    health: 92,
    code: "o3MbZe",
    languages: ["HTML", "CSS", "Dockerfile", "JavaScript"],
    tags: ["html", "website"],
  },
  {
    __typename: "Template",
    id: "f2fcdfdb-1aa9-4a10-9eba-0f1ef4ef1c8c",
    isApproved: false,
    activeProjects: 60,
    projects: 171,
    description: "Lightweight, privacy-friendly alternative to Disqus",
    readme:
      "Overview\n\nCusdis is an open-source, lightweight (~5kb gzip), privacy-friendly alternative to Disqus. This template allows you to host Cusdis on Railway with minimal fuss.\n\nHighlights\n\nLightweight comment widget, with i18n, dark mode\nEmail notifications\nWebhooks\nUniversal embed code\nOne-click import data from Disqus\nModeration dashboard\nIntegrations\n\nLearn More\n\nGitHub\nDocumentation",
    name: "Cusdis",
    category: "Blogs",
    health: 20,
    code: "Vpmder",
    languages: ["TypeScript", "JavaScript", "Svelte", "HTML", "Dockerfile", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "5c007663-b111-4cca-b91f-2635ecbf7573",
    isApproved: false,
    activeProjects: 26,
    projects: 74,
    description: "An example R Shiny application",
    readme:
      "R Shiny is a web framework for creating interactive web applications and dashboards in R programming language. With Shiny, you can build web applications using only R code, without needing to know HTML, CSS, or JavaScript.\n\nShiny is built on top of the popular R statistical computing language, so it is easy to integrate your R code and data analysis into your web application. The framework allows you to create reactive web applications, where changes to the user interface (such as a drop-down menu selection) automatically trigger updates to the application's output (kinda sorta like a Python Notebook)\n\nThis template gives you boilerplate to go and deploy an R Shiny application. Data science away!",
    name: "Shiny",
    category: "Starters",
    health: null,
    code: "KgW-n8",
    languages: null,
    tags: ["data", "analytics", "r"],
  },
  {
    __typename: "Template",
    id: "49a76c47-2094-4c81-9407-7624563e9607",
    isApproved: false,
    activeProjects: 2991,
    projects: 5316,
    description: "Web framework for developing RESTful APIs in Python",
    readme:
      "Overview\n\nFastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.\n\nHighlights\n\nFast: Very high performance, on par with¬†NodeJS¬†and¬†Go¬†(thanks to Starlette and Pydantic).¬†One of the fastest Python frameworks available.\nFast to code: Increase the speed to develop features by about 200% to 300%. *\nFewer bugs: Reduce about 40% of human (developer) induced errors. *\nIntuitive: Great editor support.¬†¬†everywhere. Less time debugging.\n    \n    Completion\n    \nEasy: Designed to be easy to use and learn. Less time reading docs.\nShort: Minimize code duplication. Multiple features from each parameter declaration. Fewer bugs.\nRobust: Get production-ready code. With automatic interactive documentation.\nStandards-based: Based on (and fully compatible with) the open standards for APIs:¬†OpenAPI¬†(previously known as Swagger) and¬†JSON Schema.\n\nLearn More\n\nDocumentation\nGitHub",
    name: "FastAPI",
    category: "Starters",
    health: 88,
    code: "-NvLj4",
    languages: ["Python"],
    tags: ["python", "server"],
  },
  {
    __typename: "Template",
    id: "6a2a6a56-7e3e-4717-b811-d53974aadbab",
    isApproved: false,
    activeProjects: 36,
    projects: 141,
    description: "The official Railway blog",
    readme:
      "Overview\n\nDeploy the official Railway blog repo, which uses the Notion API to convert pages into blog posts.\n\nHighlights\n\nNextJS\nTypeScript\nTailwindCSS\nNotion\n\nLearn More\n\nView the production deployment of official Railway Blog to see an example.",
    name: "Railway Blog",
    category: "CMS",
    health: null,
    code: "EVFIqE",
    languages: ["TypeScript", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "1266af39-2ee0-4962-8873-d701fe1e6d8c",
    isApproved: true,
    activeProjects: 999,
    projects: 2625,
    description: "Turn any SQL database into an API. Optional S3 and WebSockets Included!",
    readme:
      "Overview\n\nDirectus is the world‚Äôs first Open Data Platform for instantly turning any SQL database into an API with a beautiful CMS dashboard.\n\nHighlights\n\nExtensions Marketplace\nPrivate Networking out of the box\n100% JavaScript modular codebase\nInstall on top of any SQL database\nDesign and build a REST + GraphQL API in minutes\nEnable anyone to author content, manage media, and visualize data\nBuild admin panels, manage digital experiences content, power SaaS platforms, and more\n\nLearn More\n\nDirectus\nDocumentation\nGitHub\n\nNOTE:\n\nCommunication to Postgres is done exclusively over the private network and the database is not exposed externally in any way by default, This is done so that there are no egress fees for the database, if you want to enable access from outside of the private network you can go to the databases settings page to enable TCP proxying and enter the internal port 5432. The TCP proxy can be again removed at any point to close off external access.",
    name: "Directus",
    category: "CMS",
    health: 100,
    code: "2fy758",
    languages: [],
    tags: ["api", "no-code", "analytics", "data"],
  },
  {
    __typename: "Template",
    id: "161fc3a0-08a9-4c6f-9ea4-e3e221bc9092",
    isApproved: false,
    activeProjects: 5,
    projects: 17,
    description: "Hubert is the coolest fish",
    readme:
      "You can deploy your own hubert using this template! Hubert its an aquatic animal that lives under the sea ( not in the sky, not yet atleast ).\n\nFind the original Hubert at https://hubert.fish\n\nfeatures\nHubert üê°üê†üêü\nHubert üê°üê†üêü\nHubert üê°üê†üêü\nHubert üê°üê†üêü",
    name: "hubert",
    category: "Other",
    health: null,
    code: "9kDZns",
    languages: ["TypeScript", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c76a1aa5-6c80-4d1f-acab-7acd8d2b11d8",
    isApproved: false,
    activeProjects: 187,
    projects: 500,
    description: "An example app running a cron job",
    readme:
      "Overview\n\nA simple example for deploying and running a cron job on¬†Railway using JavaScript.\n\nHighlights\n\nPrints a message every minute\n\nLearn More\n\nView the official node-cron repo.",
    name: "Node Cron",
    category: "Starters",
    health: 100,
    code: "KViDnA",
    languages: null,
    tags: ["typescript", "cron"],
  },
  {
    __typename: "Template",
    id: "b7b6f0af-a5b3-4b0c-99ad-0badc986d743",
    isApproved: false,
    activeProjects: 774,
    projects: 2237,
    description: "Scheduling infrastructure for absolutely everyone",
    readme:
      "\n  \n   \n  \n\n  Cal.com (formerly Calendso)\n\n  \n    The open-source Calendly successor.\n    \n    Learn more ¬ª\n    \n    \n    Discord\n    ¬∑\n    Website\n    ¬∑\n    Issues\n    ¬∑\n    Roadmap\nScheduling infrastructure for absolutely everyone\n\nThe open source Calendly successor. You are in charge\nof your own data, workflow, and appearance.\n\nCalendly and other scheduling tools are awesome. It made our lives massively easier. We're using it for business meetings, seminars, yoga classes, and even calls with our families. However, most tools are very limited in terms of control and customization.\n\nThat's where Cal.com comes in. Self-hosted or hosted by us. White-label by design. API-driven and ready to be deployed on your own domain. Full control of your events and data.\n\nAbout the Project\n\nObtaining the Google API Credentials\n\nOpen Google API Console. If you don't have a project in your Google Cloud subscription, you'll need to create one before proceeding further. Under Dashboard pane, select Enable APIS and Services.\nIn the search box, type calendar and select the Google Calendar API search result.\nEnable the selected API.\nNext, go to the OAuth consent screen from the side pane. Select the app type (Internal or External) and enter the basic app details on the first page.\nIn the second page on Scopes, select Add or Remove Scopes. Search for Calendar.event and select the scope with scope value .../auth/calendar.events, .../auth/calendar.readonly and select Update.\nIn the third page (Test Users), add the Google account(s) you'll using. Make sure the details are correct on the last page of the wizard and your consent screen will be configured.\nNow select Credentials from the side pane and then select Create Credentials. Select the OAuth Client ID option.\nSelect Web Application as the Application Type.\nUnder Authorized redirect URI's, select Add URI and then add the URI /api/integrations/googlecalendar/callback and /api/auth/callback/google replacing Cal.com URL with the URI at which your application runs.\nThe key will be created and you will be redirected back to the Credentials page. Select the newly generated client ID under OAuth 2.0 Client IDs.\nSelect Download JSON. Copy the contents of this file and paste the entire JSON string in the .env file as the value for GOOGLE_API_CREDENTIALS key.\n\nHighlights\n\nNext.js\ntRPC\nReact\nTailwind\nPrisma",
    name: "Cal",
    category: "Other",
    health: 80,
    code: "cal",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "84076826-d9bd-4524-a2d4-5d2a06a0bbcc",
    isApproved: false,
    activeProjects: 1180,
    projects: 2541,
    description: "VS Code in the browser",
    readme:
      "Overview\n\nCoder is your self-hosted remote development platform. \n\nCoder shifts software development from local machines to on-prem and public cloud infrastructure. Onboard new developers in minutes, build code on powerful servers‚Äîall while keeping source code and data secure behind your firewall.\n\nThis template creates a dev environment that you can access from any device.\n\nHighlights\n\nCreate a code-server deployment on Railway\nAdd custom tools like NodeJS\nRedeploy automatically after each change\n\nLearn More\n\nCoder\ncode-server\nGuide: Launching code-server on Railway",
    name: "Code Server",
    category: "Other",
    health: 96,
    code: "code-server",
    languages: null,
    tags: null,
  },
  {
    __typename: "Template",
    id: "9b1d6a52-f7c0-4a0e-8997-6bca97c83e81",
    isApproved: false,
    activeProjects: 57,
    projects: 231,
    description: "Self-hosted, analytics tool for those who care about privacy",
    readme:
      "\n    \n        \n    \n\n\nAckee\n\nSelf-hosted, Node.js based analytics tool for those who care about privacy. Ackee runs on your own server, analyzes the traffic of your websites and provides useful statistics in a minimal interface\n\nOverview\n\nAckee is a self-hosted analytics tool that cares about privacy. We believe that you don't need to track every aspect of your visitors. Ackee keeps tracked data anonymized to avoid that users are identifiable, while still providing helpful insights. It's the right tool for everyone who doesn't need a full-featured marketing analytics platform like Google Analytics.\n\nHighlights\n\nSelf-hosted: Ackee runs on your own server and is 100% open-source\nModern technologies: Lightweight Node.js and MongoDB architecture\nBeautiful: Minimal and focused interface\nNo cookies: No unique user tracking and therefore no required cookie message\nEvents: Track button clicks, newsletter subscriptions and more\nGraphQL API: Fully documented GraphQL API that allows you to build new tools upon Ackee\n\nLearn More\n\nhttps://ackee.electerious.com/\nhttps://github.com/electerious/Ackee",
    name: "Ackee",
    category: "Analytics",
    health: 100,
    code: "ackee",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4fac4d44-9295-4844-b8d0-29121f20c61b",
    isApproved: false,
    activeProjects: 661,
    projects: 1633,
    description: "A simple Rails app",
    readme:
      "Overview\n\nThe Rails web framework, also known as Ruby on Rails, is an open-source web application framework written in the Ruby programming language. It provides a set of tools and conventions for building web applications, making it easier and faster for developers to create high-quality web applications.\n\nAlthough yes, we are named Railway, you can deploy more than just Rails. (But yes, the Rails template is good.)\n\nHighlights\n\nThis template deploys a Rails 7 Hello World application onto Railway with Postgres and Redis.\n\nLearn More\n\nTo run common Rails development flows for local development, you can prefix your Rails command with railway run\n\nNote: rails console is not supported on Railway.",
    name: "Rails",
    category: "Starters",
    health: 88,
    code: "sibk1f",
    languages: ["Ruby", "HTML", "CSS", "JavaScript", "Procfile"],
    tags: ["ruby", "server"],
  },
  {
    __typename: "Template",
    id: "78f171f3-f4da-4fc6-b5fd-7c914763d63d",
    isApproved: false,
    activeProjects: 54,
    projects: 95,
    description: "A simple Sinatra webserver",
    readme:
      "Sinatra is a lightweight web framework written in Ruby. It allows developers to quickly and easily create web applications and APIs using minimal code. Sinatra is often referred to as a \"micro\" framework because it provides only the bare essentials needed to build a web application.\n\nThis template is pretty simple all it deploys is a pretty short file ready for you to extend to your next big thing.\n\nrequire 'sinatra'\n\nget '/' do\n  'Choo Choo! Welcome to your Sinatra server üöÖ'\nend",
    name: "Ruby Sinatra",
    category: "Starters",
    health: 100,
    code: "oo2_Dy",
    languages: null,
    tags: ["ruby", "webserver"],
  },
  {
    __typename: "Template",
    id: "5a7a67f9-8add-431e-bf55-f47395d2e6ae",
    isApproved: false,
    activeProjects: 1,
    projects: 24,
    description: "Open-source low-code framework to build & deploy internal tools with ease.",
    readme:
      "ToolJet is an open-source low-code framework to build and deploy internal tools with minimal engineering effort. ToolJet's drag-and-drop frontend builder allows you to create complex, responsive frontends within minutes. Additionally, you can integrate various data sources, including databases like PostgreSQL, MongoDB, and Elasticsearch; API endpoints with OpenAPI spec and OAuth2 support; SaaS tools such as Stripe, Slack, Google Sheets, Airtable, and Notion; as well as object storage services like S3, GCS, and Minio, to fetch and write data.\n\nToolJet product screenshot\n\nLinks\n\nWebsite: https://www.tooljet.com\nDocs: https://docs.tooljet.com/docs",
    name: "ToolJet",
    category: "Other",
    health: 33,
    code: "tc78tx",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "0300ae92-733e-433e-b1e7-8cf75e65b4bf",
    isApproved: false,
    activeProjects: 197,
    projects: 603,
    description: "Open-source authentication and authorization solution for your business.",
    readme:
      "Overview\n\nAuthorizer is an open-source¬†authentication¬†and¬†authorization¬†solution that comes with easy to integrate frontend SDKs while also allowing you to bring your own database. You can think of it as a self-hosted alternative to¬†Auth0.\n\nHighlights\n\nDeploy production-ready¬†authorizer.dev¬†instance¬†with¬†PostgreSQL¬†/¬†MySQL¬†and Redis for free and build with it in 30seconds\nOne-click deploys with the required PostgreSQL and Redis databases automatically provisioned\n\nLearn More\n\nAuthorizer Environment Variables\nGitHub\nDockerHub\nDeploying Authorizer on Railway [Video]",
    name: "Authorizer",
    category: "Authentication",
    health: 92,
    code: "authorizer",
    languages: ["Dockerfile"],
    tags: ["authentication", "authorization"],
  },
  {
    __typename: "Template",
    id: "e5ce2ef4-e2f1-49f3-b61e-7c1bc284c91c",
    isApproved: false,
    activeProjects: 7,
    projects: 8,
    description: "A discord bot that would create codebins using https://notebin.cf",
    readme:
      'Notebin Bot\nA discord bot that will save your text to https://www.notebin.cf\nLink: click here\n\n\nDeploy on Railway\n\nLinks\n\nNotebin - https://notebin.cf\nNotebin api - https://notebin.cf/api \nNotebin src - https://github.com/spicybirsge/notebin\n\nRequirements for self hosting\n\nNode v16. 6.0 or higher\n\nSelf hosting\n\nGo to https://discord.com/developers and create a bot and get its token\nThen copy this project and add an env variable called token and set its value to the token you got\nRun the command npm install to install all dependencies\nRun the project using node index.js\nWanna deploy this easily? click the "Deploy on Railway" button.\n',
    name: "notebin-bot",
    category: "Bots",
    health: null,
    code: "3NbRXM",
    languages: null,
    tags: null,
  },
  {
    __typename: "Template",
    id: "7572a3ec-a76a-456e-ac46-d88a5cd8c853",
    isApproved: false,
    activeProjects: 2,
    projects: 4,
    description: "A codebin with syntax higlighting and made with ejs.",
    readme:
      'Notebin Bot\nA discord bot that will save your text to https://www.notebin.cf\nLink: click here\n\nDeploy on Railway\n\nLinks\n\nNotebin - https://notebin.cf\nNotebin api - https://notebin.cf/api \nNotebin src - https://github.com/spicybirsge/notebin\n\nRequirements for self hosting\n\nNode v16. 6.0 or higher\n\nSelf hosting\n\nGo to https://discord.com/developers and create a bot and get its token\nThen copy this project and add an env variable called token and set its value to the token you got\nRun the command npm install to install all dependencies\nRun the project using node index.js\nWanna deploy this easily? click the "Deploy on Railway" button.\n',
    name: "notebin",
    category: "Starters",
    health: null,
    code: "ePrxoz",
    languages: null,
    tags: null,
  },
  {
    __typename: "Template",
    id: "55c83b6f-ba67-4a9a-b87c-b84d1edba890",
    isApproved: false,
    activeProjects: 4811,
    projects: 9378,
    description: "A simple Django application",
    readme:
      "Overview\n\nDjango is a high-level Python web framework that encourages rapid development and clean, pragmatic design. Built by experienced developers, it takes care of much of the hassle of web development, so you can focus on writing your app without needing to reinvent the wheel. It‚Äôs free and open source.\n\nHighlights\n\nRidiculously fast\nReassuringly secure\nExceedingly scalable\nFully loaded\nIncredibly versatile\n\nLearn More\n\nDjango\nDocumentation",
    name: "Django",
    category: "Starters",
    health: 100,
    code: "GB6Eki",
    languages: ["Python"],
    tags: ["python", "webserver"],
  },
  {
    __typename: "Template",
    id: "c50f41d9-3f6f-4400-855f-e2807bf002ae",
    isApproved: false,
    activeProjects: 51,
    projects: 95,
    description: "Build better products with customer feedback",
    readme:
      "LogChimp is a software tool that complements your existing product management process by assisting every stakeholder in understanding customer demands, prioritising features, and rallying everyone around the roadmap.\n\nWebsite: https://logchimp.codecarrot.net\nGitHub: https://github.com/logchimp/logchimp",
    name: "LogChimp",
    category: "Observability",
    health: 67,
    code: "3Bm-Un",
    languages: ["Vue", "JavaScript", "TypeScript", "HTML", "Sass", "Shell", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "81980871-36b2-4a43-8c53-4043147a5c7a",
    isApproved: false,
    activeProjects: 956,
    projects: 1651,
    description: "Self-hosted newsletter and mailing list manager",
    readme:
      "\n    \n        \n    \n\n\nSelf-hosted newsletter and mailing list manager\n\n\n    Performance and features packed into a single binary.\n    \n    Free and open source.\n\n\nlistmonk is a standalone, self-hosted, newsletter and mailing list manager. It is fast, feature-rich, and packed into a single binary. It uses a PostgreSQL 13 database as its data store.\n\nNotes:\nMake sure to go into listmonk's settings menu and update the Root URL to your Railway generated or custom domain. Example: https://listmonk-production.up.railway.app (sans trailing slash)\n\nHighlights\nMailing lists\nTransactional mails\nAnalytics\nTemplating\nExtensible",
    name: "Listmonk",
    category: "Other",
    health: 96,
    code: "listmonk",
    languages: ["Shell", "Dockerfile"],
    tags: ["newsletter", "mailing list", "golang"],
  },
  {
    __typename: "Template",
    id: "1e1ec4fc-67fe-456f-87f7-dff0b77a8f9d",
    isApproved: false,
    activeProjects: 163,
    projects: 643,
    description: "A self-hosted cross-platform password manager",
    readme:
      "Alternative implementation of the Bitwarden server API written in Rust and compatible with upstream Bitwarden clients, perfect for self-hosted deployment where running the official resource-heavy service might not be ideal.",
    name: "Vaultwarden",
    category: "Other",
    health: 92,
    code: "vaultwarden",
    languages: ["Dockerfile"],
    tags: ["password manager", "rust", "bitwarden"],
  },
  {
    __typename: "Template",
    id: "750d6444-88af-4fd1-a8d6-752a440e94e9",
    isApproved: false,
    activeProjects: 119,
    projects: 433,
    description: "Instant GraphQL APIs for your PostgreSQL database",
    readme:
      "Overview\n\nHasura is an open-source product that accelerates API development by 10x by giving you¬†GraphQL\n¬†or REST APIs with built-in authorization on your data, instantly.\n\nThis example sets up a¬†Hasura¬†instance with a¬†PostgreSQL¬†database.\n\nHighlights\n\nBuild modern apps & APIs 10x faster\nBuilt-in authorization and caching\nBlazing fast GraphQL & REST APIs\nOpen source\n\nLearn More\n\nHasura GraphQL Engine\nGitHub",
    name: "Hasura",
    category: "Starters",
    health: 96,
    code: "hasura",
    languages: [],
    tags: ["api", "graphql", "webserver"],
  },
  {
    __typename: "Template",
    id: "b6fb62d2-134f-4b04-8aa5-f857d070be0b",
    isApproved: false,
    activeProjects: 148,
    projects: 417,
    description: "Next-gen, Pusher-compatible, open-source WebSockets server",
    readme:
      "\n    \n        \n    \n\n\nStop paying for ‚Ç¨xpen$ive realtime.\n\nSoketi is your simple, fast, and resilient open-source WebSockets server. üì£\n\nBlazing fast speed ‚ö°\n\nThe server is built on top of uWebSockets.js - a C application ported to Node.js. uWebSockets.js is demonstrated to perform at levels 8.5x that of Fastify and at least 10x that of Socket.IO. (source)\n\nEasy to use üë∂\n\nWhether you run your infrastructure in containers or monoliths, soketi got your back. There are multiple ways to install and configure soketi, from single instances for development, to tens of active instances at scale with hundreds or thousands of active users.\n\nPusher Protocol v7 üì°\n\nsoketi implements the Pusher Protocol v7. Therefore, any Pusher-maintained or compatible client can connect to it, bringing a plug-and-play experience for existing applications that are already compatible with this protocol.\n\nApp-based access üîê\n\nYou and your users can access the API and WebSockets through Pusher-like apps which serve keys and secrets to connect or authenticate requests for broadcasting events or checking channels statuses. soketi also comes built-in with support for DynamoDB and SQL-based servers like Postgres.\n\nProduction-ready! ü§ñ\n\nIn addition to being a good companion during local development, soketi comes with the resiliency and speed required for demanding production applications.\n\nHighlights\n\nPusher compatible\nBuilt-in app management\nBlazing fast\nReady for production\nHTTP Webhooks\n\nLearn More\n\nSoketi\nDocumentation\nGitHub",
    name: "Soketi",
    category: "Starters",
    health: 96,
    code: "soketi",
    languages: [],
    tags: ["websockets", "pusher", "javascript"],
  },
  {
    __typename: "Template",
    id: "36b8dff6-ed97-491e-a1f0-89fd561eb5c0",
    isApproved: false,
    activeProjects: 529,
    projects: 1341,
    description: "Web browser automation built for everyone, and loved by developers",
    readme:
      "\n    \n        \n    \n\n\nBrowserless\n\nBrowserless allows remote clients to connect and execute headless work, all inside of docker\n\nOverview\n\nBrowserless supports the standard, Puppeteer, Selenium and Playwright libraries.\n\nIt takes care of common issues such as missing system-fonts, missing external libraries, and performance improvements, along with edge-cases like downloading files and managing sessions. For details, check out the documentation.\n\nIf you've been struggling to deploy headless browsers without running into issues or bloated resource requirements, then Browserless was built for you.\n\nExamples\n\nVarious minimal code examples for using Browserless on Railway with some common libraries -\n\nhttps://github.com/brody192/puppeteer-example (Node)\n\nhttps://github.com/brody192/playwright-example (Node)\n\nhttps://github.com/brody192/playwright-example-python\n\nhttps://github.com/brody192/selenium-example (Node)\n\nhttps://github.com/brody192/selenium-example-python\n\nhttps://github.com/brody192/chromedp-example (Golang)\n\nHighlights\n\nWorks seamlessly with Puppeteer, Playwright, and Selenium.\nNo need to install extra packages, dependencies, or system libraries.\nRAM, CPU and GPU are fully managed to stop browsers devouring resources.\nScaling and load balancing is handled for you to absorb any traffic surges.\nChrome's zombie processes are cleared away to stop servers from clogging up.\n\nFeatures\n\nParallelism and queueing are built-in and configurable.\nFonts and emoji's working out-of-the-box.\nWorks with most headless libraries.\nConfigurable session timers to keep things running smoothly.\nError tolerant: if Chrome dies it won't.\n\nLearn More\n\nBrowserless\n",
    name: "Browserless v1",
    category: "Automation",
    health: 100,
    code: "browserless",
    languages: ["Dockerfile", "Shell"],
    tags: ["browser", "chrome", "automation", "testing"],
  },
  {
    __typename: "Template",
    id: "d1f08724-cfbb-4dc6-a00d-b7ad30203878",
    isApproved: true,
    activeProjects: 999,
    projects: 2970,
    description: "An open source, privacy-focused alternative to Google Analytics",
    readme:
      "\nUmami is a simple, fast, privacy-focused alternative to Google Analytics.\n\nUmami makes it easy to collect, analyze, and understand your web data, while maintaining visitor privacy and data ownership.\n\n\n\nNotes:\n\nYour Umami deployment will create a default administrator account with the username admin and the password umami. The first thing you will want to do is login and change your password.\n\nCommunication to Postgres is done exclusively over the private network and the database is not exposed externally in any way by default, if you want to enable access from outside of the private network you can go to the databases settings to enable TCP proxying and enter the internal port (5432) the TCP proxy can be again removed at any point to close off external access.\n\nUpon changing the Railway provided domain or adding a custom domain, a redeploy of the umami service is needed so that it can refresh the domain used in redirects and logins.\n\nAll the features you need\n\nUmami is packed with amazing features that enable you to better\nunderstand your website traffic.\n\nSimple analytics: Umami measures just the important metrics that you care about and everything is easily accessible at just a glance.\n\nVisitor insights: Get detailed breakdowns about your visitors including what browser, OS and device they used.\n\nCustom events: Umami measures just the important metrics that you care about and everything is easily accessible at just a glance.\n\nPowerful filters: Dive deeper into your data using easy to apply filters. Segment your users by any metric such as browser, OS, and country.\n\nRealtime data: Get a realtime view of your current website traffic. See the exact pages where your visitors are landing.\n\nRobust reports: Umami has built-in reporting to help you gain deeper insights into your data.\n\n    Explore more features ‚Üí",
    name: "Umami",
    category: "Analytics",
    health: 100,
    code: "umami-analytics",
    languages: [],
    tags: null,
  },
  {
    __typename: "Template",
    id: "b0fbe1b2-9375-4230-9937-651bd44e753b",
    isApproved: false,
    activeProjects: 54,
    projects: 121,
    description: "A simple, secure, and fast browser-based real-time video calling solution",
    readme:
      "Overview\n\nMiroTalk is a free browser-based, real-time video calling service. Start your next video call with a single click.\n\nThis template will create a Railway deployment with MiroTalk already installed.\n\nHighlights\n\nScreen sharing\nWebCam streaming\nChat room\nMeeting recording\nInteractive whiteboard\nFile sharing\nTotal privacy\nMaximum security\n\nLearn More\n\nMiroTalk p2p\nGitHub",
    name: "Mirotalk",
    category: "Other",
    health: 100,
    code: "mirotalk",
    languages: ["JavaScript", "HTML", "CSS", "PHP", "Python", "Shell", "Dockerfile"],
    tags: ["javascript", "webrtc", "video call"],
  },
  {
    __typename: "Template",
    id: "da2fc5b1-a37f-4a1f-9a9d-b8fba70fa93d",
    isApproved: false,
    activeProjects: 85,
    projects: 384,
    description: "An example Remix paired with a PostgresSQL Database",
    readme:
      "Overview\n\nRemix is a full stack web framework that lets you focus on the user interface and work back through web standards to deliver a fast, slick, and resilient user experience. \n\nHighlights\n\nDeploy Remix‚Äôs ‚ÄúIndie Stack‚Äù app with a Postgres Database\nGet a working app with Prisma, Tailwind, and Cypress tests\n\nLearn More\n\nView the indie stack app at https://github.com/remix-run/indie-stack",
    name: "Remix Indie Stack",
    category: "Starters",
    health: 0,
    code: "remix",
    languages: ["TypeScript", "JavaScript", "Dockerfile", "Shell"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "c266e316-439b-4278-835a-8b25f7f45670",
    isApproved: false,
    activeProjects: 262,
    projects: 748,
    description: "An example SvelteKit application",
    readme:
      'SvelteKit Starter\n\nA Railway Template that deploys SvelteKit. It provides a starting point for building web applications using the SvelteKit framework. This deploys a simple "Hello World" web-app using the attached GitHub repo.\n\nThis provides a pre-configured setup for deploying your web application on Railway with one (or two) clicks.\n\n',
    name: "SvelteKit",
    category: "Starters",
    health: 86,
    code: "svelte-kit",
    languages: ["TypeScript", "Svelte", "CSS", "JavaScript", "HTML"],
    tags: ["web", "frontend", "typescript"],
  },
  {
    __typename: "Template",
    id: "ec125144-7c72-4ea8-a75c-76067a7fd8b3",
    isApproved: false,
    activeProjects: 238,
    projects: 1088,
    description: "Turn your audience into a business.",
    readme:
      "Overview\n\nGhost is a powerful app for new-media creators to publish, share, and grow a business around their content. It comes with modern tools to build a website, publish content, send newsletters & offer paid subscriptions to members.\n\nHighlights\n\nPublish by web & email newsletter.\nRich media & dynamic cards.\nNewsletters built-in.\nNative analytics.\n\nLearn More\n\nWebsite\nDocumentation",
    name: "Ghost",
    category: "Blogs",
    health: 52,
    code: "ghost",
    languages: ["JavaScript", "Shell", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "2dcfd89a-41f4-483c-9720-8ce8c6851d20",
    isApproved: false,
    activeProjects: 9,
    projects: 45,
    description: "A simple message board for your organization or project",
    readme:
      "Overview\n\nBeam is an simple tool from the folks at PlanetScale to write posts to share across an organization. Think of it like a lightweight internal blog. \n\nHighlights\n\nMarkdown-based editor with preview\nImage drag and drop\nComments and likes\nSearch\nResponsive layout with dark mode support\nAdmin role for hiding posts\n\nLearn More\n\nIntroducing Beam\nGitHub",
    name: "Beam",
    category: "Blogs",
    health: 0,
    code: "beam",
    languages: ["TypeScript", "Shell", "JavaScript", "CSS"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4fe50f05-1f90-424e-b6a2-a200c3ac8d4a",
    isApproved: false,
    activeProjects: 107,
    projects: 179,
    description: "A Telegram RSS bot that cares about your reading experience",
    readme:
      "Note: This is the latest dev version, which is always up-to-date. GitHub repository: https://github.com/Rongronggg9/RSS-to-Telegram-Bot\n\nPreparation\n\nTurn to @BotFather, send /newbot create a new bot, then get its token (env variable: TOKEN). After that, send /setinline, select your bot, and reply with an inline placeholder you like to enable inline mode for your bot. For example, @RSStT_Bot is using Please input a command to continue....\nTurn to @userinfobot to get your user ID (env variable: MANAGER).\nGet Telegraph API access tokens (env variable: TELEGRAPH_TOKEN). Refresh the page every time you get a new token. If you have a lot of subscriptions, make sure to get at least 5 tokens.\n\nFor more details, refer to the deployment guide.",
    name: "RSS to Telegram Bot (dev)",
    category: "Bots",
    health: 100,
    code: "1_Wcri",
    languages: ["Python", "Dockerfile", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "4a04c444-5596-487b-a7e1-c8b429d9ff4f",
    isApproved: false,
    activeProjects: 147,
    projects: 258,
    description: "A Telegram RSS bot that cares about your reading experience",
    readme:
      "Note: This is the latest stable version, which may be outdated. It is recommended to deploy the dev version.\nGitHub repository: https://github.com/Rongronggg9/RSS-to-Telegram-Bot\n\nPreparation\n\nTurn to @BotFather, send /newbot create a new bot, then get its token (env variable: TOKEN). After that, send /setinline, select your bot, and reply with an inline placeholder you like to enable inline mode for your bot. For example, @RSStT_Bot is using Please input a command to continue....\nTurn to @userinfobot to get your user ID (env variable: MANAGER).\nGet Telegraph API access tokens (env variable: TELEGRAPH_TOKEN). Refresh the page every time you get a new token. If you have a lot of subscriptions, make sure to get at least 5 tokens.\n\nFor more details, refer to the deployment guide.",
    name: "RSS to Telegram Bot (master)",
    category: "Bots",
    health: 100,
    code: "UojxgA",
    languages: ["Python", "Dockerfile", "Procfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "a612fb3a-d905-4b78-819b-423ca9a107d6",
    isApproved: false,
    activeProjects: 82,
    projects: 197,
    description: "A simple job queue service",
    readme:
      "Overview\n\nQuirrel makes job queues simple as cake, enabling features like delayed execution, and cron scheduling.\n\nHighlights\n\nFirst-class support selected frameworks NextJS and Blitz\nEnd-to-end encryption\nOpen source codebase\n\nLearn More\n\nView the official Quirrel website.",
    name: "Quirrel",
    category: "Queues",
    health: 100,
    code: "quirrel",
    languages: ["Dockerfile"],
    tags: null,
  },
  {
    __typename: "Template",
    id: "e02734a9-12cc-452d-a5e1-d810da04675a",
    isApproved: false,
    activeProjects: 0,
    projects: 1,
    description: "A template for testing things",
    readme:
      "A very good description. A very good description. A very good description. A very good description. A very good description. A very good description. A very good description. A very good description. A very good description. A very good description. A very good description.",
    name: "my awesome template",
    category: "Other",
    health: null,
    code: "QmwYS5",
    languages: [],
    tags: null,
  },
];
